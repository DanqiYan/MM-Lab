{
  "os": "Linux-4.18.0-553.16.1.el8_10.x86_64-x86_64-with-glibc2.28",
  "python": "3.10.14",
  "startedAt": "2024-09-21T04:30:08.895998Z",
  "args": [
    "--local_rank=7",
    "--deepspeed",
    "/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json",
    "--data_path",
    "/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json",
    "--image_folder",
    "/home/atuin/b211dd/b211dd20/dataset",
    "--is_multimodal",
    "True",
    "--conv_version",
    "phi",
    "--model_name_or_path",
    "microsoft/phi-2",
    "--vision_tower",
    "google/siglip-so400m-patch14-384",
    "--vision_tower2",
    "",
    "--connector_type",
    "mlp2x_gelu",
    "--mm_vision_select_layer",
    "-2",
    "--image_aspect_ratio",
    "square",
    "--attn_implementation",
    "flash_attention_2",
    "--fp16",
    "True",
    "--training_recipe",
    "common",
    "--tune_type_llm",
    "full",
    "--tune_type_vision_tower",
    "frozen",
    "--tune_vision_tower_from_layer",
    "0",
    "--tune_type_connector",
    "full",
    "--group_by_modality_length",
    "True",
    "--pretrained_model_path",
    "/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain",
    "--output_dir",
    "/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full",
    "--num_train_epochs",
    "1",
    "--per_device_train_batch_size",
    "4",
    "--per_device_eval_batch_size",
    "4",
    "--gradient_accumulation_steps",
    "4",
    "--evaluation_strategy",
    "no",
    "--save_strategy",
    "steps",
    "--save_steps",
    "50000",
    "--save_total_limit",
    "1",
    "--learning_rate",
    "2e-5",
    "--weight_decay",
    "0.",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "1",
    "--tf32",
    "False",
    "--model_max_length",
    "3072",
    "--gradient_checkpointing",
    "True",
    "--dataloader_num_workers",
    "8",
    "--lazy_preprocess",
    "True",
    "--report_to",
    "wandb",
    "--tokenizer_use_fast",
    "False",
    "--run_name",
    "tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full"
  ],
  "program": "/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py",
  "codePath": "tinyllava/train/train.py",
  "root": "/home/hpc/b211dd/b211dd20/compression/tinyllava_framework",
  "host": "a0703.nhr.fau.de",
  "username": "b211dd20",
  "executable": "/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10",
  "codePathLocal": "tinyllava/train/train.py",
  "cpu_count": 128,
  "cpu_count_logical": 128,
  "gpu": "[NVIDIA A100-SXM4-40GB, NVIDIA A100-SXM4-40GB, NVIDIA A100-SXM4-40GB, NVIDIA A100-SXM4-40GB, NVIDIA A100-SXM4-40GB, NVIDIA A100-SXM4-40GB, NVIDIA A100-SXM4-40GB, NVIDIA A100-SXM4-40GB]",
  "gpu_count": 8,
  "disk": {
    "/": {
      "total": "951006986240",
      "used": "12366487552"
    }
  },
  "memory": {
    "total": "1082030284800"
  },
  "cpu": {
    "count": 128,
    "countLogical": 128
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA A100-SXM4-40GB",
      "memoryTotal": "42949672960",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-40GB",
      "memoryTotal": "42949672960",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-40GB",
      "memoryTotal": "42949672960",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-40GB",
      "memoryTotal": "42949672960",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-40GB",
      "memoryTotal": "42949672960",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-40GB",
      "memoryTotal": "42949672960",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-40GB",
      "memoryTotal": "42949672960",
      "cudaCores": 6912,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA A100-SXM4-40GB",
      "memoryTotal": "42949672960",
      "cudaCores": 6912,
      "architecture": "Ampere"
    }
  ],
  "slurm": {
    "cluster_name": "alex",
    "conf": "/var/tmp/slurmd_spool/conf-cache/slurm.conf",
    "cpus_on_node": "128",
    "export_env": "NONE",
    "get_user_env": "1",
    "gpus_on_node": "8",
    "gtids": "0",
    "job_account": "b211dd",
    "job_cpus_per_node": "128",
    "job_end_time": "1726979367",
    "job_gid": "80175",
    "job_gpus": "0,1,2,3,4,5,6,7",
    "job_id": "2061818",
    "job_name": "finetune_phi_new",
    "job_nodelist": "a0703",
    "job_num_nodes": "1",
    "job_partition": "a100",
    "job_qos": "normal",
    "job_start_time": "1726892967",
    "job_uid": "211974",
    "job_user": "b211dd20",
    "jobid": "2061818",
    "localid": "0",
    "mem_per_cpu": "7500",
    "nnodes": "1",
    "nodeid": "0",
    "nodelist": "a0703",
    "nprocs": "1",
    "ntasks": "1",
    "prio_process": "0",
    "procid": "0",
    "script_context": "prolog_task",
    "submit_dir": "/home/hpc/b211dd/b211dd20/compression/tinyllava_framework",
    "submit_host": "alex1.nhr.fau.de",
    "task_pid": "2074884",
    "tasks_per_node": "1",
    "topology_addr": "a0703",
    "topology_addr_pattern": "node"
  },
  "cudaVersion": "12.6"
}