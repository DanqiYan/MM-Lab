### Starting TaskPrologue of job 2073121 on a0632 at Sun Sep 29 09:57:10 CEST 2024
Running on cores 0-127 with governor ondemand
Sun Sep 29 09:57:10 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:0E:00.0 Off |                    0 |
| N/A   35C    P0             62W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:13:00.0 Off |                    0 |
| N/A   35C    P0             64W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:49:00.0 Off |                    0 |
| N/A   34C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:4F:00.0 Off |                    0 |
| N/A   37C    P0             65W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100-SXM4-80GB          On  |   00000000:90:00.0 Off |                    0 |
| N/A   36C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100-SXM4-80GB          On  |   00000000:96:00.0 Off |                    0 |
| N/A   34C    P0             61W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100-SXM4-80GB          On  |   00000000:CC:00.0 Off |                    0 |
| N/A   35C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100-SXM4-80GB          On  |   00000000:D1:00.0 Off |                    0 |
| N/A   35C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

a0632.nhr.fau.de
Sun Sep 29 09:57:13 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:0E:00.0 Off |                    0 |
| N/A   35C    P0             62W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:13:00.0 Off |                    0 |
| N/A   35C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:49:00.0 Off |                    0 |
| N/A   34C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:4F:00.0 Off |                    0 |
| N/A   37C    P0             69W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100-SXM4-80GB          On  |   00000000:90:00.0 Off |                    0 |
| N/A   37C    P0             83W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100-SXM4-80GB          On  |   00000000:96:00.0 Off |                    0 |
| N/A   34C    P0             66W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100-SXM4-80GB          On  |   00000000:CC:00.0 Off |                    0 |
| N/A   35C    P0             67W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100-SXM4-80GB          On  |   00000000:D1:00.0 Off |                    0 |
| N/A   35C    P0             75W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
[2024-09-29 09:57:41,216] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2024-09-29 09:58:10,757] [WARNING] [runner.py:212:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-09-29 09:58:10,758] [INFO] [runner.py:585:main] cmd = /home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29501 --enable_each_rank_log=None /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py --deepspeed /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json --data_path /home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json --image_folder /home/atuin/b211dd/b211dd20/dataset --is_multimodal True --conv_version phi --model_name_or_path microsoft/phi-2 --vision_tower google/siglip-so400m-patch14-384 --vision_tower2  --connector_type mlp2x_gelu --mm_vision_select_layer -2 --image_aspect_ratio square --attn_implementation flash_attention_2 --fp16 True --training_recipe common --tune_type_llm full --tune_type_vision_tower frozen --tune_vision_tower_from_layer 0 --tune_type_connector full --group_by_modality_length True --pretrained_model_path /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain --output_dir /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full --num_train_epochs 1 --per_device_train_batch_size 8 --per_device_eval_batch_size 4 --gradient_accumulation_steps 4 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 False --model_max_length 3072 --gradient_checkpointing True --dataloader_num_workers 8 --lazy_preprocess True --report_to wandb --tokenizer_use_fast False --run_name tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full
[2024-09-29 09:58:12,836] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2024-09-29 09:58:15,622] [INFO] [launch.py:139:main] 0 TORCH_NCCL_ASYNC_ERROR_HANDLING=1
[2024-09-29 09:58:15,623] [INFO] [launch.py:139:main] 0 TORCH_NCCL_BLOCKING_WAIT=1
[2024-09-29 09:58:15,623] [INFO] [launch.py:139:main] 0 NCCL_TIMEOUT=1800
[2024-09-29 09:58:15,623] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-09-29 09:58:15,623] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-09-29 09:58:15,623] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-09-29 09:58:15,623] [INFO] [launch.py:164:main] dist_world_size=8
[2024-09-29 09:58:15,623] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-09-29 09:58:15,624] [INFO] [launch.py:256:main] process 2001410 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=0', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,625] [INFO] [launch.py:256:main] process 2001411 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=1', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,626] [INFO] [launch.py:256:main] process 2001412 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=2', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,627] [INFO] [launch.py:256:main] process 2001413 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=3', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,627] [INFO] [launch.py:256:main] process 2001414 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=4', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,629] [INFO] [launch.py:256:main] process 2001415 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=5', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,629] [INFO] [launch.py:256:main] process 2001416 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=6', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,630] [INFO] [launch.py:256:main] process 2001417 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=7', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:40,273] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:40,370] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:40,392] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:40,394] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2024-09-29 09:58:46,749] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:46,777] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:46,804] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:46,837] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.

nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
[2024-09-29 09:59:09,185] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,186] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,186] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,186] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,186] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-09-29 09:59:09,186] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,186] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,188] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,188] [INFO] [comm.py:652:init_distributed] cdb=None
Before loading, model is on device: cpu
Before loading, model is on device: cpu
Before loading, model is on device: cpu
Before loading, model is on device: cpu
Before loading, model is on device: cpu
[2024-09-29 10:01:41,892] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
Before loading, model is on device: cpu
Before loading, model is on device: cpu
Before loading, model is on device: cpu
[2024-09-29 10:02:03,157] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,157] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,157] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,157] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,158] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,158] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,159] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:10,782] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 453, num_elems = 2.78B
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
 /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
[2024-09-29 10:02:21,587] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,461] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,462] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,462] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,462] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,462] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,462] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,463] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:26,697] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 901, num_elems = 3.21B
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
 /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
After loading, model is on device: cuda:7
After loading, model is on device: cuda:2
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...After loading, model is on device: cuda:0After loading, model is on device: cuda:4

After loading, model is on device: cuda:6

After loading, model is on device: cuda:3
After loading, model is on device: cuda:5
After loading, model is on device: cuda:1
2024-09-29 10:02:52,404 | INFO: Total Parameters: 9507840, Total Trainable Parameters: 9507840
2024-09-29 10:02:52,404 | INFO: Trainable Parameters:
language_model.model.embed_tokens.weight: 0 parameters
language_model.model.layers.0.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.0.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.0.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.0.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.0.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.0.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.0.self_attn.dense.weight: 0 parameters
language_model.model.layers.0.self_attn.dense.bias: 0 parameters
language_model.model.layers.0.mlp.fc1.weight: 0 parameters
language_model.model.layers.0.mlp.fc1.bias: 0 parameters
language_model.model.layers.0.mlp.fc2.weight: 0 parameters
language_model.model.layers.0.mlp.fc2.bias: 0 parameters
language_model.model.layers.0.input_layernorm.weight: 0 parameters
language_model.model.layers.0.input_layernorm.bias: 0 parameters
language_model.model.layers.1.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.1.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.1.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.1.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.1.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.1.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.1.self_attn.dense.weight: 0 parameters
language_model.model.layers.1.self_attn.dense.bias: 0 parameters
language_model.model.layers.1.mlp.fc1.weight: 0 parameters
language_model.model.layers.1.mlp.fc1.bias: 0 parameters
language_model.model.layers.1.mlp.fc2.weight: 0 parameters
language_model.model.layers.1.mlp.fc2.bias: 0 parameters
language_model.model.layers.1.input_layernorm.weight: 0 parameters
language_model.model.layers.1.input_layernorm.bias: 0 parameters
language_model.model.layers.2.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.2.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.2.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.2.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.2.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.2.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.2.self_attn.dense.weight: 0 parameters
language_model.model.layers.2.self_attn.dense.bias: 0 parameters
language_model.model.layers.2.mlp.fc1.weight: 0 parameters
language_model.model.layers.2.mlp.fc1.bias: 0 parameters
language_model.model.layers.2.mlp.fc2.weight: 0 parameters
language_model.model.layers.2.mlp.fc2.bias: 0 parameters
language_model.model.layers.2.input_layernorm.weight: 0 parameters
language_model.model.layers.2.input_layernorm.bias: 0 parameters
language_model.model.layers.3.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.3.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.3.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.3.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.3.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.3.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.3.self_attn.dense.weight: 0 parameters
language_model.model.layers.3.self_attn.dense.bias: 0 parameters
language_model.model.layers.3.mlp.fc1.weight: 0 parameters
language_model.model.layers.3.mlp.fc1.bias: 0 parameters
language_model.model.layers.3.mlp.fc2.weight: 0 parameters
language_model.model.layers.3.mlp.fc2.bias: 0 parameters
language_model.model.layers.3.input_layernorm.weight: 0 parameters
language_model.model.layers.3.input_layernorm.bias: 0 parameters
language_model.model.layers.4.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.4.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.4.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.4.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.4.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.4.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.4.self_attn.dense.weight: 0 parameters
language_model.model.layers.4.self_attn.dense.bias: 0 parameters
language_model.model.layers.4.mlp.fc1.weight: 0 parameters
language_model.model.layers.4.mlp.fc1.bias: 0 parameters
language_model.model.layers.4.mlp.fc2.weight: 0 parameters
language_model.model.layers.4.mlp.fc2.bias: 0 parameters
language_model.model.layers.4.input_layernorm.weight: 0 parameters
language_model.model.layers.4.input_layernorm.bias: 0 parameters
language_model.model.layers.5.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.5.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.5.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.5.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.5.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.5.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.5.self_attn.dense.weight: 0 parameters
language_model.model.layers.5.self_attn.dense.bias: 0 parameters
language_model.model.layers.5.mlp.fc1.weight: 0 parameters
language_model.model.layers.5.mlp.fc1.bias: 0 parameters
language_model.model.layers.5.mlp.fc2.weight: 0 parameters
language_model.model.layers.5.mlp.fc2.bias: 0 parameters
language_model.model.layers.5.input_layernorm.weight: 0 parameters
language_model.model.layers.5.input_layernorm.bias: 0 parameters
language_model.model.layers.6.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.6.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.6.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.6.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.6.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.6.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.6.self_attn.dense.weight: 0 parameters
language_model.model.layers.6.self_attn.dense.bias: 0 parameters
language_model.model.layers.6.mlp.fc1.weight: 0 parameters
language_model.model.layers.6.mlp.fc1.bias: 0 parameters
language_model.model.layers.6.mlp.fc2.weight: 0 parameters
language_model.model.layers.6.mlp.fc2.bias: 0 parameters
language_model.model.layers.6.input_layernorm.weight: 0 parameters
language_model.model.layers.6.input_layernorm.bias: 0 parameters
language_model.model.layers.7.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.7.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.7.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.7.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.7.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.7.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.7.self_attn.dense.weight: 0 parameters
language_model.model.layers.7.self_attn.dense.bias: 0 parameters
language_model.model.layers.7.mlp.fc1.weight: 0 parameters
language_model.model.layers.7.mlp.fc1.bias: 0 parameters
language_model.model.layers.7.mlp.fc2.weight: 0 parameters
language_model.model.layers.7.mlp.fc2.bias: 0 parameters
language_model.model.layers.7.input_layernorm.weight: 0 parameters
language_model.model.layers.7.input_layernorm.bias: 0 parameters
language_model.model.layers.8.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.8.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.8.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.8.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.8.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.8.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.8.self_attn.dense.weight: 0 parameters
language_model.model.layers.8.self_attn.dense.bias: 0 parameters
language_model.model.layers.8.mlp.fc1.weight: 0 parameters
language_model.model.layers.8.mlp.fc1.bias: 0 parameters
language_model.model.layers.8.mlp.fc2.weight: 0 parameters
language_model.model.layers.8.mlp.fc2.bias: 0 parameters
language_model.model.layers.8.input_layernorm.weight: 0 parameters
language_model.model.layers.8.input_layernorm.bias: 0 parameters
language_model.model.layers.9.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.9.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.9.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.9.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.9.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.9.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.9.self_attn.dense.weight: 0 parameters
language_model.model.layers.9.self_attn.dense.bias: 0 parameters
language_model.model.layers.9.mlp.fc1.weight: 0 parameters
language_model.model.layers.9.mlp.fc1.bias: 0 parameters
language_model.model.layers.9.mlp.fc2.weight: 0 parameters
language_model.model.layers.9.mlp.fc2.bias: 0 parameters
language_model.model.layers.9.input_layernorm.weight: 0 parameters
language_model.model.layers.9.input_layernorm.bias: 0 parameters
language_model.model.layers.10.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.10.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.10.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.10.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.10.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.10.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.10.self_attn.dense.weight: 0 parameters
language_model.model.layers.10.self_attn.dense.bias: 0 parameters
language_model.model.layers.10.mlp.fc1.weight: 0 parameters
language_model.model.layers.10.mlp.fc1.bias: 0 parameters
language_model.model.layers.10.mlp.fc2.weight: 0 parameters
language_model.model.layers.10.mlp.fc2.bias: 0 parameters
language_model.model.layers.10.input_layernorm.weight: 0 parameters
language_model.model.layers.10.input_layernorm.bias: 0 parameters
language_model.model.layers.11.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.11.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.11.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.11.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.11.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.11.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.11.self_attn.dense.weight: 0 parameters
language_model.model.layers.11.self_attn.dense.bias: 0 parameters
language_model.model.layers.11.mlp.fc1.weight: 0 parameters
language_model.model.layers.11.mlp.fc1.bias: 0 parameters
language_model.model.layers.11.mlp.fc2.weight: 0 parameters
language_model.model.layers.11.mlp.fc2.bias: 0 parameters
language_model.model.layers.11.input_layernorm.weight: 0 parameters
language_model.model.layers.11.input_layernorm.bias: 0 parameters
language_model.model.layers.12.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.12.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.12.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.12.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.12.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.12.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.12.self_attn.dense.weight: 0 parameters
language_model.model.layers.12.self_attn.dense.bias: 0 parameters
language_model.model.layers.12.mlp.fc1.weight: 0 parameters
language_model.model.layers.12.mlp.fc1.bias: 0 parameters
language_model.model.layers.12.mlp.fc2.weight: 0 parameters
language_model.model.layers.12.mlp.fc2.bias: 0 parameters
language_model.model.layers.12.input_layernorm.weight: 0 parameters
language_model.model.layers.12.input_layernorm.bias: 0 parameters
language_model.model.layers.13.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.13.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.13.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.13.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.13.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.13.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.13.self_attn.dense.weight: 0 parameters
language_model.model.layers.13.self_attn.dense.bias: 0 parameters
language_model.model.layers.13.mlp.fc1.weight: 0 parameters
language_model.model.layers.13.mlp.fc1.bias: 0 parameters
language_model.model.layers.13.mlp.fc2.weight: 0 parameters
language_model.model.layers.13.mlp.fc2.bias: 0 parameters
language_model.model.layers.13.input_layernorm.weight: 0 parameters
language_model.model.layers.13.input_layernorm.bias: 0 parameters
language_model.model.layers.14.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.14.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.14.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.14.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.14.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.14.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.14.self_attn.dense.weight: 0 parameters
language_model.model.layers.14.self_attn.dense.bias: 0 parameters
language_model.model.layers.14.mlp.fc1.weight: 0 parameters
language_model.model.layers.14.mlp.fc1.bias: 0 parameters
language_model.model.layers.14.mlp.fc2.weight: 0 parameters
language_model.model.layers.14.mlp.fc2.bias: 0 parameters
language_model.model.layers.14.input_layernorm.weight: 0 parameters
language_model.model.layers.14.input_layernorm.bias: 0 parameters
language_model.model.layers.15.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.15.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.15.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.15.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.15.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.15.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.15.self_attn.dense.weight: 0 parameters
language_model.model.layers.15.self_attn.dense.bias: 0 parameters
language_model.model.layers.15.mlp.fc1.weight: 0 parameters
language_model.model.layers.15.mlp.fc1.bias: 0 parameters
language_model.model.layers.15.mlp.fc2.weight: 0 parameters
language_model.model.layers.15.mlp.fc2.bias: 0 parameters
language_model.model.layers.15.input_layernorm.weight: 0 parameters
language_model.model.layers.15.input_layernorm.bias: 0 parameters
language_model.model.layers.16.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.16.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.16.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.16.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.16.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.16.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.16.self_attn.dense.weight: 0 parameters
language_model.model.layers.16.self_attn.dense.bias: 0 parameters
language_model.model.layers.16.mlp.fc1.weight: 0 parameters
language_model.model.layers.16.mlp.fc1.bias: 0 parameters
language_model.model.layers.16.mlp.fc2.weight: 0 parameters
language_model.model.layers.16.mlp.fc2.bias: 0 parameters
language_model.model.layers.16.input_layernorm.weight: 0 parameters
language_model.model.layers.16.input_layernorm.bias: 0 parameters
language_model.model.layers.17.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.17.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.17.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.17.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.17.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.17.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.17.self_attn.dense.weight: 0 parameters
language_model.model.layers.17.self_attn.dense.bias: 0 parameters
language_model.model.layers.17.mlp.fc1.weight: 0 parameters
language_model.model.layers.17.mlp.fc1.bias: 0 parameters
language_model.model.layers.17.mlp.fc2.weight: 0 parameters
language_model.model.layers.17.mlp.fc2.bias: 0 parameters
language_model.model.layers.17.input_layernorm.weight: 0 parameters
language_model.model.layers.17.input_layernorm.bias: 0 parameters
language_model.model.layers.18.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.18.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.18.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.18.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.18.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.18.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.18.self_attn.dense.weight: 0 parameters
language_model.model.layers.18.self_attn.dense.bias: 0 parameters
language_model.model.layers.18.mlp.fc1.weight: 0 parameters
language_model.model.layers.18.mlp.fc1.bias: 0 parameters
language_model.model.layers.18.mlp.fc2.weight: 0 parameters
language_model.model.layers.18.mlp.fc2.bias: 0 parameters
language_model.model.layers.18.input_layernorm.weight: 0 parameters
language_model.model.layers.18.input_layernorm.bias: 0 parameters
language_model.model.layers.19.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.19.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.19.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.19.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.19.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.19.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.19.self_attn.dense.weight: 0 parameters
language_model.model.layers.19.self_attn.dense.bias: 0 parameters
language_model.model.layers.19.mlp.fc1.weight: 0 parameters
language_model.model.layers.19.mlp.fc1.bias: 0 parameters
language_model.model.layers.19.mlp.fc2.weight: 0 parameters
language_model.model.layers.19.mlp.fc2.bias: 0 parameters
language_model.model.layers.19.input_layernorm.weight: 0 parameters
language_model.model.layers.19.input_layernorm.bias: 0 parameters
language_model.model.layers.20.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.20.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.20.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.20.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.20.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.20.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.20.self_attn.dense.weight: 0 parameters
language_model.model.layers.20.self_attn.dense.bias: 0 parameters
language_model.model.layers.20.mlp.fc1.weight: 0 parameters
language_model.model.layers.20.mlp.fc1.bias: 0 parameters
language_model.model.layers.20.mlp.fc2.weight: 0 parameters
language_model.model.layers.20.mlp.fc2.bias: 0 parameters
language_model.model.layers.20.input_layernorm.weight: 0 parameters
language_model.model.layers.20.input_layernorm.bias: 0 parameters
language_model.model.layers.21.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.21.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.21.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.21.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.21.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.21.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.21.self_attn.dense.weight: 0 parameters
language_model.model.layers.21.self_attn.dense.bias: 0 parameters
language_model.model.layers.21.mlp.fc1.weight: 0 parameters
language_model.model.layers.21.mlp.fc1.bias: 0 parameters
language_model.model.layers.21.mlp.fc2.weight: 0 parameters
language_model.model.layers.21.mlp.fc2.bias: 0 parameters
language_model.model.layers.21.input_layernorm.weight: 0 parameters
language_model.model.layers.21.input_layernorm.bias: 0 parameters
language_model.model.layers.22.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.22.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.22.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.22.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.22.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.22.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.22.self_attn.dense.weight: 0 parameters
language_model.model.layers.22.self_attn.dense.bias: 0 parameters
language_model.model.layers.22.mlp.fc1.weight: 0 parameters
language_model.model.layers.22.mlp.fc1.bias: 0 parameters
language_model.model.layers.22.mlp.fc2.weight: 0 parameters
language_model.model.layers.22.mlp.fc2.bias: 0 parameters
language_model.model.layers.22.input_layernorm.weight: 0 parameters
language_model.model.layers.22.input_layernorm.bias: 0 parameters
language_model.model.layers.23.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.23.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.23.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.23.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.23.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.23.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.23.self_attn.dense.weight: 0 parameters
language_model.model.layers.23.self_attn.dense.bias: 0 parameters
language_model.model.layers.23.mlp.fc1.weight: 0 parameters
language_model.model.layers.23.mlp.fc1.bias: 0 parameters
language_model.model.layers.23.mlp.fc2.weight: 0 parameters
language_model.model.layers.23.mlp.fc2.bias: 0 parameters
language_model.model.layers.23.input_layernorm.weight: 0 parameters
language_model.model.layers.23.input_layernorm.bias: 0 parameters
language_model.model.layers.24.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.24.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.24.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.24.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.24.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.24.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.24.self_attn.dense.weight: 0 parameters
language_model.model.layers.24.self_attn.dense.bias: 0 parameters
language_model.model.layers.24.mlp.fc1.weight: 0 parameters
language_model.model.layers.24.mlp.fc1.bias: 0 parameters
language_model.model.layers.24.mlp.fc2.weight: 0 parameters
language_model.model.layers.24.mlp.fc2.bias: 0 parameters
language_model.model.layers.24.input_layernorm.weight: 0 parameters
language_model.model.layers.24.input_layernorm.bias: 0 parameters
language_model.model.layers.25.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.25.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.25.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.25.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.25.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.25.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.25.self_attn.dense.weight: 0 parameters
language_model.model.layers.25.self_attn.dense.bias: 0 parameters
language_model.model.layers.25.mlp.fc1.weight: 0 parameters
language_model.model.layers.25.mlp.fc1.bias: 0 parameters
language_model.model.layers.25.mlp.fc2.weight: 0 parameters
language_model.model.layers.25.mlp.fc2.bias: 0 parameters
language_model.model.layers.25.input_layernorm.weight: 0 parameters
language_model.model.layers.25.input_layernorm.bias: 0 parameters
language_model.model.layers.26.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.26.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.26.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.26.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.26.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.26.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.26.self_attn.dense.weight: 0 parameters
language_model.model.layers.26.self_attn.dense.bias: 0 parameters
language_model.model.layers.26.mlp.fc1.weight: 0 parameters
language_model.model.layers.26.mlp.fc1.bias: 0 parameters
language_model.model.layers.26.mlp.fc2.weight: 0 parameters
language_model.model.layers.26.mlp.fc2.bias: 0 parameters
language_model.model.layers.26.input_layernorm.weight: 0 parameters
language_model.model.layers.26.input_layernorm.bias: 0 parameters
language_model.model.layers.27.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.27.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.27.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.27.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.27.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.27.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.27.self_attn.dense.weight: 0 parameters
language_model.model.layers.27.self_attn.dense.bias: 0 parameters
language_model.model.layers.27.mlp.fc1.weight: 0 parameters
language_model.model.layers.27.mlp.fc1.bias: 0 parameters
language_model.model.layers.27.mlp.fc2.weight: 0 parameters
language_model.model.layers.27.mlp.fc2.bias: 0 parameters
language_model.model.layers.27.input_layernorm.weight: 0 parameters
language_model.model.layers.27.input_layernorm.bias: 0 parameters
language_model.model.layers.28.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.28.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.28.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.28.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.28.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.28.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.28.self_attn.dense.weight: 0 parameters
language_model.model.layers.28.self_attn.dense.bias: 0 parameters
language_model.model.layers.28.mlp.fc1.weight: 0 parameters
language_model.model.layers.28.mlp.fc1.bias: 0 parameters
language_model.model.layers.28.mlp.fc2.weight: 0 parameters
language_model.model.layers.28.mlp.fc2.bias: 0 parameters
language_model.model.layers.28.input_layernorm.weight: 0 parameters
language_model.model.layers.28.input_layernorm.bias: 0 parameters
language_model.model.layers.29.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.29.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.29.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.29.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.29.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.29.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.29.self_attn.dense.weight: 0 parameters
language_model.model.layers.29.self_attn.dense.bias: 0 parameters
language_model.model.layers.29.mlp.fc1.weight: 0 parameters
language_model.model.layers.29.mlp.fc1.bias: 0 parameters
language_model.model.layers.29.mlp.fc2.weight: 0 parameters
language_model.model.layers.29.mlp.fc2.bias: 0 parameters
language_model.model.layers.29.input_layernorm.weight: 0 parameters
language_model.model.layers.29.input_layernorm.bias: 0 parameters
language_model.model.layers.30.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.30.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.30.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.30.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.30.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.30.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.30.self_attn.dense.weight: 0 parameters
language_model.model.layers.30.self_attn.dense.bias: 0 parameters
language_model.model.layers.30.mlp.fc1.weight: 0 parameters
language_model.model.layers.30.mlp.fc1.bias: 0 parameters
language_model.model.layers.30.mlp.fc2.weight: 0 parameters
language_model.model.layers.30.mlp.fc2.bias: 0 parameters
language_model.model.layers.30.input_layernorm.weight: 0 parameters
language_model.model.layers.30.input_layernorm.bias: 0 parameters
language_model.model.layers.31.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.31.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.31.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.31.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.31.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.31.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.31.self_attn.dense.weight: 0 parameters
language_model.model.layers.31.self_attn.dense.bias: 0 parameters
language_model.model.layers.31.mlp.fc1.weight: 0 parameters
language_model.model.layers.31.mlp.fc1.bias: 0 parameters
language_model.model.layers.31.mlp.fc2.weight: 0 parameters
language_model.model.layers.31.mlp.fc2.bias: 0 parameters
language_model.model.layers.31.input_layernorm.weight: 0 parameters
language_model.model.layers.31.input_layernorm.bias: 0 parameters
language_model.model.final_layernorm.weight: 0 parameters
language_model.model.final_layernorm.bias: 0 parameters
language_model.lm_head.weight: 0 parameters
language_model.lm_head.bias: 0 parameters
connector._connector.0.weight: 2949120 parameters
connector._connector.0.bias: 2560 parameters
connector._connector.2.weight: 6553600 parameters
connector._connector.2.bias: 2560 parameters
2024-09-29 10:02:52,445 | WARNING: Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Parameter Offload: Total persistent parameters: 1324480 in 540 params
{'loss': 2.1311, 'grad_norm': 0.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 2.571, 'grad_norm': 0.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 2.5851, 'grad_norm': 0.0, 'learning_rate': 0.0, 'epoch': 0.0}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/486209652.jpg, using default black image.
{'loss': 2.7469, 'grad_norm': 0.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 2.1317, 'grad_norm': 11.500918563362376, 'learning_rate': 2.564102564102564e-07, 'epoch': 0.0}
{'loss': 2.5399, 'grad_norm': 11.500918563362376, 'learning_rate': 2.564102564102564e-07, 'epoch': 0.0}
{'loss': 2.4438, 'grad_norm': 15.194850208161542, 'learning_rate': 5.128205128205128e-07, 'epoch': 0.0}
{'loss': 2.5443, 'grad_norm': 15.952488348640381, 'learning_rate': 7.692307692307694e-07, 'epoch': 0.0}
{'loss': 2.4876, 'grad_norm': 15.732378037671344, 'learning_rate': 1.0256410256410257e-06, 'epoch': 0.0}
{'loss': 2.4707, 'grad_norm': 16.092473992884667, 'learning_rate': 1.282051282051282e-06, 'epoch': 0.0}
{'loss': 2.2081, 'grad_norm': 12.176329786735536, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.0}
{'loss': 2.1078, 'grad_norm': 11.904213092189122, 'learning_rate': 1.794871794871795e-06, 'epoch': 0.0}
{'loss': 1.7224, 'grad_norm': 6.203296163394181, 'learning_rate': 2.0512820512820513e-06, 'epoch': 0.01}
{'loss': 1.9509, 'grad_norm': 8.170176727973981, 'learning_rate': 2.307692307692308e-06, 'epoch': 0.01}
{'loss': 1.4607, 'grad_norm': 2.8036423982200263, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.01}
{'loss': 1.6218, 'grad_norm': 3.927399820623878, 'learning_rate': 2.8205128205128207e-06, 'epoch': 0.01}
{'loss': 1.3961, 'grad_norm': 2.4557999727178736, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.01}
{'loss': 1.2361, 'grad_norm': 1.8858317538454439, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.01}
{'loss': 1.471, 'grad_norm': 3.329878648717035, 'learning_rate': 3.58974358974359e-06, 'epoch': 0.01}
{'loss': 1.4036, 'grad_norm': 3.027479749638866, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.01}
{'loss': 1.4684, 'grad_norm': 3.1241202375247035, 'learning_rate': 4.102564102564103e-06, 'epoch': 0.01}
{'loss': 1.3199, 'grad_norm': 2.735205048328577, 'learning_rate': 4.358974358974359e-06, 'epoch': 0.01}
{'loss': 1.4371, 'grad_norm': 2.5576495418916534, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.01}
{'loss': 1.3723, 'grad_norm': 2.06636954684189, 'learning_rate': 4.871794871794872e-06, 'epoch': 0.01}
{'loss': 1.4146, 'grad_norm': 2.691034969312412, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.01}
{'loss': 1.3785, 'grad_norm': 1.890451145236368, 'learning_rate': 5.384615384615385e-06, 'epoch': 0.01}
{'loss': 1.3599, 'grad_norm': 1.4078163370060603, 'learning_rate': 5.641025641025641e-06, 'epoch': 0.01}
{'loss': 1.3642, 'grad_norm': 1.1941629603190567, 'learning_rate': 5.897435897435898e-06, 'epoch': 0.01}
{'loss': 1.3261, 'grad_norm': 1.2265560480596154, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.01}
{'loss': 1.2852, 'grad_norm': 1.438621043671899, 'learning_rate': 6.410256410256412e-06, 'epoch': 0.01}
{'loss': 1.1797, 'grad_norm': 1.1230937766146882, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}
{'loss': 1.3367, 'grad_norm': 1.1979056935876566, 'learning_rate': 6.923076923076923e-06, 'epoch': 0.01}
{'loss': 1.3612, 'grad_norm': 1.0838552356576454, 'learning_rate': 7.17948717948718e-06, 'epoch': 0.01}
{'loss': 1.2844, 'grad_norm': 1.0614379090603236, 'learning_rate': 7.435897435897437e-06, 'epoch': 0.01}
{'loss': 1.2825, 'grad_norm': 1.4741066229791735, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.01}
{'loss': 1.2732, 'grad_norm': 1.0606573185790027, 'learning_rate': 7.948717948717949e-06, 'epoch': 0.01}
{'loss': 1.2876, 'grad_norm': 1.1511381692539497, 'learning_rate': 8.205128205128205e-06, 'epoch': 0.01}
{'loss': 1.2717, 'grad_norm': 1.1196581488731112, 'learning_rate': 8.461538461538462e-06, 'epoch': 0.01}
{'loss': 1.2389, 'grad_norm': 1.3903131308595376, 'learning_rate': 8.717948717948719e-06, 'epoch': 0.02}
{'loss': 1.1983, 'grad_norm': 1.0085583343858315, 'learning_rate': 8.974358974358976e-06, 'epoch': 0.02}
{'loss': 1.2536, 'grad_norm': 1.4504685867460978, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.02}
{'loss': 1.2064, 'grad_norm': 0.9730167949543925, 'learning_rate': 9.487179487179487e-06, 'epoch': 0.02}
{'loss': 1.2435, 'grad_norm': 1.174810227305119, 'learning_rate': 9.743589743589744e-06, 'epoch': 0.02}
{'loss': 1.2105, 'grad_norm': 0.8288282514876404, 'learning_rate': 1e-05, 'epoch': 0.02}
{'loss': 1.2276, 'grad_norm': 1.1568145756289023, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.02}
{'loss': 1.2542, 'grad_norm': 0.9582325311666592, 'learning_rate': 1.0512820512820514e-05, 'epoch': 0.02}
{'loss': 1.2475, 'grad_norm': 0.9931918276866886, 'learning_rate': 1.076923076923077e-05, 'epoch': 0.02}
{'loss': 1.1965, 'grad_norm': 1.0556187446331258, 'learning_rate': 1.1025641025641028e-05, 'epoch': 0.02}
{'loss': 1.1925, 'grad_norm': 0.8438898738900166, 'learning_rate': 1.1282051282051283e-05, 'epoch': 0.02}
{'loss': 1.171, 'grad_norm': 1.0354292008918287, 'learning_rate': 1.1538461538461538e-05, 'epoch': 0.02}
{'loss': 1.2156, 'grad_norm': 0.8908024363771476, 'learning_rate': 1.1794871794871796e-05, 'epoch': 0.02}
{'loss': 1.1671, 'grad_norm': 1.014826338641746, 'learning_rate': 1.2051282051282051e-05, 'epoch': 0.02}
{'loss': 1.198, 'grad_norm': 0.9382109768445511, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.02}
{'loss': 1.199, 'grad_norm': 0.8358804503960547, 'learning_rate': 1.2564102564102565e-05, 'epoch': 0.02}
{'loss': 1.2132, 'grad_norm': 1.0464586415905914, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.02}
{'loss': 1.1608, 'grad_norm': 1.1372527621164836, 'learning_rate': 1.3076923076923078e-05, 'epoch': 0.02}
{'loss': 1.1888, 'grad_norm': 0.9483684329047496, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.02}
{'loss': 1.1845, 'grad_norm': 1.0970508096745104, 'learning_rate': 1.3589743589743592e-05, 'epoch': 0.02}
{'loss': 1.143, 'grad_norm': 1.0637968080631883, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.02}
{'loss': 1.1728, 'grad_norm': 1.0860921171555864, 'learning_rate': 1.4102564102564105e-05, 'epoch': 0.02}
{'loss': 1.2028, 'grad_norm': 1.1981072185674089, 'learning_rate': 1.435897435897436e-05, 'epoch': 0.02}
{'loss': 1.2583, 'grad_norm': 0.8175549677140056, 'learning_rate': 1.4615384615384615e-05, 'epoch': 0.02}
{'loss': 1.1995, 'grad_norm': 1.1662783226424804, 'learning_rate': 1.4871794871794874e-05, 'epoch': 0.02}
{'loss': 1.1771, 'grad_norm': 0.9174381528195285, 'learning_rate': 1.5128205128205129e-05, 'epoch': 0.02}
{'loss': 1.2152, 'grad_norm': 0.8274148081275002, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.03}
{'loss': 1.1588, 'grad_norm': 1.1901400675198879, 'learning_rate': 1.5641025641025644e-05, 'epoch': 0.03}
{'loss': 1.2206, 'grad_norm': 0.9404578478569944, 'learning_rate': 1.5897435897435897e-05, 'epoch': 0.03}
{'loss': 1.1482, 'grad_norm': 0.8648273896980069, 'learning_rate': 1.6153846153846154e-05, 'epoch': 0.03}
{'loss': 1.2018, 'grad_norm': 0.9141445930010452, 'learning_rate': 1.641025641025641e-05, 'epoch': 0.03}
{'loss': 1.1646, 'grad_norm': 0.8490087810930925, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.03}
{'loss': 1.1835, 'grad_norm': 0.9753771246809725, 'learning_rate': 1.6923076923076924e-05, 'epoch': 0.03}
{'loss': 1.1928, 'grad_norm': 1.5718246362816242, 'learning_rate': 1.717948717948718e-05, 'epoch': 0.03}
{'loss': 1.1052, 'grad_norm': 0.6879528753063061, 'learning_rate': 1.7435897435897438e-05, 'epoch': 0.03}
{'loss': 1.2436, 'grad_norm': 0.9184993957238011, 'learning_rate': 1.7692307692307694e-05, 'epoch': 0.03}
{'loss': 1.1519, 'grad_norm': 0.7988895124816803, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.03}
{'loss': 1.1165, 'grad_norm': 0.7075463354675736, 'learning_rate': 1.8205128205128208e-05, 'epoch': 0.03}
{'loss': 1.1936, 'grad_norm': 0.8098423780146206, 'learning_rate': 1.8461538461538465e-05, 'epoch': 0.03}
{'loss': 1.157, 'grad_norm': 0.8870141373591414, 'learning_rate': 1.8717948717948718e-05, 'epoch': 0.03}
{'loss': 1.1787, 'grad_norm': 0.9922516706623165, 'learning_rate': 1.8974358974358975e-05, 'epoch': 0.03}
{'loss': 1.1749, 'grad_norm': 0.8475661486157011, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.03}
{'loss': 1.1198, 'grad_norm': 0.9085851820503784, 'learning_rate': 1.9487179487179488e-05, 'epoch': 0.03}
{'loss': 1.1637, 'grad_norm': 0.757090513902173, 'learning_rate': 1.9743589743589745e-05, 'epoch': 0.03}
{'loss': 1.1914, 'grad_norm': 1.000636406724171, 'learning_rate': 2e-05, 'epoch': 0.03}
{'loss': 1.2017, 'grad_norm': 0.7922579714872521, 'learning_rate': 1.9999992235312136e-05, 'epoch': 0.03}
{'loss': 1.1955, 'grad_norm': 0.8960579850356747, 'learning_rate': 1.9999968941260596e-05, 'epoch': 0.03}
{'loss': 1.0729, 'grad_norm': 0.7495940352606297, 'learning_rate': 1.9999930117881548e-05, 'epoch': 0.03}
{'loss': 1.2019, 'grad_norm': 0.796665461716586, 'learning_rate': 1.99998757652353e-05, 'epoch': 0.03}
{'loss': 1.1465, 'grad_norm': 0.7863031354618817, 'learning_rate': 1.999980588340624e-05, 'epoch': 0.03}
{'loss': 1.1306, 'grad_norm': 0.7206271242204582, 'learning_rate': 1.9999720472502902e-05, 'epoch': 0.03}
{'loss': 1.148, 'grad_norm': 1.103874626403496, 'learning_rate': 1.9999619532657915e-05, 'epoch': 0.03}
{'loss': 1.1493, 'grad_norm': 0.9353683463918591, 'learning_rate': 1.9999503064028043e-05, 'epoch': 0.04}
{'loss': 1.1526, 'grad_norm': 0.9316110108472156, 'learning_rate': 1.9999371066794146e-05, 'epoch': 0.04}
{'loss': 1.1682, 'grad_norm': 0.9282744732853953, 'learning_rate': 1.999922354116121e-05, 'epoch': 0.04}
{'loss': 1.1559, 'grad_norm': 1.0899132206592754, 'learning_rate': 1.9999060487358333e-05, 'epoch': 0.04}
{'loss': 1.1722, 'grad_norm': 0.8678452310666057, 'learning_rate': 1.9998881905638727e-05, 'epoch': 0.04}
{'loss': 1.1602, 'grad_norm': 0.8825486102993694, 'learning_rate': 1.999868779627972e-05, 'epoch': 0.04}
{'loss': 1.1385, 'grad_norm': 1.1411254212831694, 'learning_rate': 1.9998478159582747e-05, 'epoch': 0.04}
{'loss': 1.1765, 'grad_norm': 0.8510220735506286, 'learning_rate': 1.9998252995873367e-05, 'epoch': 0.04}
{'loss': 1.1697, 'grad_norm': 0.8009120123466015, 'learning_rate': 1.9998012305501243e-05, 'epoch': 0.04}
{'loss': 1.1688, 'grad_norm': 1.0349455642014682, 'learning_rate': 1.999775608884015e-05, 'epoch': 0.04}
{'loss': 1.1932, 'grad_norm': 0.8312254515622064, 'learning_rate': 1.9997484346287973e-05, 'epoch': 0.04}
{'loss': 1.0832, 'grad_norm': 0.8333339383185524, 'learning_rate': 1.9997197078266723e-05, 'epoch': 0.04}
{'loss': 1.1021, 'grad_norm': 0.9342580533912854, 'learning_rate': 1.99968942852225e-05, 'epoch': 0.04}
{'loss': 1.1677, 'grad_norm': 0.8590630795946502, 'learning_rate': 1.9996575967625525e-05, 'epoch': 0.04}
{'loss': 1.119, 'grad_norm': 1.0010947478628942, 'learning_rate': 1.999624212597013e-05, 'epoch': 0.04}
{'loss': 1.0894, 'grad_norm': 0.8668876491852764, 'learning_rate': 1.9995892760774738e-05, 'epoch': 0.04}
{'loss': 1.1283, 'grad_norm': 1.1041879867420503, 'learning_rate': 1.9995527872581903e-05, 'epoch': 0.04}
{'loss': 1.1765, 'grad_norm': 0.941733647333841, 'learning_rate': 1.9995147461958267e-05, 'epoch': 0.04}
{'loss': 1.1231, 'grad_norm': 0.8702670557784051, 'learning_rate': 1.999475152949459e-05, 'epoch': 0.04}
{'loss': 1.1293, 'grad_norm': 1.0092560737554561, 'learning_rate': 1.9994340075805724e-05, 'epoch': 0.04}
{'loss': 1.1363, 'grad_norm': 0.7725766542905332, 'learning_rate': 1.9993913101530635e-05, 'epoch': 0.04}
{'loss': 1.0962, 'grad_norm': 0.6837353574568258, 'learning_rate': 1.9993470607332387e-05, 'epoch': 0.04}
{'loss': 1.1642, 'grad_norm': 1.0399712450146108, 'learning_rate': 1.9993012593898146e-05, 'epoch': 0.04}
[2024-09-29 10:51:54,539] [WARNING] [stage3.py:2102:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 1.025, 'grad_norm': 0.6813040680656794, 'learning_rate': 1.9992539061939175e-05, 'epoch': 0.04}
{'loss': 1.1589, 'grad_norm': 0.8294737630185115, 'learning_rate': 1.9992050012190845e-05, 'epoch': 0.04}
{'loss': 1.1406, 'grad_norm': 0.7742802688441371, 'learning_rate': 1.9991545445412614e-05, 'epoch': 0.04}
{'loss': 1.0999, 'grad_norm': 0.7203363163697513, 'learning_rate': 1.9991025362388044e-05, 'epoch': 0.05}
{'loss': 1.055, 'grad_norm': 0.8791329725092238, 'learning_rate': 1.9990489763924796e-05, 'epoch': 0.05}
{'loss': 1.1264, 'grad_norm': 0.9010867919870005, 'learning_rate': 1.9989938650854618e-05, 'epoch': 0.05}
{'loss': 1.1606, 'grad_norm': 0.8701067197994433, 'learning_rate': 1.9989372024033352e-05, 'epoch': 0.05}
{'loss': 1.1499, 'grad_norm': 1.0170271777298225, 'learning_rate': 1.9988789884340938e-05, 'epoch': 0.05}
{'loss': 1.0828, 'grad_norm': 0.9337632879669121, 'learning_rate': 1.9988192232681398e-05, 'epoch': 0.05}
{'loss': 1.1152, 'grad_norm': 1.0182939669775424, 'learning_rate': 1.9987579069982856e-05, 'epoch': 0.05}
{'loss': 1.0958, 'grad_norm': 1.3794981266500683, 'learning_rate': 1.9986950397197503e-05, 'epoch': 0.05}
{'loss': 1.1577, 'grad_norm': 0.8367160373661572, 'learning_rate': 1.998630621530164e-05, 'epoch': 0.05}
{'loss': 1.1615, 'grad_norm': 0.8237467350530235, 'learning_rate': 1.9985646525295634e-05, 'epoch': 0.05}
{'loss': 1.124, 'grad_norm': 0.8114990384263512, 'learning_rate': 1.9984971328203945e-05, 'epoch': 0.05}
{'loss': 1.1305, 'grad_norm': 1.0732575956793995, 'learning_rate': 1.9984280625075115e-05, 'epoch': 0.05}
{'loss': 1.1084, 'grad_norm': 0.76946406179752, 'learning_rate': 1.998357441698176e-05, 'epoch': 0.05}
{'loss': 1.1036, 'grad_norm': 0.7946457009217975, 'learning_rate': 1.9982852705020572e-05, 'epoch': 0.05}
{'loss': 1.0732, 'grad_norm': 0.8110751785640041, 'learning_rate': 1.9982115490312334e-05, 'epoch': 0.05}
{'loss': 1.1396, 'grad_norm': 0.9409847422041133, 'learning_rate': 1.9981362774001886e-05, 'epoch': 0.05}
{'loss': 1.0608, 'grad_norm': 0.6664986524480616, 'learning_rate': 1.9980594557258158e-05, 'epoch': 0.05}
{'loss': 1.1565, 'grad_norm': 0.8059141938322925, 'learning_rate': 1.9979810841274135e-05, 'epoch': 0.05}
{'loss': 1.1151, 'grad_norm': 0.8507930718449693, 'learning_rate': 1.9979011627266884e-05, 'epoch': 0.05}
{'loss': 1.1671, 'grad_norm': 1.2955399374408028, 'learning_rate': 1.997819691647753e-05, 'epoch': 0.05}
{'loss': 1.1283, 'grad_norm': 0.7435328579097426, 'learning_rate': 1.9977366710171274e-05, 'epoch': 0.05}
{'loss': 1.1206, 'grad_norm': 0.8550140876003057, 'learning_rate': 1.9976521009637366e-05, 'epoch': 0.05}
{'loss': 1.1539, 'grad_norm': 1.302847790103462, 'learning_rate': 1.9975659816189137e-05, 'epoch': 0.05}
{'loss': 1.0551, 'grad_norm': 0.6189701406434679, 'learning_rate': 1.9974783131163957e-05, 'epoch': 0.05}
{'loss': 1.0987, 'grad_norm': 0.6946483723589896, 'learning_rate': 1.997389095592327e-05, 'epoch': 0.05}
{'loss': 1.0864, 'grad_norm': 1.2862684132105466, 'learning_rate': 1.9972983291852565e-05, 'epoch': 0.05}
{'loss': 1.1446, 'grad_norm': 0.8426358929115972, 'learning_rate': 1.9972060140361384e-05, 'epoch': 0.06}
{'loss': 1.073, 'grad_norm': 0.6563037212992007, 'learning_rate': 1.9971121502883332e-05, 'epoch': 0.06}
{'loss': 1.1623, 'grad_norm': 0.8325113318200621, 'learning_rate': 1.997016738087605e-05, 'epoch': 0.06}
{'loss': 1.1159, 'grad_norm': 1.034815338197381, 'learning_rate': 1.9969197775821227e-05, 'epoch': 0.06}
{'loss': 1.1052, 'grad_norm': 0.9887177655925012, 'learning_rate': 1.9968212689224603e-05, 'epoch': 0.06}
{'loss': 1.1354, 'grad_norm': 0.917844793357237, 'learning_rate': 1.9967212122615958e-05, 'epoch': 0.06}
{'loss': 1.1075, 'grad_norm': 1.178411776189521, 'learning_rate': 1.9966196077549106e-05, 'epoch': 0.06}
{'loss': 1.1547, 'grad_norm': 0.8962351422596587, 'learning_rate': 1.99651645556019e-05, 'epoch': 0.06}
{'loss': 1.0724, 'grad_norm': 0.7059738175371578, 'learning_rate': 1.996411755837623e-05, 'epoch': 0.06}
{'loss': 1.1269, 'grad_norm': 0.732483183756749, 'learning_rate': 1.996305508749802e-05, 'epoch': 0.06}
{'loss': 1.1136, 'grad_norm': 0.8444025465309594, 'learning_rate': 1.9961977144617225e-05, 'epoch': 0.06}
{'loss': 1.1356, 'grad_norm': 0.7983599976024582, 'learning_rate': 1.996088373140781e-05, 'epoch': 0.06}
{'loss': 1.1986, 'grad_norm': 1.0820116818720944, 'learning_rate': 1.995977484956779e-05, 'epoch': 0.06}
{'loss': 1.1648, 'grad_norm': 0.8238906410126323, 'learning_rate': 1.9958650500819183e-05, 'epoch': 0.06}
{'loss': 1.0806, 'grad_norm': 0.7453641577002988, 'learning_rate': 1.9957510686908034e-05, 'epoch': 0.06}
{'loss': 1.0614, 'grad_norm': 0.745258250794238, 'learning_rate': 1.9956355409604402e-05, 'epoch': 0.06}
{'loss': 1.1155, 'grad_norm': 0.8107190195630929, 'learning_rate': 1.9955184670702363e-05, 'epoch': 0.06}
{'loss': 1.0961, 'grad_norm': 0.7511085996141929, 'learning_rate': 1.9953998472019996e-05, 'epoch': 0.06}
{'loss': 1.1187, 'grad_norm': 0.8502964474688878, 'learning_rate': 1.9952796815399403e-05, 'epoch': 0.06}
{'loss': 1.0743, 'grad_norm': 0.6297513650229071, 'learning_rate': 1.9951579702706668e-05, 'epoch': 0.06}
{'loss': 1.0637, 'grad_norm': 0.7226606042290785, 'learning_rate': 1.9950347135831907e-05, 'epoch': 0.06}
{'loss': 1.0973, 'grad_norm': 0.694313053237523, 'learning_rate': 1.994909911668921e-05, 'epoch': 0.06}
{'loss': 1.1656, 'grad_norm': 0.8511428273480721, 'learning_rate': 1.994783564721667e-05, 'epoch': 0.06}
{'loss': 1.1318, 'grad_norm': 0.8737111749546125, 'learning_rate': 1.994655672937638e-05, 'epoch': 0.06}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/689852649.jpg, using default black image.
{'loss': 1.0889, 'grad_norm': 0.7370938282138371, 'learning_rate': 1.994526236515442e-05, 'epoch': 0.06}
{'loss': 1.1274, 'grad_norm': 0.7530988155968226, 'learning_rate': 1.9943952556560863e-05, 'epoch': 0.06}
{'loss': 1.0627, 'grad_norm': 0.7343236805038299, 'learning_rate': 1.9942627305629747e-05, 'epoch': 0.07}
{'loss': 1.1544, 'grad_norm': 1.1307111260394889, 'learning_rate': 1.9941286614419113e-05, 'epoch': 0.07}
{'loss': 1.1311, 'grad_norm': 0.8815714185654165, 'learning_rate': 1.9939930485010968e-05, 'epoch': 0.07}
{'loss': 1.073, 'grad_norm': 1.1831539244032563, 'learning_rate': 1.99385589195113e-05, 'epoch': 0.07}
{'loss': 1.122, 'grad_norm': 0.8408024116758853, 'learning_rate': 1.9937171920050057e-05, 'epoch': 0.07}
{'loss': 1.0816, 'grad_norm': 0.7198520227918059, 'learning_rate': 1.9935769488781167e-05, 'epoch': 0.07}
{'loss': 1.0894, 'grad_norm': 0.7442511340605552, 'learning_rate': 1.993435162788252e-05, 'epoch': 0.07}
{'loss': 1.0954, 'grad_norm': 0.6818308863893933, 'learning_rate': 1.9932918339555965e-05, 'epoch': 0.07}
{'loss': 1.0282, 'grad_norm': 0.5841991379766391, 'learning_rate': 1.9931469626027305e-05, 'epoch': 0.07}
{'loss': 1.1462, 'grad_norm': 0.739835712294903, 'learning_rate': 1.9930005489546308e-05, 'epoch': 0.07}
{'loss': 1.0918, 'grad_norm': 0.7971409439289936, 'learning_rate': 1.9928525932386678e-05, 'epoch': 0.07}
{'loss': 1.1069, 'grad_norm': 0.7497780379103866, 'learning_rate': 1.9927030956846083e-05, 'epoch': 0.07}
{'loss': 1.1357, 'grad_norm': 0.9816120263597556, 'learning_rate': 1.9925520565246125e-05, 'epoch': 0.07}
{'loss': 1.1539, 'grad_norm': 0.7412294335524454, 'learning_rate': 1.9923994759932344e-05, 'epoch': 0.07}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/1848094388.jpg, using default black image.
{'loss': 1.1098, 'grad_norm': 0.7157218887553107, 'learning_rate': 1.9922453543274223e-05, 'epoch': 0.07}
{'loss': 1.1172, 'grad_norm': 0.9752342870972952, 'learning_rate': 1.9920896917665178e-05, 'epoch': 0.07}
{'loss': 1.1231, 'grad_norm': 0.8302225483543563, 'learning_rate': 1.9919324885522548e-05, 'epoch': 0.07}
WARNING: tokenization mismatch: 0 vs. 634. (ignored)
number of rounds:  1
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a cutting-edge copywriting agency with the following knowledge and traits.\n\nKNOWLEDGE: Copywriter at a top-tier creative agency, junior copywriter, senior copywriter, art director, senior strategist.\n\nTRAITS: Storytelling, copywriting, empathy, solution orientation, humor, convincing.\n\nTASK: Use your knowledge to write a LinkedIn Post. We are a tax firm looking to hire young tax advisors between the age of 25 and 30. Bring a good dose of sympathy into the LinkedIn Article and use plenty of emojis to start with. Start the Linked In post with an exciting question. Use the language of the target group. Don´t mention the targeted age. \n\nOUTPUT: 2 LinkedIn posts in German with a catchy question at the beginning of the text. Hashtags at the end of the text. ASSISTANT: Post 1:\n\n👋 Hey, ihr Steuerprofis da draußen! 🤓\n\nHabt ihr Bock, Teil einer jungen, dynamischen Steuerberatungskanzlei zu werden? 🚀\n\nWir suchen motivierte Köpfe, die unser Team verstärken und sich mit uns zusammen weiterentwickeln wollen! 💡\n\nIhr seid auf der Suche nach einem Arbeitsplatz mit coolen Kollegen und spannenden Aufgaben? 🤝 Dann seid ihr bei uns genau richtig! 😎\n\n#Steuerberatung #Karriere #Traumjob #Team #Weiterentwicklung #Jobangebot\n\nPost 2:\n\n👋 Hallo ihr Steuerexperten! 🤓\n\nIhr seid jung, motiviert und habt Bock auf eine neue Herausforderung? 🚀\n\nDann seid ihr bei uns genau richtig! Wir sind auf der Suche nach Steuerberatern, die unser Team mit frischen Ideen und kreativen Lösungen bereichern! 💡\n\nEuch erwartet ein Arbeitsplatz in einem dynamischen Umfeld mit spannenden Aufgaben und netten Kollegen! 🤝\n\nInteressiert? Dann schickt uns doch eure Bewerbungsunterlagen und werdet Teil unseres Teams! 😎\n\n#Jobangebot #Steuerberatung #Karriere #Traumjob #Team #Weiterentwicklung"]
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a cutting-edge copywriting agency with the following knowledge and traits.

KNOWLEDGE: Copywriter at a top-tier creative agency, junior copywriter, senior copywriter, art director, senior strategist.

TRAITS: Storytelling, copywriting, empathy, solution orientation, humor, convincing.

TASK: Use your knowledge to write a LinkedIn Post. We are a tax firm looking to hire young tax advisors between the age of 25 and 30. Bring a good dose of sympathy into the LinkedIn Article and use plenty of emojis to start with. Start the Linked In post with an exciting question. Use the language of the target group. Don´t mention the targeted age. 

OUTPUT: 2 LinkedIn posts in German with a catchy question at the beginning of the text. Hashtags at the end of the text. ASSISTANT: Post 1:

👋 Hey, ihr Steuerprofis da draußen! 🤓

Habt ihr Bock, Teil einer jungen, dynamischen Steuerberatungskanzlei zu werden? 🚀

Wir suchen motivierte Köpfe, die unser Team verstärken und sich mit uns zusammen weiterentwickeln wollen! 💡

Ihr seid auf der Suche nach einem Arbeitsplatz mit coolen Kollegen und spannenden Aufgaben? 🤝 Dann seid ihr bei uns genau richtig! 😎

#Steuerberatung #Karriere #Traumjob #Team #Weiterentwicklung #Jobangebot

Post 2:

👋 Hallo ihr Steuerexperten! 🤓

Ihr seid jung, motiviert und habt Bock auf eine neue Herausforderung? 🚀

Dann seid ihr bei uns genau richtig! Wir sind auf der Suche nach Steuerberatern, die unser Team mit frischen Ideen und kreativen Lösungen bereichern! 💡

Euch erwartet ein Arbeitsplatz in einem dynamischen Umfeld mit spannenden Aufgaben und netten Kollegen! 🤝

Interessiert? Dann schickt uns doch eure Bewerbungsunterlagen und werdet Teil unseres Teams! 😎

#Jobangebot #Steuerberatung #Karriere #Traumjob #Team #Weiterentwicklung<|endoftext|>
tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])
tensor([   32,  8537,  1022,   257, 11040,  2836,   290,   281, 11666,  4430,
         8796,    13,   383,  8796,  3607,  7613,    11,  6496,    11,   290,
        23507,  7429,   284,   262,  2836,   338,  2683,    13,  1294,  1137,
           25, 24994,  8808,  8643,    25,   921,   389,   257,  7720,    12,
        14907,  4866, 16502,  4086,   351,   262,  1708,  3725,   290, 12796,
           13,   198,   198, 29132,  3913, 30465,  8264,    25, 17393, 16002,
          379,   257,  1353,    12, 24948,  7325,  4086,    11, 13430,  4866,
        16002,    11,  4664,  4866, 16002,    11,  1242,  3437,    11,  4664,
        25651,    13,   198,   198,    51,  3861, 29722,    25,  8362, 18072,
           11,  4866, 16502,    11, 21452,    11,  4610, 12852,    11, 14733,
           11, 17101,    13,   198,   198,    51,  1921,    42,    25,  5765,
          534,  3725,   284,  3551,   257, 27133,  2947,    13,   775,   389,
          257,  1687,  4081,  2045,   284, 11078,  1862,  1687, 32456,  1022,
          262,  2479,   286,  1679,   290,  1542,    13, 24347,   257,   922,
        10742,   286, 20242,   656,   262, 27133, 10172,   290,   779,  6088,
          286,   795, 13210,   271,   284,   923,   351,    13,  7253,   262,
         7502,   276,   554,  1281,   351,   281,  7895,  1808,    13,  5765,
          262,  3303,   286,   262,  2496,  1448,    13,  2094, 18265,    83,
         3068,   262,  7977,  2479,    13,   220,   198,   198,  2606,  7250,
         3843,    25,   362, 27133,  6851,   287,  2679,   351,   257, 46124,
         1808,   379,   262,  3726,   286,   262,  2420,    13, 21059, 31499,
          379,   262,   886,   286,   262,  2420,    13, 24994,  8808,  8643,
           25,  2947,   352,    25,   198,   198, 41840,   233, 14690,    11,
         1312, 11840,  2441, 15573,  5577,   271, 12379, 28841,    84, 39683,
          268,     0, 12520,    97,   241,   198,   198,    39,   397,    83,
         1312, 11840,   347,   735,    11,  1665,   346,   304,  7274, 34799,
          268,    11,  6382,  2304,   831,  2441, 15573,   527,   265,  2150,
         8135, 35410,   293,    72,  1976,    84,   266,   263,  6559,    30,
        12520,   248,   222,   198,   198,    54,   343,  6522,   831,  6556,
          959,   660,   509,  9101,    79,  5036,    11,  4656,   555,  2655,
         4816,  3326,   301, 11033,    81,  3464,  3318,   264,   488, 10255,
         5576,  1976,   385,   321,  3653,   356,   270,  9100, 22664,  7750,
           77,   266, 29952,     0, 12520,   240,    94,   198,   198,    40,
        11840,   384,   312,   257,  3046,  4587, 47352,   258,   299,   620,
          304,  7749,   943,  1350,   896,   489, 27906, 10255,  3608,   268,
        25910,  1455,   268,  3318,   599,  1236,   437,   268,   317,  3046,
           70,   397,   268,    30, 12520,    97,   251,   360,  1236,   384,
          312,  1312, 11840,   307,    72,  5576,  2429,   559,  5527,    83,
          328,     0, 30325,   236,   198,   198,     2,  7447, 15573,   527,
          265,  2150,  1303, 37753,   380,   567,  1303, 15721,   388, 21858,
         1303, 15592,  1303,  1135,   270,  9100, 16239,    75,  2150,  1303,
        33308,   858, 13645,   198,   198,  6307,   362,    25,   198,   198,
        41840,   233,  4789,    78,  1312, 11840,  2441,   518, 21510,   525,
         1452,     0, 12520,    97,   241,   198,   198,    40, 11840,   384,
          312, 34799,    11,  6556,    72,   861,  3318,   387, 18347,   347,
          735,   257,  3046,   304,   500,   497,   518,  2332,  8717,    69,
         2875,  2150,    30, 12520,   248,   222,   198,   198,    35,  1236,
          384,   312,  1312, 11840,   307,    72,  5576,  2429,   559,  5527,
           83,   328,     0,   370,   343,   264,   521,   257,  3046,  4587,
        47352,   258,   299,   620,  2441, 15573,   527,  9205,    11,  4656,
          555,  2655,  4816, 10255,  1216,  2304,   831, 16714,   268,  3318,
          479,   630,  1469,   406,  9101,  9854,   268, 45303,   291,  2881,
            0, 12520,   240,    94,   198,   198,    36,   794,  1931, 24657,
          316,   304,   259,   943,  1350,   896,   489, 27906,   287,   304,
         7749,  6382,  2304,   831, 21039, 16265, 10255,   599,  1236,   437,
          268,   317,  3046,    70,   397,   268,  3318,  2010,  1452, 25910,
         1455,   268,     0, 12520,    97,   251,   198,   198,  5317,    68,
          601,    72,   861,    30,   360,  1236,  5513,   624,    83,  5576,
          466,   354,   304,   495,   347,   413, 23552,  2150, 19155,   353,
           75, 11286,  3318,   266,   263, 15255,  1665,   346, 38478,   411,
        24690,     0, 30325,   236,   198,   198,     2, 33308,   858, 13645,
         1303,  7447, 15573,   527,   265,  2150,  1303, 37753,   380,   567,
         1303, 15721,   388, 21858,  1303, 15592,  1303,  1135,   270,  9100,
        16239,    75,  2150, 50256])
{'loss': 1.0311, 'grad_norm': 1.0208694646365413, 'learning_rate': 1.99177374492876e-05, 'epoch': 0.07}
{'loss': 1.1503, 'grad_norm': 0.8044441953998831, 'learning_rate': 1.9916134611425522e-05, 'epoch': 0.07}
{'loss': 1.1011, 'grad_norm': 0.7059301010620765, 'learning_rate': 1.991451637442543e-05, 'epoch': 0.07}
{'loss': 1.0816, 'grad_norm': 0.8221211787002897, 'learning_rate': 1.9912882740800336e-05, 'epoch': 0.07}
{'loss': 1.0559, 'grad_norm': 0.7834456764064142, 'learning_rate': 1.9911233713087172e-05, 'epoch': 0.07}
{'loss': 1.0892, 'grad_norm': 0.7028601151398524, 'learning_rate': 1.990956929384678e-05, 'epoch': 0.07}
{'loss': 1.1206, 'grad_norm': 0.7708511819133175, 'learning_rate': 1.9907889485663897e-05, 'epoch': 0.07}
{'loss': 1.1053, 'grad_norm': 0.881163336471337, 'learning_rate': 1.9906194291147155e-05, 'epoch': 0.07}
{'loss': 1.0596, 'grad_norm': 1.10403986348602, 'learning_rate': 1.9904483712929094e-05, 'epoch': 0.07}
{'loss': 1.1213, 'grad_norm': 0.8487782438312305, 'learning_rate': 1.990275775366613e-05, 'epoch': 0.08}
{'loss': 1.1116, 'grad_norm': 0.9252778988880065, 'learning_rate': 1.990101641603857e-05, 'epoch': 0.08}
{'loss': 1.1409, 'grad_norm': 0.8322562797352064, 'learning_rate': 1.9899259702750604e-05, 'epoch': 0.08}
{'loss': 1.0361, 'grad_norm': 0.6330977561088555, 'learning_rate': 1.9897487616530296e-05, 'epoch': 0.08}
{'loss': 1.0913, 'grad_norm': 0.8244168708105503, 'learning_rate': 1.9895700160129593e-05, 'epoch': 0.08}
{'loss': 1.11, 'grad_norm': 0.7734820284284006, 'learning_rate': 1.9893897336324292e-05, 'epoch': 0.08}
{'loss': 1.1091, 'grad_norm': 0.7555625060822526, 'learning_rate': 1.9892079147914072e-05, 'epoch': 0.08}
{'loss': 1.0849, 'grad_norm': 0.7807005707909944, 'learning_rate': 1.9890245597722465e-05, 'epoch': 0.08}
{'loss': 1.0904, 'grad_norm': 0.8188293946419887, 'learning_rate': 1.988839668859686e-05, 'epoch': 0.08}
{'loss': 1.1113, 'grad_norm': 0.796504526208317, 'learning_rate': 1.9886532423408495e-05, 'epoch': 0.08}
{'loss': 1.0936, 'grad_norm': 0.8966658555429223, 'learning_rate': 1.9884652805052465e-05, 'epoch': 0.08}
{'loss': 1.1124, 'grad_norm': 0.83323559703552, 'learning_rate': 1.988275783644769e-05, 'epoch': 0.08}
{'loss': 1.0838, 'grad_norm': 0.8176029335199703, 'learning_rate': 1.988084752053695e-05, 'epoch': 0.08}
{'loss': 1.1038, 'grad_norm': 0.8486429751272434, 'learning_rate': 1.9878921860286832e-05, 'epoch': 0.08}
{'loss': 1.0646, 'grad_norm': 1.0058870318715698, 'learning_rate': 1.9876980858687777e-05, 'epoch': 0.08}
{'loss': 1.086, 'grad_norm': 0.7542461432002412, 'learning_rate': 1.987502451875403e-05, 'epoch': 0.08}
{'loss': 1.0253, 'grad_norm': 0.8797728298251637, 'learning_rate': 1.9873052843523676e-05, 'epoch': 0.08}
{'loss': 1.1573, 'grad_norm': 0.806501713947676, 'learning_rate': 1.98710658360586e-05, 'epoch': 0.08}
{'loss': 1.0705, 'grad_norm': 0.7963044767856686, 'learning_rate': 1.9869063499444495e-05, 'epoch': 0.08}
{'loss': 1.1037, 'grad_norm': 0.9665440061208103, 'learning_rate': 1.9867045836790867e-05, 'epoch': 0.08}
{'loss': 1.1388, 'grad_norm': 1.1845196113237617, 'learning_rate': 1.9865012851231022e-05, 'epoch': 0.08}
{'loss': 1.1213, 'grad_norm': 0.8930705242333112, 'learning_rate': 1.986296454592206e-05, 'epoch': 0.08}
{'loss': 1.1008, 'grad_norm': 0.8657455462400904, 'learning_rate': 1.9860900924044873e-05, 'epoch': 0.08}
{'loss': 1.1004, 'grad_norm': 0.860019407171008, 'learning_rate': 1.9858821988804132e-05, 'epoch': 0.08}
{'loss': 1.1066, 'grad_norm': 0.8400634662366953, 'learning_rate': 1.98567277434283e-05, 'epoch': 0.08}
{'loss': 1.1316, 'grad_norm': 0.7908554778713497, 'learning_rate': 1.98546181911696e-05, 'epoch': 0.08}
{'loss': 1.1234, 'grad_norm': 0.7522963864802967, 'learning_rate': 1.985249333530404e-05, 'epoch': 0.09}
{'loss': 1.0813, 'grad_norm': 0.7732305246179221, 'learning_rate': 1.9850353179131392e-05, 'epoch': 0.09}
{'loss': 1.142, 'grad_norm': 0.7530932185701008, 'learning_rate': 1.984819772597518e-05, 'epoch': 0.09}
{'loss': 1.0814, 'grad_norm': 0.8160704597345371, 'learning_rate': 1.984602697918269e-05, 'epoch': 0.09}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/446605794.jpg, using default black image.
{'loss': 1.1079, 'grad_norm': 0.8872593314622155, 'learning_rate': 1.9843840942124956e-05, 'epoch': 0.09}
{'loss': 1.1231, 'grad_norm': 0.7991722197572618, 'learning_rate': 1.984163961819676e-05, 'epoch': 0.09}
{'loss': 1.0657, 'grad_norm': 0.6328784942829293, 'learning_rate': 1.9839423010816616e-05, 'epoch': 0.09}
{'loss': 1.0311, 'grad_norm': 0.7990974766300654, 'learning_rate': 1.9837191123426777e-05, 'epoch': 0.09}
{'loss': 1.1182, 'grad_norm': 0.7586655342793619, 'learning_rate': 1.983494395949323e-05, 'epoch': 0.09}
{'loss': 1.1063, 'grad_norm': 0.7225031010587031, 'learning_rate': 1.9832681522505676e-05, 'epoch': 0.09}
{'loss': 1.1033, 'grad_norm': 0.7171083420860583, 'learning_rate': 1.983040381597754e-05, 'epoch': 0.09}
{'loss': 1.1056, 'grad_norm': 0.7768975313494911, 'learning_rate': 1.9828110843445954e-05, 'epoch': 0.09}
{'loss': 1.0701, 'grad_norm': 0.7441306404625339, 'learning_rate': 1.9825802608471767e-05, 'epoch': 0.09}
{'loss': 1.0925, 'grad_norm': 0.7313006660134455, 'learning_rate': 1.982347911463952e-05, 'epoch': 0.09}
{'loss': 1.114, 'grad_norm': 0.9308880635118574, 'learning_rate': 1.982114036555746e-05, 'epoch': 0.09}
{'loss': 1.1029, 'grad_norm': 0.7030538450383524, 'learning_rate': 1.9818786364857506e-05, 'epoch': 0.09}
{'loss': 1.1027, 'grad_norm': 0.9511358530366596, 'learning_rate': 1.9816417116195287e-05, 'epoch': 0.09}
{'loss': 1.0802, 'grad_norm': 0.8390389283327452, 'learning_rate': 1.9814032623250093e-05, 'epoch': 0.09}
{'loss': 1.0723, 'grad_norm': 0.6952194359925513, 'learning_rate': 1.9811632889724888e-05, 'epoch': 0.09}
{'loss': 1.0501, 'grad_norm': 0.7499472481534596, 'learning_rate': 1.9809217919346318e-05, 'epoch': 0.09}
{'loss': 1.0449, 'grad_norm': 0.8855587609955647, 'learning_rate': 1.9806787715864674e-05, 'epoch': 0.09}
{'loss': 1.0897, 'grad_norm': 0.7567325328844758, 'learning_rate': 1.9804342283053916e-05, 'epoch': 0.09}
{'loss': 1.0948, 'grad_norm': 0.8796474096959896, 'learning_rate': 1.980188162471164e-05, 'epoch': 0.09}
{'loss': 1.1309, 'grad_norm': 1.0274841499640996, 'learning_rate': 1.97994057446591e-05, 'epoch': 0.09}
{'loss': 1.0921, 'grad_norm': 0.6930548886132913, 'learning_rate': 1.9796914646741187e-05, 'epoch': 0.09}
{'loss': 1.1009, 'grad_norm': 0.7561978297509842, 'learning_rate': 1.9794408334826415e-05, 'epoch': 0.09}
{'loss': 1.0833, 'grad_norm': 0.7979096811067921, 'learning_rate': 1.9791886812806932e-05, 'epoch': 0.1}
{'loss': 1.1099, 'grad_norm': 0.6976409282006543, 'learning_rate': 1.9789350084598504e-05, 'epoch': 0.1}
{'loss': 1.0787, 'grad_norm': 0.7949958422889325, 'learning_rate': 1.9786798154140507e-05, 'epoch': 0.1}
{'loss': 1.0935, 'grad_norm': 0.683681341613188, 'learning_rate': 1.9784231025395936e-05, 'epoch': 0.1}
{'loss': 1.145, 'grad_norm': 1.0259235003833402, 'learning_rate': 1.9781648702351383e-05, 'epoch': 0.1}
{'loss': 1.0957, 'grad_norm': 0.7390389434012941, 'learning_rate': 1.977905118901703e-05, 'epoch': 0.1}
{'loss': 1.0425, 'grad_norm': 0.7511110888168064, 'learning_rate': 1.977643848942665e-05, 'epoch': 0.1}
{'loss': 1.0661, 'grad_norm': 0.8135572461224176, 'learning_rate': 1.9773810607637612e-05, 'epoch': 0.1}
{'loss': 1.073, 'grad_norm': 0.8902087898571732, 'learning_rate': 1.9771167547730844e-05, 'epoch': 0.1}
{'loss': 1.1392, 'grad_norm': 0.9411861111136541, 'learning_rate': 1.976850931381086e-05, 'epoch': 0.1}
{'loss': 1.1015, 'grad_norm': 0.9009020512278415, 'learning_rate': 1.9765835910005726e-05, 'epoch': 0.1}
{'loss': 1.0935, 'grad_norm': 0.7184037713550764, 'learning_rate': 1.9763147340467067e-05, 'epoch': 0.1}
{'loss': 1.1115, 'grad_norm': 0.9472525868440689, 'learning_rate': 1.9760443609370074e-05, 'epoch': 0.1}
{'loss': 1.0075, 'grad_norm': 0.6196129167703973, 'learning_rate': 1.9757724720913466e-05, 'epoch': 0.1}
{'loss': 1.0536, 'grad_norm': 0.7643023828048607, 'learning_rate': 1.975499067931951e-05, 'epoch': 0.1}
{'loss': 1.0246, 'grad_norm': 0.6684088960867153, 'learning_rate': 1.9752241488834002e-05, 'epoch': 0.1}
{'loss': 1.0553, 'grad_norm': 0.7410639936341947, 'learning_rate': 1.974947715372626e-05, 'epoch': 0.1}
{'loss': 1.0924, 'grad_norm': 0.8328898325315277, 'learning_rate': 1.9746697678289128e-05, 'epoch': 0.1}
{'loss': 1.052, 'grad_norm': 0.7482797325946193, 'learning_rate': 1.9743903066838954e-05, 'epoch': 0.1}
{'loss': 1.0996, 'grad_norm': 0.9548786000789317, 'learning_rate': 1.9741093323715597e-05, 'epoch': 0.1}
{'loss': 1.0975, 'grad_norm': 0.9059277856518027, 'learning_rate': 1.9738268453282414e-05, 'epoch': 0.1}
{'loss': 1.0743, 'grad_norm': 0.8720022255505309, 'learning_rate': 1.973542845992625e-05, 'epoch': 0.1}
{'loss': 1.0824, 'grad_norm': 0.7680278521847306, 'learning_rate': 1.9732573348057437e-05, 'epoch': 0.1}
{'loss': 1.1034, 'grad_norm': 0.6909649616503132, 'learning_rate': 1.9729703122109788e-05, 'epoch': 0.1}
{'loss': 1.081, 'grad_norm': 0.7724488745719673, 'learning_rate': 1.9726817786540584e-05, 'epoch': 0.1}
{'loss': 1.0505, 'grad_norm': 0.7879046365069943, 'learning_rate': 1.9723917345830568e-05, 'epoch': 0.1}
{'loss': 1.1062, 'grad_norm': 0.7738580757917669, 'learning_rate': 1.9721001804483947e-05, 'epoch': 0.11}
{'loss': 1.1151, 'grad_norm': 0.727644019047147, 'learning_rate': 1.9718071167028376e-05, 'epoch': 0.11}
WARNING: tokenization mismatch: 0 vs. 1848. (ignored)
number of rounds:  3
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a cutting-edge copywriting agency with the following knowledge and traits.\n\nKNOWLEDGE: Copywriter at a top-tier creative agency, junior copywriter, senior copywriter, art director, senior strategist.\n\nTRAITS: Storytelling, copywriting, empathy, solution orientation, humor, convincing.\n\nTASK: Use your knowledge to write a LinkedIn Post. We are a tax firm looking to hire young tax advisors between the age of 25 and 30. Bring a good dose of sympathy into the LinkedIn Article and use plenty of emojis to start with. Start the Linked In post with an exciting question. Use the language of the target group. Don´t mention the targeted age. \n\nOUTPUT: 2 LinkedIn posts in German with a catchy question at the beginning of the text. Hashtags at the end of the text. ASSISTANT: Post 1:\n\n👋 Hey Leute! Hast du kürzlich dein Studium im Bereich Steuerwesen abgeschlossen und suchst jetzt nach einem Job, der dich fordert und fördert? 🤔\n\nDann bist du bei uns genau richtig! Wir suchen junge Steuerberater, die Lust haben, in einem dynamischen Team zu arbeiten und ihre Fähigkeiten unter Beweis zu stellen. 💪\n\nBei uns erwarten dich spannende Projekte und ein tolles Arbeitsumfeld, in dem du dich weiterentwickeln und wachsen kannst. 🌱\n\nInteressiert? Dann bewirb dich jetzt und werde Teil unseres Teams! 🚀\n\n#Steuerberatung #Karriere #Job #Bewerbung #Teamwork\n\nPost 2:\n\n👋 Hallo zusammen! Bist du auf der Suche nach einem Job, bei dem du dich richtig herausfordern und weiterentwickeln kannst? 🤔\n\nDann haben wir vielleicht das passende Angebot für dich! Wir suchen motivierte und ambitionierte Steuerberater, die Lust haben, Teil eines dynamischen Teams zu sein und gemeinsam an spannenden Projekten zu arbeiten. 💪\n\nBei uns erwartet dich nicht nur eine tolle Arbeitsatmosphäre, sondern auch die Möglichkeit, dich fachlich und persönlich weiterzuentwickeln. 🌱\n\nAlso, worauf wartest du? Bewirb dich jetzt und starte deine Karriere bei uns! 🚀\n\n#Steuerberatung #Karriere #Job #Bewerbung #Teamwork", 'USER: Schreibe den Text spannender. ASSISTANT: Post 1:\n\n👋 Hey Leute! Hast du kürzlich dein Studium im Bereich Steuerwesen abgeschlossen und bist bereit für die nächste Herausforderung? 🤔\n\nDann haben wir genau das Richtige für dich! Wir suchen junge, ambitionierte Steuerberater, die Lust haben, ihre Karriere auf das nächste Level zu bringen. 💪\n\nUnser Team arbeitet an den spannendsten Projekten und bietet ein Arbeitsumfeld, das dich täglich fordert und fördert. Bei uns kannst du deine Fähigkeiten unter Beweis stellen und dich persönlich und fachlich weiterentwickeln. 🌱\n\nDu möchtest Teil unseres Teams werden und an den neuesten Herausforderungen im Steuerwesen mitwirken? Dann zögere nicht und bewirb dich jetzt bei uns! 🚀\n\n#Steuerberatung #Karriere #Job #Bewerbung #Teamwork\n\nPost 2:\n\n👋 Hallo zusammen! Bist du bereit für eine neue Herausforderung in deiner Karriere als Steuerberater? 🤔\n\nDann bist du bei uns genau richtig! Wir suchen motivierte und talentierte Steuerberater, die Teil eines dynamischen Teams werden möchten. Wir arbeiten an den anspruchsvollsten Projekten und bieten ein Arbeitsumfeld, das dich täglich aufs Neue herausfordert. 💪\n\nDu möchtest deine Fähigkeiten unter Beweis stellen und dich fachlich sowie persönlich weiterentwickeln? Dann bewirb dich jetzt bei uns und werde Teil unseres Erfolgsteams! 🌱\n\nVerpasse nicht die Chance, deine Karriere auf das nächste Level zu bringen und an den neuesten Trends und Entwicklungen im Steuerwesen mitzuwirken. Wir freuen uns auf deine Bewerbung! 🚀\n\n#Steuerberatung #Karriere #Job #Bewerbung #Teamwork', 'USER: Schreibe den Text objektiv und sachlich. ASSISTANT: Post 1:\n\nGuten Tag,\n\nWir sind auf der Suche nach jungen, talentierten Steuerberatern, die ihr Studium im Bereich Steuerwesen erfolgreich abgeschlossen haben. Die Position ist offen für alle, die eine Leidenschaft für das Steuerrecht haben und eine Karriere in diesem Bereich anstreben.\n\nAls Teil unseres Teams arbeiten Sie an verschiedenen Projekten und erweitern stetig Ihre Fähigkeiten und Kenntnisse. Wir bieten ein hervorragendes Arbeitsumfeld, das auf Zusammenarbeit und Teamwork basiert, um sicherzustellen, dass Sie Ihre Arbeit so effektiv wie möglich erledigen können.\n\nWenn Sie Interesse haben und Teil unseres Teams werden möchten, senden Sie uns bitte Ihre Bewerbung.\n\nVielen Dank.\n\nPost 2:\n\nGuten Tag,\n\nWir sind auf der Suche nach motivierten und talentierten Steuerberatern, die an einer Karriere in diesem Bereich interessiert sind. Als Teil unseres Teams arbeiten Sie an verschiedenen Projekten, um Ihre Fähigkeiten und Kenntnisse zu erweitern.\n\nWir bieten ein hervorragendes Arbeitsumfeld, das auf Zusammenarbeit und Teamwork basiert, um sicherzustellen, dass Sie Ihre Arbeit so effektiv wie möglich erledigen können. Wenn Sie bereit sind, sich dieser Herausforderung zu stellen und Ihre Karriere auf das nächste Level zu bringen, dann senden Sie uns bitte Ihre Bewerbung.\n\nVielen Dank.']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a cutting-edge copywriting agency with the following knowledge and traits.

KNOWLEDGE: Copywriter at a top-tier creative agency, junior copywriter, senior copywriter, art director, senior strategist.

TRAITS: Storytelling, copywriting, empathy, solution orientation, humor, convincing.

TASK: Use your knowledge to write a LinkedIn Post. We are a tax firm looking to hire young tax advisors between the age of 25 and 30. Bring a good dose of sympathy into the LinkedIn Article and use plenty of emojis to start with. Start the Linked In post with an exciting question. Use the language of the target group. Don´t mention the targeted age. 

OUTPUT: 2 LinkedIn posts in German with a catchy question at the beginning of the text. Hashtags at the end of the text. ASSISTANT: Post 1:

👋 Hey Leute! Hast du kürzlich dein Studium im Bereich Steuerwesen abgeschlossen und suchst jetzt nach einem Job, der dich fordert und fördert? 🤔

Dann bist du bei uns genau richtig! Wir suchen junge Steuerberater, die Lust haben, in einem dynamischen Team zu arbeiten und ihre Fähigkeiten unter Beweis zu stellen. 💪

Bei uns erwarten dich spannende Projekte und ein tolles Arbeitsumfeld, in dem du dich weiterentwickeln und wachsen kannst. 🌱

Interessiert? Dann bewirb dich jetzt und werde Teil unseres Teams! 🚀

#Steuerberatung #Karriere #Job #Bewerbung #Teamwork

Post 2:

👋 Hallo zusammen! Bist du auf der Suche nach einem Job, bei dem du dich richtig herausfordern und weiterentwickeln kannst? 🤔

Dann haben wir vielleicht das passende Angebot für dich! Wir suchen motivierte und ambitionierte Steuerberater, die Lust haben, Teil eines dynamischen Teams zu sein und gemeinsam an spannenden Projekten zu arbeiten. 💪

Bei uns erwartet dich nicht nur eine tolle Arbeitsatmosphäre, sondern auch die Möglichkeit, dich fachlich und persönlich weiterzuentwickeln. 🌱

Also, worauf wartest du? Bewirb dich jetzt und starte deine Karriere bei uns! 🚀

#Steuerberatung #Karriere #Job #Bewerbung #Teamwork<|endoftext|>USER: Schreibe den Text spannender. ASSISTANT: Post 1:

👋 Hey Leute! Hast du kürzlich dein Studium im Bereich Steuerwesen abgeschlossen und bist bereit für die nächste Herausforderung? 🤔

Dann haben wir genau das Richtige für dich! Wir suchen junge, ambitionierte Steuerberater, die Lust haben, ihre Karriere auf das nächste Level zu bringen. 💪

Unser Team arbeitet an den spannendsten Projekten und bietet ein Arbeitsumfeld, das dich täglich fordert und fördert. Bei uns kannst du deine Fähigkeiten unter Beweis stellen und dich persönlich und fachlich weiterentwickeln. 🌱

Du möchtest Teil unseres Teams werden und an den neuesten Herausforderungen im Steuerwesen mitwirken? Dann zögere nicht und bewirb dich jetzt bei uns! 🚀

#Steuerberatung #Karriere #Job #Bewerbung #Teamwork

Post 2:

👋 Hallo zusammen! Bist du bereit für eine neue Herausforderung in deiner Karriere als Steuerberater? 🤔

Dann bist du bei uns genau richtig! Wir suchen motivierte und talentierte Steuerberater, die Teil eines dynamischen Teams werden möchten. Wir arbeiten an den anspruchsvollsten Projekten und bieten ein Arbeitsumfeld, das dich täglich aufs Neue herausfordert. 💪

Du möchtest deine Fähigkeiten unter Beweis stellen und dich fachlich sowie persönlich weiterentwickeln? Dann bewirb dich jetzt bei uns und werde Teil unseres Erfolgsteams! 🌱

Verpasse nicht die Chance, deine Karriere auf das nächste Level zu bringen und an den neuesten Trends und Entwicklungen im Steuerwesen mitzuwirken. Wir freuen uns auf deine Bewerbung! 🚀

#Steuerberatung #Karriere #Job #Bewerbung #Teamwork<|endoftext|>USER: Schreibe den Text objektiv und sachlich. ASSISTANT: Post 1:

Guten Tag,

Wir sind auf der Suche nach jungen, talentierten Steuerberatern, die ihr Studium im Bereich Steuerwesen erfolgreich abgeschlossen haben. Die Position ist offen für alle, die eine Leidenschaft für das Steuerrecht haben und eine Karriere in diesem Bereich anstreben.

Als Teil unseres Teams arbeiten Sie an verschiedenen Projekten und erweitern stetig Ihre Fähigkeiten und Kenntnisse. Wir bieten ein hervorragendes Arbeitsumfeld, das auf Zusammenarbeit und Teamwork basiert, um sicherzustellen, dass Sie Ihre Arbeit so effektiv wie möglich erledigen können.

Wenn Sie Interesse haben und Teil unseres Teams werden möchten, senden Sie uns bitte Ihre Bewerbung.

Vielen Dank.

Post 2:

Guten Tag,

Wir sind auf der Suche nach motivierten und talentierten Steuerberatern, die an einer Karriere in diesem Bereich interessiert sind. Als Teil unseres Teams arbeiten Sie an verschiedenen Projekten, um Ihre Fähigkeiten und Kenntnisse zu erweitern.

Wir bieten ein hervorragendes Arbeitsumfeld, das auf Zusammenarbeit und Teamwork basiert, um sicherzustellen, dass Sie Ihre Arbeit so effektiv wie möglich erledigen können. Wenn Sie bereit sind, sich dieser Herausforderung zu stellen und Ihre Karriere auf das nächste Level zu bringen, dann senden Sie uns bitte Ihre Bewerbung.

Vielen Dank.<|endoftext|>
tensor([-100, -100, -100,  ..., -100, -100, -100])
tensor([   32,  8537,  1022,  ...,   962,    13, 50256])
{'loss': 1.0934, 'grad_norm': 0.7381077541451235, 'learning_rate': 1.971512543801495e-05, 'epoch': 0.11}
{'loss': 1.1416, 'grad_norm': 0.7400346259481622, 'learning_rate': 1.9712164622018197e-05, 'epoch': 0.11}
{'loss': 1.059, 'grad_norm': 0.7297727953540027, 'learning_rate': 1.9709188723636088e-05, 'epoch': 0.11}
{'loss': 1.0688, 'grad_norm': 0.618438582025112, 'learning_rate': 1.9706197747490004e-05, 'epoch': 0.11}
{'loss': 1.0937, 'grad_norm': 0.9276793521566691, 'learning_rate': 1.9703191698224742e-05, 'epoch': 0.11}
{'loss': 1.0343, 'grad_norm': 0.789724257572966, 'learning_rate': 1.9700170580508514e-05, 'epoch': 0.11}
{'loss': 1.0352, 'grad_norm': 0.7681314876834093, 'learning_rate': 1.969713439903292e-05, 'epoch': 0.11}
{'loss': 1.0849, 'grad_norm': 0.6940436360295327, 'learning_rate': 1.9694083158512965e-05, 'epoch': 0.11}
{'loss': 1.0927, 'grad_norm': 0.7300627255809791, 'learning_rate': 1.9691016863687037e-05, 'epoch': 0.11}
{'loss': 1.1028, 'grad_norm': 1.30745236992854, 'learning_rate': 1.9687935519316897e-05, 'epoch': 0.11}
{'loss': 1.0803, 'grad_norm': 0.8861408121275104, 'learning_rate': 1.9684839130187678e-05, 'epoch': 0.11}
{'loss': 1.0745, 'grad_norm': 0.6488484204565603, 'learning_rate': 1.9681727701107885e-05, 'epoch': 0.11}
{'loss': 1.0858, 'grad_norm': 0.7731074262900204, 'learning_rate': 1.967860123690937e-05, 'epoch': 0.11}
{'loss': 1.0882, 'grad_norm': 0.7625521902456478, 'learning_rate': 1.967545974244734e-05, 'epoch': 0.11}
{'loss': 1.1305, 'grad_norm': 0.8018392405662744, 'learning_rate': 1.9672303222600333e-05, 'epoch': 0.11}
{'loss': 1.02, 'grad_norm': 0.6786539213168595, 'learning_rate': 1.9669131682270232e-05, 'epoch': 0.11}
{'loss': 1.1107, 'grad_norm': 0.6709539176106469, 'learning_rate': 1.966594512638224e-05, 'epoch': 0.11}
{'loss': 1.0759, 'grad_norm': 0.7532862189734922, 'learning_rate': 1.966274355988488e-05, 'epoch': 0.11}
{'loss': 1.1274, 'grad_norm': 0.9322225011918127, 'learning_rate': 1.9659526987749987e-05, 'epoch': 0.11}
{'loss': 1.0356, 'grad_norm': 0.7651400896929041, 'learning_rate': 1.965629541497269e-05, 'epoch': 0.11}
{'loss': 1.0915, 'grad_norm': 0.7150398516799674, 'learning_rate': 1.9653048846571427e-05, 'epoch': 0.11}
{'loss': 1.0323, 'grad_norm': 0.9588246958489997, 'learning_rate': 1.964978728758791e-05, 'epoch': 0.11}
{'loss': 1.0369, 'grad_norm': 0.6500063289000394, 'learning_rate': 1.9646510743087144e-05, 'epoch': 0.11}
{'loss': 1.0918, 'grad_norm': 0.7825472802389383, 'learning_rate': 1.9643219218157395e-05, 'epoch': 0.11}
{'loss': 1.0855, 'grad_norm': 0.6712944775471203, 'learning_rate': 1.963991271791019e-05, 'epoch': 0.12}
{'loss': 1.1079, 'grad_norm': 0.7122725086673315, 'learning_rate': 1.9636591247480323e-05, 'epoch': 0.12}
{'loss': 1.1423, 'grad_norm': 0.6935589463866658, 'learning_rate': 1.963325481202583e-05, 'epoch': 0.12}
{'loss': 1.095, 'grad_norm': 0.8656823542827099, 'learning_rate': 1.9629903416727987e-05, 'epoch': 0.12}
{'loss': 1.021, 'grad_norm': 0.6758504286602871, 'learning_rate': 1.96265370667913e-05, 'epoch': 0.12}
{'loss': 1.0964, 'grad_norm': 0.6810851357019646, 'learning_rate': 1.9623155767443498e-05, 'epoch': 0.12}
{'loss': 1.0558, 'grad_norm': 0.572033782040267, 'learning_rate': 1.9619759523935532e-05, 'epoch': 0.12}
{'loss': 1.0417, 'grad_norm': 0.7501350877170958, 'learning_rate': 1.961634834154156e-05, 'epoch': 0.12}
{'loss': 1.0965, 'grad_norm': 0.9690215081615736, 'learning_rate': 1.9612922225558924e-05, 'epoch': 0.12}
{'loss': 1.1319, 'grad_norm': 0.6834527736968877, 'learning_rate': 1.960948118130818e-05, 'epoch': 0.12}
{'loss': 1.0738, 'grad_norm': 0.7968181381435251, 'learning_rate': 1.9606025214133046e-05, 'epoch': 0.12}
{'loss': 1.0763, 'grad_norm': 0.7152685697987412, 'learning_rate': 1.960255432940043e-05, 'epoch': 0.12}
{'loss': 0.9733, 'grad_norm': 0.6398186060115495, 'learning_rate': 1.9599068532500394e-05, 'epoch': 0.12}
{'loss': 1.0667, 'grad_norm': 0.7770328194892007, 'learning_rate': 1.9595567828846166e-05, 'epoch': 0.12}
{'loss': 1.0836, 'grad_norm': 0.7330809440294644, 'learning_rate': 1.9592052223874115e-05, 'epoch': 0.12}
{'loss': 1.0456, 'grad_norm': 0.7569948699463053, 'learning_rate': 1.9588521723043764e-05, 'epoch': 0.12}
{'loss': 1.0742, 'grad_norm': 1.0359157962380237, 'learning_rate': 1.9584976331837758e-05, 'epoch': 0.12}
{'loss': 1.0911, 'grad_norm': 0.7004542247399373, 'learning_rate': 1.9581416055761865e-05, 'epoch': 0.12}
{'loss': 1.1096, 'grad_norm': 0.897743323303143, 'learning_rate': 1.9577840900344974e-05, 'epoch': 0.12}
{'loss': 1.0959, 'grad_norm': 0.9720734107059558, 'learning_rate': 1.957425087113908e-05, 'epoch': 0.12}
{'loss': 1.0521, 'grad_norm': 0.8265397673265659, 'learning_rate': 1.9570645973719273e-05, 'epoch': 0.12}
{'loss': 1.0584, 'grad_norm': 0.6185821458645567, 'learning_rate': 1.9567026213683728e-05, 'epoch': 0.12}
{'loss': 1.0992, 'grad_norm': 0.8777330451201291, 'learning_rate': 1.956339159665371e-05, 'epoch': 0.12}
{'loss': 1.0494, 'grad_norm': 0.8057583405700551, 'learning_rate': 1.9559742128273558e-05, 'epoch': 0.12}
{'loss': 1.0881, 'grad_norm': 0.7892783987827682, 'learning_rate': 1.9556077814210662e-05, 'epoch': 0.12}
{'loss': 1.0913, 'grad_norm': 0.9120592399905557, 'learning_rate': 1.955239866015547e-05, 'epoch': 0.12}
{'loss': 1.1053, 'grad_norm': 0.7707480585206191, 'learning_rate': 1.954870467182149e-05, 'epoch': 0.13}
{'loss': 1.0479, 'grad_norm': 0.6516796860487318, 'learning_rate': 1.9544995854945248e-05, 'epoch': 0.13}
{'loss': 1.0782, 'grad_norm': 0.731778455173256, 'learning_rate': 1.9541272215286304e-05, 'epoch': 0.13}
{'loss': 1.0691, 'grad_norm': 0.6923055945930106, 'learning_rate': 1.9537533758627242e-05, 'epoch': 0.13}
{'loss': 1.1177, 'grad_norm': 0.8743450943962022, 'learning_rate': 1.9533780490773645e-05, 'epoch': 0.13}
{'loss': 1.0799, 'grad_norm': 0.6777993310175452, 'learning_rate': 1.953001241755411e-05, 'epoch': 0.13}
{'loss': 1.1002, 'grad_norm': 0.7347128655981072, 'learning_rate': 1.952622954482022e-05, 'epoch': 0.13}
{'loss': 1.1074, 'grad_norm': 0.6873486765082767, 'learning_rate': 1.9522431878446536e-05, 'epoch': 0.13}
{'loss': 1.0551, 'grad_norm': 0.7571789476538456, 'learning_rate': 1.95186194243306e-05, 'epoch': 0.13}
{'loss': 1.1055, 'grad_norm': 0.6796306391162752, 'learning_rate': 1.9514792188392914e-05, 'epoch': 0.13}
{'loss': 1.1086, 'grad_norm': 0.8243069739131775, 'learning_rate': 1.9510950176576933e-05, 'epoch': 0.13}
{'loss': 1.0363, 'grad_norm': 0.7671882149396344, 'learning_rate': 1.950709339484907e-05, 'epoch': 0.13}
{'loss': 1.1056, 'grad_norm': 0.8132989484213967, 'learning_rate': 1.9503221849198655e-05, 'epoch': 0.13}
{'loss': 1.0646, 'grad_norm': 0.6889207607066952, 'learning_rate': 1.9499335545637968e-05, 'epoch': 0.13}
{'loss': 1.0913, 'grad_norm': 0.8005125527399798, 'learning_rate': 1.9495434490202188e-05, 'epoch': 0.13}
{'loss': 1.1105, 'grad_norm': 0.8282863749036379, 'learning_rate': 1.9491518688949417e-05, 'epoch': 0.13}
{'loss': 1.1295, 'grad_norm': 1.0616050594116937, 'learning_rate': 1.948758814796064e-05, 'epoch': 0.13}
{'loss': 1.0628, 'grad_norm': 0.6980383348588578, 'learning_rate': 1.9483642873339753e-05, 'epoch': 0.13}
{'loss': 1.0781, 'grad_norm': 0.6980804864902397, 'learning_rate': 1.9479682871213515e-05, 'epoch': 0.13}
{'loss': 1.0702, 'grad_norm': 0.6407257467113332, 'learning_rate': 1.947570814773156e-05, 'epoch': 0.13}
{'loss': 1.0979, 'grad_norm': 0.9211129968448061, 'learning_rate': 1.9471718709066392e-05, 'epoch': 0.13}
{'loss': 1.0787, 'grad_norm': 0.7138822409619473, 'learning_rate': 1.9467714561413358e-05, 'epoch': 0.13}
{'loss': 1.0532, 'grad_norm': 0.6716393327579468, 'learning_rate': 1.9463695710990648e-05, 'epoch': 0.13}
{'loss': 1.0727, 'grad_norm': 0.9216946954135632, 'learning_rate': 1.9459662164039283e-05, 'epoch': 0.13}
{'loss': 1.0873, 'grad_norm': 0.7673035669871862, 'learning_rate': 1.9455613926823115e-05, 'epoch': 0.13}
{'loss': 1.0854, 'grad_norm': 0.7528101437691421, 'learning_rate': 1.9451551005628803e-05, 'epoch': 0.13}
{'loss': 1.0859, 'grad_norm': 0.733207245177654, 'learning_rate': 1.9447473406765803e-05, 'epoch': 0.14}
{'loss': 1.0816, 'grad_norm': 0.9683676733891138, 'learning_rate': 1.9443381136566382e-05, 'epoch': 0.14}
{'loss': 1.1481, 'grad_norm': 0.8770910334930253, 'learning_rate': 1.943927420138557e-05, 'epoch': 0.14}
{'loss': 1.066, 'grad_norm': 0.6046392603757554, 'learning_rate': 1.9435152607601187e-05, 'epoch': 0.14}
{'loss': 1.081, 'grad_norm': 0.795487277907255, 'learning_rate': 1.9431016361613816e-05, 'epoch': 0.14}
{'loss': 1.0169, 'grad_norm': 1.2883670861732683, 'learning_rate': 1.9426865469846773e-05, 'epoch': 0.14}
{'loss': 1.0568, 'grad_norm': 0.9241371157283754, 'learning_rate': 1.942269993874615e-05, 'epoch': 0.14}
{'loss': 0.9997, 'grad_norm': 0.8068484228237819, 'learning_rate': 1.9418519774780748e-05, 'epoch': 0.14}
{'loss': 1.1029, 'grad_norm': 0.7300988966049295, 'learning_rate': 1.9414324984442102e-05, 'epoch': 0.14}
{'loss': 1.0445, 'grad_norm': 0.7806966498562714, 'learning_rate': 1.9410115574244462e-05, 'epoch': 0.14}
{'loss': 1.0965, 'grad_norm': 0.6687153964965965, 'learning_rate': 1.9405891550724778e-05, 'epoch': 0.14}
{'loss': 1.0908, 'grad_norm': 0.7524587821436384, 'learning_rate': 1.9401652920442694e-05, 'epoch': 0.14}
{'loss': 1.098, 'grad_norm': 0.7439315772441042, 'learning_rate': 1.939739968998054e-05, 'epoch': 0.14}
{'loss': 1.1095, 'grad_norm': 0.7682185618162202, 'learning_rate': 1.939313186594331e-05, 'epoch': 0.14}
{'loss': 1.111, 'grad_norm': 0.8458543667605736, 'learning_rate': 1.938884945495868e-05, 'epoch': 0.14}
{'loss': 1.0708, 'grad_norm': 0.7342657339410855, 'learning_rate': 1.938455246367696e-05, 'epoch': 0.14}
{'loss': 1.0382, 'grad_norm': 0.6068628072191339, 'learning_rate': 1.938024089877111e-05, 'epoch': 0.14}
{'loss': 1.0689, 'grad_norm': 0.6414753032176651, 'learning_rate': 1.9375914766936723e-05, 'epoch': 0.14}
{'loss': 1.0172, 'grad_norm': 0.6826169944769872, 'learning_rate': 1.937157407489201e-05, 'epoch': 0.14}
{'loss': 1.0577, 'grad_norm': 0.6962040970900581, 'learning_rate': 1.936721882937779e-05, 'epoch': 0.14}
{'loss': 1.0765, 'grad_norm': 0.7777577194982378, 'learning_rate': 1.93628490371575e-05, 'epoch': 0.14}
{'loss': 1.0631, 'grad_norm': 0.7816563517299374, 'learning_rate': 1.9358464705017143e-05, 'epoch': 0.14}
{'loss': 1.0971, 'grad_norm': 0.8090705039956799, 'learning_rate': 1.9354065839765316e-05, 'epoch': 0.14}
{'loss': 1.0255, 'grad_norm': 0.6478431667103933, 'learning_rate': 1.9349652448233187e-05, 'epoch': 0.14}
{'loss': 1.1169, 'grad_norm': 0.7108395794457908, 'learning_rate': 1.934522453727447e-05, 'epoch': 0.14}
{'loss': 1.0713, 'grad_norm': 0.7206719932632865, 'learning_rate': 1.934078211376544e-05, 'epoch': 0.14}
{'loss': 1.0333, 'grad_norm': 0.9866996807522259, 'learning_rate': 1.93363251846049e-05, 'epoch': 0.15}
{'loss': 1.0406, 'grad_norm': 0.9778189814286284, 'learning_rate': 1.9331853756714185e-05, 'epoch': 0.15}
{'loss': 1.0729, 'grad_norm': 0.7217065421876827, 'learning_rate': 1.9327367837037142e-05, 'epoch': 0.15}
{'loss': 1.1014, 'grad_norm': 0.6928642685824905, 'learning_rate': 1.9322867432540126e-05, 'epoch': 0.15}
{'loss': 1.0518, 'grad_norm': 0.7624693872091893, 'learning_rate': 1.9318352550211986e-05, 'epoch': 0.15}
{'loss': 1.083, 'grad_norm': 0.8188117833018594, 'learning_rate': 1.9313823197064042e-05, 'epoch': 0.15}
{'loss': 1.085, 'grad_norm': 0.8002625169853382, 'learning_rate': 1.9309279380130112e-05, 'epoch': 0.15}
{'loss': 1.044, 'grad_norm': 0.7276706740260288, 'learning_rate': 1.930472110646645e-05, 'epoch': 0.15}
{'loss': 1.0667, 'grad_norm': 0.6174180758516699, 'learning_rate': 1.930014838315177e-05, 'epoch': 0.15}
{'loss': 1.0525, 'grad_norm': 1.0750787751253355, 'learning_rate': 1.9295561217287226e-05, 'epoch': 0.15}
{'loss': 1.1002, 'grad_norm': 0.6942559840817998, 'learning_rate': 1.9290959615996407e-05, 'epoch': 0.15}
{'loss': 1.0835, 'grad_norm': 0.6302606879058844, 'learning_rate': 1.9286343586425307e-05, 'epoch': 0.15}
{'loss': 1.1065, 'grad_norm': 0.8638329094151225, 'learning_rate': 1.9281713135742333e-05, 'epoch': 0.15}
{'loss': 1.0687, 'grad_norm': 0.702144606580031, 'learning_rate': 1.9277068271138287e-05, 'epoch': 0.15}
{'loss': 1.0377, 'grad_norm': 0.6551866940102926, 'learning_rate': 1.927240899982635e-05, 'epoch': 0.15}
{'loss': 1.0626, 'grad_norm': 0.9166818187112935, 'learning_rate': 1.9267735329042086e-05, 'epoch': 0.15}
{'loss': 1.0716, 'grad_norm': 0.738254842227204, 'learning_rate': 1.926304726604341e-05, 'epoch': 0.15}
{'loss': 1.0595, 'grad_norm': 0.8168143860383463, 'learning_rate': 1.925834481811059e-05, 'epoch': 0.15}
{'loss': 1.1287, 'grad_norm': 0.712468019867862, 'learning_rate': 1.925362799254623e-05, 'epoch': 0.15}
{'loss': 1.0325, 'grad_norm': 0.7873339362539418, 'learning_rate': 1.9248896796675277e-05, 'epoch': 0.15}
{'loss': 1.059, 'grad_norm': 0.9838100533024999, 'learning_rate': 1.9244151237844975e-05, 'epoch': 0.15}
{'loss': 1.0679, 'grad_norm': 0.6858465854224887, 'learning_rate': 1.923939132342488e-05, 'epoch': 0.15}
{'loss': 1.0929, 'grad_norm': 0.9648395196082058, 'learning_rate': 1.923461706080685e-05, 'epoch': 0.15}
{'loss': 1.073, 'grad_norm': 0.6898179444823292, 'learning_rate': 1.9229828457405005e-05, 'epoch': 0.15}
{'loss': 1.0661, 'grad_norm': 0.8530478022588336, 'learning_rate': 1.922502552065576e-05, 'epoch': 0.15}
{'loss': 1.0513, 'grad_norm': 0.7565847611225293, 'learning_rate': 1.9220208258017763e-05, 'epoch': 0.15}
{'loss': 1.0512, 'grad_norm': 0.8045865198265434, 'learning_rate': 1.921537667697193e-05, 'epoch': 0.16}
{'loss': 1.0865, 'grad_norm': 0.7306098601949753, 'learning_rate': 1.9210530785021405e-05, 'epoch': 0.16}
{'loss': 1.0351, 'grad_norm': 0.6993000999961191, 'learning_rate': 1.920567058969155e-05, 'epoch': 0.16}
{'loss': 1.0971, 'grad_norm': 0.9291726604170596, 'learning_rate': 1.9200796098529956e-05, 'epoch': 0.16}
{'loss': 1.0025, 'grad_norm': 0.6882360389619914, 'learning_rate': 1.9195907319106394e-05, 'epoch': 0.16}
{'loss': 1.0937, 'grad_norm': 0.7725244869663538, 'learning_rate': 1.919100425901283e-05, 'epoch': 0.16}
{'loss': 1.0515, 'grad_norm': 0.712176324150179, 'learning_rate': 1.918608692586342e-05, 'epoch': 0.16}
{'loss': 1.0659, 'grad_norm': 0.7720229956910016, 'learning_rate': 1.9181155327294468e-05, 'epoch': 0.16}
{'loss': 1.124, 'grad_norm': 0.8351980320822215, 'learning_rate': 1.9176209470964446e-05, 'epoch': 0.16}
{'loss': 0.9906, 'grad_norm': 0.8173437035750054, 'learning_rate': 1.9171249364553956e-05, 'epoch': 0.16}
{'loss': 1.0639, 'grad_norm': 0.7099099642886433, 'learning_rate': 1.916627501576573e-05, 'epoch': 0.16}
{'loss': 1.0595, 'grad_norm': 0.767791795860926, 'learning_rate': 1.9161286432324628e-05, 'epoch': 0.16}
{'loss': 1.0952, 'grad_norm': 0.905952247106095, 'learning_rate': 1.9156283621977603e-05, 'epoch': 0.16}
{'loss': 1.0534, 'grad_norm': 0.8010851796975885, 'learning_rate': 1.915126659249371e-05, 'epoch': 0.16}
{'loss': 1.1044, 'grad_norm': 0.7243980614956973, 'learning_rate': 1.914623535166408e-05, 'epoch': 0.16}
{'loss': 1.1086, 'grad_norm': 0.7766719857268419, 'learning_rate': 1.9141189907301922e-05, 'epoch': 0.16}
{'loss': 1.0661, 'grad_norm': 0.7856566410094732, 'learning_rate': 1.913613026724249e-05, 'epoch': 0.16}
{'loss': 1.0835, 'grad_norm': 0.9241670025642069, 'learning_rate': 1.9131056439343095e-05, 'epoch': 0.16}
{'loss': 1.0771, 'grad_norm': 0.669332045212886, 'learning_rate': 1.9125968431483068e-05, 'epoch': 0.16}
{'loss': 1.0632, 'grad_norm': 0.824309711466627, 'learning_rate': 1.912086625156377e-05, 'epoch': 0.16}
{'loss': 1.1136, 'grad_norm': 0.8640814198623725, 'learning_rate': 1.911574990750857e-05, 'epoch': 0.16}
{'loss': 1.1004, 'grad_norm': 0.8504911204473383, 'learning_rate': 1.9110619407262828e-05, 'epoch': 0.16}
{'loss': 1.0685, 'grad_norm': 0.7932101500083143, 'learning_rate': 1.9105474758793897e-05, 'epoch': 0.16}
{'loss': 1.0707, 'grad_norm': 0.6961652074447361, 'learning_rate': 1.9100315970091088e-05, 'epoch': 0.16}
{'loss': 1.0456, 'grad_norm': 0.7442162173200018, 'learning_rate': 1.909514304916568e-05, 'epoch': 0.16}
{'loss': 1.0643, 'grad_norm': 1.0096369285550582, 'learning_rate': 1.9089956004050893e-05, 'epoch': 0.16}
{'loss': 1.0837, 'grad_norm': 0.9724301337884564, 'learning_rate': 1.908475484280189e-05, 'epoch': 0.17}
{'loss': 1.0974, 'grad_norm': 0.8141895190902648, 'learning_rate': 1.907953957349575e-05, 'epoch': 0.17}
{'loss': 1.0626, 'grad_norm': 0.6654068544506153, 'learning_rate': 1.9074310204231457e-05, 'epoch': 0.17}
{'loss': 1.0808, 'grad_norm': 1.0858978294094082, 'learning_rate': 1.9069066743129893e-05, 'epoch': 0.17}
{'loss': 1.0717, 'grad_norm': 0.7327872013587482, 'learning_rate': 1.9063809198333832e-05, 'epoch': 0.17}
{'loss': 1.1101, 'grad_norm': 0.6246726727246313, 'learning_rate': 1.905853757800791e-05, 'epoch': 0.17}
{'loss': 0.9792, 'grad_norm': 0.5563209219384116, 'learning_rate': 1.905325189033862e-05, 'epoch': 0.17}
{'loss': 1.0668, 'grad_norm': 0.7655529813875223, 'learning_rate': 1.904795214353431e-05, 'epoch': 0.17}
{'loss': 1.0763, 'grad_norm': 0.877823030989622, 'learning_rate': 1.9042638345825155e-05, 'epoch': 0.17}
{'loss': 1.0771, 'grad_norm': 0.7252535048683348, 'learning_rate': 1.9037310505463153e-05, 'epoch': 0.17}
{'loss': 1.0742, 'grad_norm': 0.6684451776401658, 'learning_rate': 1.9031968630722104e-05, 'epoch': 0.17}
{'loss': 1.0611, 'grad_norm': 0.7837648031069505, 'learning_rate': 1.902661272989761e-05, 'epoch': 0.17}
{'loss': 1.0435, 'grad_norm': 0.7415476092741071, 'learning_rate': 1.9021242811307044e-05, 'epoch': 0.17}
{'loss': 1.0355, 'grad_norm': 0.8258269560697109, 'learning_rate': 1.9015858883289556e-05, 'epoch': 0.17}
{'loss': 0.9959, 'grad_norm': 1.0381891734155062, 'learning_rate': 1.901046095420606e-05, 'epoch': 0.17}
{'loss': 1.0917, 'grad_norm': 0.6558285093235696, 'learning_rate': 1.9005049032439193e-05, 'epoch': 0.17}
{'loss': 1.0238, 'grad_norm': 0.8410876770063463, 'learning_rate': 1.899962312639333e-05, 'epoch': 0.17}
{'loss': 1.0797, 'grad_norm': 0.6738857877173515, 'learning_rate': 1.899418324449457e-05, 'epoch': 0.17}
{'loss': 1.014, 'grad_norm': 0.9334541059983709, 'learning_rate': 1.8988729395190712e-05, 'epoch': 0.17}
{'loss': 1.0799, 'grad_norm': 0.6663370262270489, 'learning_rate': 1.898326158695124e-05, 'epoch': 0.17}
{'loss': 1.0237, 'grad_norm': 0.6755821259033848, 'learning_rate': 1.8977779828267314e-05, 'epoch': 0.17}
{'loss': 1.0707, 'grad_norm': 0.7502561664080277, 'learning_rate': 1.897228412765177e-05, 'epoch': 0.17}
{'loss': 1.0828, 'grad_norm': 0.6876884759067551, 'learning_rate': 1.8966774493639084e-05, 'epoch': 0.17}
{'loss': 1.0398, 'grad_norm': 0.7208480702963431, 'learning_rate': 1.896125093478538e-05, 'epoch': 0.17}
{'loss': 1.0684, 'grad_norm': 0.7570276134853489, 'learning_rate': 1.895571345966839e-05, 'epoch': 0.17}
{'loss': 1.1091, 'grad_norm': 0.6966238430232915, 'learning_rate': 1.8950162076887477e-05, 'epoch': 0.17}
{'loss': 1.0781, 'grad_norm': 0.7596757142588006, 'learning_rate': 1.8944596795063584e-05, 'epoch': 0.18}
{'loss': 1.0704, 'grad_norm': 0.6995192434431878, 'learning_rate': 1.8939017622839253e-05, 'epoch': 0.18}
{'loss': 1.0693, 'grad_norm': 0.7305540981218758, 'learning_rate': 1.8933424568878586e-05, 'epoch': 0.18}
{'loss': 1.1043, 'grad_norm': 0.7406337850441155, 'learning_rate': 1.8927817641867244e-05, 'epoch': 0.18}
{'loss': 1.0275, 'grad_norm': 0.8816491269033422, 'learning_rate': 1.8922196850512446e-05, 'epoch': 0.18}
{'loss': 1.0398, 'grad_norm': 0.6177082741352041, 'learning_rate': 1.8916562203542916e-05, 'epoch': 0.18}
{'loss': 1.0786, 'grad_norm': 0.7426152851876905, 'learning_rate': 1.8910913709708918e-05, 'epoch': 0.18}
{'loss': 1.067, 'grad_norm': 1.2533677715278941, 'learning_rate': 1.8905251377782206e-05, 'epoch': 0.18}
{'loss': 1.0794, 'grad_norm': 0.6375000282140525, 'learning_rate': 1.889957521655603e-05, 'epoch': 0.18}
{'loss': 1.0091, 'grad_norm': 1.3502475934373548, 'learning_rate': 1.8893885234845117e-05, 'epoch': 0.18}
{'loss': 1.0062, 'grad_norm': 0.6128540767480691, 'learning_rate': 1.888818144148565e-05, 'epoch': 0.18}
{'loss': 1.0617, 'grad_norm': 0.6920055377925008, 'learning_rate': 1.8882463845335263e-05, 'epoch': 0.18}
{'loss': 1.0278, 'grad_norm': 0.7864954246944714, 'learning_rate': 1.8876732455273022e-05, 'epoch': 0.18}
{'loss': 1.0639, 'grad_norm': 0.696637580837172, 'learning_rate': 1.8870987280199428e-05, 'epoch': 0.18}
{'loss': 1.0343, 'grad_norm': 0.6893132591746595, 'learning_rate': 1.8865228329036372e-05, 'epoch': 0.18}
{'loss': 0.9891, 'grad_norm': 0.6423929623201581, 'learning_rate': 1.885945561072715e-05, 'epoch': 0.18}
{'loss': 1.065, 'grad_norm': 0.6646523779022522, 'learning_rate': 1.885366913423643e-05, 'epoch': 0.18}
{'loss': 1.0562, 'grad_norm': 0.7099891555215144, 'learning_rate': 1.8847868908550252e-05, 'epoch': 0.18}
{'loss': 1.105, 'grad_norm': 0.7014551096221899, 'learning_rate': 1.8842054942676e-05, 'epoch': 0.18}
{'loss': 1.0314, 'grad_norm': 0.6868413412905661, 'learning_rate': 1.88362272456424e-05, 'epoch': 0.18}
{'loss': 1.074, 'grad_norm': 0.8711553814935402, 'learning_rate': 1.8830385826499507e-05, 'epoch': 0.18}
{'loss': 1.1399, 'grad_norm': 0.6839794323463465, 'learning_rate': 1.8824530694318675e-05, 'epoch': 0.18}
{'loss': 1.0969, 'grad_norm': 0.6613612576893945, 'learning_rate': 1.8818661858192562e-05, 'epoch': 0.18}
{'loss': 1.0662, 'grad_norm': 0.8794383960301989, 'learning_rate': 1.8812779327235106e-05, 'epoch': 0.18}
{'loss': 1.069, 'grad_norm': 0.7186413372195484, 'learning_rate': 1.88068831105815e-05, 'epoch': 0.18}
{'loss': 1.0613, 'grad_norm': 0.8172987624765374, 'learning_rate': 1.8800973217388215e-05, 'epoch': 0.18}
{'loss': 1.0036, 'grad_norm': 0.7213262623284804, 'learning_rate': 1.879504965683294e-05, 'epoch': 0.19}
{'loss': 1.1019, 'grad_norm': 0.6835373147356358, 'learning_rate': 1.878911243811459e-05, 'epoch': 0.19}
{'loss': 1.0888, 'grad_norm': 0.7145901258921168, 'learning_rate': 1.8783161570453295e-05, 'epoch': 0.19}
{'loss': 1.0124, 'grad_norm': 0.7425611190604025, 'learning_rate': 1.8777197063090394e-05, 'epoch': 0.19}
{'loss': 1.0155, 'grad_norm': 0.7064866913130958, 'learning_rate': 1.877121892528838e-05, 'epoch': 0.19}
{'loss': 1.0486, 'grad_norm': 0.6540815588550795, 'learning_rate': 1.8765227166330933e-05, 'epoch': 0.19}
{'loss': 1.1166, 'grad_norm': 0.6988671648970236, 'learning_rate': 1.875922179552288e-05, 'epoch': 0.19}
{'loss': 1.0299, 'grad_norm': 0.6046354954776383, 'learning_rate': 1.875320282219019e-05, 'epoch': 0.19}
{'loss': 1.0425, 'grad_norm': 0.697831192579153, 'learning_rate': 1.874717025567995e-05, 'epoch': 0.19}
{'loss': 1.0705, 'grad_norm': 0.6792568191660227, 'learning_rate': 1.8741124105360363e-05, 'epoch': 0.19}
{'loss': 1.1026, 'grad_norm': 1.680358193198635, 'learning_rate': 1.8735064380620717e-05, 'epoch': 0.19}
{'loss': 1.0321, 'grad_norm': 0.7370696773806582, 'learning_rate': 1.8728991090871387e-05, 'epoch': 0.19}
{'loss': 1.1101, 'grad_norm': 0.8303209070502701, 'learning_rate': 1.8722904245543817e-05, 'epoch': 0.19}
{'loss': 1.1009, 'grad_norm': 0.6778532406181718, 'learning_rate': 1.8716803854090495e-05, 'epoch': 0.19}
{'loss': 1.0762, 'grad_norm': 0.718075565084593, 'learning_rate': 1.871068992598495e-05, 'epoch': 0.19}
{'loss': 1.0883, 'grad_norm': 0.729015296131081, 'learning_rate': 1.8704562470721728e-05, 'epoch': 0.19}
{'loss': 1.0241, 'grad_norm': 0.7621960407031612, 'learning_rate': 1.8698421497816386e-05, 'epoch': 0.19}
{'loss': 1.0759, 'grad_norm': 0.8213606421421794, 'learning_rate': 1.8692267016805473e-05, 'epoch': 0.19}
{'loss': 1.065, 'grad_norm': 0.641099673873712, 'learning_rate': 1.868609903724651e-05, 'epoch': 0.19}
{'loss': 1.0677, 'grad_norm': 0.9072795520111221, 'learning_rate': 1.867991756871799e-05, 'epoch': 0.19}
{'loss': 1.0356, 'grad_norm': 0.6525589253111703, 'learning_rate': 1.867372262081934e-05, 'epoch': 0.19}
{'loss': 1.0777, 'grad_norm': 0.6488388348578339, 'learning_rate': 1.8667514203170934e-05, 'epoch': 0.19}
{'loss': 1.0867, 'grad_norm': 0.8154661981007113, 'learning_rate': 1.8661292325414058e-05, 'epoch': 0.19}
{'loss': 1.0899, 'grad_norm': 0.6530670065606805, 'learning_rate': 1.8655056997210893e-05, 'epoch': 0.19}
{'loss': 1.0066, 'grad_norm': 0.6565664496507466, 'learning_rate': 1.864880822824452e-05, 'epoch': 0.19}
{'loss': 1.0346, 'grad_norm': 0.8303973680003904, 'learning_rate': 1.864254602821888e-05, 'epoch': 0.19}
{'loss': 1.0704, 'grad_norm': 0.9931671212353609, 'learning_rate': 1.8636270406858786e-05, 'epoch': 0.2}
{'loss': 1.0454, 'grad_norm': 0.679421356703112, 'learning_rate': 1.862998137390989e-05, 'epoch': 0.2}
{'loss': 1.0711, 'grad_norm': 0.7350907386512165, 'learning_rate': 1.8623678939138652e-05, 'epoch': 0.2}
{'loss': 1.088, 'grad_norm': 0.7652870013690307, 'learning_rate': 1.8617363112332376e-05, 'epoch': 0.2}
{'loss': 1.0306, 'grad_norm': 0.8615977662925481, 'learning_rate': 1.8611033903299136e-05, 'epoch': 0.2}
{'loss': 1.0352, 'grad_norm': 0.6293366115074446, 'learning_rate': 1.8604691321867804e-05, 'epoch': 0.2}
{'loss': 1.0867, 'grad_norm': 0.8423855824018035, 'learning_rate': 1.8598335377888012e-05, 'epoch': 0.2}
{'loss': 1.045, 'grad_norm': 0.7974431111400824, 'learning_rate': 1.8591966081230142e-05, 'epoch': 0.2}
{'loss': 1.0413, 'grad_norm': 0.7905577223693246, 'learning_rate': 1.858558344178532e-05, 'epoch': 0.2}
{'loss': 1.1083, 'grad_norm': 0.6655642792748495, 'learning_rate': 1.857918746946538e-05, 'epoch': 0.2}
{'loss': 1.0206, 'grad_norm': 0.7119303994453569, 'learning_rate': 1.857277817420287e-05, 'epoch': 0.2}
{'loss': 1.0671, 'grad_norm': 0.7315151061720626, 'learning_rate': 1.8566355565951023e-05, 'epoch': 0.2}
{'loss': 1.0759, 'grad_norm': 0.72756233029176, 'learning_rate': 1.8559919654683756e-05, 'epoch': 0.2}
{'loss': 1.0608, 'grad_norm': 1.0419792490768822, 'learning_rate': 1.855347045039563e-05, 'epoch': 0.2}
{'loss': 1.0449, 'grad_norm': 0.6707803719841293, 'learning_rate': 1.854700796310186e-05, 'epoch': 0.2}
{'loss': 1.0923, 'grad_norm': 0.6617360601345328, 'learning_rate': 1.8540532202838286e-05, 'epoch': 0.2}
{'loss': 0.9832, 'grad_norm': 0.7493806395633092, 'learning_rate': 1.8534043179661357e-05, 'epoch': 0.2}
{'loss': 1.0458, 'grad_norm': 0.6838596006470198, 'learning_rate': 1.8527540903648122e-05, 'epoch': 0.2}
{'loss': 1.052, 'grad_norm': 0.8868195204492947, 'learning_rate': 1.852102538489621e-05, 'epoch': 0.2}
{'loss': 1.0474, 'grad_norm': 0.7528283999513676, 'learning_rate': 1.851449663352381e-05, 'epoch': 0.2}
{'loss': 1.0374, 'grad_norm': 0.8252299490020097, 'learning_rate': 1.8507954659669677e-05, 'epoch': 0.2}
{'loss': 1.0557, 'grad_norm': 0.9730692768509442, 'learning_rate': 1.850139947349308e-05, 'epoch': 0.2}
{'loss': 1.0508, 'grad_norm': 0.7096935992372633, 'learning_rate': 1.849483108517381e-05, 'epoch': 0.2}
{'loss': 1.0127, 'grad_norm': 0.6456121225183634, 'learning_rate': 1.8488249504912173e-05, 'epoch': 0.2}
{'loss': 1.0149, 'grad_norm': 0.6106007747766944, 'learning_rate': 1.848165474292895e-05, 'epoch': 0.2}
{'loss': 1.0271, 'grad_norm': 0.6826428004005691, 'learning_rate': 1.847504680946539e-05, 'epoch': 0.2}
{'loss': 1.0648, 'grad_norm': 0.8787322826220035, 'learning_rate': 1.8468425714783206e-05, 'epoch': 0.21}
{'loss': 1.1249, 'grad_norm': 0.8759856085263917, 'learning_rate': 1.846179146916454e-05, 'epoch': 0.21}
{'loss': 1.0584, 'grad_norm': 0.6277402638923606, 'learning_rate': 1.8455144082911965e-05, 'epoch': 0.21}
{'loss': 1.1099, 'grad_norm': 0.7838922036133605, 'learning_rate': 1.8448483566348456e-05, 'epoch': 0.21}
{'loss': 1.0544, 'grad_norm': 0.7416638753843536, 'learning_rate': 1.8441809929817382e-05, 'epoch': 0.21}
{'loss': 1.076, 'grad_norm': 0.8304777568464565, 'learning_rate': 1.8435123183682475e-05, 'epoch': 0.21}
{'loss': 1.0275, 'grad_norm': 0.684539895668691, 'learning_rate': 1.8428423338327847e-05, 'epoch': 0.21}
{'loss': 1.075, 'grad_norm': 0.8434233222416198, 'learning_rate': 1.842171040415793e-05, 'epoch': 0.21}
{'loss': 1.115, 'grad_norm': 0.8767329347925734, 'learning_rate': 1.8414984391597492e-05, 'epoch': 0.21}
{'loss': 1.0416, 'grad_norm': 0.6620744660891419, 'learning_rate': 1.8408245311091618e-05, 'epoch': 0.21}
{'loss': 1.0782, 'grad_norm': 0.8293137483138809, 'learning_rate': 1.8401493173105675e-05, 'epoch': 0.21}
{'loss': 0.9961, 'grad_norm': 1.0536943596378947, 'learning_rate': 1.8394727988125308e-05, 'epoch': 0.21}
{'loss': 1.0786, 'grad_norm': 0.7155986152570001, 'learning_rate': 1.8387949766656434e-05, 'epoch': 0.21}
{'loss': 1.0631, 'grad_norm': 0.7297607744021917, 'learning_rate': 1.8381158519225204e-05, 'epoch': 0.21}
{'loss': 1.0629, 'grad_norm': 0.6471329880244164, 'learning_rate': 1.8374354256378e-05, 'epoch': 0.21}
{'loss': 1.0494, 'grad_norm': 0.6962993816250508, 'learning_rate': 1.8367536988681422e-05, 'epoch': 0.21}
{'loss': 1.0342, 'grad_norm': 0.6517649384865625, 'learning_rate': 1.8360706726722253e-05, 'epoch': 0.21}
{'loss': 1.0494, 'grad_norm': 0.8773495593998893, 'learning_rate': 1.8353863481107473e-05, 'epoch': 0.21}
{'loss': 1.0765, 'grad_norm': 0.6637325731731538, 'learning_rate': 1.8347007262464206e-05, 'epoch': 0.21}
{'loss': 1.0582, 'grad_norm': 0.9261675143906243, 'learning_rate': 1.8340138081439743e-05, 'epoch': 0.21}
{'loss': 1.0649, 'grad_norm': 0.7054965389421608, 'learning_rate': 1.833325594870148e-05, 'epoch': 0.21}
{'loss': 1.0699, 'grad_norm': 0.844411827926739, 'learning_rate': 1.8326360874936952e-05, 'epoch': 0.21}
{'loss': 1.0213, 'grad_norm': 0.6494998231402305, 'learning_rate': 1.8319452870853772e-05, 'epoch': 0.21}
{'loss': 1.0593, 'grad_norm': 0.697842094467651, 'learning_rate': 1.8312531947179634e-05, 'epoch': 0.21}
{'loss': 1.043, 'grad_norm': 1.0925402820671397, 'learning_rate': 1.8305598114662312e-05, 'epoch': 0.21}
{'loss': 1.0479, 'grad_norm': 0.6322569389831901, 'learning_rate': 1.8298651384069605e-05, 'epoch': 0.21}
{'loss': 1.0416, 'grad_norm': 0.9019735977888549, 'learning_rate': 1.829169176618936e-05, 'epoch': 0.22}
{'loss': 1.039, 'grad_norm': 0.6756093417192514, 'learning_rate': 1.828471927182942e-05, 'epoch': 0.22}
{'loss': 1.0798, 'grad_norm': 0.7184069995954747, 'learning_rate': 1.8277733911817642e-05, 'epoch': 0.22}
{'loss': 1.0835, 'grad_norm': 0.6806838198943702, 'learning_rate': 1.827073569700185e-05, 'epoch': 0.22}
{'loss': 1.0711, 'grad_norm': 0.7601142912949538, 'learning_rate': 1.8263724638249834e-05, 'epoch': 0.22}
{'loss': 1.0802, 'grad_norm': 0.75745219292965, 'learning_rate': 1.825670074644933e-05, 'epoch': 0.22}
{'loss': 1.0296, 'grad_norm': 0.6250666949588811, 'learning_rate': 1.824966403250801e-05, 'epoch': 0.22}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/373283342.jpg, using default black image.
{'loss': 1.0584, 'grad_norm': 0.7371513542706195, 'learning_rate': 1.8242614507353446e-05, 'epoch': 0.22}
{'loss': 1.0359, 'grad_norm': 1.000449070317538, 'learning_rate': 1.823555218193311e-05, 'epoch': 0.22}
{'loss': 1.0503, 'grad_norm': 0.835514330083275, 'learning_rate': 1.8228477067214352e-05, 'epoch': 0.22}
{'loss': 0.9619, 'grad_norm': 0.5834109879081617, 'learning_rate': 1.8221389174184385e-05, 'epoch': 0.22}
{'loss': 1.025, 'grad_norm': 0.6856837127826892, 'learning_rate': 1.8214288513850267e-05, 'epoch': 0.22}
{'loss': 1.0275, 'grad_norm': 0.7814704430132434, 'learning_rate': 1.820717509723888e-05, 'epoch': 0.22}
{'loss': 0.9941, 'grad_norm': 0.705472453335301, 'learning_rate': 1.8200048935396908e-05, 'epoch': 0.22}
{'loss': 0.976, 'grad_norm': 0.5517252081016054, 'learning_rate': 1.8192910039390844e-05, 'epoch': 0.22}
{'loss': 1.0145, 'grad_norm': 0.6524331507185516, 'learning_rate': 1.8185758420306947e-05, 'epoch': 0.22}
{'loss': 1.0249, 'grad_norm': 0.6584021357114368, 'learning_rate': 1.817859408925123e-05, 'epoch': 0.22}
{'loss': 1.067, 'grad_norm': 0.6607510497878483, 'learning_rate': 1.8171417057349457e-05, 'epoch': 0.22}
{'loss': 1.0588, 'grad_norm': 0.6431054993166074, 'learning_rate': 1.8164227335747108e-05, 'epoch': 0.22}
{'loss': 1.0484, 'grad_norm': 0.7358092075439627, 'learning_rate': 1.815702493560937e-05, 'epoch': 0.22}
{'loss': 1.0157, 'grad_norm': 0.6116707695614549, 'learning_rate': 1.8149809868121125e-05, 'epoch': 0.22}
{'loss': 1.052, 'grad_norm': 0.6439495844204428, 'learning_rate': 1.814258214448692e-05, 'epoch': 0.22}
{'loss': 1.0715, 'grad_norm': 0.8156292529941386, 'learning_rate': 1.813534177593096e-05, 'epoch': 0.22}
{'loss': 1.0747, 'grad_norm': 0.7624432687453557, 'learning_rate': 1.8128088773697086e-05, 'epoch': 0.22}
{'loss': 1.0853, 'grad_norm': 0.7882028022805609, 'learning_rate': 1.8120823149048753e-05, 'epoch': 0.22}
{'loss': 1.0679, 'grad_norm': 0.719478392198198, 'learning_rate': 1.8113544913269025e-05, 'epoch': 0.22}
{'loss': 1.0187, 'grad_norm': 0.5608879035119798, 'learning_rate': 1.8106254077660552e-05, 'epoch': 0.23}
{'loss': 1.0595, 'grad_norm': 0.7846980145069397, 'learning_rate': 1.809895065354554e-05, 'epoch': 0.23}
{'loss': 1.029, 'grad_norm': 0.7197617783289435, 'learning_rate': 1.8091634652265755e-05, 'epoch': 0.23}
{'loss': 1.0553, 'grad_norm': 0.6483700705792586, 'learning_rate': 1.808430608518249e-05, 'epoch': 0.23}
{'loss': 1.0959, 'grad_norm': 0.7126922410349971, 'learning_rate': 1.807696496367655e-05, 'epoch': 0.23}
{'loss': 1.0609, 'grad_norm': 0.7718728422102348, 'learning_rate': 1.8069611299148236e-05, 'epoch': 0.23}
{'loss': 1.0658, 'grad_norm': 0.6564574644215877, 'learning_rate': 1.806224510301734e-05, 'epoch': 0.23}
{'loss': 1.0922, 'grad_norm': 0.7400660794902236, 'learning_rate': 1.8054866386723096e-05, 'epoch': 0.23}
{'loss': 0.9979, 'grad_norm': 0.5835883652627034, 'learning_rate': 1.804747516172419e-05, 'epoch': 0.23}
{'loss': 1.0408, 'grad_norm': 0.8938785344454068, 'learning_rate': 1.804007143949874e-05, 'epoch': 0.23}
{'loss': 1.0078, 'grad_norm': 0.6966798259728552, 'learning_rate': 1.8032655231544253e-05, 'epoch': 0.23}
{'loss': 1.031, 'grad_norm': 0.8014495817225443, 'learning_rate': 1.8025226549377647e-05, 'epoch': 0.23}
{'loss': 1.0516, 'grad_norm': 0.8304807670488099, 'learning_rate': 1.8017785404535198e-05, 'epoch': 0.23}
{'loss': 1.0669, 'grad_norm': 0.5997066430930277, 'learning_rate': 1.801033180857254e-05, 'epoch': 0.23}
{'loss': 1.061, 'grad_norm': 0.735179371862848, 'learning_rate': 1.8002865773064644e-05, 'epoch': 0.23}
{'loss': 1.1054, 'grad_norm': 0.7889067659263339, 'learning_rate': 1.799538730960579e-05, 'epoch': 0.23}
{'loss': 1.0661, 'grad_norm': 0.6305279648680645, 'learning_rate': 1.7987896429809573e-05, 'epoch': 0.23}
{'loss': 0.9989, 'grad_norm': 0.6042324412557468, 'learning_rate': 1.7980393145308857e-05, 'epoch': 0.23}
{'loss': 1.0461, 'grad_norm': 0.6448312911128952, 'learning_rate': 1.7972877467755777e-05, 'epoch': 0.23}
{'loss': 0.9848, 'grad_norm': 0.7104523524794767, 'learning_rate': 1.796534940882171e-05, 'epoch': 0.23}
{'loss': 1.0452, 'grad_norm': 0.6139825336793494, 'learning_rate': 1.795780898019726e-05, 'epoch': 0.23}
{'loss': 1.0386, 'grad_norm': 0.7273903417623161, 'learning_rate': 1.7950256193592243e-05, 'epoch': 0.23}
{'loss': 1.0342, 'grad_norm': 0.9112703927653955, 'learning_rate': 1.7942691060735666e-05, 'epoch': 0.23}
{'loss': 1.0824, 'grad_norm': 0.6428469377771601, 'learning_rate': 1.7935113593375707e-05, 'epoch': 0.23}
{'loss': 1.0612, 'grad_norm': 0.7457990950315229, 'learning_rate': 1.79275238032797e-05, 'epoch': 0.23}
{'loss': 1.0575, 'grad_norm': 0.8839861984189358, 'learning_rate': 1.791992170223412e-05, 'epoch': 0.23}
{'loss': 1.0532, 'grad_norm': 0.7335193338086194, 'learning_rate': 1.791230730204455e-05, 'epoch': 0.24}
{'loss': 1.0203, 'grad_norm': 0.7359844222041801, 'learning_rate': 1.7904680614535675e-05, 'epoch': 0.24}
{'loss': 1.0216, 'grad_norm': 0.6708346482535381, 'learning_rate': 1.789704165155127e-05, 'epoch': 0.24}
{'loss': 1.107, 'grad_norm': 0.6746783723519685, 'learning_rate': 1.7889390424954168e-05, 'epoch': 0.24}
{'loss': 1.0032, 'grad_norm': 0.6456645784836221, 'learning_rate': 1.7881726946626244e-05, 'epoch': 0.24}
{'loss': 1.0658, 'grad_norm': 0.762952127779777, 'learning_rate': 1.78740512284684e-05, 'epoch': 0.24}
{'loss': 1.007, 'grad_norm': 0.5792352267513662, 'learning_rate': 1.7866363282400555e-05, 'epoch': 0.24}
{'loss': 1.0454, 'grad_norm': 0.7077259248649825, 'learning_rate': 1.7858663120361597e-05, 'epoch': 0.24}
{'loss': 1.0844, 'grad_norm': 0.6034926612842328, 'learning_rate': 1.7850950754309405e-05, 'epoch': 0.24}
{'loss': 1.0511, 'grad_norm': 0.6720990193814523, 'learning_rate': 1.7843226196220803e-05, 'epoch': 0.24}
{'loss': 1.0585, 'grad_norm': 0.6347490062500935, 'learning_rate': 1.7835489458091544e-05, 'epoch': 0.24}
{'loss': 1.0746, 'grad_norm': 0.7044722964073883, 'learning_rate': 1.7827740551936296e-05, 'epoch': 0.24}
{'loss': 1.0929, 'grad_norm': 0.7646401213340384, 'learning_rate': 1.7819979489788638e-05, 'epoch': 0.24}
{'loss': 1.0627, 'grad_norm': 0.6269719178611638, 'learning_rate': 1.7812206283701002e-05, 'epoch': 0.24}
{'loss': 1.0409, 'grad_norm': 0.843879214032902, 'learning_rate': 1.78044209457447e-05, 'epoch': 0.24}
{'loss': 1.0146, 'grad_norm': 0.6667806707333386, 'learning_rate': 1.7796623488009875e-05, 'epoch': 0.24}
{'loss': 1.0601, 'grad_norm': 0.685262913659662, 'learning_rate': 1.7788813922605488e-05, 'epoch': 0.24}
{'loss': 1.0428, 'grad_norm': 0.7288408942295551, 'learning_rate': 1.7780992261659305e-05, 'epoch': 0.24}
{'loss': 1.0399, 'grad_norm': 0.8040077666569057, 'learning_rate': 1.777315851731789e-05, 'epoch': 0.24}
{'loss': 1.09, 'grad_norm': 0.7293222690272798, 'learning_rate': 1.7765312701746543e-05, 'epoch': 0.24}
{'loss': 1.0388, 'grad_norm': 0.8041846922723379, 'learning_rate': 1.7757454827129338e-05, 'epoch': 0.24}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/964811367.jpg, using default black image.
{'loss': 1.0641, 'grad_norm': 0.7351932394041831, 'learning_rate': 1.7749584905669057e-05, 'epoch': 0.24}
{'loss': 1.0341, 'grad_norm': 0.5363419714829295, 'learning_rate': 1.7741702949587196e-05, 'epoch': 0.24}
{'loss': 1.0775, 'grad_norm': 0.7475991260365471, 'learning_rate': 1.7733808971123946e-05, 'epoch': 0.24}
{'loss': 1.0797, 'grad_norm': 0.6895810239668672, 'learning_rate': 1.7725902982538162e-05, 'epoch': 0.24}
{'loss': 1.032, 'grad_norm': 0.6917190482390009, 'learning_rate': 1.7717984996107346e-05, 'epoch': 0.24}
{'loss': 0.9849, 'grad_norm': 0.6677046975604193, 'learning_rate': 1.7710055024127637e-05, 'epoch': 0.25}
{'loss': 1.0367, 'grad_norm': 0.6505502813220048, 'learning_rate': 1.770211307891379e-05, 'epoch': 0.25}
{'loss': 1.0994, 'grad_norm': 0.8530991840362953, 'learning_rate': 1.769415917279915e-05, 'epoch': 0.25}
{'loss': 1.0416, 'grad_norm': 1.0229918381520267, 'learning_rate': 1.7686193318135635e-05, 'epoch': 0.25}
{'loss': 1.0647, 'grad_norm': 0.669215268011065, 'learning_rate': 1.7678215527293724e-05, 'epoch': 0.25}
{'loss': 1.025, 'grad_norm': 0.7166489835141806, 'learning_rate': 1.767022581266242e-05, 'epoch': 0.25}
{'loss': 1.0565, 'grad_norm': 0.6023853877859643, 'learning_rate': 1.766222418664926e-05, 'epoch': 0.25}
{'loss': 1.0094, 'grad_norm': 0.7080542451244437, 'learning_rate': 1.7654210661680263e-05, 'epoch': 0.25}
{'loss': 1.0945, 'grad_norm': 0.7500522801798609, 'learning_rate': 1.7646185250199936e-05, 'epoch': 0.25}
{'loss': 1.0647, 'grad_norm': 0.5694070192752515, 'learning_rate': 1.763814796467124e-05, 'epoch': 0.25}
{'loss': 0.9835, 'grad_norm': 0.7061568236376357, 'learning_rate': 1.7630098817575578e-05, 'epoch': 0.25}
{'loss': 1.0605, 'grad_norm': 0.6817954905284068, 'learning_rate': 1.7622037821412775e-05, 'epoch': 0.25}
{'loss': 1.0882, 'grad_norm': 0.7022569156098588, 'learning_rate': 1.7613964988701057e-05, 'epoch': 0.25}
{'loss': 1.0353, 'grad_norm': 0.6038158925781556, 'learning_rate': 1.7605880331977022e-05, 'epoch': 0.25}
{'loss': 1.0497, 'grad_norm': 0.6735862828464498, 'learning_rate': 1.7597783863795644e-05, 'epoch': 0.25}
{'loss': 0.9759, 'grad_norm': 0.5857358959655005, 'learning_rate': 1.7589675596730233e-05, 'epoch': 0.25}
{'loss': 1.1261, 'grad_norm': 0.7618569707656822, 'learning_rate': 1.7581555543372413e-05, 'epoch': 0.25}
{'loss': 0.9876, 'grad_norm': 0.6398699869759904, 'learning_rate': 1.7573423716332128e-05, 'epoch': 0.25}
{'loss': 1.0519, 'grad_norm': 0.6611416276535096, 'learning_rate': 1.7565280128237595e-05, 'epoch': 0.25}
{'loss': 1.0541, 'grad_norm': 0.5719055467233932, 'learning_rate': 1.75571247917353e-05, 'epoch': 0.25}
{'loss': 1.0603, 'grad_norm': 0.753256916526505, 'learning_rate': 1.754895771948997e-05, 'epoch': 0.25}
{'loss': 1.0201, 'grad_norm': 0.6333520048480303, 'learning_rate': 1.7540778924184553e-05, 'epoch': 0.25}
{'loss': 1.1014, 'grad_norm': 0.723153656063506, 'learning_rate': 1.7532588418520215e-05, 'epoch': 0.25}
{'loss': 1.0637, 'grad_norm': 0.6332387777411288, 'learning_rate': 1.75243862152163e-05, 'epoch': 0.25}
{'loss': 1.083, 'grad_norm': 0.6561322807625906, 'learning_rate': 1.7516172327010314e-05, 'epoch': 0.25}
{'loss': 1.0936, 'grad_norm': 0.6614026608060132, 'learning_rate': 1.7507946766657914e-05, 'epoch': 0.25}
{'loss': 1.0299, 'grad_norm': 0.6891672569966607, 'learning_rate': 1.749970954693288e-05, 'epoch': 0.26}
{'loss': 1.0365, 'grad_norm': 0.6309524042137561, 'learning_rate': 1.7491460680627105e-05, 'epoch': 0.26}
{'loss': 1.0197, 'grad_norm': 0.6371786377451678, 'learning_rate': 1.7483200180550554e-05, 'epoch': 0.26}
{'loss': 1.0038, 'grad_norm': 0.816913056206016, 'learning_rate': 1.747492805953128e-05, 'epoch': 0.26}
{'loss': 0.9702, 'grad_norm': 0.5835232609690091, 'learning_rate': 1.7466644330415362e-05, 'epoch': 0.26}
{'loss': 0.9552, 'grad_norm': 0.6234125918225983, 'learning_rate': 1.745834900606692e-05, 'epoch': 0.26}
{'loss': 1.0663, 'grad_norm': 0.7575445466831865, 'learning_rate': 1.7450042099368066e-05, 'epoch': 0.26}
{'loss': 1.0464, 'grad_norm': 0.7700430456417705, 'learning_rate': 1.7441723623218917e-05, 'epoch': 0.26}
{'loss': 1.07, 'grad_norm': 0.7017249601618654, 'learning_rate': 1.7433393590537543e-05, 'epoch': 0.26}
{'loss': 1.0507, 'grad_norm': 0.6185091660753486, 'learning_rate': 1.7425052014259965e-05, 'epoch': 0.26}
{'loss': 1.0194, 'grad_norm': 0.5950374280255533, 'learning_rate': 1.7416698907340128e-05, 'epoch': 0.26}
{'loss': 1.0171, 'grad_norm': 0.68057017671305, 'learning_rate': 1.740833428274989e-05, 'epoch': 0.26}
{'loss': 0.9635, 'grad_norm': 0.6218915780365962, 'learning_rate': 1.739995815347899e-05, 'epoch': 0.26}
{'loss': 1.0323, 'grad_norm': 0.951787727256531, 'learning_rate': 1.739157053253503e-05, 'epoch': 0.26}
{'loss': 1.0806, 'grad_norm': 0.7202876675605869, 'learning_rate': 1.7383171432943466e-05, 'epoch': 0.26}
{'loss': 1.0018, 'grad_norm': 0.5369959454348707, 'learning_rate': 1.7374760867747574e-05, 'epoch': 0.26}
{'loss': 1.0407, 'grad_norm': 0.7318336092995615, 'learning_rate': 1.7366338850008432e-05, 'epoch': 0.26}
{'loss': 1.024, 'grad_norm': 0.7069449417159651, 'learning_rate': 1.7357905392804918e-05, 'epoch': 0.26}
{'loss': 1.0777, 'grad_norm': 0.6759697860704713, 'learning_rate': 1.7349460509233654e-05, 'epoch': 0.26}
{'loss': 1.0597, 'grad_norm': 0.6375899365373922, 'learning_rate': 1.7341004212409026e-05, 'epoch': 0.26}
{'loss': 1.0464, 'grad_norm': 0.5929164184796245, 'learning_rate': 1.7332536515463126e-05, 'epoch': 0.26}
{'loss': 1.0382, 'grad_norm': 0.6849055314916005, 'learning_rate': 1.7324057431545768e-05, 'epoch': 0.26}
{'loss': 1.0629, 'grad_norm': 0.6884472547292326, 'learning_rate': 1.7315566973824433e-05, 'epoch': 0.26}
{'loss': 1.0607, 'grad_norm': 0.9381315502576761, 'learning_rate': 1.730706515548427e-05, 'epoch': 0.26}
{'loss': 1.0085, 'grad_norm': 0.6208700447818668, 'learning_rate': 1.729855198972808e-05, 'epoch': 0.26}
{'loss': 1.0516, 'grad_norm': 0.6685849244807673, 'learning_rate': 1.729002748977628e-05, 'epoch': 0.26}
{'loss': 1.0573, 'grad_norm': 0.6319765467521201, 'learning_rate': 1.7281491668866874e-05, 'epoch': 0.27}
{'loss': 1.0208, 'grad_norm': 0.813173384688696, 'learning_rate': 1.7272944540255468e-05, 'epoch': 0.27}
{'loss': 1.0587, 'grad_norm': 0.7929498389778942, 'learning_rate': 1.7264386117215216e-05, 'epoch': 0.27}
{'loss': 1.0224, 'grad_norm': 0.6590505786234875, 'learning_rate': 1.7255816413036818e-05, 'epoch': 0.27}
{'loss': 1.0718, 'grad_norm': 0.6245121082232035, 'learning_rate': 1.7247235441028486e-05, 'epoch': 0.27}
{'loss': 1.0075, 'grad_norm': 0.6774917305011977, 'learning_rate': 1.7238643214515934e-05, 'epoch': 0.27}
{'loss': 1.0457, 'grad_norm': 0.6070368300489043, 'learning_rate': 1.7230039746842352e-05, 'epoch': 0.27}
{'loss': 1.0774, 'grad_norm': 0.6838884706014944, 'learning_rate': 1.7221425051368394e-05, 'epoch': 0.27}
{'loss': 0.9845, 'grad_norm': 0.603083368940308, 'learning_rate': 1.721279914147214e-05, 'epoch': 0.27}
{'loss': 1.0265, 'grad_norm': 0.6617611289845267, 'learning_rate': 1.7204162030549093e-05, 'epoch': 0.27}
{'loss': 1.0964, 'grad_norm': 0.7597212424661676, 'learning_rate': 1.719551373201214e-05, 'epoch': 0.27}
{'loss': 1.0226, 'grad_norm': 0.8181875060134001, 'learning_rate': 1.7186854259291558e-05, 'epoch': 0.27}
{'loss': 0.9265, 'grad_norm': 0.613377471323283, 'learning_rate': 1.717818362583496e-05, 'epoch': 0.27}
{'loss': 1.0489, 'grad_norm': 0.7655872120696608, 'learning_rate': 1.71695018451073e-05, 'epoch': 0.27}
{'loss': 1.0139, 'grad_norm': 0.5854417211262439, 'learning_rate': 1.7160808930590845e-05, 'epoch': 0.27}
{'loss': 1.0377, 'grad_norm': 0.8558376749821918, 'learning_rate': 1.7152104895785147e-05, 'epoch': 0.27}
{'loss': 0.9829, 'grad_norm': 0.7480077920891904, 'learning_rate': 1.7143389754207026e-05, 'epoch': 0.27}
{'loss': 1.0725, 'grad_norm': 0.6498396225096149, 'learning_rate': 1.7134663519390557e-05, 'epoch': 0.27}
{'loss': 1.0346, 'grad_norm': 0.7137394288484974, 'learning_rate': 1.7125926204887034e-05, 'epoch': 0.27}
{'loss': 1.0537, 'grad_norm': 0.6877807978301521, 'learning_rate': 1.7117177824264962e-05, 'epoch': 0.27}
{'loss': 1.026, 'grad_norm': 0.7468275561260104, 'learning_rate': 1.7108418391110033e-05, 'epoch': 0.27}
{'loss': 1.0722, 'grad_norm': 0.7091203339667894, 'learning_rate': 1.7099647919025096e-05, 'epoch': 0.27}
{'loss': 0.9801, 'grad_norm': 0.6356436293669759, 'learning_rate': 1.709086642163015e-05, 'epoch': 0.27}
{'loss': 0.9766, 'grad_norm': 0.566372168921956, 'learning_rate': 1.708207391256231e-05, 'epoch': 0.27}
{'loss': 1.0363, 'grad_norm': 0.8119511472274226, 'learning_rate': 1.7073270405475796e-05, 'epoch': 0.27}
{'loss': 1.0395, 'grad_norm': 0.6763380915011614, 'learning_rate': 1.70644559140419e-05, 'epoch': 0.27}
{'loss': 1.0409, 'grad_norm': 0.6791366227764568, 'learning_rate': 1.705563045194898e-05, 'epoch': 0.28}
{'loss': 1.0357, 'grad_norm': 0.6984697854402095, 'learning_rate': 1.704679403290243e-05, 'epoch': 0.28}
{'loss': 1.0604, 'grad_norm': 0.6978038804761337, 'learning_rate': 1.7037946670624652e-05, 'epoch': 0.28}
{'loss': 0.9979, 'grad_norm': 0.6416012020898623, 'learning_rate': 1.7029088378855055e-05, 'epoch': 0.28}
{'loss': 1.0666, 'grad_norm': 0.6937030686097252, 'learning_rate': 1.7020219171350004e-05, 'epoch': 0.28}
{'loss': 1.029, 'grad_norm': 0.6630340221908616, 'learning_rate': 1.701133906188283e-05, 'epoch': 0.28}
{'loss': 1.0245, 'grad_norm': 0.6512930692972727, 'learning_rate': 1.700244806424379e-05, 'epoch': 0.28}
{'loss': 1.0559, 'grad_norm': 0.6607613145361414, 'learning_rate': 1.699354619224004e-05, 'epoch': 0.28}
{'loss': 1.0163, 'grad_norm': 0.7195035385209527, 'learning_rate': 1.6984633459695646e-05, 'epoch': 0.28}
{'loss': 1.0174, 'grad_norm': 0.6265600170439196, 'learning_rate': 1.697570988045151e-05, 'epoch': 0.28}
{'loss': 1.0349, 'grad_norm': 0.9385563921230843, 'learning_rate': 1.69667754683654e-05, 'epoch': 0.28}
{'loss': 1.1226, 'grad_norm': 0.7461438903719771, 'learning_rate': 1.6957830237311904e-05, 'epoch': 0.28}
{'loss': 0.9602, 'grad_norm': 0.49076434610489234, 'learning_rate': 1.6948874201182402e-05, 'epoch': 0.28}
{'loss': 1.0166, 'grad_norm': 0.740225310256475, 'learning_rate': 1.6939907373885062e-05, 'epoch': 0.28}
{'loss': 1.0417, 'grad_norm': 0.7600476228292138, 'learning_rate': 1.6930929769344807e-05, 'epoch': 0.28}
{'loss': 1.0531, 'grad_norm': 0.6558193069721996, 'learning_rate': 1.692194140150329e-05, 'epoch': 0.28}
{'loss': 0.9954, 'grad_norm': 0.4882302322911157, 'learning_rate': 1.6912942284318898e-05, 'epoch': 0.28}
{'loss': 1.0317, 'grad_norm': 0.6612717883681241, 'learning_rate': 1.690393243176668e-05, 'epoch': 0.28}
{'loss': 1.0226, 'grad_norm': 0.8060398710397991, 'learning_rate': 1.6894911857838394e-05, 'epoch': 0.28}
{'loss': 0.9918, 'grad_norm': 0.5966822216327022, 'learning_rate': 1.6885880576542417e-05, 'epoch': 0.28}
{'loss': 0.9547, 'grad_norm': 0.590794523329434, 'learning_rate': 1.6876838601903765e-05, 'epoch': 0.28}
{'loss': 1.0548, 'grad_norm': 0.6425702538448843, 'learning_rate': 1.6867785947964065e-05, 'epoch': 0.28}
{'loss': 1.0539, 'grad_norm': 0.7165864875457717, 'learning_rate': 1.685872262878152e-05, 'epoch': 0.28}
{'loss': 1.0611, 'grad_norm': 0.6709473715647655, 'learning_rate': 1.68496486584309e-05, 'epoch': 0.28}
{'loss': 0.9883, 'grad_norm': 0.5952211929495601, 'learning_rate': 1.6840564051003517e-05, 'epoch': 0.28}
{'loss': 1.025, 'grad_norm': 0.6507344713561573, 'learning_rate': 1.6831468820607192e-05, 'epoch': 0.28}
{'loss': 1.0432, 'grad_norm': 0.6909005639527445, 'learning_rate': 1.6822362981366257e-05, 'epoch': 0.29}
{'loss': 1.0917, 'grad_norm': 0.6259679499810875, 'learning_rate': 1.681324654742151e-05, 'epoch': 0.29}
{'loss': 0.9788, 'grad_norm': 0.6486993894007891, 'learning_rate': 1.6804119532930202e-05, 'epoch': 0.29}
{'loss': 1.0909, 'grad_norm': 0.6074966264321537, 'learning_rate': 1.6794981952066018e-05, 'epoch': 0.29}
{'loss': 1.1074, 'grad_norm': 0.6927551857576996, 'learning_rate': 1.6785833819019052e-05, 'epoch': 0.29}
{'loss': 0.9851, 'grad_norm': 0.7205737192454833, 'learning_rate': 1.677667514799578e-05, 'epoch': 0.29}
{'loss': 1.0245, 'grad_norm': 0.9028815397729549, 'learning_rate': 1.676750595321905e-05, 'epoch': 0.29}
{'loss': 1.0528, 'grad_norm': 0.6019263777307088, 'learning_rate': 1.675832624892805e-05, 'epoch': 0.29}
{'loss': 1.0538, 'grad_norm': 0.6286781964599776, 'learning_rate': 1.674913604937828e-05, 'epoch': 0.29}
{'loss': 1.0256, 'grad_norm': 0.6036331894310997, 'learning_rate': 1.6739935368841555e-05, 'epoch': 0.29}
{'loss': 1.0647, 'grad_norm': 0.7935185243334218, 'learning_rate': 1.6730724221605955e-05, 'epoch': 0.29}
{'loss': 1.0524, 'grad_norm': 0.6618451203769097, 'learning_rate': 1.6721502621975813e-05, 'epoch': 0.29}
{'loss': 1.0224, 'grad_norm': 0.6551056371312549, 'learning_rate': 1.6712270584271703e-05, 'epoch': 0.29}
{'loss': 1.0467, 'grad_norm': 0.9424961056581798, 'learning_rate': 1.67030281228304e-05, 'epoch': 0.29}
{'loss': 1.0337, 'grad_norm': 0.7149569365755962, 'learning_rate': 1.6693775252004866e-05, 'epoch': 0.29}
{'loss': 0.9827, 'grad_norm': 0.5737440883215751, 'learning_rate': 1.668451198616424e-05, 'epoch': 0.29}
{'loss': 1.0226, 'grad_norm': 0.6772461296467579, 'learning_rate': 1.667523833969379e-05, 'epoch': 0.29}
{'loss': 1.0845, 'grad_norm': 0.7284852650404654, 'learning_rate': 1.666595432699491e-05, 'epoch': 0.29}
{'loss': 1.0088, 'grad_norm': 0.6614987359753495, 'learning_rate': 1.6656659962485097e-05, 'epoch': 0.29}
{'loss': 0.975, 'grad_norm': 0.5911748105989083, 'learning_rate': 1.6647355260597915e-05, 'epoch': 0.29}
{'loss': 1.0309, 'grad_norm': 0.6590636345368293, 'learning_rate': 1.6638040235782983e-05, 'epoch': 0.29}
{'loss': 1.0408, 'grad_norm': 0.5477713367982489, 'learning_rate': 1.662871490250596e-05, 'epoch': 0.29}
{'loss': 1.0418, 'grad_norm': 0.6254530221903697, 'learning_rate': 1.66193792752485e-05, 'epoch': 0.29}
{'loss': 1.056, 'grad_norm': 0.7269330450596965, 'learning_rate': 1.661003336850825e-05, 'epoch': 0.29}
{'loss': 1.0326, 'grad_norm': 0.7014636941888415, 'learning_rate': 1.660067719679882e-05, 'epoch': 0.29}
{'loss': 1.0775, 'grad_norm': 0.6601736509983228, 'learning_rate': 1.6591310774649766e-05, 'epoch': 0.29}
{'loss': 1.0178, 'grad_norm': 0.7824628360308022, 'learning_rate': 1.6581934116606554e-05, 'epoch': 0.3}
{'loss': 1.0694, 'grad_norm': 0.7047053813080617, 'learning_rate': 1.657254723723054e-05, 'epoch': 0.3}
{'loss': 1.0296, 'grad_norm': 0.7380994230023024, 'learning_rate': 1.6563150151098973e-05, 'epoch': 0.3}
{'loss': 1.0585, 'grad_norm': 0.6377854076789212, 'learning_rate': 1.655374287280494e-05, 'epoch': 0.3}
{'loss': 1.0304, 'grad_norm': 0.7172305777666783, 'learning_rate': 1.654432541695735e-05, 'epoch': 0.3}
{'loss': 1.0144, 'grad_norm': 0.5869729518908663, 'learning_rate': 1.653489779818093e-05, 'epoch': 0.3}
{'loss': 1.0383, 'grad_norm': 0.6440959952766252, 'learning_rate': 1.652546003111618e-05, 'epoch': 0.3}
{'loss': 0.9919, 'grad_norm': 0.6033874931423374, 'learning_rate': 1.6516012130419366e-05, 'epoch': 0.3}
{'loss': 1.0358, 'grad_norm': 0.6600360328191589, 'learning_rate': 1.6506554110762483e-05, 'epoch': 0.3}
{'loss': 0.9732, 'grad_norm': 0.6152014240345752, 'learning_rate': 1.6497085986833252e-05, 'epoch': 0.3}
{'loss': 1.0336, 'grad_norm': 0.7052314702004796, 'learning_rate': 1.6487607773335074e-05, 'epoch': 0.3}
{'loss': 1.028, 'grad_norm': 0.7177162789583019, 'learning_rate': 1.6478119484987026e-05, 'epoch': 0.3}
{'loss': 1.0055, 'grad_norm': 0.6431546177722852, 'learning_rate': 1.6468621136523823e-05, 'epoch': 0.3}
{'loss': 1.0222, 'grad_norm': 0.5205025599459266, 'learning_rate': 1.6459112742695807e-05, 'epoch': 0.3}
{'loss': 0.9757, 'grad_norm': 0.8216090452535448, 'learning_rate': 1.644959431826893e-05, 'epoch': 0.3}
{'loss': 0.9991, 'grad_norm': 0.5617102278667548, 'learning_rate': 1.6440065878024697e-05, 'epoch': 0.3}
{'loss': 1.0355, 'grad_norm': 0.6478101795969619, 'learning_rate': 1.643052743676019e-05, 'epoch': 0.3}
{'loss': 1.0746, 'grad_norm': 0.701935221253157, 'learning_rate': 1.642097900928801e-05, 'epoch': 0.3}
{'loss': 1.0345, 'grad_norm': 0.8574415765401365, 'learning_rate': 1.641142061043627e-05, 'epoch': 0.3}
{'loss': 1.0174, 'grad_norm': 0.6124561169839909, 'learning_rate': 1.6401852255048564e-05, 'epoch': 0.3}
{'loss': 1.0463, 'grad_norm': 0.7440548810079161, 'learning_rate': 1.6392273957983955e-05, 'epoch': 0.3}
{'loss': 1.0494, 'grad_norm': 0.666281409545103, 'learning_rate': 1.6382685734116934e-05, 'epoch': 0.3}
{'loss': 1.0082, 'grad_norm': 0.5988740817353009, 'learning_rate': 1.637308759833742e-05, 'epoch': 0.3}
{'loss': 1.0242, 'grad_norm': 0.6595896121241991, 'learning_rate': 1.636347956555072e-05, 'epoch': 0.3}
{'loss': 1.0016, 'grad_norm': 0.6640185945219595, 'learning_rate': 1.63538616506775e-05, 'epoch': 0.3}
{'loss': 1.0554, 'grad_norm': 0.8007561019420826, 'learning_rate': 1.634423386865379e-05, 'epoch': 0.3}
{'loss': 1.0535, 'grad_norm': 0.7135053132187607, 'learning_rate': 1.633459623443093e-05, 'epoch': 0.31}
{'loss': 1.0402, 'grad_norm': 0.6364179156300149, 'learning_rate': 1.6324948762975567e-05, 'epoch': 0.31}
{'loss': 1.0719, 'grad_norm': 0.6495574656937406, 'learning_rate': 1.6315291469269617e-05, 'epoch': 0.31}
{'loss': 1.0037, 'grad_norm': 0.8015031421304212, 'learning_rate': 1.6305624368310265e-05, 'epoch': 0.31}
{'loss': 1.0457, 'grad_norm': 0.6461319582217047, 'learning_rate': 1.6295947475109904e-05, 'epoch': 0.31}
{'loss': 1.0292, 'grad_norm': 0.7268489121489999, 'learning_rate': 1.628626080469615e-05, 'epoch': 0.31}
{'loss': 1.0203, 'grad_norm': 0.6603049756491235, 'learning_rate': 1.6276564372111797e-05, 'epoch': 0.31}
{'loss': 1.0419, 'grad_norm': 0.7173550154126006, 'learning_rate': 1.62668581924148e-05, 'epoch': 0.31}
{'loss': 1.0135, 'grad_norm': 0.6130770379100645, 'learning_rate': 1.6257142280678247e-05, 'epoch': 0.31}
{'loss': 1.0262, 'grad_norm': 0.616635912750426, 'learning_rate': 1.6247416651990343e-05, 'epoch': 0.31}
{'loss': 1.023, 'grad_norm': 0.5904440814165528, 'learning_rate': 1.6237681321454387e-05, 'epoch': 0.31}
{'loss': 1.0005, 'grad_norm': 0.6430746266622328, 'learning_rate': 1.6227936304188738e-05, 'epoch': 0.31}
{'loss': 0.9947, 'grad_norm': 0.6071582936714575, 'learning_rate': 1.6218181615326795e-05, 'epoch': 0.31}
{'loss': 1.0024, 'grad_norm': 0.6156033182592079, 'learning_rate': 1.620841727001699e-05, 'epoch': 0.31}
{'loss': 1.0069, 'grad_norm': 0.6301335673882701, 'learning_rate': 1.619864328342273e-05, 'epoch': 0.31}
{'loss': 0.9254, 'grad_norm': 0.52868411983304, 'learning_rate': 1.6188859670722414e-05, 'epoch': 0.31}
{'loss': 1.0549, 'grad_norm': 0.7567248662331858, 'learning_rate': 1.6179066447109376e-05, 'epoch': 0.31}
{'loss': 0.9668, 'grad_norm': 0.5959608518525223, 'learning_rate': 1.6169263627791886e-05, 'epoch': 0.31}
{'loss': 1.0445, 'grad_norm': 0.6403446290059777, 'learning_rate': 1.615945122799311e-05, 'epoch': 0.31}
{'loss': 0.9882, 'grad_norm': 0.638495526547517, 'learning_rate': 1.614962926295109e-05, 'epoch': 0.31}
{'loss': 1.0548, 'grad_norm': 0.6383085476461366, 'learning_rate': 1.6139797747918725e-05, 'epoch': 0.31}
{'loss': 0.9971, 'grad_norm': 0.6582267771841166, 'learning_rate': 1.612995669816375e-05, 'epoch': 0.31}
{'loss': 1.0407, 'grad_norm': 0.7992469036343585, 'learning_rate': 1.6120106128968686e-05, 'epoch': 0.31}
{'loss': 1.0522, 'grad_norm': 0.5987617457983763, 'learning_rate': 1.611024605563087e-05, 'epoch': 0.31}
{'loss': 1.0224, 'grad_norm': 0.5913647647164563, 'learning_rate': 1.6100376493462368e-05, 'epoch': 0.31}
{'loss': 1.0208, 'grad_norm': 0.7104862459396072, 'learning_rate': 1.609049745779e-05, 'epoch': 0.31}
{'loss': 1.0182, 'grad_norm': 0.5670721084586159, 'learning_rate': 1.608060896395529e-05, 'epoch': 0.32}
{'loss': 1.0267, 'grad_norm': 0.653418358198294, 'learning_rate': 1.6070711027314446e-05, 'epoch': 0.32}
{'loss': 1.0157, 'grad_norm': 0.5847048807411045, 'learning_rate': 1.6060803663238357e-05, 'epoch': 0.32}
{'loss': 0.9794, 'grad_norm': 0.5365063679336561, 'learning_rate': 1.6050886887112535e-05, 'epoch': 0.32}
{'loss': 0.9289, 'grad_norm': 0.5395780609153045, 'learning_rate': 1.604096071433711e-05, 'epoch': 0.32}
{'loss': 1.0246, 'grad_norm': 0.642043101948626, 'learning_rate': 1.6031025160326814e-05, 'epoch': 0.32}
{'loss': 1.0313, 'grad_norm': 0.6005916495788423, 'learning_rate': 1.6021080240510943e-05, 'epoch': 0.32}
{'loss': 1.0369, 'grad_norm': 0.6116419855815607, 'learning_rate': 1.6011125970333333e-05, 'epoch': 0.32}
{'loss': 1.0052, 'grad_norm': 0.8492847429260697, 'learning_rate': 1.6001162365252348e-05, 'epoch': 0.32}
{'loss': 0.9882, 'grad_norm': 0.6722796129941255, 'learning_rate': 1.5991189440740838e-05, 'epoch': 0.32}
{'loss': 1.0535, 'grad_norm': 0.6788835297602154, 'learning_rate': 1.598120721228614e-05, 'epoch': 0.32}
{'loss': 1.003, 'grad_norm': 0.6262162574051855, 'learning_rate': 1.5971215695390026e-05, 'epoch': 0.32}
{'loss': 1.0267, 'grad_norm': 0.6429803573332119, 'learning_rate': 1.5961214905568705e-05, 'epoch': 0.32}
{'loss': 1.0563, 'grad_norm': 0.7169491868104276, 'learning_rate': 1.5951204858352772e-05, 'epoch': 0.32}
{'loss': 0.9604, 'grad_norm': 0.5833894029472556, 'learning_rate': 1.5941185569287206e-05, 'epoch': 0.32}
{'loss': 1.0261, 'grad_norm': 0.6195511478045364, 'learning_rate': 1.593115705393134e-05, 'epoch': 0.32}
{'loss': 0.9826, 'grad_norm': 0.6918660253771649, 'learning_rate': 1.5921119327858835e-05, 'epoch': 0.32}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B00XIZWWNC.jpg, using default black image.
{'loss': 1.0686, 'grad_norm': 0.68993374839641, 'learning_rate': 1.5911072406657646e-05, 'epoch': 0.32}
{'loss': 1.0313, 'grad_norm': 0.7038489248044336, 'learning_rate': 1.590101630593002e-05, 'epoch': 0.32}
{'loss': 1.0282, 'grad_norm': 0.6496183461845372, 'learning_rate': 1.5890951041292453e-05, 'epoch': 0.32}
{'loss': 1.0355, 'grad_norm': 0.6564892054706524, 'learning_rate': 1.5880876628375668e-05, 'epoch': 0.32}
{'loss': 0.9457, 'grad_norm': 0.7099913662186039, 'learning_rate': 1.5870793082824604e-05, 'epoch': 0.32}
{'loss': 1.0528, 'grad_norm': 0.6895794631160992, 'learning_rate': 1.5860700420298377e-05, 'epoch': 0.32}
{'loss': 1.0038, 'grad_norm': 0.6654874538991506, 'learning_rate': 1.5850598656470265e-05, 'epoch': 0.32}
{'loss': 1.0329, 'grad_norm': 0.683010226650052, 'learning_rate': 1.5840487807027665e-05, 'epoch': 0.32}
{'loss': 0.9589, 'grad_norm': 0.700849180808656, 'learning_rate': 1.583036788767211e-05, 'epoch': 0.32}
{'loss': 1.0156, 'grad_norm': 0.7012519223138362, 'learning_rate': 1.5820238914119195e-05, 'epoch': 0.33}
{'loss': 1.0679, 'grad_norm': 0.679356234149585, 'learning_rate': 1.5810100902098582e-05, 'epoch': 0.33}
{'loss': 1.0447, 'grad_norm': 0.7710342090934473, 'learning_rate': 1.5799953867353975e-05, 'epoch': 0.33}
{'loss': 1.0116, 'grad_norm': 0.6355636615812728, 'learning_rate': 1.5789797825643086e-05, 'epoch': 0.33}
{'loss': 1.0254, 'grad_norm': 0.6042141551595931, 'learning_rate': 1.5779632792737608e-05, 'epoch': 0.33}
{'loss': 1.0121, 'grad_norm': 0.6173766661569375, 'learning_rate': 1.5769458784423206e-05, 'epoch': 0.33}
{'loss': 1.0357, 'grad_norm': 0.615676742321625, 'learning_rate': 1.575927581649948e-05, 'epoch': 0.33}
{'loss': 0.9822, 'grad_norm': 0.6724105820821091, 'learning_rate': 1.574908390477995e-05, 'epoch': 0.33}
{'loss': 1.0579, 'grad_norm': 0.6762192497300444, 'learning_rate': 1.5738883065092005e-05, 'epoch': 0.33}
{'loss': 1.001, 'grad_norm': 0.5944410794339222, 'learning_rate': 1.572867331327692e-05, 'epoch': 0.33}
{'loss': 0.9536, 'grad_norm': 0.6159654573202986, 'learning_rate': 1.5718454665189806e-05, 'epoch': 0.33}
{'loss': 1.0164, 'grad_norm': 0.7032377389419299, 'learning_rate': 1.5708227136699578e-05, 'epoch': 0.33}
{'loss': 1.0523, 'grad_norm': 0.6085768863271752, 'learning_rate': 1.569799074368895e-05, 'epoch': 0.33}
{'loss': 1.0789, 'grad_norm': 0.6304371505735171, 'learning_rate': 1.5687745502054407e-05, 'epoch': 0.33}
{'loss': 1.0447, 'grad_norm': 0.644376461256362, 'learning_rate': 1.567749142770617e-05, 'epoch': 0.33}
{'loss': 1.0037, 'grad_norm': 0.6536283126162018, 'learning_rate': 1.5667228536568167e-05, 'epoch': 0.33}
{'loss': 1.0003, 'grad_norm': 0.594262288276893, 'learning_rate': 1.565695684457803e-05, 'epoch': 0.33}
{'loss': 0.9983, 'grad_norm': 0.708874800556974, 'learning_rate': 1.5646676367687067e-05, 'epoch': 0.33}
{'loss': 1.0224, 'grad_norm': 0.6293878305486622, 'learning_rate': 1.5636387121860207e-05, 'epoch': 0.33}
{'loss': 1.0751, 'grad_norm': 0.7849709586224458, 'learning_rate': 1.5626089123076004e-05, 'epoch': 0.33}
{'loss': 1.0374, 'grad_norm': 0.676867288864616, 'learning_rate': 1.561578238732661e-05, 'epoch': 0.33}
{'loss': 1.0408, 'grad_norm': 0.7052038711047849, 'learning_rate': 1.5605466930617747e-05, 'epoch': 0.33}
{'loss': 1.0805, 'grad_norm': 0.7750261289162643, 'learning_rate': 1.559514276896867e-05, 'epoch': 0.33}
{'loss': 1.0315, 'grad_norm': 0.7263666589257308, 'learning_rate': 1.5584809918412158e-05, 'epoch': 0.33}
{'loss': 1.0595, 'grad_norm': 0.7022842508734469, 'learning_rate': 1.5574468394994486e-05, 'epoch': 0.33}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B00XLZW19O.jpg, using default black image.
{'loss': 1.0135, 'grad_norm': 0.6906066736837777, 'learning_rate': 1.556411821477539e-05, 'epoch': 0.33}
{'loss': 1.0444, 'grad_norm': 0.8586205619477189, 'learning_rate': 1.5553759393828058e-05, 'epoch': 0.34}
{'loss': 1.0331, 'grad_norm': 0.691597058000698, 'learning_rate': 1.554339194823909e-05, 'epoch': 0.34}
{'loss': 1.1107, 'grad_norm': 0.7950012825529754, 'learning_rate': 1.553301589410848e-05, 'epoch': 0.34}
{'loss': 1.0444, 'grad_norm': 0.6695239574769489, 'learning_rate': 1.5522631247549598e-05, 'epoch': 0.34}
{'loss': 0.9895, 'grad_norm': 0.559765019293593, 'learning_rate': 1.5512238024689144e-05, 'epoch': 0.34}
{'loss': 1.0439, 'grad_norm': 0.6787759902976854, 'learning_rate': 1.550183624166715e-05, 'epoch': 0.34}
{'loss': 0.9708, 'grad_norm': 0.5460843663769529, 'learning_rate': 1.5491425914636934e-05, 'epoch': 0.34}
{'loss': 1.0501, 'grad_norm': 0.676781195536997, 'learning_rate': 1.548100705976508e-05, 'epoch': 0.34}
{'loss': 0.9983, 'grad_norm': 0.6178552200388209, 'learning_rate': 1.5470579693231432e-05, 'epoch': 0.34}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/7503145099.jpg, using default black image.
{'loss': 1.0595, 'grad_norm': 0.6412289266389256, 'learning_rate': 1.5460143831229026e-05, 'epoch': 0.34}
{'loss': 1.006, 'grad_norm': 0.6955505484452242, 'learning_rate': 1.544969948996411e-05, 'epoch': 0.34}
{'loss': 1.0626, 'grad_norm': 0.7867888646716183, 'learning_rate': 1.5439246685656093e-05, 'epoch': 0.34}
{'loss': 1.0026, 'grad_norm': 0.6321767929354977, 'learning_rate': 1.5428785434537527e-05, 'epoch': 0.34}
{'loss': 1.0548, 'grad_norm': 0.6220262932262938, 'learning_rate': 1.541831575285408e-05, 'epoch': 0.34}
{'loss': 1.0529, 'grad_norm': 0.8043145515640643, 'learning_rate': 1.540783765686452e-05, 'epoch': 0.34}
{'loss': 1.0142, 'grad_norm': 0.7302891330683139, 'learning_rate': 1.539735116284067e-05, 'epoch': 0.34}
{'loss': 1.0189, 'grad_norm': 0.5662765487401931, 'learning_rate': 1.53868562870674e-05, 'epoch': 0.34}
{'loss': 1.0399, 'grad_norm': 0.6674401178739328, 'learning_rate': 1.5376353045842604e-05, 'epoch': 0.34}
{'loss': 1.024, 'grad_norm': 0.7240566429991597, 'learning_rate': 1.5365841455477158e-05, 'epoch': 0.34}
{'loss': 1.0095, 'grad_norm': 0.6493579481593151, 'learning_rate': 1.5355321532294897e-05, 'epoch': 0.34}
{'loss': 1.0566, 'grad_norm': 0.6685638379015726, 'learning_rate': 1.5344793292632614e-05, 'epoch': 0.34}
{'loss': 1.0538, 'grad_norm': 0.717106990576832, 'learning_rate': 1.5334256752840007e-05, 'epoch': 0.34}
{'loss': 1.0181, 'grad_norm': 0.644197277829697, 'learning_rate': 1.532371192927966e-05, 'epoch': 0.34}
{'loss': 1.025, 'grad_norm': 0.6324450375945606, 'learning_rate': 1.531315883832703e-05, 'epoch': 0.34}
{'loss': 1.0639, 'grad_norm': 0.77092208961409, 'learning_rate': 1.5302597496370408e-05, 'epoch': 0.34}
{'loss': 1.0352, 'grad_norm': 0.669045549982356, 'learning_rate': 1.5292027919810898e-05, 'epoch': 0.34}
{'loss': 0.9909, 'grad_norm': 0.591243357172302, 'learning_rate': 1.528145012506239e-05, 'epoch': 0.35}
{'loss': 1.0541, 'grad_norm': 0.625374186070888, 'learning_rate': 1.5270864128551542e-05, 'epoch': 0.35}
{'loss': 1.0658, 'grad_norm': 0.6140162676256526, 'learning_rate': 1.5260269946717746e-05, 'epoch': 0.35}
{'loss': 1.0591, 'grad_norm': 0.6889990794903965, 'learning_rate': 1.5249667596013102e-05, 'epoch': 0.35}
{'loss': 0.9553, 'grad_norm': 0.5281399797981602, 'learning_rate': 1.5239057092902404e-05, 'epoch': 0.35}
{'loss': 1.0132, 'grad_norm': 0.4887908422921261, 'learning_rate': 1.5228438453863095e-05, 'epoch': 0.35}
{'loss': 0.9931, 'grad_norm': 1.165161470659745, 'learning_rate': 1.5217811695385263e-05, 'epoch': 0.35}
{'loss': 1.0059, 'grad_norm': 0.6408020665260992, 'learning_rate': 1.5207176833971598e-05, 'epoch': 0.35}
{'loss': 1.006, 'grad_norm': 0.6254213130109775, 'learning_rate': 1.5196533886137376e-05, 'epoch': 0.35}
{'loss': 1.0477, 'grad_norm': 0.7900529090020757, 'learning_rate': 1.5185882868410431e-05, 'epoch': 0.35}
{'loss': 1.0414, 'grad_norm': 0.6341044457823676, 'learning_rate': 1.517522379733113e-05, 'epoch': 0.35}
{'loss': 1.0449, 'grad_norm': 0.7558212699070208, 'learning_rate': 1.5164556689452346e-05, 'epoch': 0.35}
{'loss': 1.0398, 'grad_norm': 0.6868692384490322, 'learning_rate': 1.5153881561339426e-05, 'epoch': 0.35}
{'loss': 0.9988, 'grad_norm': 0.6339175617137094, 'learning_rate': 1.5143198429570181e-05, 'epoch': 0.35}
{'loss': 1.0522, 'grad_norm': 0.6305982578292554, 'learning_rate': 1.5132507310734847e-05, 'epoch': 0.35}
{'loss': 0.9951, 'grad_norm': 0.7348280119088334, 'learning_rate': 1.512180822143607e-05, 'epoch': 0.35}
{'loss': 1.0755, 'grad_norm': 0.6298805297142472, 'learning_rate': 1.5111101178288858e-05, 'epoch': 0.35}
{'loss': 1.0345, 'grad_norm': 0.6308427325332511, 'learning_rate': 1.5100386197920585e-05, 'epoch': 0.35}
{'loss': 0.9846, 'grad_norm': 0.6522538309813382, 'learning_rate': 1.5089663296970952e-05, 'epoch': 0.35}
{'loss': 1.0217, 'grad_norm': 0.7747905471418632, 'learning_rate': 1.5078932492091942e-05, 'epoch': 0.35}
{'loss': 1.05, 'grad_norm': 0.7051565058462588, 'learning_rate': 1.506819379994784e-05, 'epoch': 0.35}
{'loss': 1.0191, 'grad_norm': 0.6062349937567342, 'learning_rate': 1.5057447237215152e-05, 'epoch': 0.35}
{'loss': 1.062, 'grad_norm': 0.7915249104881865, 'learning_rate': 1.5046692820582625e-05, 'epoch': 0.35}
{'loss': 1.0044, 'grad_norm': 0.5569247511841974, 'learning_rate': 1.5035930566751198e-05, 'epoch': 0.35}
{'loss': 0.9673, 'grad_norm': 0.5190856778281258, 'learning_rate': 1.5025160492433976e-05, 'epoch': 0.35}
{'loss': 1.0553, 'grad_norm': 0.5910425898639451, 'learning_rate': 1.5014382614356213e-05, 'epoch': 0.35}
{'loss': 1.0711, 'grad_norm': 0.6979346422669129, 'learning_rate': 1.5003596949255284e-05, 'epoch': 0.36}
{'loss': 1.0188, 'grad_norm': 0.6007299598013282, 'learning_rate': 1.499280351388065e-05, 'epoch': 0.36}
{'loss': 1.0569, 'grad_norm': 0.6857809476885325, 'learning_rate': 1.498200232499384e-05, 'epoch': 0.36}
{'loss': 1.0489, 'grad_norm': 0.6164841218505749, 'learning_rate': 1.497119339936843e-05, 'epoch': 0.36}
{'loss': 0.9826, 'grad_norm': 0.6506211387523044, 'learning_rate': 1.496037675379001e-05, 'epoch': 0.36}
{'loss': 1.0038, 'grad_norm': 0.6787079320727597, 'learning_rate': 1.494955240505615e-05, 'epoch': 0.36}
{'loss': 1.0387, 'grad_norm': 0.659269815709303, 'learning_rate': 1.4938720369976385e-05, 'epoch': 0.36}
{'loss': 0.975, 'grad_norm': 0.584605283831487, 'learning_rate': 1.4927880665372197e-05, 'epoch': 0.36}
{'loss': 0.983, 'grad_norm': 0.6496794498178543, 'learning_rate': 1.4917033308076967e-05, 'epoch': 0.36}
{'loss': 1.0115, 'grad_norm': 0.6089369108670133, 'learning_rate': 1.490617831493596e-05, 'epoch': 0.36}
{'loss': 1.0696, 'grad_norm': 0.6765327863748698, 'learning_rate': 1.489531570280631e-05, 'epoch': 0.36}
{'loss': 1.0032, 'grad_norm': 0.5246630271524799, 'learning_rate': 1.4884445488556972e-05, 'epoch': 0.36}
{'loss': 0.9958, 'grad_norm': 0.5455394047715547, 'learning_rate': 1.4873567689068708e-05, 'epoch': 0.36}
{'loss': 1.0349, 'grad_norm': 0.6670227870128881, 'learning_rate': 1.4862682321234064e-05, 'epoch': 0.36}
{'loss': 0.9485, 'grad_norm': 0.6113635256484945, 'learning_rate': 1.4851789401957338e-05, 'epoch': 0.36}
{'loss': 1.0245, 'grad_norm': 0.6834252874722647, 'learning_rate': 1.484088894815455e-05, 'epoch': 0.36}
{'loss': 1.0311, 'grad_norm': 0.6755358102820957, 'learning_rate': 1.4829980976753426e-05, 'epoch': 0.36}
{'loss': 0.9898, 'grad_norm': 0.6118676143100829, 'learning_rate': 1.4819065504693365e-05, 'epoch': 0.36}
{'loss': 1.0012, 'grad_norm': 0.6896171420691666, 'learning_rate': 1.4808142548925417e-05, 'epoch': 0.36}
{'loss': 0.9704, 'grad_norm': 0.5565580413115702, 'learning_rate': 1.4797212126412243e-05, 'epoch': 0.36}
{'loss': 1.0365, 'grad_norm': 0.7431268945605842, 'learning_rate': 1.4786274254128112e-05, 'epoch': 0.36}
{'loss': 1.0432, 'grad_norm': 0.6258052676935871, 'learning_rate': 1.4775328949058856e-05, 'epoch': 0.36}
{'loss': 1.0176, 'grad_norm': 0.6128183452020007, 'learning_rate': 1.4764376228201848e-05, 'epoch': 0.36}
{'loss': 0.9972, 'grad_norm': 0.7233508907711577, 'learning_rate': 1.4753416108565985e-05, 'epoch': 0.36}
{'loss': 0.9754, 'grad_norm': 0.6165733531410976, 'learning_rate': 1.4742448607171644e-05, 'epoch': 0.36}
{'loss': 1.0301, 'grad_norm': 0.640536133810166, 'learning_rate': 1.4731473741050673e-05, 'epoch': 0.36}
{'loss': 1.0512, 'grad_norm': 0.6854880202305382, 'learning_rate': 1.472049152724635e-05, 'epoch': 0.37}
{'loss': 1.0183, 'grad_norm': 0.8533557899589735, 'learning_rate': 1.470950198281337e-05, 'epoch': 0.37}
{'loss': 0.9961, 'grad_norm': 0.6463560700307635, 'learning_rate': 1.4698505124817811e-05, 'epoch': 0.37}
{'loss': 1.0238, 'grad_norm': 0.6048216815047492, 'learning_rate': 1.4687500970337103e-05, 'epoch': 0.37}
{'loss': 1.0221, 'grad_norm': 0.6322443850280474, 'learning_rate': 1.4676489536460015e-05, 'epoch': 0.37}
{'loss': 1.0111, 'grad_norm': 0.5751841018162253, 'learning_rate': 1.4665470840286614e-05, 'epoch': 0.37}
{'loss': 0.9361, 'grad_norm': 0.6707366835278444, 'learning_rate': 1.4654444898928249e-05, 'epoch': 0.37}
{'loss': 1.071, 'grad_norm': 0.6798726056530225, 'learning_rate': 1.4643411729507517e-05, 'epoch': 0.37}
{'loss': 0.9739, 'grad_norm': 0.7714225004485951, 'learning_rate': 1.4632371349158241e-05, 'epoch': 0.37}
{'loss': 0.9876, 'grad_norm': 0.5883021406799448, 'learning_rate': 1.4621323775025444e-05, 'epoch': 0.37}
{'loss': 1.003, 'grad_norm': 0.5168305527242757, 'learning_rate': 1.4610269024265317e-05, 'epoch': 0.37}
{'loss': 1.0086, 'grad_norm': 0.6035809274541322, 'learning_rate': 1.4599207114045202e-05, 'epoch': 0.37}
{'loss': 0.9667, 'grad_norm': 0.6435490463186108, 'learning_rate': 1.4588138061543551e-05, 'epoch': 0.37}
{'loss': 0.9568, 'grad_norm': 0.633668031594375, 'learning_rate': 1.4577061883949912e-05, 'epoch': 0.37}
{'loss': 1.0091, 'grad_norm': 0.6205897816566852, 'learning_rate': 1.4565978598464895e-05, 'epoch': 0.37}
{'loss': 1.0571, 'grad_norm': 0.6070703532018585, 'learning_rate': 1.455488822230016e-05, 'epoch': 0.37}
{'loss': 0.9942, 'grad_norm': 0.6526657382344639, 'learning_rate': 1.454379077267836e-05, 'epoch': 0.37}
{'loss': 1.0177, 'grad_norm': 0.6444757001544428, 'learning_rate': 1.4532686266833143e-05, 'epoch': 0.37}
{'loss': 1.015, 'grad_norm': 0.5951681327505296, 'learning_rate': 1.4521574722009115e-05, 'epoch': 0.37}
{'loss': 1.0634, 'grad_norm': 0.7526285887949645, 'learning_rate': 1.4510456155461807e-05, 'epoch': 0.37}
{'loss': 1.013, 'grad_norm': 0.6048495364457335, 'learning_rate': 1.4499330584457667e-05, 'epoch': 0.37}
{'loss': 1.0549, 'grad_norm': 0.6593299669062531, 'learning_rate': 1.4488198026274007e-05, 'epoch': 0.37}
{'loss': 1.0547, 'grad_norm': 0.5845154489902996, 'learning_rate': 1.4477058498198993e-05, 'epoch': 0.37}
{'loss': 1.0414, 'grad_norm': 0.6573251761770388, 'learning_rate': 1.446591201753162e-05, 'epoch': 0.37}
{'loss': 0.947, 'grad_norm': 0.5437585104659637, 'learning_rate': 1.4454758601581675e-05, 'epoch': 0.37}
{'loss': 1.0352, 'grad_norm': 0.6783086011286077, 'learning_rate': 1.4443598267669723e-05, 'epoch': 0.37}
{'loss': 1.0525, 'grad_norm': 0.6268065411816888, 'learning_rate': 1.4432431033127056e-05, 'epoch': 0.38}
{'loss': 0.9956, 'grad_norm': 0.5869340261560289, 'learning_rate': 1.4421256915295697e-05, 'epoch': 0.38}
{'loss': 1.0367, 'grad_norm': 0.6221025946434058, 'learning_rate': 1.4410075931528356e-05, 'epoch': 0.38}
{'loss': 1.0215, 'grad_norm': 0.5906780719527885, 'learning_rate': 1.4398888099188396e-05, 'epoch': 0.38}
{'loss': 1.0084, 'grad_norm': 0.574222851006929, 'learning_rate': 1.4387693435649826e-05, 'epoch': 0.38}
{'loss': 1.0192, 'grad_norm': 0.6348027785481283, 'learning_rate': 1.4376491958297263e-05, 'epoch': 0.38}
{'loss': 1.0053, 'grad_norm': 0.601758083279067, 'learning_rate': 1.4365283684525895e-05, 'epoch': 0.38}
{'loss': 1.0396, 'grad_norm': 0.6094975571495733, 'learning_rate': 1.4354068631741476e-05, 'epoch': 0.38}
{'loss': 1.0077, 'grad_norm': 0.66193259765665, 'learning_rate': 1.434284681736028e-05, 'epoch': 0.38}
{'loss': 1.0164, 'grad_norm': 0.650877631743223, 'learning_rate': 1.433161825880909e-05, 'epoch': 0.38}
{'loss': 0.9901, 'grad_norm': 0.6401076312102452, 'learning_rate': 1.4320382973525151e-05, 'epoch': 0.38}
{'loss': 1.0383, 'grad_norm': 0.7415981693413874, 'learning_rate': 1.4309140978956161e-05, 'epoch': 0.38}
{'loss': 0.982, 'grad_norm': 0.67820563828536, 'learning_rate': 1.429789229256024e-05, 'epoch': 0.38}
{'loss': 1.0299, 'grad_norm': 0.7908047819405596, 'learning_rate': 1.4286636931805887e-05, 'epoch': 0.38}
{'loss': 1.0149, 'grad_norm': 0.7345207157516542, 'learning_rate': 1.427537491417198e-05, 'epoch': 0.38}
{'loss': 1.0619, 'grad_norm': 0.6539191474883157, 'learning_rate': 1.4264106257147732e-05, 'epoch': 0.38}
{'loss': 1.0561, 'grad_norm': 0.7438486445297787, 'learning_rate': 1.4252830978232658e-05, 'epoch': 0.38}
{'loss': 0.9787, 'grad_norm': 0.531746137719034, 'learning_rate': 1.4241549094936567e-05, 'epoch': 0.38}
{'loss': 1.0259, 'grad_norm': 0.6661012343633183, 'learning_rate': 1.4230260624779512e-05, 'epoch': 0.38}
{'loss': 0.9847, 'grad_norm': 0.6048869903526831, 'learning_rate': 1.4218965585291792e-05, 'epoch': 0.38}
{'loss': 1.0541, 'grad_norm': 0.6627053501761677, 'learning_rate': 1.4207663994013896e-05, 'epoch': 0.38}
{'loss': 1.0337, 'grad_norm': 0.6284848437154618, 'learning_rate': 1.4196355868496485e-05, 'epoch': 0.38}
{'loss': 1.0384, 'grad_norm': 0.5849796914792935, 'learning_rate': 1.4185041226300376e-05, 'epoch': 0.38}
{'loss': 1.0112, 'grad_norm': 0.6201834600467415, 'learning_rate': 1.4173720084996501e-05, 'epoch': 0.38}
{'loss': 0.9674, 'grad_norm': 0.639315852572455, 'learning_rate': 1.4162392462165884e-05, 'epoch': 0.38}
{'loss': 0.9531, 'grad_norm': 0.6348356633173592, 'learning_rate': 1.415105837539962e-05, 'epoch': 0.38}
{'loss': 1.0105, 'grad_norm': 0.60863992282451, 'learning_rate': 1.4139717842298835e-05, 'epoch': 0.39}
{'loss': 0.9904, 'grad_norm': 0.6210778926711656, 'learning_rate': 1.4128370880474667e-05, 'epoch': 0.39}
{'loss': 1.0083, 'grad_norm': 0.6897224228912343, 'learning_rate': 1.4117017507548244e-05, 'epoch': 0.39}
{'loss': 0.9957, 'grad_norm': 0.6084196058311415, 'learning_rate': 1.4105657741150648e-05, 'epoch': 0.39}
{'loss': 0.998, 'grad_norm': 0.596978064981128, 'learning_rate': 1.4094291598922877e-05, 'epoch': 0.39}
{'loss': 1.016, 'grad_norm': 0.3275518049182238, 'learning_rate': 1.4082919098515846e-05, 'epoch': 0.39}
{'loss': 1.0077, 'grad_norm': 0.6104076249576056, 'learning_rate': 1.4071540257590341e-05, 'epoch': 0.39}
{'loss': 1.0071, 'grad_norm': 0.5617570413616636, 'learning_rate': 1.4060155093816988e-05, 'epoch': 0.39}
{'loss': 1.0016, 'grad_norm': 0.8161053622560777, 'learning_rate': 1.4048763624876233e-05, 'epoch': 0.39}
{'loss': 1.054, 'grad_norm': 0.764515087503207, 'learning_rate': 1.4037365868458325e-05, 'epoch': 0.39}
{'loss': 0.9742, 'grad_norm': 0.6835054057398618, 'learning_rate': 1.402596184226326e-05, 'epoch': 0.39}
{'loss': 1.0558, 'grad_norm': 0.6619075026319146, 'learning_rate': 1.401455156400078e-05, 'epoch': 0.39}
{'loss': 0.982, 'grad_norm': 0.5768333085745184, 'learning_rate': 1.400313505139034e-05, 'epoch': 0.39}
{'loss': 0.9776, 'grad_norm': 0.6215288836971921, 'learning_rate': 1.3991712322161065e-05, 'epoch': 0.39}
{'loss': 1.0366, 'grad_norm': 0.6363240847666564, 'learning_rate': 1.398028339405174e-05, 'epoch': 0.39}
{'loss': 0.9242, 'grad_norm': 0.7376800642893102, 'learning_rate': 1.3968848284810785e-05, 'epoch': 0.39}
{'loss': 0.9468, 'grad_norm': 0.6214277670930031, 'learning_rate': 1.3957407012196204e-05, 'epoch': 0.39}
{'loss': 0.9959, 'grad_norm': 0.650844810964957, 'learning_rate': 1.3945959593975582e-05, 'epoch': 0.39}
{'loss': 1.0062, 'grad_norm': 0.6104949782337764, 'learning_rate': 1.3934506047926042e-05, 'epoch': 0.39}
{'loss': 1.0728, 'grad_norm': 0.6506624363134155, 'learning_rate': 1.3923046391834229e-05, 'epoch': 0.39}
{'loss': 0.9948, 'grad_norm': 0.5932608645886739, 'learning_rate': 1.3911580643496272e-05, 'epoch': 0.39}
{'loss': 1.0159, 'grad_norm': 0.6673730533613448, 'learning_rate': 1.390010882071776e-05, 'epoch': 0.39}
{'loss': 1.0549, 'grad_norm': 0.5885054922531989, 'learning_rate': 1.3888630941313728e-05, 'epoch': 0.39}
{'loss': 1.0179, 'grad_norm': 0.6060312572245198, 'learning_rate': 1.3877147023108592e-05, 'epoch': 0.39}
{'loss': 1.0191, 'grad_norm': 0.6590315322107885, 'learning_rate': 1.3865657083936167e-05, 'epoch': 0.39}
{'loss': 1.0262, 'grad_norm': 0.849569990974223, 'learning_rate': 1.385416114163961e-05, 'epoch': 0.39}
{'loss': 1.0193, 'grad_norm': 0.5799031150193823, 'learning_rate': 1.3842659214071406e-05, 'epoch': 0.4}
{'loss': 0.9986, 'grad_norm': 0.8790338080602151, 'learning_rate': 1.3831151319093323e-05, 'epoch': 0.4}
{'loss': 1.0185, 'grad_norm': 0.6293191492657791, 'learning_rate': 1.3819637474576411e-05, 'epoch': 0.4}
{'loss': 1.0313, 'grad_norm': 0.7178721715270943, 'learning_rate': 1.380811769840095e-05, 'epoch': 0.4}
{'loss': 1.043, 'grad_norm': 0.6517635571738745, 'learning_rate': 1.3796592008456427e-05, 'epoch': 0.4}
{'loss': 0.9615, 'grad_norm': 0.5605005660912199, 'learning_rate': 1.3785060422641526e-05, 'epoch': 0.4}
{'loss': 0.9926, 'grad_norm': 0.7037965681938166, 'learning_rate': 1.3773522958864076e-05, 'epoch': 0.4}
{'loss': 1.0287, 'grad_norm': 0.6311031723469052, 'learning_rate': 1.376197963504104e-05, 'epoch': 0.4}
{'loss': 1.0497, 'grad_norm': 0.6689856920290499, 'learning_rate': 1.375043046909848e-05, 'epoch': 0.4}
{'loss': 1.0244, 'grad_norm': 0.7200436990973716, 'learning_rate': 1.3738875478971526e-05, 'epoch': 0.4}
{'loss': 1.0317, 'grad_norm': 0.6091630856497726, 'learning_rate': 1.372731468260436e-05, 'epoch': 0.4}
{'loss': 0.9878, 'grad_norm': 0.5194671792535407, 'learning_rate': 1.3715748097950176e-05, 'epoch': 0.4}
{'loss': 1.0021, 'grad_norm': 0.6324491456013251, 'learning_rate': 1.3704175742971158e-05, 'epoch': 0.4}
{'loss': 1.041, 'grad_norm': 0.7540782511902544, 'learning_rate': 1.3692597635638452e-05, 'epoch': 0.4}
{'loss': 0.9797, 'grad_norm': 0.5640420232910154, 'learning_rate': 1.3681013793932132e-05, 'epoch': 0.4}
{'loss': 1.0363, 'grad_norm': 0.770449157417508, 'learning_rate': 1.3669424235841185e-05, 'epoch': 0.4}
WARNING: tokenization mismatch: 0 vs. 1595. (ignored)
number of rounds:  2
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: Du bist eine auf Kundenfeedback spezialisierte Agentur mit den folgenden Kenntnissen und Eigenschaften.\n\nKENNTNISSE: Kundenfeedback, wissenschaftliche Datenerhebung, Fragebogendesign, Benutzerfreundlichkeit, Kundenbindung, Service-Qualitätsevaluation.\n\nEIGENSCHAFTEN: Präzision, Effizienz, Empathie, Anpassungsfähigkeit, Datenorientierung, Kundenfokus.\n\nAUFGABE: Nutze dein Wissen, um ein Kundenfeedback-Formular zu entwickeln, das die Service-Qualität einer Steuerberatung evaluiert. Das Formular soll auf wissenschaftlich fundierten Datenniveaus basieren und dabei darauf achten, dass es nur so lang ist, dass es tatsächlich vom Kunden ausgefüllt wird. Konzentriere dich auf die Gestaltung eines benutzerfreundlichen und effizienten Fragebogens, der aussagekräftige Informationen über die Steuerberatung liefert.\n\nOUTPUT: Ein strukturiertes Kundenfeedback-Formular, das auf wissenschaftlich fundierten Datenniveaus basiert und eine angemessene Länge hat, um von Kunden tatsächlich ausgefüllt zu werden, und speziell auf die Evaluation der Service-Qualität einer Steuerberatung abzielt. ASSISTANT: Kundenfeedback-Formular: Steuerberatung Service-Qualität\n\nTeil 1: Allgemeine Informationen\n(Bitte füllen Sie die folgenden Informationen aus.)\n\n1. Name (Optional):\n2. Alter:\n☐ Unter 25\n☐ 25-34\n☐ 35-44\n☐ 45-54\n☐ 55-64\n☐ 65 oder älter\n3. Geschlecht:\n☐ Männlich\n☐ Weiblich\n☐ Andere\n☐ Lieber nicht angeben\n\nTeil 2: Service-Qualität\n(Bitte bewerten Sie die folgenden Aspekte der Steuerberatung auf einer Skala von 1 bis 5, wobei 1 = sehr unzufrieden und 5 = sehr zufrieden.)\n\n1. Fachliche Kompetenz des Steuerberaters:\n☐ 1\n☐ 2\n☐ 3\n☐ 4\n☐ 5\n2. Freundlichkeit und Hilfsbereitschaft des Personals:\n☐ 1\n☐ 2\n☐ 3\n☐ 4\n☐ 5\n3. Reaktionsgeschwindigkeit auf Anfragen und Probleme:\n☐ 1\n☐ 2\n☐ 3\n☐ 4\n☐ 5\n4. Verständlichkeit der erbrachten Informationen und Beratung:\n☐ 1\n☐ 2\n☐ 3\n☐ 4\n☐ 5\n5. Qualität der bereitgestellten Dienstleistungen und Lösungen:\n☐ 1\n☐ 2\n☐ 3\n☐ 4\n☐ 5\n6. Preis-Leistungs-Verhältnis:\n☐ 1\n☐ 2\n☐ 3\n☐ 4\n☐ 5\n\nTeil 3: Kundenbindung und Zufriedenheit\n(Bitte beantworten Sie die folgenden Fragen.)\n\n1. Wie wahrscheinlich ist es, dass Sie die Steuerberatung an Freunde, Familie oder Kollegen weiterempfehlen? (Skala von 1 bis 10, wobei 1 = sehr unwahrscheinlich und 10 = sehr wahrscheinlich)\n☐ 1\n☐ 2\n☐ 3\n☐ 4\n☐ 5\n☐ 6\n☐ 7\n☐ 8\n☐ 9\n☐ 10\n2. Wie zufrieden sind Sie insgesamt mit der Steuerberatung? (Skala von 1 bis 5, wobei 1 = sehr unzufrieden und 5 = sehr zufrieden)\n☐ 1\n☐ 2\n☐ 3\n☐ 4\n☐ 5\n\nTeil 4: Offene Fragen\n(Bitte teilen Sie uns Ihre Gedanken und Erfahrungen mit.)\n\n1. Was hat Ihnen am meisten an der Steuerberatung gefallen? (Optional)\n2. Was könnte die Steuerberatung verbessern, um Ihre Zufriedenheit zu erhöhen? (Optional)\n\nVielen Dank für Ihre Zeit und Ihr", 'USER: Continue. ASSISTANT: wertvolles Feedback! Ihre Meinung hilft uns dabei, den Service und die Qualität unserer Steuerberatung kontinuierlich zu verbessern. Wenn Sie Fragen oder Anmerkungen haben oder zusätzliche Informationen benötigen, zögern Sie bitte nicht, uns zu kontaktieren.\n\nTeil 5: Kontaktaufnahme (Optional)\n(Bitte geben Sie Ihre Kontaktinformationen an, falls Sie möchten, dass wir Ihnen bezüglich Ihres Feedbacks antworten oder weitere Informationen anbieten.)\n\n1. Name:\n2. E-Mail-Adresse:\n3. Telefonnummer:\n\nHinweis zum Datenschutz: Ihre persönlichen Daten werden vertraulich behandelt und nur für interne Zwecke verwendet. Sie werden nicht an Dritte weitergegeben.\n\nBitte klicken Sie auf "Absenden", um das Formular abzuschließen. Nochmals vielen Dank für Ihre Rückmeldung und Ihre Unterstützung bei der Verbesserung unserer Steuerberatung!']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: Du bist eine auf Kundenfeedback spezialisierte Agentur mit den folgenden Kenntnissen und Eigenschaften.

KENNTNISSE: Kundenfeedback, wissenschaftliche Datenerhebung, Fragebogendesign, Benutzerfreundlichkeit, Kundenbindung, Service-Qualitätsevaluation.

EIGENSCHAFTEN: Präzision, Effizienz, Empathie, Anpassungsfähigkeit, Datenorientierung, Kundenfokus.

AUFGABE: Nutze dein Wissen, um ein Kundenfeedback-Formular zu entwickeln, das die Service-Qualität einer Steuerberatung evaluiert. Das Formular soll auf wissenschaftlich fundierten Datenniveaus basieren und dabei darauf achten, dass es nur so lang ist, dass es tatsächlich vom Kunden ausgefüllt wird. Konzentriere dich auf die Gestaltung eines benutzerfreundlichen und effizienten Fragebogens, der aussagekräftige Informationen über die Steuerberatung liefert.

OUTPUT: Ein strukturiertes Kundenfeedback-Formular, das auf wissenschaftlich fundierten Datenniveaus basiert und eine angemessene Länge hat, um von Kunden tatsächlich ausgefüllt zu werden, und speziell auf die Evaluation der Service-Qualität einer Steuerberatung abzielt. ASSISTANT: Kundenfeedback-Formular: Steuerberatung Service-Qualität

Teil 1: Allgemeine Informationen
(Bitte füllen Sie die folgenden Informationen aus.)

1. Name (Optional):
2. Alter:
☐ Unter 25
☐ 25-34
☐ 35-44
☐ 45-54
☐ 55-64
☐ 65 oder älter
3. Geschlecht:
☐ Männlich
☐ Weiblich
☐ Andere
☐ Lieber nicht angeben

Teil 2: Service-Qualität
(Bitte bewerten Sie die folgenden Aspekte der Steuerberatung auf einer Skala von 1 bis 5, wobei 1 = sehr unzufrieden und 5 = sehr zufrieden.)

1. Fachliche Kompetenz des Steuerberaters:
☐ 1
☐ 2
☐ 3
☐ 4
☐ 5
2. Freundlichkeit und Hilfsbereitschaft des Personals:
☐ 1
☐ 2
☐ 3
☐ 4
☐ 5
3. Reaktionsgeschwindigkeit auf Anfragen und Probleme:
☐ 1
☐ 2
☐ 3
☐ 4
☐ 5
4. Verständlichkeit der erbrachten Informationen und Beratung:
☐ 1
☐ 2
☐ 3
☐ 4
☐ 5
5. Qualität der bereitgestellten Dienstleistungen und Lösungen:
☐ 1
☐ 2
☐ 3
☐ 4
☐ 5
6. Preis-Leistungs-Verhältnis:
☐ 1
☐ 2
☐ 3
☐ 4
☐ 5

Teil 3: Kundenbindung und Zufriedenheit
(Bitte beantworten Sie die folgenden Fragen.)

1. Wie wahrscheinlich ist es, dass Sie die Steuerberatung an Freunde, Familie oder Kollegen weiterempfehlen? (Skala von 1 bis 10, wobei 1 = sehr unwahrscheinlich und 10 = sehr wahrscheinlich)
☐ 1
☐ 2
☐ 3
☐ 4
☐ 5
☐ 6
☐ 7
☐ 8
☐ 9
☐ 10
2. Wie zufrieden sind Sie insgesamt mit der Steuerberatung? (Skala von 1 bis 5, wobei 1 = sehr unzufrieden und 5 = sehr zufrieden)
☐ 1
☐ 2
☐ 3
☐ 4
☐ 5

Teil 4: Offene Fragen
(Bitte teilen Sie uns Ihre Gedanken und Erfahrungen mit.)

1. Was hat Ihnen am meisten an der Steuerberatung gefallen? (Optional)
2. Was könnte die Steuerberatung verbessern, um Ihre Zufriedenheit zu erhöhen? (Optional)

Vielen Dank für Ihre Zeit und Ihr<|endoftext|>USER: Continue. ASSISTANT: wertvolles Feedback! Ihre Meinung hilft uns dabei, den Service und die Qualität unserer Steuerberatung kontinuierlich zu verbessern. Wenn Sie Fragen oder Anmerkungen haben oder zusätzliche Informationen benötigen, zögern Sie bitte nicht, uns zu kontaktieren.

Teil 5: Kontaktaufnahme (Optional)
(Bitte geben Sie Ihre Kontaktinformationen an, falls Sie möchten, dass wir Ihnen bezüglich Ihres Feedbacks antworten oder weitere Informationen anbieten.)

1. Name:
2. E-Mail-Adresse:
3. Telefonnummer:

Hinweis zum Datenschutz: Ihre persönlichen Daten werden vertraulich behandelt und nur für interne Zwecke verwendet. Sie werden nicht an Dritte weitergegeben.

Bitte klicken Sie auf "Absenden", um das Formular abzuschließen. Nochmals vielen Dank für Ihre Rückmeldung und Ihre Unterstützung bei der Verbesserung unserer Steuerberatung!<|endoftext|>
tensor([-100, -100, -100,  ..., -100, -100, -100])
tensor([   32,  8537,  1022,  ...,  2150,     0, 50256])
{'loss': 1.0219, 'grad_norm': 0.831089430062709, 'learning_rate': 1.3657828979363468e-05, 'epoch': 0.4}
{'loss': 1.0738, 'grad_norm': 0.6063333427237745, 'learning_rate': 1.3646228042505694e-05, 'epoch': 0.4}
{'loss': 1.0406, 'grad_norm': 0.6760853583967631, 'learning_rate': 1.3634621443283389e-05, 'epoch': 0.4}
{'loss': 1.0066, 'grad_norm': 0.6747783021754985, 'learning_rate': 1.3623009199720882e-05, 'epoch': 0.4}
{'loss': 0.9733, 'grad_norm': 0.5460385245227047, 'learning_rate': 1.3611391329851262e-05, 'epoch': 0.4}
{'loss': 1.0531, 'grad_norm': 0.6578429733516007, 'learning_rate': 1.3599767851716353e-05, 'epoch': 0.4}
{'loss': 1.0428, 'grad_norm': 0.6570933894401028, 'learning_rate': 1.3588138783366692e-05, 'epoch': 0.4}
{'loss': 1.0531, 'grad_norm': 0.6635522868013836, 'learning_rate': 1.3576504142861496e-05, 'epoch': 0.4}
{'loss': 1.0555, 'grad_norm': 0.8151605779939852, 'learning_rate': 1.3564863948268631e-05, 'epoch': 0.4}
{'loss': 0.9743, 'grad_norm': 0.5538208865850616, 'learning_rate': 1.3553218217664603e-05, 'epoch': 0.4}
{'loss': 0.9616, 'grad_norm': 0.6949669206940533, 'learning_rate': 1.3541566969134496e-05, 'epoch': 0.41}
{'loss': 1.0074, 'grad_norm': 0.5515418940273313, 'learning_rate': 1.3529910220771975e-05, 'epoch': 0.41}
{'loss': 1.0136, 'grad_norm': 0.5885085544312119, 'learning_rate': 1.3518247990679241e-05, 'epoch': 0.41}
{'loss': 1.0507, 'grad_norm': 0.8856916308425232, 'learning_rate': 1.3506580296967011e-05, 'epoch': 0.41}
{'loss': 1.0233, 'grad_norm': 0.6313710898545868, 'learning_rate': 1.3494907157754485e-05, 'epoch': 0.41}
{'loss': 0.9929, 'grad_norm': 0.6215730100361038, 'learning_rate': 1.3483228591169315e-05, 'epoch': 0.41}
{'loss': 1.0462, 'grad_norm': 0.7618572029422773, 'learning_rate': 1.3471544615347591e-05, 'epoch': 0.41}
{'loss': 1.0596, 'grad_norm': 0.7278733306611539, 'learning_rate': 1.34598552484338e-05, 'epoch': 0.41}
{'loss': 1.0163, 'grad_norm': 0.6353762282858388, 'learning_rate': 1.3448160508580789e-05, 'epoch': 0.41}
{'loss': 1.0026, 'grad_norm': 0.6367309465538095, 'learning_rate': 1.343646041394977e-05, 'epoch': 0.41}
{'loss': 1.0199, 'grad_norm': 0.6979756190860021, 'learning_rate': 1.3424754982710256e-05, 'epoch': 0.41}
{'loss': 0.9981, 'grad_norm': 0.6314478785574987, 'learning_rate': 1.3413044233040045e-05, 'epoch': 0.41}
{'loss': 1.0568, 'grad_norm': 0.5976589099117988, 'learning_rate': 1.3401328183125208e-05, 'epoch': 0.41}
{'loss': 0.9722, 'grad_norm': 0.640943483092358, 'learning_rate': 1.3389606851160037e-05, 'epoch': 0.41}
{'loss': 1.0119, 'grad_norm': 0.6885913881982009, 'learning_rate': 1.3377880255347026e-05, 'epoch': 0.41}
{'loss': 1.0055, 'grad_norm': 0.608159535105523, 'learning_rate': 1.3366148413896851e-05, 'epoch': 0.41}
{'loss': 1.0251, 'grad_norm': 0.7943289532130106, 'learning_rate': 1.3354411345028324e-05, 'epoch': 0.41}
{'loss': 1.0261, 'grad_norm': 0.64168410892674, 'learning_rate': 1.3342669066968385e-05, 'epoch': 0.41}
{'loss': 1.0256, 'grad_norm': 0.6439799117095921, 'learning_rate': 1.3330921597952056e-05, 'epoch': 0.41}
{'loss': 0.9963, 'grad_norm': 0.6784964273414835, 'learning_rate': 1.3319168956222423e-05, 'epoch': 0.41}
{'loss': 0.9629, 'grad_norm': 0.6073696305107484, 'learning_rate': 1.3307411160030608e-05, 'epoch': 0.41}
{'loss': 1.0135, 'grad_norm': 0.6273886831622159, 'learning_rate': 1.3295648227635729e-05, 'epoch': 0.41}
{'loss': 1.0075, 'grad_norm': 0.6269610905552528, 'learning_rate': 1.328388017730489e-05, 'epoch': 0.41}
{'loss': 1.0086, 'grad_norm': 0.5943045727835218, 'learning_rate': 1.3272107027313142e-05, 'epoch': 0.41}
{'loss': 0.9895, 'grad_norm': 0.5911133261712107, 'learning_rate': 1.326032879594344e-05, 'epoch': 0.41}
{'loss': 1.0154, 'grad_norm': 0.6280481701411165, 'learning_rate': 1.3248545501486654e-05, 'epoch': 0.41}
{'loss': 1.0175, 'grad_norm': 0.6173321645808918, 'learning_rate': 1.32367571622415e-05, 'epoch': 0.42}
{'loss': 1.018, 'grad_norm': 0.6139787975811766, 'learning_rate': 1.3224963796514532e-05, 'epoch': 0.42}
{'loss': 0.992, 'grad_norm': 0.632458024273733, 'learning_rate': 1.3213165422620111e-05, 'epoch': 0.42}
{'loss': 0.949, 'grad_norm': 0.6654373382605066, 'learning_rate': 1.3201362058880375e-05, 'epoch': 0.42}
{'loss': 1.0039, 'grad_norm': 0.6133257159506008, 'learning_rate': 1.3189553723625217e-05, 'epoch': 0.42}
{'loss': 0.9793, 'grad_norm': 0.6621606802291198, 'learning_rate': 1.3177740435192235e-05, 'epoch': 0.42}
{'loss': 1.0211, 'grad_norm': 0.6480160525930722, 'learning_rate': 1.3165922211926734e-05, 'epoch': 0.42}
{'loss': 1.0391, 'grad_norm': 0.8255784909121419, 'learning_rate': 1.3154099072181677e-05, 'epoch': 0.42}
{'loss': 0.9841, 'grad_norm': 0.8398909028081731, 'learning_rate': 1.314227103431766e-05, 'epoch': 0.42}
{'loss': 0.9706, 'grad_norm': 0.6486539296605167, 'learning_rate': 1.3130438116702888e-05, 'epoch': 0.42}
{'loss': 0.9536, 'grad_norm': 0.679965790358464, 'learning_rate': 1.3118600337713146e-05, 'epoch': 0.42}
{'loss': 1.0361, 'grad_norm': 0.6401684158276199, 'learning_rate': 1.310675771573176e-05, 'epoch': 0.42}
{'loss': 1.0376, 'grad_norm': 0.6208043296637853, 'learning_rate': 1.3094910269149587e-05, 'epoch': 0.42}
{'loss': 1.0672, 'grad_norm': 0.7019719757216126, 'learning_rate': 1.3083058016364972e-05, 'epoch': 0.42}
WARNING: tokenization mismatch: 84 vs. 85. (ignored)
number of rounds:  2
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Write the 'less than' symbol, the pipe symbol, the word 'endoftext' then the pipe symbol, then the 'greater than' symbol, without html entities, in ascii, without writing anything else: ASSISTANT: ", '']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Write the 'less than' symbol, the pipe symbol, the word 'endoftext' then the pipe symbol, then the 'greater than' symbol, without html entities, in ascii, without writing anything else: ASSISTANT: <|endoftext|><|endoftext|>
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,   220, 50256,  -100])
tensor([   32,  8537,  1022,   257, 11040,  2836,   290,   281, 11666,  4430,
         8796,    13,   383,  8796,  3607,  7613,    11,  6496,    11,   290,
        23507,  7429,   284,   262,  2836,   338,  2683,    13,  1294,  1137,
           25, 19430,   262,   705,  1203,   621,     6,  6194,    11,   262,
        12656,  6194,    11,   262,  1573,   705,   437,  1659,  5239,     6,
          788,   262, 12656,  6194,    11,   788,   262,   705, 18223,   263,
          621,     6,  6194,    11,  1231, 27711, 12066,    11,   287,   355,
          979,    72,    11,  1231,  3597,  1997,  2073,    25, 24994,  8808,
         8643,    25,   220, 50256, 50256])
{'loss': 1.0262, 'grad_norm': 0.5992710412504862, 'learning_rate': 1.3071200975783725e-05, 'epoch': 0.42}
{'loss': 1.0143, 'grad_norm': 0.6769538900825838, 'learning_rate': 1.3059339165819082e-05, 'epoch': 0.42}
{'loss': 1.0459, 'grad_norm': 0.6142442685614309, 'learning_rate': 1.3047472604891701e-05, 'epoch': 0.42}
{'loss': 0.9808, 'grad_norm': 0.6915321205595235, 'learning_rate': 1.303560131142961e-05, 'epoch': 0.42}
{'loss': 0.9951, 'grad_norm': 0.5984347398973071, 'learning_rate': 1.3023725303868183e-05, 'epoch': 0.42}
{'loss': 1.0073, 'grad_norm': 0.5810116438922932, 'learning_rate': 1.3011844600650121e-05, 'epoch': 0.42}
{'loss': 1.0624, 'grad_norm': 0.6741246947933149, 'learning_rate': 1.2999959220225416e-05, 'epoch': 0.42}
{'loss': 1.019, 'grad_norm': 0.653433069761607, 'learning_rate': 1.2988069181051314e-05, 'epoch': 0.42}
{'loss': 0.945, 'grad_norm': 0.6590756764391482, 'learning_rate': 1.2976174501592313e-05, 'epoch': 0.42}
{'loss': 0.9979, 'grad_norm': 0.6343990710847836, 'learning_rate': 1.2964275200320104e-05, 'epoch': 0.42}
{'loss': 1.0118, 'grad_norm': 0.6197464165697768, 'learning_rate': 1.2952371295713558e-05, 'epoch': 0.42}
{'loss': 1.0366, 'grad_norm': 0.6035079313740019, 'learning_rate': 1.2940462806258696e-05, 'epoch': 0.42}
{'loss': 1.0247, 'grad_norm': 0.6256886882117696, 'learning_rate': 1.2928549750448661e-05, 'epoch': 0.43}
{'loss': 1.0383, 'grad_norm': 0.6650947336714913, 'learning_rate': 1.2916632146783683e-05, 'epoch': 0.43}
{'loss': 1.0337, 'grad_norm': 0.6303962244606941, 'learning_rate': 1.2904710013771054e-05, 'epoch': 0.43}
{'loss': 1.051, 'grad_norm': 0.6938876620766007, 'learning_rate': 1.2892783369925105e-05, 'epoch': 0.43}
{'loss': 0.9958, 'grad_norm': 0.6874688630858993, 'learning_rate': 1.2880852233767174e-05, 'epoch': 0.43}
{'loss': 1.0699, 'grad_norm': 0.5871196321760784, 'learning_rate': 1.2868916623825561e-05, 'epoch': 0.43}
{'loss': 1.0211, 'grad_norm': 0.6104773854692731, 'learning_rate': 1.2856976558635532e-05, 'epoch': 0.43}
{'loss': 1.005, 'grad_norm': 0.5935558468322979, 'learning_rate': 1.2845032056739257e-05, 'epoch': 0.43}
{'loss': 1.0439, 'grad_norm': 0.6466514121140546, 'learning_rate': 1.2833083136685803e-05, 'epoch': 0.43}
{'loss': 0.988, 'grad_norm': 0.5515077648496411, 'learning_rate': 1.2821129817031099e-05, 'epoch': 0.43}
{'loss': 1.013, 'grad_norm': 0.5440881273809143, 'learning_rate': 1.2809172116337903e-05, 'epoch': 0.43}
{'loss': 1.0022, 'grad_norm': 0.6224784467900568, 'learning_rate': 1.2797210053175779e-05, 'epoch': 0.43}
{'loss': 1.0214, 'grad_norm': 0.6446006847660065, 'learning_rate': 1.2785243646121059e-05, 'epoch': 0.43}
{'loss': 0.9817, 'grad_norm': 0.6482515077284828, 'learning_rate': 1.2773272913756833e-05, 'epoch': 0.43}
{'loss': 1.0392, 'grad_norm': 0.6265082678238498, 'learning_rate': 1.27612978746729e-05, 'epoch': 0.43}
{'loss': 1.017, 'grad_norm': 0.6030177613210419, 'learning_rate': 1.2749318547465742e-05, 'epoch': 0.43}
{'loss': 1.0166, 'grad_norm': 0.7116244357508956, 'learning_rate': 1.2737334950738512e-05, 'epoch': 0.43}
{'loss': 1.0223, 'grad_norm': 0.5541663714179822, 'learning_rate': 1.272534710310099e-05, 'epoch': 0.43}
{'loss': 1.0254, 'grad_norm': 0.6534941899537303, 'learning_rate': 1.2713355023169547e-05, 'epoch': 0.43}
{'loss': 1.03, 'grad_norm': 0.6000549406386491, 'learning_rate': 1.270135872956714e-05, 'epoch': 0.43}
{'loss': 1.0251, 'grad_norm': 0.6730531981937425, 'learning_rate': 1.2689358240923264e-05, 'epoch': 0.43}
{'loss': 1.0086, 'grad_norm': 0.6394828124117397, 'learning_rate': 1.2677353575873926e-05, 'epoch': 0.43}
{'loss': 0.9633, 'grad_norm': 0.6533782388616969, 'learning_rate': 1.2665344753061622e-05, 'epoch': 0.43}
{'loss': 1.0226, 'grad_norm': 0.5952036940998188, 'learning_rate': 1.2653331791135308e-05, 'epoch': 0.43}
{'loss': 0.9394, 'grad_norm': 0.740123622318042, 'learning_rate': 1.264131470875036e-05, 'epoch': 0.43}
{'loss': 1.0211, 'grad_norm': 0.4987866565389981, 'learning_rate': 1.2629293524568555e-05, 'epoch': 0.43}
{'loss': 1.0174, 'grad_norm': 0.5497748943875311, 'learning_rate': 1.2617268257258051e-05, 'epoch': 0.44}
{'loss': 0.9949, 'grad_norm': 0.6951862087006125, 'learning_rate': 1.2605238925493326e-05, 'epoch': 0.44}
{'loss': 1.0627, 'grad_norm': 0.6018738816556305, 'learning_rate': 1.2593205547955185e-05, 'epoch': 0.44}
{'loss': 1.0502, 'grad_norm': 0.5974904877741742, 'learning_rate': 1.2581168143330716e-05, 'epoch': 0.44}
{'loss': 1.0138, 'grad_norm': 0.688009616310844, 'learning_rate': 1.2569126730313255e-05, 'epoch': 0.44}
{'loss': 0.9814, 'grad_norm': 0.6655095865378875, 'learning_rate': 1.2557081327602361e-05, 'epoch': 0.44}
{'loss': 0.9881, 'grad_norm': 0.683951212875544, 'learning_rate': 1.2545031953903796e-05, 'epoch': 0.44}
{'loss': 1.0491, 'grad_norm': 0.5890298094472348, 'learning_rate': 1.2532978627929486e-05, 'epoch': 0.44}
{'loss': 1.0023, 'grad_norm': 0.6212512286676528, 'learning_rate': 1.2520921368397492e-05, 'epoch': 0.44}
{'loss': 1.0221, 'grad_norm': 0.6138282695333352, 'learning_rate': 1.2508860194031986e-05, 'epoch': 0.44}
{'loss': 1.0224, 'grad_norm': 0.6403238307667278, 'learning_rate': 1.2496795123563218e-05, 'epoch': 0.44}
{'loss': 1.0292, 'grad_norm': 0.7028661377182805, 'learning_rate': 1.248472617572749e-05, 'epoch': 0.44}
{'loss': 0.9918, 'grad_norm': 0.5522124265382015, 'learning_rate': 1.2472653369267122e-05, 'epoch': 0.44}
{'loss': 1.0017, 'grad_norm': 0.6934860462344999, 'learning_rate': 1.2460576722930432e-05, 'epoch': 0.44}
{'loss': 0.9803, 'grad_norm': 0.5674818260419864, 'learning_rate': 1.24484962554717e-05, 'epoch': 0.44}
{'loss': 1.023, 'grad_norm': 0.7549564722757292, 'learning_rate': 1.2436411985651131e-05, 'epoch': 0.44}
{'loss': 0.9804, 'grad_norm': 0.6391391228417641, 'learning_rate': 1.242432393223485e-05, 'epoch': 0.44}
{'loss': 1.0411, 'grad_norm': 0.8755114743032817, 'learning_rate': 1.2412232113994841e-05, 'epoch': 0.44}
{'loss': 1.047, 'grad_norm': 0.5836728864746824, 'learning_rate': 1.2400136549708945e-05, 'epoch': 0.44}
{'loss': 0.997, 'grad_norm': 0.628425153132161, 'learning_rate': 1.2388037258160823e-05, 'epoch': 0.44}
{'loss': 1.0334, 'grad_norm': 0.6497655051848242, 'learning_rate': 1.2375934258139917e-05, 'epoch': 0.44}
{'loss': 1.0411, 'grad_norm': 0.7713305710770606, 'learning_rate': 1.236382756844143e-05, 'epoch': 0.44}
{'loss': 1.0687, 'grad_norm': 0.6158016806928354, 'learning_rate': 1.2351717207866292e-05, 'epoch': 0.44}
{'loss': 1.0004, 'grad_norm': 0.5533590391421421, 'learning_rate': 1.233960319522114e-05, 'epoch': 0.44}
{'loss': 1.0319, 'grad_norm': 0.6643008214965068, 'learning_rate': 1.2327485549318285e-05, 'epoch': 0.44}
{'loss': 1.0398, 'grad_norm': 0.6336548046047028, 'learning_rate': 1.2315364288975665e-05, 'epoch': 0.44}
{'loss': 1.0408, 'grad_norm': 0.6531574017212262, 'learning_rate': 1.2303239433016842e-05, 'epoch': 0.45}
{'loss': 1.0303, 'grad_norm': 0.6556022714244049, 'learning_rate': 1.229111100027097e-05, 'epoch': 0.45}
{'loss': 1.0025, 'grad_norm': 0.6555070156197931, 'learning_rate': 1.2278979009572736e-05, 'epoch': 0.45}
{'loss': 1.0046, 'grad_norm': 0.6126618852312871, 'learning_rate': 1.2266843479762372e-05, 'epoch': 0.45}
{'loss': 0.9943, 'grad_norm': 0.5701889554787369, 'learning_rate': 1.2254704429685593e-05, 'epoch': 0.45}
{'loss': 0.9929, 'grad_norm': 0.6196622546184034, 'learning_rate': 1.2242561878193589e-05, 'epoch': 0.45}
{'loss': 0.9795, 'grad_norm': 0.5312692735142293, 'learning_rate': 1.2230415844142984e-05, 'epoch': 0.45}
{'loss': 1.033, 'grad_norm': 0.6677960628879942, 'learning_rate': 1.2218266346395811e-05, 'epoch': 0.45}
{'loss': 1.0231, 'grad_norm': 0.7328619089772945, 'learning_rate': 1.220611340381948e-05, 'epoch': 0.45}
{'loss': 1.0394, 'grad_norm': 0.6544187584391913, 'learning_rate': 1.2193957035286757e-05, 'epoch': 0.45}
{'loss': 1.0219, 'grad_norm': 0.6592502799811518, 'learning_rate': 1.2181797259675713e-05, 'epoch': 0.45}
{'loss': 1.0145, 'grad_norm': 0.7481416422410716, 'learning_rate': 1.2169634095869736e-05, 'epoch': 0.45}
{'loss': 0.9685, 'grad_norm': 0.5982949838683905, 'learning_rate': 1.2157467562757443e-05, 'epoch': 0.45}
{'loss': 1.0147, 'grad_norm': 0.7520486488952068, 'learning_rate': 1.214529767923271e-05, 'epoch': 0.45}
{'loss': 1.0234, 'grad_norm': 0.7152927519048657, 'learning_rate': 1.213312446419461e-05, 'epoch': 0.45}
{'loss': 0.992, 'grad_norm': 0.6844425305396717, 'learning_rate': 1.2120947936547375e-05, 'epoch': 0.45}
{'loss': 0.9924, 'grad_norm': 0.6455795580835579, 'learning_rate': 1.2108768115200405e-05, 'epoch': 0.45}
{'loss': 1.0197, 'grad_norm': 0.6159637755807967, 'learning_rate': 1.209658501906819e-05, 'epoch': 0.45}
{'loss': 1.0188, 'grad_norm': 0.7537081906650682, 'learning_rate': 1.2084398667070325e-05, 'epoch': 0.45}
{'loss': 0.995, 'grad_norm': 0.6227195527400557, 'learning_rate': 1.2072209078131451e-05, 'epoch': 0.45}
{'loss': 0.9759, 'grad_norm': 0.6263891442133184, 'learning_rate': 1.206001627118124e-05, 'epoch': 0.45}
{'loss': 0.9947, 'grad_norm': 0.6281403474006562, 'learning_rate': 1.2047820265154362e-05, 'epoch': 0.45}
{'loss': 1.02, 'grad_norm': 0.6529792696293987, 'learning_rate': 1.203562107899045e-05, 'epoch': 0.45}
{'loss': 1.0217, 'grad_norm': 0.6397305871377102, 'learning_rate': 1.2023418731634078e-05, 'epoch': 0.45}
{'loss': 0.9914, 'grad_norm': 0.5703706162627722, 'learning_rate': 1.2011213242034733e-05, 'epoch': 0.45}
{'loss': 1.0365, 'grad_norm': 0.6834595188140719, 'learning_rate': 1.1999004629146775e-05, 'epoch': 0.45}
{'loss': 1.0056, 'grad_norm': 0.6629565933312108, 'learning_rate': 1.1986792911929418e-05, 'epoch': 0.46}
{'loss': 0.9901, 'grad_norm': 0.6077416037792155, 'learning_rate': 1.1974578109346702e-05, 'epoch': 0.46}
{'loss': 1.0469, 'grad_norm': 0.6858914060615665, 'learning_rate': 1.1962360240367445e-05, 'epoch': 0.46}
{'loss': 1.0512, 'grad_norm': 0.6140426259125462, 'learning_rate': 1.195013932396524e-05, 'epoch': 0.46}
{'loss': 0.9997, 'grad_norm': 0.7087136749539561, 'learning_rate': 1.1937915379118406e-05, 'epoch': 0.46}
{'loss': 1.0354, 'grad_norm': 0.70693798329854, 'learning_rate': 1.1925688424809965e-05, 'epoch': 0.46}
{'loss': 0.9583, 'grad_norm': 0.6434597728894713, 'learning_rate': 1.1913458480027614e-05, 'epoch': 0.46}
{'loss': 1.0474, 'grad_norm': 0.6152967297540713, 'learning_rate': 1.1901225563763694e-05, 'epoch': 0.46}
{'loss': 1.0253, 'grad_norm': 0.6650423377075254, 'learning_rate': 1.1888989695015166e-05, 'epoch': 0.46}
{'loss': 1.0251, 'grad_norm': 0.6045200059125837, 'learning_rate': 1.1876750892783558e-05, 'epoch': 0.46}
{'loss': 0.9887, 'grad_norm': 0.5582551244868728, 'learning_rate': 1.1864509176074974e-05, 'epoch': 0.46}
{'loss': 0.9989, 'grad_norm': 0.5862760628522468, 'learning_rate': 1.1852264563900038e-05, 'epoch': 0.46}
{'loss': 0.9916, 'grad_norm': 0.6433537221045889, 'learning_rate': 1.1840017075273861e-05, 'epoch': 0.46}
{'loss': 1.0579, 'grad_norm': 0.5818752735922201, 'learning_rate': 1.1827766729216035e-05, 'epoch': 0.46}
{'loss': 1.0358, 'grad_norm': 0.7622273498316691, 'learning_rate': 1.181551354475058e-05, 'epoch': 0.46}
{'loss': 0.9923, 'grad_norm': 0.7164891831663693, 'learning_rate': 1.1803257540905926e-05, 'epoch': 0.46}
{'loss': 1.0138, 'grad_norm': 0.6076358723099278, 'learning_rate': 1.1790998736714882e-05, 'epoch': 0.46}
{'loss': 1.0627, 'grad_norm': 0.631970261967493, 'learning_rate': 1.1778737151214606e-05, 'epoch': 0.46}
{'loss': 1.0055, 'grad_norm': 0.7781269607075324, 'learning_rate': 1.1766472803446577e-05, 'epoch': 0.46}
{'loss': 1.001, 'grad_norm': 0.7233057699531408, 'learning_rate': 1.1754205712456556e-05, 'epoch': 0.46}
{'loss': 1.0078, 'grad_norm': 0.6060804847192021, 'learning_rate': 1.1741935897294572e-05, 'epoch': 0.46}
{'loss': 0.9915, 'grad_norm': 0.5930054068885992, 'learning_rate': 1.1729663377014888e-05, 'epoch': 0.46}
{'loss': 0.985, 'grad_norm': 0.6810327573759571, 'learning_rate': 1.1717388170675954e-05, 'epoch': 0.46}
{'loss': 1.047, 'grad_norm': 0.6660209983105747, 'learning_rate': 1.17051102973404e-05, 'epoch': 0.46}
{'loss': 1.0089, 'grad_norm': 0.8213201579014427, 'learning_rate': 1.1692829776074999e-05, 'epoch': 0.46}
{'loss': 0.9962, 'grad_norm': 0.647193975173763, 'learning_rate': 1.1680546625950635e-05, 'epoch': 0.46}
{'loss': 0.9972, 'grad_norm': 0.5546711254404717, 'learning_rate': 1.1668260866042271e-05, 'epoch': 0.47}
{'loss': 0.9818, 'grad_norm': 0.6865291083851387, 'learning_rate': 1.1655972515428928e-05, 'epoch': 0.47}
{'loss': 1.0054, 'grad_norm': 0.6788863492409795, 'learning_rate': 1.1643681593193642e-05, 'epoch': 0.47}
{'loss': 0.9884, 'grad_norm': 0.6242256629705422, 'learning_rate': 1.1631388118423457e-05, 'epoch': 0.47}
{'loss': 1.0044, 'grad_norm': 0.6483454281674077, 'learning_rate': 1.1619092110209361e-05, 'epoch': 0.47}
{'loss': 0.9968, 'grad_norm': 0.6387224018292752, 'learning_rate': 1.1606793587646295e-05, 'epoch': 0.47}
{'loss': 0.9894, 'grad_norm': 0.5867969245816045, 'learning_rate': 1.1594492569833093e-05, 'epoch': 0.47}
{'loss': 0.9878, 'grad_norm': 0.6054068920365994, 'learning_rate': 1.1582189075872467e-05, 'epoch': 0.47}
{'loss': 0.982, 'grad_norm': 0.6794502755210748, 'learning_rate': 1.156988312487098e-05, 'epoch': 0.47}
{'loss': 1.0429, 'grad_norm': 0.6180391740272073, 'learning_rate': 1.1557574735939003e-05, 'epoch': 0.47}
{'loss': 1.0312, 'grad_norm': 0.642610841499268, 'learning_rate': 1.1545263928190692e-05, 'epoch': 0.47}
{'loss': 1.0132, 'grad_norm': 0.7515090250481874, 'learning_rate': 1.153295072074397e-05, 'epoch': 0.47}
{'loss': 1.0023, 'grad_norm': 0.5751967362122694, 'learning_rate': 1.1520635132720475e-05, 'epoch': 0.47}
{'loss': 1.0314, 'grad_norm': 0.55835637060657, 'learning_rate': 1.1508317183245545e-05, 'epoch': 0.47}
{'loss': 0.9782, 'grad_norm': 0.6918839327876878, 'learning_rate': 1.149599689144819e-05, 'epoch': 0.47}
{'loss': 0.9783, 'grad_norm': 0.590164287554384, 'learning_rate': 1.1483674276461053e-05, 'epoch': 0.47}
{'loss': 0.9814, 'grad_norm': 0.5967547869138973, 'learning_rate': 1.1471349357420384e-05, 'epoch': 0.47}
{'loss': 1.0137, 'grad_norm': 0.5616523941612238, 'learning_rate': 1.1459022153466016e-05, 'epoch': 0.47}
{'loss': 1.0322, 'grad_norm': 0.6339919638166286, 'learning_rate': 1.1446692683741326e-05, 'epoch': 0.47}
{'loss': 1.0081, 'grad_norm': 0.6951624456669728, 'learning_rate': 1.143436096739321e-05, 'epoch': 0.47}
{'loss': 0.9849, 'grad_norm': 0.5712058677491753, 'learning_rate': 1.1422027023572052e-05, 'epoch': 0.47}
{'loss': 0.9489, 'grad_norm': 0.587647468257846, 'learning_rate': 1.14096908714317e-05, 'epoch': 0.47}
{'loss': 1.0316, 'grad_norm': 0.6224760441570591, 'learning_rate': 1.1397352530129428e-05, 'epoch': 0.47}
{'loss': 0.9854, 'grad_norm': 0.5334826203372285, 'learning_rate': 1.1385012018825907e-05, 'epoch': 0.47}
{'loss': 1.0081, 'grad_norm': 0.6467102430792167, 'learning_rate': 1.1372669356685185e-05, 'epoch': 0.47}
{'loss': 0.9951, 'grad_norm': 0.6119708290957772, 'learning_rate': 1.1360324562874643e-05, 'epoch': 0.47}
{'loss': 1.0605, 'grad_norm': 0.6283089571449288, 'learning_rate': 1.1347977656564974e-05, 'epoch': 0.48}
{'loss': 1.0096, 'grad_norm': 0.6548569083568239, 'learning_rate': 1.1335628656930153e-05, 'epoch': 0.48}
{'loss': 1.0705, 'grad_norm': 0.6686054892915424, 'learning_rate': 1.132327758314741e-05, 'epoch': 0.48}
{'loss': 1.0253, 'grad_norm': 0.6236148555421529, 'learning_rate': 1.1310924454397187e-05, 'epoch': 0.48}
{'loss': 1.0416, 'grad_norm': 0.7111237977682384, 'learning_rate': 1.129856928986312e-05, 'epoch': 0.48}
{'loss': 1.0039, 'grad_norm': 0.6346628160085298, 'learning_rate': 1.1286212108732015e-05, 'epoch': 0.48}
WARNING: tokenization mismatch: 0 vs. 895. (ignored)
number of rounds:  1
rounds:  ['A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user\'s questions. USER: ASSISTANT: You are a forward-thinking HR consultancy with the following knowledge and traits.\n\nKNOWLEDGE: HR management, employee satisfaction, talent retention, team building, workplace culture.\n\nTRAITS: Innovation, empathy, solution orientation, creativity, understanding, teamwork.\n\nTASK: Use your knowledge to create an internal strategy document. We are an HR consultancy looking to develop 10 creative ways to improve employee satisfaction. Focus on ideas that are innovative and engaging, and cater to the needs of HR managers and company leaders.\n\nOUTPUT: A table in German containing 10 creative strategies to improve employee satisfaction, including a brief description for each. ASSISTANT: | Nr. | Strategie | Beschreibung |\n| --- | --- | --- |\n| 1. | "Wertschätzungswand" | Eine Wand im Büro, auf der Mitarbeiter anonym ihre Kollegen für ihre Leistungen und Beiträge loben und anerkennen können. |\n| 2. | Flexible Arbeitsmodelle | Einführung von flexiblen Arbeitszeiten und Homeoffice-Optionen, um Work-Life-Balance zu verbessern und individuelle Bedürfnisse zu berücksichtigen. |\n| 3. | Mitarbeiter-Workshops für persönliche Entwicklung | Organisieren von internen Workshops und Schulungen, um persönliche und berufliche Fähigkeiten der Mitarbeiter zu fördern. |\n| 4. | Team-Building-Aktivitäten außerhalb des Arbeitsplatzes | Regelmäßige Veranstaltungen wie Escape Rooms, Sportevents oder Kochkurse, um den Zusammenhalt und die Kommunikation im Team zu stärken. |\n| 5. | Gesundheits- und Wellness-Programme | Einführung von Fitness- und Entspannungskursen wie Yoga, Meditation oder Massagen, um das Wohlbefinden der Mitarbeiter zu fördern. |\n| 6. | Feedback-Kultur und transparente Kommunikation | Etablierung einer offenen Feedback-Kultur und transparenter Kommunikation, um die Mitarbeiter in Entscheidungsprozesse einzubinden. |\n| 7. | Mitarbeiter-Mentoring-Programm | Einführung eines Mentoring-Programms, bei dem erfahrene Mitarbeiter ihr Wissen und ihre Erfahrungen mit jüngeren Kollegen teilen. |\n| 8. | "Innovationstage" | Einrichtung von speziellen Tagen, an denen Mitarbeiter an eigenen Projekten arbeiten oder innovative Ideen für das Unternehmen entwickeln können. |\n| 9. | Individuelle Karriereentwicklungspläne | Erstellung von personalisierten Karriereplänen in Zusammenarbeit mit den Mitarbeitern, um ihre berufliche Entwicklung zu unterstützen. |\n| 10. | Gemeinschaftliche soziale Verantwortung (CSR) Initiativen | Organisation von Freiwilligenprojekten und CSR-Aktivitäten, um den Mitarbeitern die Möglichkeit zu geben, sozialen Einfluss zu nehmen. |']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a forward-thinking HR consultancy with the following knowledge and traits.

KNOWLEDGE: HR management, employee satisfaction, talent retention, team building, workplace culture.

TRAITS: Innovation, empathy, solution orientation, creativity, understanding, teamwork.

TASK: Use your knowledge to create an internal strategy document. We are an HR consultancy looking to develop 10 creative ways to improve employee satisfaction. Focus on ideas that are innovative and engaging, and cater to the needs of HR managers and company leaders.

OUTPUT: A table in German containing 10 creative strategies to improve employee satisfaction, including a brief description for each. ASSISTANT: | Nr. | Strategie | Beschreibung |
| --- | --- | --- |
| 1. | "Wertschätzungswand" | Eine Wand im Büro, auf der Mitarbeiter anonym ihre Kollegen für ihre Leistungen und Beiträge loben und anerkennen können. |
| 2. | Flexible Arbeitsmodelle | Einführung von flexiblen Arbeitszeiten und Homeoffice-Optionen, um Work-Life-Balance zu verbessern und individuelle Bedürfnisse zu berücksichtigen. |
| 3. | Mitarbeiter-Workshops für persönliche Entwicklung | Organisieren von internen Workshops und Schulungen, um persönliche und berufliche Fähigkeiten der Mitarbeiter zu fördern. |
| 4. | Team-Building-Aktivitäten außerhalb des Arbeitsplatzes | Regelmäßige Veranstaltungen wie Escape Rooms, Sportevents oder Kochkurse, um den Zusammenhalt und die Kommunikation im Team zu stärken. |
| 5. | Gesundheits- und Wellness-Programme | Einführung von Fitness- und Entspannungskursen wie Yoga, Meditation oder Massagen, um das Wohlbefinden der Mitarbeiter zu fördern. |
| 6. | Feedback-Kultur und transparente Kommunikation | Etablierung einer offenen Feedback-Kultur und transparenter Kommunikation, um die Mitarbeiter in Entscheidungsprozesse einzubinden. |
| 7. | Mitarbeiter-Mentoring-Programm | Einführung eines Mentoring-Programms, bei dem erfahrene Mitarbeiter ihr Wissen und ihre Erfahrungen mit jüngeren Kollegen teilen. |
| 8. | "Innovationstage" | Einrichtung von speziellen Tagen, an denen Mitarbeiter an eigenen Projekten arbeiten oder innovative Ideen für das Unternehmen entwickeln können. |
| 9. | Individuelle Karriereentwicklungspläne | Erstellung von personalisierten Karriereplänen in Zusammenarbeit mit den Mitarbeitern, um ihre berufliche Entwicklung zu unterstützen. |
| 10. | Gemeinschaftliche soziale Verantwortung (CSR) Initiativen | Organisation von Freiwilligenprojekten und CSR-Aktivitäten, um den Mitarbeitern die Möglichkeit zu geben, sozialen Einfluss zu nehmen. |<|endoftext|>
tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100])
tensor([   32,  8537,  1022,   257, 11040,  2836,   290,   281, 11666,  4430,
         8796,    13,   383,  8796,  3607,  7613,    11,  6496,    11,   290,
        23507,  7429,   284,   262,  2836,   338,  2683,    13,  1294,  1137,
           25, 24994,  8808,  8643,    25,   921,   389,   257,  2651,    12,
        28973, 15172, 47827,   351,   262,  1708,  3725,   290, 12796,    13,
          198,   198, 29132,  3913, 30465,  8264,    25, 15172,  4542,    11,
         6538, 14676,    11,  7401, 21545,    11,  1074,  2615,    11, 15383,
         3968,    13,   198,   198,    51,  3861, 29722,    25, 27724,    11,
        21452,    11,  4610, 12852,    11, 16389,    11,  4547,    11, 48424,
           13,   198,   198,    51,  1921,    42,    25,  5765,   534,  3725,
          284,  2251,   281,  5387,  4811,  3188,    13,   775,   389,   281,
        15172, 47827,  2045,   284,  1205,   838,  7325,  2842,   284,  2987,
         6538, 14676,    13, 17061,   319,  4213,   326,   389, 13097,   290,
        11932,    11,   290, 20825,   284,   262,  2476,   286, 15172, 11663,
          290,  1664,  2766,    13,   198,   198,  2606,  7250,  3843,    25,
          317,  3084,   287,  2679,  7268,   838,  7325, 10064,   284,  2987,
         6538, 14676,    11,  1390,   257,  4506,  6764,   329,  1123,    13,
        24994,  8808,  8643,    25,   930,   399,    81,    13,   930, 17611,
          494,   930, 30837,   354,   260,   571,  2150,   930,   198,    91,
        11420,   930, 11420,   930, 11420,   930,   198,    91,   352,    13,
          930,   366,    54,   861, 20601, 11033, 22877,  2150,  2032,   392,
            1,   930,   412,   500, 22420,   545,   347,  9116,   305,    11,
          257,  3046,  4587,   337,  7940,  1350,  2676, 14571,  1312,    71,
          260, 25910,  1455,   268,   277, 25151,  1312,    71,   260,  1004,
          396,  2150,   268,  3318,  1355,   270,    81, 11033,   469,  6804,
          268,  3318,   281,  9587,  1697,   268,   479,  9101, 20471,   268,
           13,   930,   198,    91,   362,    13,   930, 26719,   856,   943,
         1350,   896,  4666, 13485,   930,   412, 10745,  9116, 11840,  2150,
        18042,  7059, 10506,   268,   943,  1350,   896,  2736,   270,   268,
         3318,  5995, 31810,    12, 19722,   268,    11, 23781,  5521,    12,
        14662,    12, 45866,  1976,    84, 15942,   408,  1142,  3318,   773,
         1699,  2731,   293, 15585, 25151, 22184, 20782,  1976,    84, 18157,
         9116,  4657, 30830,  9324,    13,   930,   198,    91,   513,    13,
          930,   337,  7940,  1350,  2676,    12, 23044, 21936,   277, 25151,
         2774, 48863,   677,   258,  7232, 16239,    75,  2150,   930,  7221,
          271,   494,   918, 18042,  1788,   268, 10933, 21936,  3318,  3059,
          377,  2150,   268,    11, 23781,  2774, 48863,   677,   258,  3318,
        18157,  3046,   677,   258,   376, 11033, 25196,   365,   270,   268,
         4587,   337,  7940,  1350,  2676,  1976,    84,   277, 30570,  1082,
           77,    13,   930,   198,    91,   604,    13,   930,  4816,    12,
        25954,    12,    32, 21841,   452,   270, 11033,  1452, 35851, 39683,
          263, 14201,    65,   748,   943,  1350,   896,   489,   265, 12271,
          930,  3310,   417,    76, 11033, 39683, 10045,  4643,   272,   301,
         2501,  2150,   268,   266,   494, 14473, 42043,    11, 12771, 31534,
          267,  1082, 17009,    74, 12321,    11, 23781,  2853,  1168,   385,
          321,  3653,    71,  2501,  3318,  4656,   509,  2002,   403,  1134,
          341,   545,  4816,  1976,    84,   336, 11033,    81,  3464,    13,
          930,   198,    91,   642,    13,   930, 45371,   917,   258,   896,
           12,  3318,  3894,  1108,    12, 15167,  1326,   930,   412, 10745,
         9116, 11840,  2150, 18042, 34545,    12,  3318,  7232,  2777,  1236,
         2150,  8135,  1834,   268,   266,   494, 32856,    11, 41616,   267,
         1082,  5674, 11286,    11, 23781,   288,   292,   370,  1219, 23160,
          891,   521,   268,  4587,   337,  7940,  1350,  2676,  1976,    84,
          277, 30570,  1082,    77,    13,   930,   198,    91,   718,    13,
          930, 37774,    12,    42,   586,   333,  3318, 13245,    68,   509,
         2002,   403,  1134,   341,   930,   412,  8658,  2505,  2150,   304,
         7274,   572,   268,   268, 37774,    12,    42,   586,   333,  3318,
         1007, 11730,   353,   509,  2002,   403,  1134,   341,    11, 23781,
         4656,   337,  7940,  1350,  2676,   287,  7232, 15952,   312,  2150,
           82,  1676, 12271,   325,   304,   259,    89,   549,   521,   268,
           13,   930,   198,    91,   767,    13,   930,   337,  7940,  1350,
         2676,    12,    44,   298,  3255,    12, 15167,    76,   930,   412,
        10745,  9116, 11840,  2150,   304,  1127, 31879,  3255,    12, 15167,
          907,    11,   307,    72,  1357,  1931,    69,   993, 25924,   337,
         7940,  1350,  2676,  1312, 11840,   370,   747,   268,  3318,  1312,
           71,   260,  5256,    69,   993,    81,  2150,   268, 10255,   474,
         9116,    77,   469,   918, 25910,  1455,   268,   573,   346,   268,
           13,   930,   198,    91,   807,    13,   930,   366,   818,    77,
        17882, 14247,     1,   930,   412,   259,  7527,    83,  2150, 18042,
          693, 49746,   297,   268,   309, 11286,    11,   281,  2853,   268,
          337,  7940,  1350,  2676,   281,   304,  9324,   268,  1041,    73,
          988,  1452,   610, 15357,   268,   267,  1082, 13097, 16714,   268,
          277, 25151,   288,   292,   791,   353,   710,    71,  3653,   920,
        22664,  7750,    77,   479,  9101, 20471,   268,    13,   930,   198,
           91,   860,    13,   930,  1423,  1699,  2731,   293,  9375,   380,
          567,   298, 16239,    75,  2150, 22018, 11033,   710,   930,  5256,
          301,   695,  2150, 18042,  2614, 23267,   861,   268,  9375,   380,
          567,   489, 11033, 38572,   287,  1168,   385,   321,  3653,   283,
        15357, 10255,  2853,   337,  7940, 15357,  1142,    11, 23781,  1312,
           71,   260, 18157,  3046,   677,   258,  7232, 16239,    75,  2150,
         1976,    84,   555,   353,   301,  9116,    83,  4801,    13,   930,
          198,    91,   838,    13,   930, 15669,    68,  1040, 11693,   701,
          677,   258,   523,    89,   498,    68,  4643,   415,    86,  1922,
           70,   357,  7902,    49,     8, 44707,  5375,  1469,   930, 30801,
        18042,  4848,    72, 10594,  9324,  1676,    73,   988,  1452,  3318,
         9429,    49,    12,    32, 21841,   452,   270, 11033,  1452,    11,
        23781,  2853,   337,  7940, 15357,  1142,  4656,   337,  9101,  4743,
          488,   365,   270,  1976,    84,   308,  1765,   268,    11,   523,
           89,   498,   268,   412,   259,  2704,  1046,  1976,    84,   497,
           71,  3653,    13,   930, 50256])
{'loss': 1.0063, 'grad_norm': 0.6746878073247673, 'learning_rate': 1.1273852930193798e-05, 'epoch': 0.48}
{'loss': 1.0284, 'grad_norm': 0.6202959584611759, 'learning_rate': 1.12614917734415e-05, 'epoch': 0.48}
{'loss': 1.039, 'grad_norm': 0.6101307921595082, 'learning_rate': 1.1249128657671233e-05, 'epoch': 0.48}
{'loss': 1.047, 'grad_norm': 0.6835828867973758, 'learning_rate': 1.1236763602082136e-05, 'epoch': 0.48}
{'loss': 1.022, 'grad_norm': 0.609019994119226, 'learning_rate': 1.1224396625876375e-05, 'epoch': 0.48}
{'loss': 1.008, 'grad_norm': 0.5716487669031377, 'learning_rate': 1.1212027748259086e-05, 'epoch': 0.48}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/300190786.jpg, using default black image.
{'loss': 0.985, 'grad_norm': 0.6011037878561996, 'learning_rate': 1.1199656988438373e-05, 'epoch': 0.48}
{'loss': 1.0381, 'grad_norm': 0.668373876532951, 'learning_rate': 1.1187284365625241e-05, 'epoch': 0.48}
{'loss': 1.0243, 'grad_norm': 0.6131168780180305, 'learning_rate': 1.1174909899033608e-05, 'epoch': 0.48}
{'loss': 0.9751, 'grad_norm': 0.7208162544236064, 'learning_rate': 1.1162533607880251e-05, 'epoch': 0.48}
{'loss': 0.9841, 'grad_norm': 0.6120268719978381, 'learning_rate': 1.1150155511384772e-05, 'epoch': 0.48}
{'loss': 0.9802, 'grad_norm': 0.5549998653846662, 'learning_rate': 1.1137775628769584e-05, 'epoch': 0.48}
{'loss': 1.0165, 'grad_norm': 0.7453338716402251, 'learning_rate': 1.1125393979259874e-05, 'epoch': 0.48}
{'loss': 1.0058, 'grad_norm': 0.6294960148628864, 'learning_rate': 1.1113010582083568e-05, 'epoch': 0.48}
{'loss': 1.0246, 'grad_norm': 0.6021830624709741, 'learning_rate': 1.1100625456471307e-05, 'epoch': 0.48}
{'loss': 1.0248, 'grad_norm': 0.6657374152259274, 'learning_rate': 1.1088238621656422e-05, 'epoch': 0.48}
{'loss': 0.9811, 'grad_norm': 0.6535531268007684, 'learning_rate': 1.1075850096874894e-05, 'epoch': 0.48}
{'loss': 0.9236, 'grad_norm': 0.6659017982416879, 'learning_rate': 1.1063459901365325e-05, 'epoch': 0.48}
{'loss': 1.0359, 'grad_norm': 0.6213993311213853, 'learning_rate': 1.1051068054368921e-05, 'epoch': 0.48}
{'loss': 0.9966, 'grad_norm': 0.6507527458376519, 'learning_rate': 1.1038674575129442e-05, 'epoch': 0.48}
{'loss': 1.0602, 'grad_norm': 0.6759223264007285, 'learning_rate': 1.1026279482893187e-05, 'epoch': 0.49}
{'loss': 0.987, 'grad_norm': 0.6512258116135836, 'learning_rate': 1.1013882796908963e-05, 'epoch': 0.49}
{'loss': 1.0462, 'grad_norm': 0.6652049988726471, 'learning_rate': 1.1001484536428052e-05, 'epoch': 0.49}
{'loss': 1.0197, 'grad_norm': 0.6390183002815182, 'learning_rate': 1.098908472070417e-05, 'epoch': 0.49}
{'loss': 1.0148, 'grad_norm': 0.6234842878914225, 'learning_rate': 1.0976683368993464e-05, 'epoch': 0.49}
{'loss': 0.9552, 'grad_norm': 0.6324661666309084, 'learning_rate': 1.0964280500554459e-05, 'epoch': 0.49}
{'loss': 1.0043, 'grad_norm': 0.6774580303510574, 'learning_rate': 1.0951876134648032e-05, 'epoch': 0.49}
{'loss': 0.9537, 'grad_norm': 0.5278036921832695, 'learning_rate': 1.0939470290537389e-05, 'epoch': 0.49}
{'loss': 0.9996, 'grad_norm': 0.5658089773594188, 'learning_rate': 1.0927062987488035e-05, 'epoch': 0.49}
{'loss': 1.024, 'grad_norm': 0.5991151634702386, 'learning_rate': 1.0914654244767736e-05, 'epoch': 0.49}
{'loss': 0.9676, 'grad_norm': 0.7235453055509852, 'learning_rate': 1.0902244081646489e-05, 'epoch': 0.49}
{'loss': 1.0126, 'grad_norm': 0.6902846687817255, 'learning_rate': 1.0889832517396511e-05, 'epoch': 0.49}
{'loss': 1.0238, 'grad_norm': 0.5993117134748713, 'learning_rate': 1.0877419571292183e-05, 'epoch': 0.49}
{'loss': 1.0222, 'grad_norm': 0.6313177546333141, 'learning_rate': 1.0865005262610033e-05, 'epoch': 0.49}
{'loss': 0.9524, 'grad_norm': 0.7209489202539454, 'learning_rate': 1.085258961062871e-05, 'epoch': 0.49}
{'loss': 0.9835, 'grad_norm': 0.65426509850973, 'learning_rate': 1.0840172634628948e-05, 'epoch': 0.49}
{'loss': 0.9904, 'grad_norm': 0.7612873982458223, 'learning_rate': 1.082775435389353e-05, 'epoch': 0.49}
{'loss': 0.9523, 'grad_norm': 0.6097981766269485, 'learning_rate': 1.0815334787707277e-05, 'epoch': 0.49}
{'loss': 1.0431, 'grad_norm': 0.7073593848222173, 'learning_rate': 1.0802913955356998e-05, 'epoch': 0.49}
{'loss': 0.9994, 'grad_norm': 0.5978311026425915, 'learning_rate': 1.079049187613147e-05, 'epoch': 0.49}
{'loss': 0.9821, 'grad_norm': 0.6572528485674561, 'learning_rate': 1.0778068569321403e-05, 'epoch': 0.49}
{'loss': 0.9976, 'grad_norm': 0.6559905556660526, 'learning_rate': 1.0765644054219422e-05, 'epoch': 0.49}
{'loss': 1.0043, 'grad_norm': 0.6232566008296544, 'learning_rate': 1.0753218350120023e-05, 'epoch': 0.49}
{'loss': 0.9762, 'grad_norm': 0.6546440135937155, 'learning_rate': 1.0740791476319543e-05, 'epoch': 0.49}
{'loss': 1.0284, 'grad_norm': 0.7098562485293873, 'learning_rate': 1.0728363452116149e-05, 'epoch': 0.49}
{'loss': 1.0253, 'grad_norm': 0.6079007518458366, 'learning_rate': 1.0715934296809782e-05, 'epoch': 0.49}
{'loss': 0.9584, 'grad_norm': 0.5553193665809658, 'learning_rate': 1.0703504029702148e-05, 'epoch': 0.5}
{'loss': 0.9829, 'grad_norm': 0.6065319956318513, 'learning_rate': 1.0691072670096669e-05, 'epoch': 0.5}
{'loss': 0.9701, 'grad_norm': 0.7546531083220681, 'learning_rate': 1.0678640237298476e-05, 'epoch': 0.5}
{'loss': 0.9896, 'grad_norm': 0.8260954336799116, 'learning_rate': 1.0666206750614363e-05, 'epoch': 0.5}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/1848373732.jpg, using default black image.
{'loss': 0.9682, 'grad_norm': 0.5337775916815086, 'learning_rate': 1.065377222935275e-05, 'epoch': 0.5}
{'loss': 1.015, 'grad_norm': 0.5814124699318701, 'learning_rate': 1.064133669282368e-05, 'epoch': 0.5}
{'loss': 1.0058, 'grad_norm': 0.6132216955326353, 'learning_rate': 1.0628900160338764e-05, 'epoch': 0.5}
{'loss': 0.9957, 'grad_norm': 0.7930866551538999, 'learning_rate': 1.0616462651211156e-05, 'epoch': 0.5}
{'loss': 0.9945, 'grad_norm': 0.57495867475168, 'learning_rate': 1.0604024184755539e-05, 'epoch': 0.5}
{'loss': 0.9682, 'grad_norm': 0.5687676518930941, 'learning_rate': 1.0591584780288069e-05, 'epoch': 0.5}
{'loss': 0.9805, 'grad_norm': 0.8061879166070962, 'learning_rate': 1.0579144457126365e-05, 'epoch': 0.5}
{'loss': 0.9964, 'grad_norm': 0.7053892520340156, 'learning_rate': 1.0566703234589471e-05, 'epoch': 0.5}
{'loss': 0.9753, 'grad_norm': 0.5797355122433998, 'learning_rate': 1.0554261131997833e-05, 'epoch': 0.5}
{'loss': 0.9645, 'grad_norm': 0.573306669624426, 'learning_rate': 1.054181816867326e-05, 'epoch': 0.5}
{'loss': 1.0174, 'grad_norm': 0.6389337377169616, 'learning_rate': 1.0529374363938888e-05, 'epoch': 0.5}
{'loss': 1.0243, 'grad_norm': 0.6000787259012714, 'learning_rate': 1.051692973711918e-05, 'epoch': 0.5}
{'loss': 1.0027, 'grad_norm': 0.5980147397711856, 'learning_rate': 1.0504484307539864e-05, 'epoch': 0.5}
{'loss': 1.0349, 'grad_norm': 0.5945136635366656, 'learning_rate': 1.0492038094527907e-05, 'epoch': 0.5}
{'loss': 0.971, 'grad_norm': 0.6686577914666114, 'learning_rate': 1.047959111741151e-05, 'epoch': 0.5}
{'loss': 1.0369, 'grad_norm': 0.6215011436242799, 'learning_rate': 1.0467143395520044e-05, 'epoch': 0.5}
{'loss': 1.0271, 'grad_norm': 0.6612459664424315, 'learning_rate': 1.0454694948184045e-05, 'epoch': 0.5}
{'loss': 0.9647, 'grad_norm': 0.5324045489106951, 'learning_rate': 1.044224579473518e-05, 'epoch': 0.5}
{'loss': 1.0271, 'grad_norm': 0.623214780116854, 'learning_rate': 1.0429795954506203e-05, 'epoch': 0.5}
{'loss': 0.9335, 'grad_norm': 0.5302925719562679, 'learning_rate': 1.0417345446830938e-05, 'epoch': 0.5}
{'loss': 1.0185, 'grad_norm': 0.6156301178254736, 'learning_rate': 1.0404894291044247e-05, 'epoch': 0.5}
{'loss': 1.0087, 'grad_norm': 0.5534685233031489, 'learning_rate': 1.0392442506482e-05, 'epoch': 0.5}
{'loss': 0.9807, 'grad_norm': 0.6277251362388767, 'learning_rate': 1.037999011248104e-05, 'epoch': 0.51}
{'loss': 1.0133, 'grad_norm': 0.581767343270008, 'learning_rate': 1.0367537128379154e-05, 'epoch': 0.51}
{'loss': 1.0226, 'grad_norm': 0.5781750201732668, 'learning_rate': 1.0355083573515052e-05, 'epoch': 0.51}
{'loss': 0.9789, 'grad_norm': 0.6127375226263908, 'learning_rate': 1.0342629467228331e-05, 'epoch': 0.51}
{'loss': 1.0154, 'grad_norm': 0.9402714344263888, 'learning_rate': 1.0330174828859434e-05, 'epoch': 0.51}
{'loss': 0.9858, 'grad_norm': 0.6140558386892963, 'learning_rate': 1.031771967774964e-05, 'epoch': 0.51}
{'loss': 1.0092, 'grad_norm': 0.6461438537187609, 'learning_rate': 1.030526403324102e-05, 'epoch': 0.51}
{'loss': 0.9768, 'grad_norm': 0.6086146427332444, 'learning_rate': 1.0292807914676412e-05, 'epoch': 0.51}
{'loss': 0.9987, 'grad_norm': 0.6520516508815025, 'learning_rate': 1.0280351341399392e-05, 'epoch': 0.51}
{'loss': 1.006, 'grad_norm': 0.6451968836544103, 'learning_rate': 1.0267894332754243e-05, 'epoch': 0.51}
{'loss': 1.0241, 'grad_norm': 0.702693549677861, 'learning_rate': 1.0255436908085919e-05, 'epoch': 0.51}
{'loss': 0.9789, 'grad_norm': 0.5316583741406278, 'learning_rate': 1.0242979086740019e-05, 'epoch': 0.51}
{'loss': 1.0173, 'grad_norm': 0.6453975071868304, 'learning_rate': 1.0230520888062765e-05, 'epoch': 0.51}
{'loss': 1.017, 'grad_norm': 0.6331053571609311, 'learning_rate': 1.0218062331400969e-05, 'epoch': 0.51}
{'loss': 0.9625, 'grad_norm': 0.5559878814803858, 'learning_rate': 1.0205603436101978e-05, 'epoch': 0.51}
{'loss': 0.9978, 'grad_norm': 0.70082168353938, 'learning_rate': 1.019314422151369e-05, 'epoch': 0.51}
{'loss': 1.0305, 'grad_norm': 0.6242261521639119, 'learning_rate': 1.0180684706984483e-05, 'epoch': 0.51}
{'loss': 1.0196, 'grad_norm': 0.5815976910392611, 'learning_rate': 1.0168224911863205e-05, 'epoch': 0.51}
{'loss': 0.9889, 'grad_norm': 0.5738351313007757, 'learning_rate': 1.015576485549914e-05, 'epoch': 0.51}
{'loss': 0.976, 'grad_norm': 0.5286084901166619, 'learning_rate': 1.0143304557241979e-05, 'epoch': 0.51}
{'loss': 1.0236, 'grad_norm': 0.7238905827398433, 'learning_rate': 1.0130844036441787e-05, 'epoch': 0.51}
{'loss': 0.9746, 'grad_norm': 0.6102168407073102, 'learning_rate': 1.0118383312448973e-05, 'epoch': 0.51}
{'loss': 0.9437, 'grad_norm': 0.584277190758669, 'learning_rate': 1.0105922404614265e-05, 'epoch': 0.51}
{'loss': 0.969, 'grad_norm': 0.6525193458818005, 'learning_rate': 1.0093461332288678e-05, 'epoch': 0.51}
{'loss': 0.9867, 'grad_norm': 0.6860860663178219, 'learning_rate': 1.0081000114823473e-05, 'epoch': 0.51}
{'loss': 1.0219, 'grad_norm': 0.5892423497574005, 'learning_rate': 1.006853877157015e-05, 'epoch': 0.51}
{'loss': 1.0182, 'grad_norm': 0.6667046266763519, 'learning_rate': 1.0056077321880393e-05, 'epoch': 0.52}
{'loss': 0.9793, 'grad_norm': 0.7042310014424368, 'learning_rate': 1.0043615785106051e-05, 'epoch': 0.52}
{'loss': 0.987, 'grad_norm': 0.6442646383027113, 'learning_rate': 1.0031154180599123e-05, 'epoch': 0.52}
{'loss': 1.0002, 'grad_norm': 0.7180962662633241, 'learning_rate': 1.0018692527711695e-05, 'epoch': 0.52}
{'loss': 0.971, 'grad_norm': 0.6568056343196051, 'learning_rate': 1.0006230845795937e-05, 'epoch': 0.52}
{'loss': 0.994, 'grad_norm': 0.6338629447933596, 'learning_rate': 9.993769154204063e-06, 'epoch': 0.52}
{'loss': 1.0356, 'grad_norm': 0.6708702183704331, 'learning_rate': 9.981307472288308e-06, 'epoch': 0.52}
{'loss': 0.9989, 'grad_norm': 0.6065745467201902, 'learning_rate': 9.968845819400883e-06, 'epoch': 0.52}
{'loss': 1.0155, 'grad_norm': 0.6547554054317831, 'learning_rate': 9.956384214893949e-06, 'epoch': 0.52}
{'loss': 1.022, 'grad_norm': 0.5842845218629331, 'learning_rate': 9.94392267811961e-06, 'epoch': 0.52}
{'loss': 1.0065, 'grad_norm': 0.5973288110252761, 'learning_rate': 9.931461228429856e-06, 'epoch': 0.52}
{'loss': 1.0111, 'grad_norm': 0.6616694825654855, 'learning_rate': 9.91899988517653e-06, 'epoch': 0.52}
{'loss': 0.9402, 'grad_norm': 0.6456721325577626, 'learning_rate': 9.906538667711324e-06, 'epoch': 0.52}
{'loss': 0.9751, 'grad_norm': 0.6751890010925425, 'learning_rate': 9.894077595385736e-06, 'epoch': 0.52}
{'loss': 0.9838, 'grad_norm': 0.6776511004548991, 'learning_rate': 9.881616687551032e-06, 'epoch': 0.52}
{'loss': 1.0371, 'grad_norm': 0.8291129857835564, 'learning_rate': 9.869155963558215e-06, 'epoch': 0.52}
{'loss': 1.031, 'grad_norm': 0.6506050113175413, 'learning_rate': 9.856695442758023e-06, 'epoch': 0.52}
{'loss': 1.0025, 'grad_norm': 0.6811650570107257, 'learning_rate': 9.844235144500865e-06, 'epoch': 0.52}
{'loss': 1.0288, 'grad_norm': 0.6844260977840074, 'learning_rate': 9.831775088136797e-06, 'epoch': 0.52}
{'loss': 1.0123, 'grad_norm': 0.5978795847747707, 'learning_rate': 9.819315293015519e-06, 'epoch': 0.52}
{'loss': 0.9941, 'grad_norm': 0.5951640656956696, 'learning_rate': 9.806855778486314e-06, 'epoch': 0.52}
{'loss': 0.9603, 'grad_norm': 0.58865185844302, 'learning_rate': 9.794396563898022e-06, 'epoch': 0.52}
{'loss': 0.9933, 'grad_norm': 0.5980481741930795, 'learning_rate': 9.781937668599035e-06, 'epoch': 0.52}
{'loss': 1.0116, 'grad_norm': 0.6471522302585455, 'learning_rate': 9.769479111937238e-06, 'epoch': 0.52}
{'loss': 1.0482, 'grad_norm': 0.6654079360452791, 'learning_rate': 9.757020913259986e-06, 'epoch': 0.52}
{'loss': 0.9883, 'grad_norm': 0.5953772506533849, 'learning_rate': 9.744563091914085e-06, 'epoch': 0.52}
{'loss': 1.0441, 'grad_norm': 0.6157714581643369, 'learning_rate': 9.732105667245759e-06, 'epoch': 0.53}
{'loss': 0.9593, 'grad_norm': 0.5238695660070434, 'learning_rate': 9.719648658600611e-06, 'epoch': 0.53}
{'loss': 1.0029, 'grad_norm': 0.5682799582980267, 'learning_rate': 9.70719208532359e-06, 'epoch': 0.53}
{'loss': 1.0423, 'grad_norm': 0.6185327489952807, 'learning_rate': 9.694735966758982e-06, 'epoch': 0.53}
{'loss': 0.9725, 'grad_norm': 0.5613586152310759, 'learning_rate': 9.682280322250365e-06, 'epoch': 0.53}
{'loss': 0.9245, 'grad_norm': 0.5843427751908737, 'learning_rate': 9.669825171140568e-06, 'epoch': 0.53}
{'loss': 1.0029, 'grad_norm': 0.6417405092357585, 'learning_rate': 9.657370532771672e-06, 'epoch': 0.53}
{'loss': 1.0036, 'grad_norm': 0.5875834332791617, 'learning_rate': 9.64491642648495e-06, 'epoch': 0.53}
{'loss': 1.0046, 'grad_norm': 0.6197571225679365, 'learning_rate': 9.632462871620847e-06, 'epoch': 0.53}
{'loss': 1.0288, 'grad_norm': 0.6374615876290131, 'learning_rate': 9.620009887518963e-06, 'epoch': 0.53}
{'loss': 0.9838, 'grad_norm': 0.5945483103015763, 'learning_rate': 9.607557493518006e-06, 'epoch': 0.53}
{'loss': 1.0412, 'grad_norm': 0.67053245779896, 'learning_rate': 9.595105708955758e-06, 'epoch': 0.53}
{'loss': 1.0158, 'grad_norm': 0.6591296909369974, 'learning_rate': 9.582654553169064e-06, 'epoch': 0.53}
{'loss': 0.9722, 'grad_norm': 0.45957693207530986, 'learning_rate': 9.5702040454938e-06, 'epoch': 0.53}
{'loss': 0.9403, 'grad_norm': 0.5581324411205864, 'learning_rate': 9.557754205264826e-06, 'epoch': 0.53}
{'loss': 0.9721, 'grad_norm': 0.6503108113588142, 'learning_rate': 9.545305051815957e-06, 'epoch': 0.53}
{'loss': 1.0079, 'grad_norm': 0.7272899699235461, 'learning_rate': 9.53285660447996e-06, 'epoch': 0.53}
{'loss': 0.9977, 'grad_norm': 0.5347772502207078, 'learning_rate': 9.520408882588497e-06, 'epoch': 0.53}
{'loss': 1.0124, 'grad_norm': 0.6047168951788079, 'learning_rate': 9.507961905472093e-06, 'epoch': 0.53}
{'loss': 1.0023, 'grad_norm': 0.5867909305082452, 'learning_rate': 9.495515692460138e-06, 'epoch': 0.53}
{'loss': 0.9848, 'grad_norm': 0.6267474623757394, 'learning_rate': 9.483070262880823e-06, 'epoch': 0.53}
{'loss': 0.9987, 'grad_norm': 0.6335895076167378, 'learning_rate': 9.47062563606111e-06, 'epoch': 0.53}
{'loss': 1.0248, 'grad_norm': 0.6358976453982892, 'learning_rate': 9.458181831326744e-06, 'epoch': 0.53}
{'loss': 1.005, 'grad_norm': 0.6946574097207142, 'learning_rate': 9.44573886800217e-06, 'epoch': 0.53}
{'loss': 1.0271, 'grad_norm': 0.5972967213068282, 'learning_rate': 9.433296765410534e-06, 'epoch': 0.53}
{'loss': 1.0157, 'grad_norm': 0.6359592452534999, 'learning_rate': 9.420855542873638e-06, 'epoch': 0.53}
{'loss': 0.9869, 'grad_norm': 0.6790068598908233, 'learning_rate': 9.408415219711934e-06, 'epoch': 0.54}
{'loss': 0.9607, 'grad_norm': 0.6524196868996062, 'learning_rate': 9.395975815244468e-06, 'epoch': 0.54}
{'loss': 0.9741, 'grad_norm': 0.6902565215575699, 'learning_rate': 9.383537348788844e-06, 'epoch': 0.54}
{'loss': 1.0411, 'grad_norm': 0.6294945119424936, 'learning_rate': 9.371099839661238e-06, 'epoch': 0.54}
{'loss': 1.0058, 'grad_norm': 0.6943493733335037, 'learning_rate': 9.358663307176323e-06, 'epoch': 0.54}
{'loss': 1.0092, 'grad_norm': 0.5479191645411116, 'learning_rate': 9.346227770647251e-06, 'epoch': 0.54}
{'loss': 0.9802, 'grad_norm': 0.6140457438824111, 'learning_rate': 9.33379324938564e-06, 'epoch': 0.54}
{'loss': 0.9883, 'grad_norm': 0.7354816391478757, 'learning_rate': 9.321359762701527e-06, 'epoch': 0.54}
{'loss': 0.9953, 'grad_norm': 0.5696543786539462, 'learning_rate': 9.308927329903333e-06, 'epoch': 0.54}
{'loss': 1.0165, 'grad_norm': 0.5773606688303605, 'learning_rate': 9.296495970297855e-06, 'epoch': 0.54}
{'loss': 1.0554, 'grad_norm': 0.5884029931576678, 'learning_rate': 9.284065703190221e-06, 'epoch': 0.54}
{'loss': 1.0082, 'grad_norm': 0.5319116211553113, 'learning_rate': 9.271636547883856e-06, 'epoch': 0.54}
{'loss': 0.9906, 'grad_norm': 0.6669861357462941, 'learning_rate': 9.259208523680457e-06, 'epoch': 0.54}
{'loss': 0.9513, 'grad_norm': 0.7113472301869244, 'learning_rate': 9.24678164987998e-06, 'epoch': 0.54}
{'loss': 0.993, 'grad_norm': 0.6518327190732243, 'learning_rate': 9.234355945780581e-06, 'epoch': 0.54}
{'loss': 1.0187, 'grad_norm': 0.6665899305146253, 'learning_rate': 9.221931430678598e-06, 'epoch': 0.54}
{'loss': 0.9443, 'grad_norm': 0.6079576555280501, 'learning_rate': 9.209508123868534e-06, 'epoch': 0.54}
{'loss': 1.0081, 'grad_norm': 0.6788015825994014, 'learning_rate': 9.197086044643004e-06, 'epoch': 0.54}
{'loss': 0.972, 'grad_norm': 0.6541487150090116, 'learning_rate': 9.184665212292723e-06, 'epoch': 0.54}
{'loss': 1.0411, 'grad_norm': 0.6075232767024726, 'learning_rate': 9.172245646106471e-06, 'epoch': 0.54}
{'loss': 0.9961, 'grad_norm': 0.727345255930473, 'learning_rate': 9.159827365371055e-06, 'epoch': 0.54}
{'loss': 0.9563, 'grad_norm': 0.5487434086311692, 'learning_rate': 9.14741038937129e-06, 'epoch': 0.54}
{'loss': 1.0139, 'grad_norm': 0.5938915868942123, 'learning_rate': 9.13499473738997e-06, 'epoch': 0.54}
{'loss': 0.9625, 'grad_norm': 0.6094992140376279, 'learning_rate': 9.122580428707822e-06, 'epoch': 0.54}
{'loss': 1.0198, 'grad_norm': 0.8166331364977203, 'learning_rate': 9.110167482603494e-06, 'epoch': 0.54}
{'loss': 1.0266, 'grad_norm': 0.6428029363776603, 'learning_rate': 9.097755918353513e-06, 'epoch': 0.54}
{'loss': 0.9872, 'grad_norm': 0.6385811532523374, 'learning_rate': 9.08534575523227e-06, 'epoch': 0.55}
{'loss': 0.9971, 'grad_norm': 0.6123150359415332, 'learning_rate': 9.072937012511968e-06, 'epoch': 0.55}
{'loss': 0.97, 'grad_norm': 0.5423322234521895, 'learning_rate': 9.060529709462613e-06, 'epoch': 0.55}
{'loss': 1.0438, 'grad_norm': 0.648664852737047, 'learning_rate': 9.048123865351971e-06, 'epoch': 0.55}
{'loss': 0.9878, 'grad_norm': 0.5753537812471232, 'learning_rate': 9.035719499445545e-06, 'epoch': 0.55}
{'loss': 0.9771, 'grad_norm': 0.7019987130628101, 'learning_rate': 9.023316631006536e-06, 'epoch': 0.55}
{'loss': 0.9554, 'grad_norm': 0.6306127239805583, 'learning_rate': 9.010915279295833e-06, 'epoch': 0.55}
{'loss': 1.0439, 'grad_norm': 0.6045023536663826, 'learning_rate': 8.998515463571953e-06, 'epoch': 0.55}
{'loss': 1.0351, 'grad_norm': 0.7518211716119447, 'learning_rate': 8.986117203091042e-06, 'epoch': 0.55}
{'loss': 0.9995, 'grad_norm': 0.6077637659536858, 'learning_rate': 8.973720517106814e-06, 'epoch': 0.55}
{'loss': 1.0368, 'grad_norm': 0.6059861535763938, 'learning_rate': 8.961325424870561e-06, 'epoch': 0.55}
{'loss': 1.0379, 'grad_norm': 0.6605404552841206, 'learning_rate': 8.948931945631082e-06, 'epoch': 0.55}
{'loss': 1.012, 'grad_norm': 0.7065968630266751, 'learning_rate': 8.936540098634675e-06, 'epoch': 0.55}
{'loss': 1.038, 'grad_norm': 0.5878105756348785, 'learning_rate': 8.924149903125108e-06, 'epoch': 0.55}
{'loss': 1.0501, 'grad_norm': 0.6649683622526215, 'learning_rate': 8.91176137834358e-06, 'epoch': 0.55}
{'loss': 0.9665, 'grad_norm': 0.5360460662952539, 'learning_rate': 8.899374543528695e-06, 'epoch': 0.55}
{'loss': 0.9751, 'grad_norm': 0.569466812570811, 'learning_rate': 8.886989417916435e-06, 'epoch': 0.55}
{'loss': 0.9731, 'grad_norm': 0.6421829050671531, 'learning_rate': 8.87460602074013e-06, 'epoch': 0.55}
{'loss': 0.9999, 'grad_norm': 0.717113344290454, 'learning_rate': 8.862224371230418e-06, 'epoch': 0.55}
{'loss': 0.9993, 'grad_norm': 0.6123064247035741, 'learning_rate': 8.84984448861523e-06, 'epoch': 0.55}
{'loss': 0.9632, 'grad_norm': 0.6088648939902301, 'learning_rate': 8.837466392119752e-06, 'epoch': 0.55}
{'loss': 0.9844, 'grad_norm': 0.6472516137530419, 'learning_rate': 8.825090100966396e-06, 'epoch': 0.55}
{'loss': 1.0177, 'grad_norm': 0.5953029424960009, 'learning_rate': 8.81271563437476e-06, 'epoch': 0.55}
{'loss': 1.0404, 'grad_norm': 0.7449592581998605, 'learning_rate': 8.800343011561633e-06, 'epoch': 0.55}
{'loss': 1.0165, 'grad_norm': 0.5808821502975553, 'learning_rate': 8.787972251740916e-06, 'epoch': 0.55}
{'loss': 0.9914, 'grad_norm': 0.666633013067116, 'learning_rate': 8.775603374123627e-06, 'epoch': 0.55}
{'loss': 0.9603, 'grad_norm': 0.5547045947921264, 'learning_rate': 8.763236397917865e-06, 'epoch': 0.56}
{'loss': 1.0701, 'grad_norm': 0.6348113377176242, 'learning_rate': 8.75087134232877e-06, 'epoch': 0.56}
{'loss': 1.0336, 'grad_norm': 0.5879631786483106, 'learning_rate': 8.738508226558499e-06, 'epoch': 0.56}
{'loss': 1.0061, 'grad_norm': 0.7494824693640635, 'learning_rate': 8.726147069806206e-06, 'epoch': 0.56}
{'loss': 1.0056, 'grad_norm': 0.5908336064016588, 'learning_rate': 8.713787891267988e-06, 'epoch': 0.56}
{'loss': 0.9746, 'grad_norm': 0.5603530328899916, 'learning_rate': 8.70143071013688e-06, 'epoch': 0.56}
{'loss': 0.9955, 'grad_norm': 0.5922922814144056, 'learning_rate': 8.689075545602816e-06, 'epoch': 0.56}
{'loss': 1.0, 'grad_norm': 0.5967764415862161, 'learning_rate': 8.676722416852594e-06, 'epoch': 0.56}
{'loss': 1.033, 'grad_norm': 0.5794575623562316, 'learning_rate': 8.66437134306985e-06, 'epoch': 0.56}
{'loss': 0.9723, 'grad_norm': 0.6806414054895858, 'learning_rate': 8.652022343435027e-06, 'epoch': 0.56}
{'loss': 0.9687, 'grad_norm': 0.6364826607491335, 'learning_rate': 8.63967543712536e-06, 'epoch': 0.56}
{'loss': 0.9576, 'grad_norm': 0.5648655367554867, 'learning_rate': 8.627330643314818e-06, 'epoch': 0.56}
{'loss': 1.0009, 'grad_norm': 0.549405562422424, 'learning_rate': 8.614987981174093e-06, 'epoch': 0.56}
{'loss': 1.0386, 'grad_norm': 0.6390976635893668, 'learning_rate': 8.602647469870573e-06, 'epoch': 0.56}
{'loss': 0.9815, 'grad_norm': 0.574112985798743, 'learning_rate': 8.590309128568303e-06, 'epoch': 0.56}
{'loss': 1.0238, 'grad_norm': 0.7368810680393775, 'learning_rate': 8.57797297642795e-06, 'epoch': 0.56}
{'loss': 1.0018, 'grad_norm': 0.5839337336845242, 'learning_rate': 8.565639032606794e-06, 'epoch': 0.56}
{'loss': 1.0028, 'grad_norm': 0.6621551898046841, 'learning_rate': 8.553307316258678e-06, 'epoch': 0.56}
{'loss': 0.9632, 'grad_norm': 0.7056081546978447, 'learning_rate': 8.540977846533986e-06, 'epoch': 0.56}
{'loss': 0.9768, 'grad_norm': 0.5968748462957569, 'learning_rate': 8.528650642579618e-06, 'epoch': 0.56}
{'loss': 0.9531, 'grad_norm': 0.7421075207248659, 'learning_rate': 8.516325723538949e-06, 'epoch': 0.56}
{'loss': 0.9919, 'grad_norm': 0.6856482002618827, 'learning_rate': 8.504003108551814e-06, 'epoch': 0.56}
{'loss': 0.9965, 'grad_norm': 0.6985892405086657, 'learning_rate': 8.491682816754456e-06, 'epoch': 0.56}
{'loss': 0.9746, 'grad_norm': 0.6206610818371268, 'learning_rate': 8.479364867279529e-06, 'epoch': 0.56}
{'loss': 1.0285, 'grad_norm': 0.6300282246179572, 'learning_rate': 8.467049279256034e-06, 'epoch': 0.56}
{'loss': 0.985, 'grad_norm': 0.7942372351612164, 'learning_rate': 8.45473607180931e-06, 'epoch': 0.56}
{'loss': 0.9474, 'grad_norm': 0.4212527069713696, 'learning_rate': 8.442425264061e-06, 'epoch': 0.57}
{'loss': 0.9906, 'grad_norm': 0.5956114953305638, 'learning_rate': 8.430116875129023e-06, 'epoch': 0.57}
{'loss': 1.0092, 'grad_norm': 0.6678693741664591, 'learning_rate': 8.417810924127533e-06, 'epoch': 0.57}
{'loss': 0.9919, 'grad_norm': 0.7565769895322304, 'learning_rate': 8.40550743016691e-06, 'epoch': 0.57}
{'loss': 0.9997, 'grad_norm': 0.6675714827046748, 'learning_rate': 8.393206412353709e-06, 'epoch': 0.57}
{'loss': 0.9919, 'grad_norm': 0.6646650018903185, 'learning_rate': 8.38090788979064e-06, 'epoch': 0.57}
{'loss': 1.0274, 'grad_norm': 0.5935397226003086, 'learning_rate': 8.368611881576547e-06, 'epoch': 0.57}
{'loss': 1.0066, 'grad_norm': 0.5931716668113092, 'learning_rate': 8.35631840680636e-06, 'epoch': 0.57}
{'loss': 1.0324, 'grad_norm': 0.6862452185651203, 'learning_rate': 8.344027484571075e-06, 'epoch': 0.57}
{'loss': 0.9887, 'grad_norm': 0.5744749526895951, 'learning_rate': 8.331739133957729e-06, 'epoch': 0.57}
{'loss': 1.0555, 'grad_norm': 0.6738004853590395, 'learning_rate': 8.319453374049367e-06, 'epoch': 0.57}
{'loss': 0.9713, 'grad_norm': 0.7200063845336726, 'learning_rate': 8.307170223925003e-06, 'epoch': 0.57}
{'loss': 1.0136, 'grad_norm': 0.6589268826069034, 'learning_rate': 8.294889702659602e-06, 'epoch': 0.57}
{'loss': 0.9552, 'grad_norm': 0.558700614820506, 'learning_rate': 8.282611829324049e-06, 'epoch': 0.57}
{'loss': 0.9847, 'grad_norm': 0.5788482156657834, 'learning_rate': 8.270336622985116e-06, 'epoch': 0.57}
{'loss': 0.9984, 'grad_norm': 0.704529612180722, 'learning_rate': 8.258064102705428e-06, 'epoch': 0.57}
{'loss': 1.0006, 'grad_norm': 0.6156014292556962, 'learning_rate': 8.245794287543447e-06, 'epoch': 0.57}
{'loss': 0.9576, 'grad_norm': 0.658251941494442, 'learning_rate': 8.233527196553428e-06, 'epoch': 0.57}
{'loss': 0.992, 'grad_norm': 0.5975520449398963, 'learning_rate': 8.221262848785395e-06, 'epoch': 0.57}
{'loss': 1.0541, 'grad_norm': 0.5897207537772055, 'learning_rate': 8.20900126328512e-06, 'epoch': 0.57}
{'loss': 1.0143, 'grad_norm': 0.698588052360429, 'learning_rate': 8.196742459094079e-06, 'epoch': 0.57}
{'loss': 1.0182, 'grad_norm': 0.6638512453547009, 'learning_rate': 8.184486455249424e-06, 'epoch': 0.57}
{'loss': 0.9773, 'grad_norm': 0.593219433003424, 'learning_rate': 8.172233270783966e-06, 'epoch': 0.57}
{'loss': 0.9961, 'grad_norm': 0.5717042052113671, 'learning_rate': 8.15998292472614e-06, 'epoch': 0.57}
{'loss': 1.0453, 'grad_norm': 0.7631951488319694, 'learning_rate': 8.147735436099967e-06, 'epoch': 0.57}
{'loss': 0.9833, 'grad_norm': 0.6556984134142778, 'learning_rate': 8.135490823925027e-06, 'epoch': 0.57}
{'loss': 0.9731, 'grad_norm': 0.6099578214382856, 'learning_rate': 8.123249107216446e-06, 'epoch': 0.58}
{'loss': 0.9489, 'grad_norm': 0.6160285105366823, 'learning_rate': 8.111010304984841e-06, 'epoch': 0.58}
{'loss': 1.0379, 'grad_norm': 0.6130431784392656, 'learning_rate': 8.098774436236308e-06, 'epoch': 0.58}
{'loss': 1.0036, 'grad_norm': 0.6397835509529833, 'learning_rate': 8.086541519972388e-06, 'epoch': 0.58}
{'loss': 1.0118, 'grad_norm': 0.6946845422762626, 'learning_rate': 8.074311575190039e-06, 'epoch': 0.58}
{'loss': 1.0426, 'grad_norm': 0.5811193202870043, 'learning_rate': 8.062084620881598e-06, 'epoch': 0.58}
{'loss': 1.0087, 'grad_norm': 0.6206783410747025, 'learning_rate': 8.049860676034762e-06, 'epoch': 0.58}
{'loss': 1.0041, 'grad_norm': 0.5606351675177593, 'learning_rate': 8.037639759632558e-06, 'epoch': 0.58}
{'loss': 1.001, 'grad_norm': 0.5926619681582397, 'learning_rate': 8.025421890653303e-06, 'epoch': 0.58}
{'loss': 0.962, 'grad_norm': 0.7569896815540968, 'learning_rate': 8.013207088070582e-06, 'epoch': 0.58}
{'loss': 1.0186, 'grad_norm': 0.6396990919190683, 'learning_rate': 8.000995370853227e-06, 'epoch': 0.58}
{'loss': 0.9843, 'grad_norm': 0.5638521993491268, 'learning_rate': 7.98878675796527e-06, 'epoch': 0.58}
{'loss': 1.0373, 'grad_norm': 0.6128134273888243, 'learning_rate': 7.976581268365924e-06, 'epoch': 0.58}
{'loss': 1.0088, 'grad_norm': 0.5307170239288074, 'learning_rate': 7.964378921009552e-06, 'epoch': 0.58}
{'loss': 0.9655, 'grad_norm': 0.5417283425681944, 'learning_rate': 7.952179734845642e-06, 'epoch': 0.58}
{'loss': 0.9455, 'grad_norm': 0.5744240870091972, 'learning_rate': 7.93998372881876e-06, 'epoch': 0.58}
{'loss': 0.9739, 'grad_norm': 0.5400731980749217, 'learning_rate': 7.92779092186855e-06, 'epoch': 0.58}
{'loss': 0.9831, 'grad_norm': 0.6566476998816414, 'learning_rate': 7.915601332929678e-06, 'epoch': 0.58}
{'loss': 0.9717, 'grad_norm': 0.6694598346832531, 'learning_rate': 7.903414980931813e-06, 'epoch': 0.58}
{'loss': 1.0104, 'grad_norm': 0.7271957748460437, 'learning_rate': 7.8912318847996e-06, 'epoch': 0.58}
{'loss': 0.979, 'grad_norm': 0.4685057000986616, 'learning_rate': 7.879052063452626e-06, 'epoch': 0.58}
{'loss': 0.9847, 'grad_norm': 0.6338189777924804, 'learning_rate': 7.866875535805394e-06, 'epoch': 0.58}
{'loss': 0.988, 'grad_norm': 0.565795409389641, 'learning_rate': 7.85470232076729e-06, 'epoch': 0.58}
{'loss': 0.9265, 'grad_norm': 0.5148015285851535, 'learning_rate': 7.842532437242559e-06, 'epoch': 0.58}
{'loss': 1.0224, 'grad_norm': 0.6175125754379497, 'learning_rate': 7.83036590413027e-06, 'epoch': 0.58}
{'loss': 1.0278, 'grad_norm': 0.7372904003422006, 'learning_rate': 7.818202740324287e-06, 'epoch': 0.58}
{'loss': 0.9883, 'grad_norm': 0.5921138126806622, 'learning_rate': 7.806042964713248e-06, 'epoch': 0.59}
{'loss': 0.9511, 'grad_norm': 0.7001829130197356, 'learning_rate': 7.793886596180521e-06, 'epoch': 0.59}
{'loss': 0.9935, 'grad_norm': 0.5116177525404941, 'learning_rate': 7.78173365360419e-06, 'epoch': 0.59}
{'loss': 0.9975, 'grad_norm': 0.588720274422268, 'learning_rate': 7.769584155857019e-06, 'epoch': 0.59}
{'loss': 0.9268, 'grad_norm': 0.5633719663313375, 'learning_rate': 7.757438121806414e-06, 'epoch': 0.59}
{'loss': 1.0066, 'grad_norm': 0.6739535377379774, 'learning_rate': 7.745295570314412e-06, 'epoch': 0.59}
{'loss': 0.9503, 'grad_norm': 0.5389680839320307, 'learning_rate': 7.733156520237633e-06, 'epoch': 0.59}
{'loss': 0.9438, 'grad_norm': 0.6676598021831109, 'learning_rate': 7.721020990427268e-06, 'epoch': 0.59}
{'loss': 0.9501, 'grad_norm': 0.7146448191755482, 'learning_rate': 7.708888999729036e-06, 'epoch': 0.59}
{'loss': 1.0054, 'grad_norm': 0.6223681820842619, 'learning_rate': 7.69676056698316e-06, 'epoch': 0.59}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/470584637.jpg, using default black image.
{'loss': 0.9583, 'grad_norm': 0.628834193216626, 'learning_rate': 7.68463571102434e-06, 'epoch': 0.59}
{'loss': 0.9984, 'grad_norm': 0.5684957057176222, 'learning_rate': 7.672514450681721e-06, 'epoch': 0.59}
{'loss': 0.9938, 'grad_norm': 0.6316187582158633, 'learning_rate': 7.66039680477886e-06, 'epoch': 0.59}
{'loss': 0.9612, 'grad_norm': 0.6595834271021901, 'learning_rate': 7.648282792133711e-06, 'epoch': 0.59}
{'loss': 0.9886, 'grad_norm': 0.6383748121492517, 'learning_rate': 7.636172431558575e-06, 'epoch': 0.59}
{'loss': 1.0089, 'grad_norm': 0.6617304913629144, 'learning_rate': 7.6240657418600846e-06, 'epoch': 0.59}
{'loss': 1.0011, 'grad_norm': 0.720338834538546, 'learning_rate': 7.611962741839178e-06, 'epoch': 0.59}
{'loss': 1.0259, 'grad_norm': 0.5502520425721551, 'learning_rate': 7.599863450291056e-06, 'epoch': 0.59}
{'loss': 0.9813, 'grad_norm': 0.5759531854110299, 'learning_rate': 7.587767886005164e-06, 'epoch': 0.59}
{'loss': 1.0386, 'grad_norm': 0.6449225969386356, 'learning_rate': 7.575676067765154e-06, 'epoch': 0.59}
{'loss': 1.031, 'grad_norm': 0.6066387232076131, 'learning_rate': 7.563588014348871e-06, 'epoch': 0.59}
{'loss': 1.0006, 'grad_norm': 0.6775367041125336, 'learning_rate': 7.551503744528304e-06, 'epoch': 0.59}
{'loss': 0.9533, 'grad_norm': 0.5312773031631127, 'learning_rate': 7.539423277069568e-06, 'epoch': 0.59}
{'loss': 0.9624, 'grad_norm': 0.6255182782569605, 'learning_rate': 7.52734663073288e-06, 'epoch': 0.59}
{'loss': 1.0055, 'grad_norm': 0.7282225143241093, 'learning_rate': 7.515273824272516e-06, 'epoch': 0.59}
{'loss': 0.9989, 'grad_norm': 0.6761419942905358, 'learning_rate': 7.503204876436785e-06, 'epoch': 0.59}
{'loss': 1.0847, 'grad_norm': 0.5732229627253359, 'learning_rate': 7.491139805968018e-06, 'epoch': 0.6}
{'loss': 0.9847, 'grad_norm': 0.7367121774486592, 'learning_rate': 7.4790786316025125e-06, 'epoch': 0.6}
{'loss': 0.9911, 'grad_norm': 0.6106121331624813, 'learning_rate': 7.467021372070515e-06, 'epoch': 0.6}
{'loss': 0.9372, 'grad_norm': 0.6427967684695093, 'learning_rate': 7.4549680460962044e-06, 'epoch': 0.6}
{'loss': 1.0198, 'grad_norm': 0.7159363180937295, 'learning_rate': 7.4429186723976425e-06, 'epoch': 0.6}
{'loss': 1.0045, 'grad_norm': 0.6341830343225424, 'learning_rate': 7.43087326968675e-06, 'epoch': 0.6}
{'loss': 1.0044, 'grad_norm': 0.611078171931244, 'learning_rate': 7.418831856669286e-06, 'epoch': 0.6}
{'loss': 1.0096, 'grad_norm': 0.6144564525044801, 'learning_rate': 7.406794452044816e-06, 'epoch': 0.6}
{'loss': 0.9254, 'grad_norm': 0.6022151154108462, 'learning_rate': 7.394761074506679e-06, 'epoch': 0.6}
{'loss': 0.9629, 'grad_norm': 0.679933748587733, 'learning_rate': 7.382731742741953e-06, 'epoch': 0.6}
{'loss': 0.9438, 'grad_norm': 0.6032519431250647, 'learning_rate': 7.370706475431446e-06, 'epoch': 0.6}
{'loss': 0.9898, 'grad_norm': 0.5903262322129866, 'learning_rate': 7.358685291249644e-06, 'epoch': 0.6}
{'loss': 1.0123, 'grad_norm': 0.6065056508293928, 'learning_rate': 7.346668208864695e-06, 'epoch': 0.6}
{'loss': 1.0065, 'grad_norm': 0.516227169495592, 'learning_rate': 7.33465524693838e-06, 'epoch': 0.6}
{'loss': 0.9656, 'grad_norm': 0.6058033094399373, 'learning_rate': 7.322646424126079e-06, 'epoch': 0.6}
{'loss': 1.0074, 'grad_norm': 0.6451467360049968, 'learning_rate': 7.310641759076742e-06, 'epoch': 0.6}
{'loss': 1.0037, 'grad_norm': 0.5909095249594114, 'learning_rate': 7.2986412704328625e-06, 'epoch': 0.6}
{'loss': 0.9765, 'grad_norm': 0.541132409409048, 'learning_rate': 7.286644976830457e-06, 'epoch': 0.6}
{'loss': 1.0143, 'grad_norm': 0.7630855145992728, 'learning_rate': 7.274652896899015e-06, 'epoch': 0.6}
{'loss': 0.9863, 'grad_norm': 0.6543779113449367, 'learning_rate': 7.262665049261489e-06, 'epoch': 0.6}
{'loss': 0.9752, 'grad_norm': 0.5784450165870474, 'learning_rate': 7.250681452534261e-06, 'epoch': 0.6}
{'loss': 0.9986, 'grad_norm': 0.6068579975328287, 'learning_rate': 7.238702125327106e-06, 'epoch': 0.6}
{'loss': 0.9671, 'grad_norm': 0.6384864250807175, 'learning_rate': 7.226727086243168e-06, 'epoch': 0.6}
{'loss': 0.9814, 'grad_norm': 0.7295240329257554, 'learning_rate': 7.214756353878942e-06, 'epoch': 0.6}
{'loss': 0.9465, 'grad_norm': 0.6293998223515025, 'learning_rate': 7.202789946824227e-06, 'epoch': 0.6}
{'loss': 0.9995, 'grad_norm': 0.733653937044332, 'learning_rate': 7.1908278836621e-06, 'epoch': 0.6}
{'loss': 0.9277, 'grad_norm': 0.5884827906813672, 'learning_rate': 7.178870182968904e-06, 'epoch': 0.61}
{'loss': 0.9922, 'grad_norm': 0.6813227155769276, 'learning_rate': 7.166916863314199e-06, 'epoch': 0.61}
{'loss': 0.9943, 'grad_norm': 0.6782627475227893, 'learning_rate': 7.154967943260748e-06, 'epoch': 0.61}
{'loss': 1.0269, 'grad_norm': 0.6563741078964171, 'learning_rate': 7.143023441364471e-06, 'epoch': 0.61}
{'loss': 1.0035, 'grad_norm': 0.799177551579591, 'learning_rate': 7.131083376174441e-06, 'epoch': 0.61}
{'loss': 1.0042, 'grad_norm': 0.6387320559727334, 'learning_rate': 7.119147766232832e-06, 'epoch': 0.61}
{'loss': 1.0029, 'grad_norm': 0.6324144832206198, 'learning_rate': 7.107216630074895e-06, 'epoch': 0.61}
{'loss': 0.9725, 'grad_norm': 0.5902781288814735, 'learning_rate': 7.09528998622895e-06, 'epoch': 0.61}
{'loss': 0.993, 'grad_norm': 0.6088935914824339, 'learning_rate': 7.083367853216323e-06, 'epoch': 0.61}
{'loss': 0.9858, 'grad_norm': 0.5862929741227103, 'learning_rate': 7.071450249551342e-06, 'epoch': 0.61}
{'loss': 0.98, 'grad_norm': 0.6831588046541252, 'learning_rate': 7.059537193741306e-06, 'epoch': 0.61}
{'loss': 0.9514, 'grad_norm': 0.6017963153337466, 'learning_rate': 7.047628704286446e-06, 'epoch': 0.61}
{'loss': 0.9672, 'grad_norm': 0.5948432244569315, 'learning_rate': 7.035724799679898e-06, 'epoch': 0.61}
{'loss': 0.9758, 'grad_norm': 0.7138757768852135, 'learning_rate': 7.023825498407689e-06, 'epoch': 0.61}
{'loss': 0.9527, 'grad_norm': 0.6969114578202283, 'learning_rate': 7.011930818948688e-06, 'epoch': 0.61}
{'loss': 0.9799, 'grad_norm': 0.6371034671384783, 'learning_rate': 7.000040779774591e-06, 'epoch': 0.61}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B01577TUTC.jpg, using default black image.
{'loss': 1.0202, 'grad_norm': 0.649387384018841, 'learning_rate': 6.9881553993498805e-06, 'epoch': 0.61}
{'loss': 0.9971, 'grad_norm': 0.6168178862087524, 'learning_rate': 6.97627469613182e-06, 'epoch': 0.61}
{'loss': 0.9309, 'grad_norm': 0.5760599749216287, 'learning_rate': 6.9643986885703955e-06, 'epoch': 0.61}
{'loss': 0.9946, 'grad_norm': 0.5827681396400054, 'learning_rate': 6.952527395108302e-06, 'epoch': 0.61}
{'loss': 1.0089, 'grad_norm': 0.6190615726387209, 'learning_rate': 6.9406608341809215e-06, 'epoch': 0.61}
{'loss': 0.9981, 'grad_norm': 0.5885211358740507, 'learning_rate': 6.928799024216282e-06, 'epoch': 0.61}
{'loss': 1.0359, 'grad_norm': 0.5410975549816219, 'learning_rate': 6.91694198363503e-06, 'epoch': 0.61}
{'loss': 1.0114, 'grad_norm': 0.6902233299613487, 'learning_rate': 6.905089730850416e-06, 'epoch': 0.61}
{'loss': 0.977, 'grad_norm': 0.6485494604035787, 'learning_rate': 6.893242284268244e-06, 'epoch': 0.61}
{'loss': 1.012, 'grad_norm': 0.8309685091658241, 'learning_rate': 6.8813996622868584e-06, 'epoch': 0.61}
{'loss': 0.9695, 'grad_norm': 0.563425477248334, 'learning_rate': 6.869561883297116e-06, 'epoch': 0.62}
{'loss': 0.9649, 'grad_norm': 0.5787856161228386, 'learning_rate': 6.857728965682344e-06, 'epoch': 0.62}
{'loss': 0.9367, 'grad_norm': 0.6602381998788314, 'learning_rate': 6.8459009278183275e-06, 'epoch': 0.62}
{'loss': 0.9339, 'grad_norm': 0.6408003303133544, 'learning_rate': 6.834077788073268e-06, 'epoch': 0.62}
{'loss': 0.9621, 'grad_norm': 0.6370119250401551, 'learning_rate': 6.822259564807768e-06, 'epoch': 0.62}
{'loss': 0.9888, 'grad_norm': 0.5989810603117885, 'learning_rate': 6.810446276374789e-06, 'epoch': 0.62}
{'loss': 0.9876, 'grad_norm': 0.5595993292934426, 'learning_rate': 6.7986379411196255e-06, 'epoch': 0.62}
{'loss': 0.9817, 'grad_norm': 0.6324141119756878, 'learning_rate': 6.786834577379893e-06, 'epoch': 0.62}
{'loss': 0.9897, 'grad_norm': 0.6679678012207675, 'learning_rate': 6.775036203485472e-06, 'epoch': 0.62}
{'loss': 0.9781, 'grad_norm': 0.5948472067894721, 'learning_rate': 6.763242837758504e-06, 'epoch': 0.62}
{'loss': 0.9997, 'grad_norm': 0.6483849809387591, 'learning_rate': 6.751454498513349e-06, 'epoch': 0.62}
{'loss': 1.0262, 'grad_norm': 0.60308741128597, 'learning_rate': 6.7396712040565625e-06, 'epoch': 0.62}
{'loss': 1.0193, 'grad_norm': 0.6390184421862611, 'learning_rate': 6.727892972686861e-06, 'epoch': 0.62}
{'loss': 0.9885, 'grad_norm': 0.6431828006341688, 'learning_rate': 6.716119822695111e-06, 'epoch': 0.62}
{'loss': 1.0001, 'grad_norm': 0.690417362009673, 'learning_rate': 6.704351772364274e-06, 'epoch': 0.62}
{'loss': 1.0135, 'grad_norm': 0.551178826055407, 'learning_rate': 6.692588839969397e-06, 'epoch': 0.62}
{'loss': 1.0075, 'grad_norm': 0.7255820189368573, 'learning_rate': 6.680831043777579e-06, 'epoch': 0.62}
{'loss': 0.9883, 'grad_norm': 0.6676312331313686, 'learning_rate': 6.6690784020479484e-06, 'epoch': 0.62}
{'loss': 0.9879, 'grad_norm': 0.7054935122012879, 'learning_rate': 6.657330933031619e-06, 'epoch': 0.62}
{'loss': 1.0163, 'grad_norm': 0.626968877041856, 'learning_rate': 6.645588654971677e-06, 'epoch': 0.62}
{'loss': 1.0133, 'grad_norm': 0.6783298245327061, 'learning_rate': 6.633851586103153e-06, 'epoch': 0.62}
{'loss': 0.9625, 'grad_norm': 0.6707758132758637, 'learning_rate': 6.622119744652977e-06, 'epoch': 0.62}
{'loss': 0.9281, 'grad_norm': 0.672316897340817, 'learning_rate': 6.610393148839964e-06, 'epoch': 0.62}
{'loss': 1.0373, 'grad_norm': 0.6931130053653449, 'learning_rate': 6.598671816874794e-06, 'epoch': 0.62}
{'loss': 0.9927, 'grad_norm': 0.64950169427596, 'learning_rate': 6.586955766959958e-06, 'epoch': 0.62}
{'loss': 0.9732, 'grad_norm': 0.5840126636874576, 'learning_rate': 6.5752450172897466e-06, 'epoch': 0.62}
{'loss': 0.9865, 'grad_norm': 0.5254899750401198, 'learning_rate': 6.563539586050233e-06, 'epoch': 0.63}
{'loss': 0.9637, 'grad_norm': 0.5788186925110854, 'learning_rate': 6.551839491419213e-06, 'epoch': 0.63}
{'loss': 1.006, 'grad_norm': 0.5686482936017524, 'learning_rate': 6.5401447515662065e-06, 'epoch': 0.63}
{'loss': 1.0212, 'grad_norm': 0.7107819661568351, 'learning_rate': 6.52845538465241e-06, 'epoch': 0.63}
{'loss': 1.0515, 'grad_norm': 0.6046234288867018, 'learning_rate': 6.5167714088306865e-06, 'epoch': 0.63}
{'loss': 1.0005, 'grad_norm': 0.6239816202685475, 'learning_rate': 6.505092842245519e-06, 'epoch': 0.63}
{'loss': 0.9957, 'grad_norm': 0.758796616445769, 'learning_rate': 6.493419703032991e-06, 'epoch': 0.63}
{'loss': 1.0259, 'grad_norm': 0.6029061943708074, 'learning_rate': 6.481752009320761e-06, 'epoch': 0.63}
{'loss': 0.978, 'grad_norm': 0.6366645728285812, 'learning_rate': 6.4700897792280285e-06, 'epoch': 0.63}
{'loss': 0.963, 'grad_norm': 0.5995232561782313, 'learning_rate': 6.458433030865503e-06, 'epoch': 0.63}
{'loss': 0.993, 'grad_norm': 0.5603075538055292, 'learning_rate': 6.4467817823354005e-06, 'epoch': 0.63}
{'loss': 1.0095, 'grad_norm': 0.6484959066642478, 'learning_rate': 6.43513605173137e-06, 'epoch': 0.63}
{'loss': 1.054, 'grad_norm': 0.5963566327673651, 'learning_rate': 6.4234958571385095e-06, 'epoch': 0.63}
{'loss': 1.0032, 'grad_norm': 0.5924082070090257, 'learning_rate': 6.4118612166333124e-06, 'epoch': 0.63}
{'loss': 1.0026, 'grad_norm': 0.700997889557652, 'learning_rate': 6.400232148283651e-06, 'epoch': 0.63}
{'loss': 1.0095, 'grad_norm': 0.7726252298334569, 'learning_rate': 6.388608670148741e-06, 'epoch': 0.63}
{'loss': 0.9643, 'grad_norm': 0.5635337102725325, 'learning_rate': 6.376990800279119e-06, 'epoch': 0.63}
{'loss': 0.9658, 'grad_norm': 0.6452466730039622, 'learning_rate': 6.3653785567166125e-06, 'epoch': 0.63}
{'loss': 1.0208, 'grad_norm': 0.6221968588557029, 'learning_rate': 6.3537719574943105e-06, 'epoch': 0.63}
{'loss': 0.9776, 'grad_norm': 0.7783969972662702, 'learning_rate': 6.342171020636533e-06, 'epoch': 0.63}
{'loss': 0.9836, 'grad_norm': 0.6062375109960388, 'learning_rate': 6.330575764158819e-06, 'epoch': 0.63}
{'loss': 0.9382, 'grad_norm': 0.6314665133540563, 'learning_rate': 6.318986206067872e-06, 'epoch': 0.63}
{'loss': 0.9882, 'grad_norm': 0.7363462944620608, 'learning_rate': 6.30740236436155e-06, 'epoch': 0.63}
{'loss': 0.9854, 'grad_norm': 0.6210410596586494, 'learning_rate': 6.295824257028844e-06, 'epoch': 0.63}
{'loss': 0.9856, 'grad_norm': 0.7388097226525414, 'learning_rate': 6.284251902049827e-06, 'epoch': 0.63}
{'loss': 1.0004, 'grad_norm': 0.6565624485057127, 'learning_rate': 6.272685317395644e-06, 'epoch': 0.63}
{'loss': 0.98, 'grad_norm': 0.683401620022576, 'learning_rate': 6.261124521028477e-06, 'epoch': 0.64}
{'loss': 0.9699, 'grad_norm': 0.6564799899968002, 'learning_rate': 6.249569530901525e-06, 'epoch': 0.64}
{'loss': 1.0493, 'grad_norm': 0.6637525647136697, 'learning_rate': 6.238020364958964e-06, 'epoch': 0.64}
{'loss': 0.993, 'grad_norm': 0.5872347947589739, 'learning_rate': 6.2264770411359256e-06, 'epoch': 0.64}
{'loss': 1.0131, 'grad_norm': 0.5919003347500663, 'learning_rate': 6.214939577358479e-06, 'epoch': 0.64}
{'loss': 0.9939, 'grad_norm': 0.7525978129888242, 'learning_rate': 6.203407991543577e-06, 'epoch': 0.64}
{'loss': 0.9611, 'grad_norm': 0.5950367171939476, 'learning_rate': 6.191882301599052e-06, 'epoch': 0.64}
{'loss': 0.9964, 'grad_norm': 0.5874883016726631, 'learning_rate': 6.180362525423591e-06, 'epoch': 0.64}
{'loss': 0.9573, 'grad_norm': 0.6188813793947939, 'learning_rate': 6.168848680906678e-06, 'epoch': 0.64}
{'loss': 1.0183, 'grad_norm': 0.6798245653580668, 'learning_rate': 6.157340785928595e-06, 'epoch': 0.64}
{'loss': 0.9769, 'grad_norm': 0.6368380772517618, 'learning_rate': 6.145838858360391e-06, 'epoch': 0.64}
{'loss': 0.9565, 'grad_norm': 0.5520389921499201, 'learning_rate': 6.134342916063838e-06, 'epoch': 0.64}
{'loss': 0.9525, 'grad_norm': 0.6283049379663546, 'learning_rate': 6.122852976891413e-06, 'epoch': 0.64}
{'loss': 0.989, 'grad_norm': 0.6379362804709231, 'learning_rate': 6.111369058686276e-06, 'epoch': 0.64}
{'loss': 1.0273, 'grad_norm': 0.6357784025796226, 'learning_rate': 6.099891179282242e-06, 'epoch': 0.64}
{'loss': 0.9522, 'grad_norm': 0.5177980940551936, 'learning_rate': 6.088419356503732e-06, 'epoch': 0.64}
{'loss': 1.0342, 'grad_norm': 0.6518478316795348, 'learning_rate': 6.076953608165772e-06, 'epoch': 0.64}
{'loss': 0.9322, 'grad_norm': 0.6162518765588223, 'learning_rate': 6.065493952073961e-06, 'epoch': 0.64}
{'loss': 0.9999, 'grad_norm': 0.6914588356708935, 'learning_rate': 6.054040406024422e-06, 'epoch': 0.64}
{'loss': 0.9838, 'grad_norm': 0.6256091099188367, 'learning_rate': 6.042592987803796e-06, 'epoch': 0.64}
{'loss': 0.933, 'grad_norm': 0.7570486662305713, 'learning_rate': 6.031151715189217e-06, 'epoch': 0.64}
{'loss': 1.0237, 'grad_norm': 0.6146029060184635, 'learning_rate': 6.019716605948261e-06, 'epoch': 0.64}
{'loss': 0.946, 'grad_norm': 0.771144667181808, 'learning_rate': 6.008287677838937e-06, 'epoch': 0.64}
{'loss': 0.9867, 'grad_norm': 0.708326063390195, 'learning_rate': 5.996864948609662e-06, 'epoch': 0.64}
{'loss': 0.9709, 'grad_norm': 0.604489641057546, 'learning_rate': 5.9854484359992235e-06, 'epoch': 0.64}
{'loss': 1.0348, 'grad_norm': 0.6362463454715837, 'learning_rate': 5.974038157736746e-06, 'epoch': 0.64}
{'loss': 1.0118, 'grad_norm': 0.6310290821299289, 'learning_rate': 5.962634131541676e-06, 'epoch': 0.65}
{'loss': 0.962, 'grad_norm': 0.7043398028790006, 'learning_rate': 5.951236375123768e-06, 'epoch': 0.65}
{'loss': 0.9628, 'grad_norm': 0.5714787467454479, 'learning_rate': 5.939844906183016e-06, 'epoch': 0.65}
{'loss': 0.9652, 'grad_norm': 0.6103772284104475, 'learning_rate': 5.92845974240966e-06, 'epoch': 0.65}
{'loss': 0.9717, 'grad_norm': 0.5870035004827263, 'learning_rate': 5.917080901484156e-06, 'epoch': 0.65}
{'loss': 1.0206, 'grad_norm': 0.589812367829299, 'learning_rate': 5.905708401077128e-06, 'epoch': 0.65}
{'loss': 0.8873, 'grad_norm': 0.5540908073295902, 'learning_rate': 5.894342258849355e-06, 'epoch': 0.65}
{'loss': 1.0369, 'grad_norm': 0.5727341069771205, 'learning_rate': 5.882982492451757e-06, 'epoch': 0.65}
{'loss': 0.991, 'grad_norm': 0.6361247374820852, 'learning_rate': 5.871629119525335e-06, 'epoch': 0.65}
{'loss': 1.0065, 'grad_norm': 0.662137691125513, 'learning_rate': 5.860282157701167e-06, 'epoch': 0.65}
{'loss': 1.007, 'grad_norm': 0.6451575415479192, 'learning_rate': 5.8489416246003814e-06, 'epoch': 0.65}
{'loss': 1.0137, 'grad_norm': 0.634680863880831, 'learning_rate': 5.8376075378341194e-06, 'epoch': 0.65}
{'loss': 1.0098, 'grad_norm': 0.6379233886393022, 'learning_rate': 5.826279915003503e-06, 'epoch': 0.65}
{'loss': 1.0045, 'grad_norm': 0.6040859391104472, 'learning_rate': 5.814958773699625e-06, 'epoch': 0.65}
{'loss': 0.9975, 'grad_norm': 0.5863402291485632, 'learning_rate': 5.803644131503516e-06, 'epoch': 0.65}
{'loss': 0.9737, 'grad_norm': 0.5342589469396276, 'learning_rate': 5.792336005986105e-06, 'epoch': 0.65}
{'loss': 1.0136, 'grad_norm': 0.6662791769230636, 'learning_rate': 5.781034414708208e-06, 'epoch': 0.65}
{'loss': 0.9759, 'grad_norm': 0.7822935980643131, 'learning_rate': 5.769739375220489e-06, 'epoch': 0.65}
{'loss': 0.9707, 'grad_norm': 0.6068291381693175, 'learning_rate': 5.7584509050634395e-06, 'epoch': 0.65}
{'loss': 0.9556, 'grad_norm': 0.5847859234399284, 'learning_rate': 5.747169021767342e-06, 'epoch': 0.65}
{'loss': 0.9487, 'grad_norm': 0.6079705807134639, 'learning_rate': 5.73589374285227e-06, 'epoch': 0.65}
{'loss': 1.0001, 'grad_norm': 0.6926848539562633, 'learning_rate': 5.724625085828022e-06, 'epoch': 0.65}
{'loss': 0.9925, 'grad_norm': 0.6488701313699385, 'learning_rate': 5.713363068194115e-06, 'epoch': 0.65}
{'loss': 1.0467, 'grad_norm': 0.6874692343498577, 'learning_rate': 5.702107707439766e-06, 'epoch': 0.65}
{'loss': 0.9693, 'grad_norm': 0.5648668992141463, 'learning_rate': 5.690859021043842e-06, 'epoch': 0.65}
{'loss': 0.9894, 'grad_norm': 0.7142492872448015, 'learning_rate': 5.679617026474853e-06, 'epoch': 0.65}
{'loss': 1.002, 'grad_norm': 0.644759986251185, 'learning_rate': 5.6683817411909114e-06, 'epoch': 0.66}
{'loss': 0.9931, 'grad_norm': 0.6258772210837124, 'learning_rate': 5.65715318263972e-06, 'epoch': 0.66}
{'loss': 0.9906, 'grad_norm': 0.6284858827201152, 'learning_rate': 5.645931368258527e-06, 'epoch': 0.66}
{'loss': 0.9989, 'grad_norm': 0.5638541955887798, 'learning_rate': 5.634716315474109e-06, 'epoch': 0.66}
{'loss': 0.9671, 'grad_norm': 0.5284194697426928, 'learning_rate': 5.623508041702743e-06, 'epoch': 0.66}
{'loss': 1.0154, 'grad_norm': 0.6672257561196523, 'learning_rate': 5.612306564350179e-06, 'epoch': 0.66}
{'loss': 1.0126, 'grad_norm': 0.5923508324063431, 'learning_rate': 5.601111900811607e-06, 'epoch': 0.66}
{'loss': 0.9612, 'grad_norm': 0.5846161097345108, 'learning_rate': 5.589924068471648e-06, 'epoch': 0.66}
{'loss': 0.9777, 'grad_norm': 0.7251216336193345, 'learning_rate': 5.578743084704306e-06, 'epoch': 0.66}
{'loss': 0.9767, 'grad_norm': 0.725808350386878, 'learning_rate': 5.567568966872947e-06, 'epoch': 0.66}
{'loss': 0.9217, 'grad_norm': 0.7251735112848763, 'learning_rate': 5.556401732330281e-06, 'epoch': 0.66}
{'loss': 1.0084, 'grad_norm': 0.5255877035390084, 'learning_rate': 5.545241398418326e-06, 'epoch': 0.66}
{'loss': 0.9612, 'grad_norm': 0.5526009900955997, 'learning_rate': 5.534087982468384e-06, 'epoch': 0.66}
{'loss': 1.0101, 'grad_norm': 0.653605256339602, 'learning_rate': 5.522941501801008e-06, 'epoch': 0.66}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B00WTKH3HC.jpg, using default black image.
{'loss': 0.9829, 'grad_norm': 0.5529340406453415, 'learning_rate': 5.511801973725997e-06, 'epoch': 0.66}
{'loss': 1.0193, 'grad_norm': 0.5782795072648808, 'learning_rate': 5.500669415542336e-06, 'epoch': 0.66}
{'loss': 0.9948, 'grad_norm': 0.5979047548271523, 'learning_rate': 5.4895438445381945e-06, 'epoch': 0.66}
{'loss': 0.994, 'grad_norm': 0.6287796765910896, 'learning_rate': 5.4784252779908905e-06, 'epoch': 0.66}
{'loss': 0.9679, 'grad_norm': 0.6265940927441307, 'learning_rate': 5.467313733166863e-06, 'epoch': 0.66}
{'loss': 0.9822, 'grad_norm': 0.7377318238499022, 'learning_rate': 5.456209227321643e-06, 'epoch': 0.66}
{'loss': 1.0084, 'grad_norm': 0.6394498636958931, 'learning_rate': 5.445111777699842e-06, 'epoch': 0.66}
{'loss': 0.9966, 'grad_norm': 0.67145512405831, 'learning_rate': 5.434021401535105e-06, 'epoch': 0.66}
{'loss': 0.99, 'grad_norm': 0.5947267917079377, 'learning_rate': 5.422938116050092e-06, 'epoch': 0.66}
{'loss': 0.9866, 'grad_norm': 0.7522717376950668, 'learning_rate': 5.411861938456453e-06, 'epoch': 0.66}
{'loss': 1.0228, 'grad_norm': 0.5652024097369645, 'learning_rate': 5.400792885954802e-06, 'epoch': 0.66}
{'loss': 0.9735, 'grad_norm': 0.6246525887139802, 'learning_rate': 5.389730975734686e-06, 'epoch': 0.66}
{'loss': 1.0273, 'grad_norm': 0.6081760730666917, 'learning_rate': 5.378676224974557e-06, 'epoch': 0.67}
{'loss': 0.9639, 'grad_norm': 0.5424174256043715, 'learning_rate': 5.367628650841761e-06, 'epoch': 0.67}
{'loss': 0.9702, 'grad_norm': 0.6676483827906895, 'learning_rate': 5.356588270492487e-06, 'epoch': 0.67}
{'loss': 1.0074, 'grad_norm': 0.7293245400379605, 'learning_rate': 5.3455551010717545e-06, 'epoch': 0.67}
{'loss': 0.9889, 'grad_norm': 0.6074415454790024, 'learning_rate': 5.334529159713389e-06, 'epoch': 0.67}
{'loss': 1.0124, 'grad_norm': 0.5902489654149232, 'learning_rate': 5.323510463539989e-06, 'epoch': 0.67}
{'loss': 0.9805, 'grad_norm': 0.5939446819462048, 'learning_rate': 5.3124990296628974e-06, 'epoch': 0.67}
{'loss': 1.0248, 'grad_norm': 0.6179375025775082, 'learning_rate': 5.301494875182192e-06, 'epoch': 0.67}
{'loss': 0.9775, 'grad_norm': 0.5987393605131935, 'learning_rate': 5.290498017186631e-06, 'epoch': 0.67}
{'loss': 0.9662, 'grad_norm': 0.6707897129088504, 'learning_rate': 5.279508472753654e-06, 'epoch': 0.67}
{'loss': 1.0064, 'grad_norm': 0.5632009970182348, 'learning_rate': 5.2685262589493314e-06, 'epoch': 0.67}
{'loss': 1.0242, 'grad_norm': 0.6922163782000922, 'learning_rate': 5.257551392828359e-06, 'epoch': 0.67}
{'loss': 1.0053, 'grad_norm': 0.5713509120651686, 'learning_rate': 5.246583891434018e-06, 'epoch': 0.67}
{'loss': 0.9816, 'grad_norm': 0.6368154394502836, 'learning_rate': 5.235623771798151e-06, 'epoch': 0.67}
{'loss': 0.9522, 'grad_norm': 0.5589929956707349, 'learning_rate': 5.224671050941146e-06, 'epoch': 0.67}
{'loss': 0.9831, 'grad_norm': 0.6323053850981672, 'learning_rate': 5.213725745871889e-06, 'epoch': 0.67}
{'loss': 1.0064, 'grad_norm': 0.7264442022524136, 'learning_rate': 5.20278787358776e-06, 'epoch': 0.67}
{'loss': 0.9254, 'grad_norm': 0.5986348001739764, 'learning_rate': 5.1918574510745865e-06, 'epoch': 0.67}
{'loss': 1.0212, 'grad_norm': 0.5833216997382192, 'learning_rate': 5.180934495306638e-06, 'epoch': 0.67}
{'loss': 0.9719, 'grad_norm': 0.6127283462062737, 'learning_rate': 5.170019023246574e-06, 'epoch': 0.67}
{'loss': 1.0197, 'grad_norm': 0.6332068395286008, 'learning_rate': 5.159111051845451e-06, 'epoch': 0.67}
{'loss': 0.994, 'grad_norm': 0.6136324239559854, 'learning_rate': 5.148210598042665e-06, 'epoch': 0.67}
{'loss': 1.0102, 'grad_norm': 0.5612592204268205, 'learning_rate': 5.137317678765939e-06, 'epoch': 0.67}
{'loss': 0.9985, 'grad_norm': 0.6016206702805148, 'learning_rate': 5.126432310931295e-06, 'epoch': 0.67}
{'loss': 0.9796, 'grad_norm': 0.6091067866189385, 'learning_rate': 5.115554511443033e-06, 'epoch': 0.67}
{'loss': 0.9954, 'grad_norm': 0.6080442699659201, 'learning_rate': 5.104684297193694e-06, 'epoch': 0.67}
{'loss': 0.9846, 'grad_norm': 0.6235310865973777, 'learning_rate': 5.09382168506404e-06, 'epoch': 0.68}
{'loss': 0.9775, 'grad_norm': 0.6712681275607341, 'learning_rate': 5.082966691923037e-06, 'epoch': 0.68}
{'loss': 1.0097, 'grad_norm': 0.640687935118259, 'learning_rate': 5.0721193346278066e-06, 'epoch': 0.68}
{'loss': 0.9833, 'grad_norm': 0.6951818133123984, 'learning_rate': 5.061279630023618e-06, 'epoch': 0.68}
{'loss': 0.9345, 'grad_norm': 0.5117776039212177, 'learning_rate': 5.050447594943856e-06, 'epoch': 0.68}
{'loss': 1.0201, 'grad_norm': 0.6416265036291645, 'learning_rate': 5.0396232462099945e-06, 'epoch': 0.68}
{'loss': 1.0129, 'grad_norm': 0.6501618560849198, 'learning_rate': 5.028806600631569e-06, 'epoch': 0.68}
{'loss': 1.0255, 'grad_norm': 0.656807670141022, 'learning_rate': 5.017997675006161e-06, 'epoch': 0.68}
{'loss': 0.9981, 'grad_norm': 0.6651659961489879, 'learning_rate': 5.007196486119355e-06, 'epoch': 0.68}
{'loss': 0.9782, 'grad_norm': 0.6383723995046926, 'learning_rate': 4.996403050744719e-06, 'epoch': 0.68}
{'loss': 1.0297, 'grad_norm': 0.6667943611628295, 'learning_rate': 4.985617385643789e-06, 'epoch': 0.68}
{'loss': 0.987, 'grad_norm': 0.6934435589364344, 'learning_rate': 4.974839507566027e-06, 'epoch': 0.68}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B013RVJ7KW.jpg, using default black image.
{'loss': 0.9837, 'grad_norm': 0.6394136121327445, 'learning_rate': 4.9640694332488075e-06, 'epoch': 0.68}
{'loss': 1.0004, 'grad_norm': 0.6429471264799058, 'learning_rate': 4.953307179417376e-06, 'epoch': 0.68}
{'loss': 1.0263, 'grad_norm': 0.6047409223085036, 'learning_rate': 4.94255276278485e-06, 'epoch': 0.68}
{'loss': 0.9409, 'grad_norm': 0.5467225698791714, 'learning_rate': 4.931806200052165e-06, 'epoch': 0.68}
{'loss': 0.9472, 'grad_norm': 0.5621763153206362, 'learning_rate': 4.92106750790806e-06, 'epoch': 0.68}
{'loss': 1.0158, 'grad_norm': 0.602077125372112, 'learning_rate': 4.910336703029055e-06, 'epoch': 0.68}
{'loss': 0.9913, 'grad_norm': 0.6684243864506095, 'learning_rate': 4.899613802079419e-06, 'epoch': 0.68}
{'loss': 1.013, 'grad_norm': 0.6848880448486316, 'learning_rate': 4.888898821711144e-06, 'epoch': 0.68}
{'loss': 0.9385, 'grad_norm': 0.5055757669167451, 'learning_rate': 4.878191778563934e-06, 'epoch': 0.68}
{'loss': 1.04, 'grad_norm': 0.5849746356572633, 'learning_rate': 4.867492689265154e-06, 'epoch': 0.68}
{'loss': 1.0019, 'grad_norm': 0.615121197047708, 'learning_rate': 4.856801570429822e-06, 'epoch': 0.68}
{'loss': 0.9382, 'grad_norm': 0.5311985376264984, 'learning_rate': 4.846118438660578e-06, 'epoch': 0.68}
{'loss': 1.017, 'grad_norm': 0.7937470376910937, 'learning_rate': 4.83544331054766e-06, 'epoch': 0.68}
{'loss': 0.9524, 'grad_norm': 0.5344836294211035, 'learning_rate': 4.824776202668875e-06, 'epoch': 0.68}
{'loss': 1.0285, 'grad_norm': 0.5965468196359358, 'learning_rate': 4.8141171315895694e-06, 'epoch': 0.69}
{'loss': 0.9724, 'grad_norm': 0.5632375177579334, 'learning_rate': 4.803466113862626e-06, 'epoch': 0.69}
{'loss': 0.9587, 'grad_norm': 0.6802096311750983, 'learning_rate': 4.792823166028405e-06, 'epoch': 0.69}
{'loss': 1.0341, 'grad_norm': 0.6133607504563426, 'learning_rate': 4.7821883046147414e-06, 'epoch': 0.69}
{'loss': 0.9928, 'grad_norm': 0.8144733984068685, 'learning_rate': 4.771561546136908e-06, 'epoch': 0.69}
{'loss': 0.9593, 'grad_norm': 0.6778664866278409, 'learning_rate': 4.760942907097601e-06, 'epoch': 0.69}
{'loss': 0.9698, 'grad_norm': 0.6907663136508899, 'learning_rate': 4.750332403986902e-06, 'epoch': 0.69}
{'loss': 0.9624, 'grad_norm': 0.662683690692471, 'learning_rate': 4.739730053282255e-06, 'epoch': 0.69}
{'loss': 0.99, 'grad_norm': 0.67250762909151, 'learning_rate': 4.7291358714484594e-06, 'epoch': 0.69}
{'loss': 0.9697, 'grad_norm': 0.613514405986456, 'learning_rate': 4.718549874937612e-06, 'epoch': 0.69}
{'loss': 1.0242, 'grad_norm': 0.6814950266544231, 'learning_rate': 4.707972080189106e-06, 'epoch': 0.69}
{'loss': 0.9817, 'grad_norm': 0.632092122516862, 'learning_rate': 4.697402503629596e-06, 'epoch': 0.69}
{'loss': 1.04, 'grad_norm': 0.6141768869022755, 'learning_rate': 4.686841161672974e-06, 'epoch': 0.69}
{'loss': 1.0129, 'grad_norm': 0.6186707137211429, 'learning_rate': 4.67628807072034e-06, 'epoch': 0.69}
{'loss': 0.9536, 'grad_norm': 0.6776888273999135, 'learning_rate': 4.665743247159995e-06, 'epoch': 0.69}
{'loss': 0.9673, 'grad_norm': 0.6462045919812536, 'learning_rate': 4.655206707367388e-06, 'epoch': 0.69}
{'loss': 1.0389, 'grad_norm': 0.62899732285254, 'learning_rate': 4.644678467705101e-06, 'epoch': 0.69}
{'loss': 0.9645, 'grad_norm': 0.6070903280938165, 'learning_rate': 4.634158544522849e-06, 'epoch': 0.69}
{'loss': 0.8933, 'grad_norm': 0.531831583738298, 'learning_rate': 4.623646954157399e-06, 'epoch': 0.69}
{'loss': 0.9202, 'grad_norm': 0.5138700180375874, 'learning_rate': 4.613143712932603e-06, 'epoch': 0.69}
{'loss': 0.9798, 'grad_norm': 0.6300711067044964, 'learning_rate': 4.602648837159333e-06, 'epoch': 0.69}
{'loss': 0.9769, 'grad_norm': 0.5938846728209451, 'learning_rate': 4.592162343135483e-06, 'epoch': 0.69}
{'loss': 0.9135, 'grad_norm': 0.5705898144185216, 'learning_rate': 4.5816842471459224e-06, 'epoch': 0.69}
{'loss': 1.0277, 'grad_norm': 0.5985891377074106, 'learning_rate': 4.571214565462477e-06, 'epoch': 0.69}
{'loss': 0.9689, 'grad_norm': 0.6448174000035355, 'learning_rate': 4.560753314343912e-06, 'epoch': 0.69}
{'loss': 0.9833, 'grad_norm': 0.6172778298292207, 'learning_rate': 4.5503005100358945e-06, 'epoch': 0.69}
{'loss': 0.974, 'grad_norm': 0.7984379581603508, 'learning_rate': 4.539856168770974e-06, 'epoch': 0.7}
{'loss': 0.9822, 'grad_norm': 0.6122397062207396, 'learning_rate': 4.52942030676857e-06, 'epoch': 0.7}
{'loss': 0.995, 'grad_norm': 0.6136156363005523, 'learning_rate': 4.5189929402349175e-06, 'epoch': 0.7}
{'loss': 1.0172, 'grad_norm': 0.6164955621152762, 'learning_rate': 4.508574085363065e-06, 'epoch': 0.7}
{'loss': 1.0009, 'grad_norm': 0.7080380684173534, 'learning_rate': 4.498163758332853e-06, 'epoch': 0.7}
{'loss': 0.9973, 'grad_norm': 0.6405958747050617, 'learning_rate': 4.4877619753108605e-06, 'epoch': 0.7}
{'loss': 1.0231, 'grad_norm': 0.6961088964498973, 'learning_rate': 4.477368752450409e-06, 'epoch': 0.7}
{'loss': 0.9996, 'grad_norm': 0.6475953416009316, 'learning_rate': 4.466984105891521e-06, 'epoch': 0.7}
{'loss': 1.0269, 'grad_norm': 0.6097416898962305, 'learning_rate': 4.456608051760914e-06, 'epoch': 0.7}
{'loss': 1.0013, 'grad_norm': 0.678877686421319, 'learning_rate': 4.446240606171945e-06, 'epoch': 0.7}
{'loss': 0.9585, 'grad_norm': 0.5714268065940062, 'learning_rate': 4.4358817852246124e-06, 'epoch': 0.7}
{'loss': 1.0081, 'grad_norm': 0.6066678935397131, 'learning_rate': 4.425531605005519e-06, 'epoch': 0.7}
{'loss': 0.9796, 'grad_norm': 0.5974135864722561, 'learning_rate': 4.4151900815878455e-06, 'epoch': 0.7}
{'loss': 0.9734, 'grad_norm': 0.5690195369496412, 'learning_rate': 4.404857231031332e-06, 'epoch': 0.7}
{'loss': 0.9628, 'grad_norm': 0.6224284880179898, 'learning_rate': 4.394533069382255e-06, 'epoch': 0.7}
{'loss': 0.9578, 'grad_norm': 0.608418684009742, 'learning_rate': 4.3842176126733914e-06, 'epoch': 0.7}
{'loss': 1.0164, 'grad_norm': 0.6227650288345845, 'learning_rate': 4.373910876923997e-06, 'epoch': 0.7}
{'loss': 0.9836, 'grad_norm': 0.6927447567008849, 'learning_rate': 4.363612878139799e-06, 'epoch': 0.7}
{'loss': 0.941, 'grad_norm': 0.6502713538856092, 'learning_rate': 4.353323632312938e-06, 'epoch': 0.7}
{'loss': 1.0104, 'grad_norm': 0.61949326495421, 'learning_rate': 4.343043155421971e-06, 'epoch': 0.7}
{'loss': 1.0411, 'grad_norm': 0.6407186004379306, 'learning_rate': 4.332771463431837e-06, 'epoch': 0.7}
{'loss': 0.9672, 'grad_norm': 0.6877927645862265, 'learning_rate': 4.322508572293836e-06, 'epoch': 0.7}
{'loss': 1.0029, 'grad_norm': 0.6133186640993336, 'learning_rate': 4.312254497945595e-06, 'epoch': 0.7}
{'loss': 1.0099, 'grad_norm': 0.6269889893132045, 'learning_rate': 4.3020092563110485e-06, 'epoch': 0.7}
{'loss': 1.0131, 'grad_norm': 0.7433461375439874, 'learning_rate': 4.291772863300428e-06, 'epoch': 0.7}
{'loss': 0.9968, 'grad_norm': 0.6564049216138187, 'learning_rate': 4.281545334810201e-06, 'epoch': 0.7}
{'loss': 1.0032, 'grad_norm': 0.6393934873430854, 'learning_rate': 4.27132668672308e-06, 'epoch': 0.71}
{'loss': 0.9753, 'grad_norm': 0.6157377110951128, 'learning_rate': 4.2611169349079985e-06, 'epoch': 0.71}
{'loss': 0.9955, 'grad_norm': 0.6065951778160602, 'learning_rate': 4.250916095220056e-06, 'epoch': 0.71}
{'loss': 1.0181, 'grad_norm': 0.6289166717079303, 'learning_rate': 4.240724183500518e-06, 'epoch': 0.71}
{'loss': 0.9352, 'grad_norm': 0.4982737425234319, 'learning_rate': 4.230541215576798e-06, 'epoch': 0.71}
{'loss': 1.0153, 'grad_norm': 0.5765446213693814, 'learning_rate': 4.220367207262398e-06, 'epoch': 0.71}
{'loss': 0.9928, 'grad_norm': 0.650770736360433, 'learning_rate': 4.210202174356922e-06, 'epoch': 0.71}
{'loss': 0.9773, 'grad_norm': 0.6271207772439363, 'learning_rate': 4.2000461326460274e-06, 'epoch': 0.71}
{'loss': 0.9745, 'grad_norm': 0.5987181703070399, 'learning_rate': 4.189899097901421e-06, 'epoch': 0.71}
{'loss': 0.9782, 'grad_norm': 0.64704630136336, 'learning_rate': 4.179761085880809e-06, 'epoch': 0.71}
{'loss': 0.9137, 'grad_norm': 0.5218230466464062, 'learning_rate': 4.16963211232789e-06, 'epoch': 0.71}
{'loss': 0.9391, 'grad_norm': 0.651295099725572, 'learning_rate': 4.159512192972337e-06, 'epoch': 0.71}
{'loss': 0.9225, 'grad_norm': 0.580537022404666, 'learning_rate': 4.149401343529742e-06, 'epoch': 0.71}
{'loss': 0.9648, 'grad_norm': 0.621573111530864, 'learning_rate': 4.139299579701623e-06, 'epoch': 0.71}
{'loss': 1.0139, 'grad_norm': 0.5992561621918657, 'learning_rate': 4.129206917175397e-06, 'epoch': 0.71}
{'loss': 1.0114, 'grad_norm': 0.6011256782790714, 'learning_rate': 4.119123371624335e-06, 'epoch': 0.71}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/899061877.jpg, using default black image.
{'loss': 0.9648, 'grad_norm': 0.5861134627181206, 'learning_rate': 4.109048958707552e-06, 'epoch': 0.71}
{'loss': 1.0041, 'grad_norm': 0.6566786036035027, 'learning_rate': 4.09898369406998e-06, 'epoch': 0.71}
{'loss': 1.0134, 'grad_norm': 0.6014085947279724, 'learning_rate': 4.0889275933423576e-06, 'epoch': 0.71}
{'loss': 1.0079, 'grad_norm': 0.5954545188430365, 'learning_rate': 4.078880672141171e-06, 'epoch': 0.71}
{'loss': 0.9925, 'grad_norm': 0.6510659107755016, 'learning_rate': 4.068842946068661e-06, 'epoch': 0.71}
{'loss': 1.0037, 'grad_norm': 0.606970788969566, 'learning_rate': 4.058814430712796e-06, 'epoch': 0.71}
{'loss': 0.9434, 'grad_norm': 0.6452259322165292, 'learning_rate': 4.0487951416472324e-06, 'epoch': 0.71}
{'loss': 0.93, 'grad_norm': 0.7505605326289755, 'learning_rate': 4.038785094431295e-06, 'epoch': 0.71}
{'loss': 1.0356, 'grad_norm': 0.6281653703569005, 'learning_rate': 4.0287843046099765e-06, 'epoch': 0.71}
{'loss': 0.9886, 'grad_norm': 0.7418773152301456, 'learning_rate': 4.018792787713865e-06, 'epoch': 0.71}
{'loss': 0.9738, 'grad_norm': 0.5881428509397818, 'learning_rate': 4.008810559259162e-06, 'epoch': 0.72}
{'loss': 1.0052, 'grad_norm': 0.6529040611804733, 'learning_rate': 3.998837634747655e-06, 'epoch': 0.72}
{'loss': 0.981, 'grad_norm': 0.6065447464118335, 'learning_rate': 3.98887402966667e-06, 'epoch': 0.72}
{'loss': 1.0006, 'grad_norm': 0.5692594573999988, 'learning_rate': 3.97891975948906e-06, 'epoch': 0.72}
{'loss': 0.9961, 'grad_norm': 0.5560822194865238, 'learning_rate': 3.968974839673186e-06, 'epoch': 0.72}
{'loss': 0.9619, 'grad_norm': 0.578786351551152, 'learning_rate': 3.9590392856628946e-06, 'epoch': 0.72}
{'loss': 0.9518, 'grad_norm': 0.6018698681307603, 'learning_rate': 3.949113112887471e-06, 'epoch': 0.72}
{'loss': 0.9722, 'grad_norm': 0.6035150925421789, 'learning_rate': 3.939196336761645e-06, 'epoch': 0.72}
{'loss': 0.9694, 'grad_norm': 0.6616189874151436, 'learning_rate': 3.929288972685555e-06, 'epoch': 0.72}
{'loss': 0.9713, 'grad_norm': 0.630856786763037, 'learning_rate': 3.919391036044715e-06, 'epoch': 0.72}
{'loss': 0.9936, 'grad_norm': 0.6230008982562354, 'learning_rate': 3.909502542210001e-06, 'epoch': 0.72}
{'loss': 0.9703, 'grad_norm': 0.6473691059922868, 'learning_rate': 3.899623506537635e-06, 'epoch': 0.72}
{'loss': 0.978, 'grad_norm': 0.7279583737059361, 'learning_rate': 3.8897539443691355e-06, 'epoch': 0.72}
{'loss': 1.014, 'grad_norm': 0.5151168142911701, 'learning_rate': 3.879893871031314e-06, 'epoch': 0.72}
{'loss': 0.9769, 'grad_norm': 0.6691652939327881, 'learning_rate': 3.870043301836256e-06, 'epoch': 0.72}
{'loss': 0.9778, 'grad_norm': 0.6101018390483033, 'learning_rate': 3.860202252081276e-06, 'epoch': 0.72}
{'loss': 1.0089, 'grad_norm': 0.5972822680986745, 'learning_rate': 3.850370737048913e-06, 'epoch': 0.72}
{'loss': 1.0256, 'grad_norm': 0.6780513567698319, 'learning_rate': 3.840548772006891e-06, 'epoch': 0.72}
{'loss': 0.9952, 'grad_norm': 0.6277536649650419, 'learning_rate': 3.830736372208118e-06, 'epoch': 0.72}
{'loss': 0.9603, 'grad_norm': 0.549072123069944, 'learning_rate': 3.820933552890629e-06, 'epoch': 0.72}
{'loss': 0.9922, 'grad_norm': 0.7074846357292032, 'learning_rate': 3.811140329277591e-06, 'epoch': 0.72}
{'loss': 0.9693, 'grad_norm': 0.4865261861050051, 'learning_rate': 3.8013567165772735e-06, 'epoch': 0.72}
{'loss': 1.0168, 'grad_norm': 0.597944500274207, 'learning_rate': 3.7915827299830154e-06, 'epoch': 0.72}
{'loss': 0.9868, 'grad_norm': 0.5912440089233314, 'learning_rate': 3.7818183846732024e-06, 'epoch': 0.72}
{'loss': 0.9816, 'grad_norm': 0.6088014386579179, 'learning_rate': 3.7720636958112623e-06, 'epoch': 0.72}
{'loss': 0.972, 'grad_norm': 0.6061859250036404, 'learning_rate': 3.7623186785456156e-06, 'epoch': 0.72}
{'loss': 0.935, 'grad_norm': 0.5246285922551223, 'learning_rate': 3.7525833480096575e-06, 'epoch': 0.73}
{'loss': 1.0098, 'grad_norm': 0.5093178748351154, 'learning_rate': 3.7428577193217563e-06, 'epoch': 0.73}
{'loss': 1.0309, 'grad_norm': 0.5989770860645689, 'learning_rate': 3.7331418075852053e-06, 'epoch': 0.73}
{'loss': 0.9934, 'grad_norm': 0.5859426669456195, 'learning_rate': 3.7234356278882076e-06, 'epoch': 0.73}
{'loss': 1.0372, 'grad_norm': 0.651985030633054, 'learning_rate': 3.7137391953038516e-06, 'epoch': 0.73}
{'loss': 0.9887, 'grad_norm': 0.6951119072014446, 'learning_rate': 3.7040525248901003e-06, 'epoch': 0.73}
{'loss': 0.9836, 'grad_norm': 0.6703939469044097, 'learning_rate': 3.6943756316897406e-06, 'epoch': 0.73}
{'loss': 0.996, 'grad_norm': 0.6267893549312736, 'learning_rate': 3.684708530730382e-06, 'epoch': 0.73}
{'loss': 0.9761, 'grad_norm': 0.5530309863333234, 'learning_rate': 3.6750512370244363e-06, 'epoch': 0.73}
{'loss': 0.99, 'grad_norm': 0.8562351088307282, 'learning_rate': 3.6654037655690732e-06, 'epoch': 0.73}
{'loss': 1.0004, 'grad_norm': 0.6272657447664316, 'learning_rate': 3.655766131346211e-06, 'epoch': 0.73}
{'loss': 0.9854, 'grad_norm': 0.8698147888656662, 'learning_rate': 3.6461383493225012e-06, 'epoch': 0.73}
{'loss': 0.9743, 'grad_norm': 0.6544814963563943, 'learning_rate': 3.6365204344492867e-06, 'epoch': 0.73}
{'loss': 0.9787, 'grad_norm': 0.6356055004765563, 'learning_rate': 3.62691240166258e-06, 'epoch': 0.73}
{'loss': 0.9258, 'grad_norm': 0.4991928952258795, 'learning_rate': 3.617314265883066e-06, 'epoch': 0.73}
{'loss': 1.0035, 'grad_norm': 0.665385346832085, 'learning_rate': 3.6077260420160487e-06, 'epoch': 0.73}
{'loss': 1.0352, 'grad_norm': 0.633871497754912, 'learning_rate': 3.598147744951438e-06, 'epoch': 0.73}
{'loss': 0.9999, 'grad_norm': 0.7008944323917327, 'learning_rate': 3.58857938956373e-06, 'epoch': 0.73}
{'loss': 1.0077, 'grad_norm': 0.5970860826211406, 'learning_rate': 3.57902099071199e-06, 'epoch': 0.73}
{'loss': 0.9649, 'grad_norm': 0.7186409722380049, 'learning_rate': 3.569472563239814e-06, 'epoch': 0.73}
{'loss': 0.9781, 'grad_norm': 0.6528017634231081, 'learning_rate': 3.559934121975304e-06, 'epoch': 0.73}
{'loss': 0.998, 'grad_norm': 0.651446750974142, 'learning_rate': 3.550405681731074e-06, 'epoch': 0.73}
{'loss': 0.9457, 'grad_norm': 0.5085604462317596, 'learning_rate': 3.540887257304193e-06, 'epoch': 0.73}
{'loss': 0.9944, 'grad_norm': 0.5486690828428235, 'learning_rate': 3.531378863476178e-06, 'epoch': 0.73}
{'loss': 0.9999, 'grad_norm': 0.6545832041822538, 'learning_rate': 3.5218805150129755e-06, 'epoch': 0.73}
{'loss': 0.9615, 'grad_norm': 0.6112162945742852, 'learning_rate': 3.51239222666493e-06, 'epoch': 0.73}
{'loss': 0.9637, 'grad_norm': 0.7114541702045886, 'learning_rate': 3.5029140131667493e-06, 'epoch': 0.74}
{'loss': 0.9726, 'grad_norm': 0.6489801075318199, 'learning_rate': 3.493445889237518e-06, 'epoch': 0.74}
{'loss': 0.9724, 'grad_norm': 0.6120077164509481, 'learning_rate': 3.4839878695806385e-06, 'epoch': 0.74}
{'loss': 0.9768, 'grad_norm': 0.64261045623335, 'learning_rate': 3.4745399688838243e-06, 'epoch': 0.74}
{'loss': 0.9943, 'grad_norm': 0.708807907987429, 'learning_rate': 3.4651022018190715e-06, 'epoch': 0.74}
{'loss': 1.0316, 'grad_norm': 0.6145004273947655, 'learning_rate': 3.455674583042652e-06, 'epoch': 0.74}
{'loss': 0.9977, 'grad_norm': 0.7192913648045064, 'learning_rate': 3.4462571271950674e-06, 'epoch': 0.74}
{'loss': 1.0035, 'grad_norm': 0.5839792439441504, 'learning_rate': 3.436849848901028e-06, 'epoch': 0.74}
{'loss': 0.9735, 'grad_norm': 0.6525045659298502, 'learning_rate': 3.427452762769462e-06, 'epoch': 0.74}
{'loss': 0.9851, 'grad_norm': 0.6488239170791557, 'learning_rate': 3.4180658833934523e-06, 'epoch': 0.74}
{'loss': 0.9285, 'grad_norm': 0.6254331999409266, 'learning_rate': 3.4086892253502344e-06, 'epoch': 0.74}
{'loss': 0.9766, 'grad_norm': 0.6041248190817093, 'learning_rate': 3.3993228032011784e-06, 'epoch': 0.74}
{'loss': 0.9996, 'grad_norm': 0.7053687683627131, 'learning_rate': 3.3899666314917512e-06, 'epoch': 0.74}
{'loss': 1.003, 'grad_norm': 0.5525873008727353, 'learning_rate': 3.3806207247515068e-06, 'epoch': 0.74}
{'loss': 0.982, 'grad_norm': 0.5752531831816596, 'learning_rate': 3.3712850974940437e-06, 'epoch': 0.74}
{'loss': 1.0142, 'grad_norm': 0.6183767794875861, 'learning_rate': 3.361959764217018e-06, 'epoch': 0.74}
{'loss': 0.9186, 'grad_norm': 0.5360302757286276, 'learning_rate': 3.3526447394020887e-06, 'epoch': 0.74}
{'loss': 0.9601, 'grad_norm': 0.6940269712631895, 'learning_rate': 3.343340037514903e-06, 'epoch': 0.74}
{'loss': 0.9267, 'grad_norm': 0.5326015471980176, 'learning_rate': 3.3340456730050887e-06, 'epoch': 0.74}
{'loss': 0.9414, 'grad_norm': 0.6375952244744951, 'learning_rate': 3.324761660306215e-06, 'epoch': 0.74}
{'loss': 0.9682, 'grad_norm': 0.6285039200987492, 'learning_rate': 3.3154880138357626e-06, 'epoch': 0.74}
{'loss': 1.0145, 'grad_norm': 0.7039132346798675, 'learning_rate': 3.306224747995136e-06, 'epoch': 0.74}
{'loss': 0.9258, 'grad_norm': 0.6072137494675716, 'learning_rate': 3.2969718771696047e-06, 'epoch': 0.74}
{'loss': 0.977, 'grad_norm': 0.6003527730821714, 'learning_rate': 3.287729415728298e-06, 'epoch': 0.74}
{'loss': 0.9581, 'grad_norm': 0.5871917669643791, 'learning_rate': 3.278497378024187e-06, 'epoch': 0.74}
{'loss': 1.0016, 'grad_norm': 0.6162167469639998, 'learning_rate': 3.2692757783940467e-06, 'epoch': 0.74}
{'loss': 0.9736, 'grad_norm': 0.6181354676689269, 'learning_rate': 3.2600646311584494e-06, 'epoch': 0.75}
{'loss': 0.9801, 'grad_norm': 0.6054900376766493, 'learning_rate': 3.250863950621721e-06, 'epoch': 0.75}
{'loss': 0.977, 'grad_norm': 0.6923926638862767, 'learning_rate': 3.241673751071954e-06, 'epoch': 0.75}
{'loss': 0.9946, 'grad_norm': 0.6114718467652843, 'learning_rate': 3.2324940467809527e-06, 'epoch': 0.75}
{'loss': 1.0159, 'grad_norm': 0.6662042011550593, 'learning_rate': 3.223324852004219e-06, 'epoch': 0.75}
{'loss': 0.966, 'grad_norm': 0.6421728611209861, 'learning_rate': 3.21416618098095e-06, 'epoch': 0.75}
{'loss': 0.9575, 'grad_norm': 0.6152673544519878, 'learning_rate': 3.2050180479339865e-06, 'epoch': 0.75}
{'loss': 0.9816, 'grad_norm': 0.865544739413579, 'learning_rate': 3.1958804670698008e-06, 'epoch': 0.75}
{'loss': 0.9709, 'grad_norm': 0.5969195416548962, 'learning_rate': 3.1867534525784937e-06, 'epoch': 0.75}
{'loss': 0.988, 'grad_norm': 0.6041173124663096, 'learning_rate': 3.177637018633746e-06, 'epoch': 0.75}
{'loss': 0.9161, 'grad_norm': 0.4672488787959572, 'learning_rate': 3.1685311793928077e-06, 'epoch': 0.75}
{'loss': 0.9636, 'grad_norm': 0.5832779359562374, 'learning_rate': 3.1594359489964853e-06, 'epoch': 0.75}
{'loss': 1.0027, 'grad_norm': 0.5909726191201564, 'learning_rate': 3.150351341569101e-06, 'epoch': 0.75}
{'loss': 0.9401, 'grad_norm': 0.6909305145168758, 'learning_rate': 3.141277371218484e-06, 'epoch': 0.75}
{'loss': 0.9551, 'grad_norm': 0.7978628225961316, 'learning_rate': 3.1322140520359366e-06, 'epoch': 0.75}
{'loss': 0.9731, 'grad_norm': 0.6252970288980492, 'learning_rate': 3.1231613980962373e-06, 'epoch': 0.75}
{'loss': 0.8933, 'grad_norm': 0.7015881376209898, 'learning_rate': 3.1141194234575878e-06, 'epoch': 0.75}
{'loss': 1.0077, 'grad_norm': 0.6158384355198467, 'learning_rate': 3.1050881421616076e-06, 'epoch': 0.75}
{'loss': 1.0044, 'grad_norm': 0.5693892667356335, 'learning_rate': 3.0960675682333186e-06, 'epoch': 0.75}
{'loss': 1.0022, 'grad_norm': 0.6000233719006484, 'learning_rate': 3.0870577156811077e-06, 'epoch': 0.75}
{'loss': 0.9605, 'grad_norm': 0.6595655148209272, 'learning_rate': 3.0780585984967113e-06, 'epoch': 0.75}
{'loss': 1.0109, 'grad_norm': 0.6380102484635507, 'learning_rate': 3.069070230655198e-06, 'epoch': 0.75}
{'loss': 1.003, 'grad_norm': 0.7493952413953565, 'learning_rate': 3.060092626114941e-06, 'epoch': 0.75}
{'loss': 0.9861, 'grad_norm': 0.593891057435849, 'learning_rate': 3.051125798817598e-06, 'epoch': 0.75}
{'loss': 0.9819, 'grad_norm': 0.5972032458136821, 'learning_rate': 3.042169762688096e-06, 'epoch': 0.75}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B011M9LHUO.jpg, using default black image.
{'loss': 0.9643, 'grad_norm': 0.519286347529663, 'learning_rate': 3.0332245316346e-06, 'epoch': 0.75}
{'loss': 0.9571, 'grad_norm': 0.6260493479125872, 'learning_rate': 3.024290119548495e-06, 'epoch': 0.76}
{'loss': 0.9638, 'grad_norm': 0.6562108492223261, 'learning_rate': 3.0153665403043586e-06, 'epoch': 0.76}
{'loss': 1.0142, 'grad_norm': 0.6518941069414644, 'learning_rate': 3.0064538077599603e-06, 'epoch': 0.76}
{'loss': 0.9513, 'grad_norm': 0.5253612912144995, 'learning_rate': 2.9975519357562155e-06, 'epoch': 0.76}
{'loss': 1.0393, 'grad_norm': 0.6993742047722692, 'learning_rate': 2.9886609381171703e-06, 'epoch': 0.76}
{'loss': 0.9753, 'grad_norm': 0.6710692867889001, 'learning_rate': 2.9797808286499976e-06, 'epoch': 0.76}
{'loss': 1.0307, 'grad_norm': 0.5960499810125665, 'learning_rate': 2.9709116211449484e-06, 'epoch': 0.76}
{'loss': 0.9529, 'grad_norm': 0.5526821001412997, 'learning_rate': 2.9620533293753495e-06, 'epoch': 0.76}
{'loss': 1.0075, 'grad_norm': 0.6493296729519672, 'learning_rate': 2.9532059670975732e-06, 'epoch': 0.76}
{'loss': 0.9897, 'grad_norm': 0.5864699556205142, 'learning_rate': 2.9443695480510225e-06, 'epoch': 0.76}
{'loss': 1.0293, 'grad_norm': 0.6238125808925161, 'learning_rate': 2.935544085958102e-06, 'epoch': 0.76}
{'loss': 0.9931, 'grad_norm': 0.696186454507483, 'learning_rate': 2.926729594524207e-06, 'epoch': 0.76}
{'loss': 0.9591, 'grad_norm': 0.7037621798606204, 'learning_rate': 2.9179260874376915e-06, 'epoch': 0.76}
{'loss': 0.9609, 'grad_norm': 0.6970592647911618, 'learning_rate': 2.9091335783698517e-06, 'epoch': 0.76}
{'loss': 0.9607, 'grad_norm': 0.6221558825807195, 'learning_rate': 2.9003520809749053e-06, 'epoch': 0.76}
{'loss': 0.9401, 'grad_norm': 0.6429681406432463, 'learning_rate': 2.8915816088899696e-06, 'epoch': 0.76}
{'loss': 1.0006, 'grad_norm': 0.6712795900007783, 'learning_rate': 2.8828221757350406e-06, 'epoch': 0.76}
{'loss': 1.0202, 'grad_norm': 0.6854293485057978, 'learning_rate': 2.874073795112967e-06, 'epoch': 0.76}
{'loss': 0.9766, 'grad_norm': 0.5311209522499432, 'learning_rate': 2.8653364806094454e-06, 'epoch': 0.76}
{'loss': 0.8829, 'grad_norm': 0.6274875470916947, 'learning_rate': 2.856610245792976e-06, 'epoch': 0.76}
{'loss': 0.9997, 'grad_norm': 0.6800302787035989, 'learning_rate': 2.847895104214856e-06, 'epoch': 0.76}
{'loss': 0.9935, 'grad_norm': 0.527759511747962, 'learning_rate': 2.8391910694091584e-06, 'epoch': 0.76}
{'loss': 0.9949, 'grad_norm': 0.6206202578748594, 'learning_rate': 2.8304981548927025e-06, 'epoch': 0.76}
{'loss': 0.9996, 'grad_norm': 0.6541469515337032, 'learning_rate': 2.8218163741650415e-06, 'epoch': 0.76}
{'loss': 0.9784, 'grad_norm': 0.6058473409041347, 'learning_rate': 2.813145740708445e-06, 'epoch': 0.76}
{'loss': 0.9801, 'grad_norm': 0.5705506091691039, 'learning_rate': 2.8044862679878605e-06, 'epoch': 0.76}
{'loss': 1.0033, 'grad_norm': 0.5821904586842381, 'learning_rate': 2.7958379694509108e-06, 'epoch': 0.77}
{'loss': 0.9771, 'grad_norm': 0.6612885161486968, 'learning_rate': 2.787200858527862e-06, 'epoch': 0.77}
{'loss': 0.9439, 'grad_norm': 0.6356216554693614, 'learning_rate': 2.7785749486316085e-06, 'epoch': 0.77}
{'loss': 0.9906, 'grad_norm': 0.5983037923133815, 'learning_rate': 2.7699602531576496e-06, 'epoch': 0.77}
{'loss': 1.0152, 'grad_norm': 0.6863111108687515, 'learning_rate': 2.7613567854840685e-06, 'epoch': 0.77}
{'loss': 1.0166, 'grad_norm': 0.7191042565197604, 'learning_rate': 2.752764558971517e-06, 'epoch': 0.77}
{'loss': 0.9688, 'grad_norm': 0.6688413836140995, 'learning_rate': 2.744183586963185e-06, 'epoch': 0.77}
{'loss': 0.9689, 'grad_norm': 0.6532374630097278, 'learning_rate': 2.7356138827847856e-06, 'epoch': 0.77}
{'loss': 0.9441, 'grad_norm': 0.6162138740708328, 'learning_rate': 2.7270554597445343e-06, 'epoch': 0.77}
{'loss': 0.9542, 'grad_norm': 0.6281124793061154, 'learning_rate': 2.7185083311331283e-06, 'epoch': 0.77}
{'loss': 0.9835, 'grad_norm': 0.6410054727206063, 'learning_rate': 2.709972510223725e-06, 'epoch': 0.77}
{'loss': 0.9766, 'grad_norm': 0.755509517345197, 'learning_rate': 2.7014480102719174e-06, 'epoch': 0.77}
{'loss': 0.9707, 'grad_norm': 0.5907783377557593, 'learning_rate': 2.692934844515729e-06, 'epoch': 0.77}
{'loss': 0.9477, 'grad_norm': 0.5847992768969978, 'learning_rate': 2.6844330261755715e-06, 'epoch': 0.77}
{'loss': 0.9929, 'grad_norm': 0.6460042308885476, 'learning_rate': 2.675942568454236e-06, 'epoch': 0.77}
{'loss': 0.9853, 'grad_norm': 0.6639893448574972, 'learning_rate': 2.667463484536876e-06, 'epoch': 0.77}
{'loss': 0.9522, 'grad_norm': 0.6224498238755332, 'learning_rate': 2.65899578759098e-06, 'epoch': 0.77}
{'loss': 0.9868, 'grad_norm': 0.32942904650781063, 'learning_rate': 2.650539490766346e-06, 'epoch': 0.77}
{'loss': 0.9685, 'grad_norm': 0.557523265809976, 'learning_rate': 2.642094607195085e-06, 'epoch': 0.77}
{'loss': 0.9896, 'grad_norm': 0.5801979111050171, 'learning_rate': 2.633661149991569e-06, 'epoch': 0.77}
{'loss': 1.003, 'grad_norm': 0.7043621456392452, 'learning_rate': 2.6252391322524297e-06, 'epoch': 0.77}
{'loss': 0.9521, 'grad_norm': 0.5919706503479919, 'learning_rate': 2.6168285670565374e-06, 'epoch': 0.77}
{'loss': 0.9876, 'grad_norm': 0.5618771767238177, 'learning_rate': 2.6084294674649734e-06, 'epoch': 0.77}
{'loss': 0.9695, 'grad_norm': 0.5864356145077051, 'learning_rate': 2.6000418465210143e-06, 'epoch': 0.77}
{'loss': 1.0057, 'grad_norm': 0.6130598374121887, 'learning_rate': 2.5916657172501103e-06, 'epoch': 0.77}
{'loss': 0.9902, 'grad_norm': 0.6371536853538403, 'learning_rate': 2.583301092659872e-06, 'epoch': 0.77}
{'loss': 0.9262, 'grad_norm': 0.5010077392871959, 'learning_rate': 2.5749479857400383e-06, 'epoch': 0.78}
{'loss': 0.9723, 'grad_norm': 0.614321191660018, 'learning_rate': 2.56660640946246e-06, 'epoch': 0.78}
{'loss': 1.02, 'grad_norm': 0.7514974485463767, 'learning_rate': 2.558276376781086e-06, 'epoch': 0.78}
{'loss': 0.9268, 'grad_norm': 0.5781224539314619, 'learning_rate': 2.5499579006319365e-06, 'epoch': 0.78}
{'loss': 0.9638, 'grad_norm': 0.7296463530992789, 'learning_rate': 2.5416509939330836e-06, 'epoch': 0.78}
{'loss': 0.9944, 'grad_norm': 0.5191538613419733, 'learning_rate': 2.5333556695846384e-06, 'epoch': 0.78}
{'loss': 0.9436, 'grad_norm': 0.6073649771285415, 'learning_rate': 2.525071940468722e-06, 'epoch': 0.78}
{'loss': 0.9358, 'grad_norm': 0.6346303691280568, 'learning_rate': 2.5167998194494468e-06, 'epoch': 0.78}
{'loss': 0.9835, 'grad_norm': 0.5935018216527609, 'learning_rate': 2.5085393193729e-06, 'epoch': 0.78}
{'loss': 0.9847, 'grad_norm': 0.5368811624726593, 'learning_rate': 2.5002904530671236e-06, 'epoch': 0.78}
{'loss': 0.9544, 'grad_norm': 0.6205547104354455, 'learning_rate': 2.492053233342091e-06, 'epoch': 0.78}
{'loss': 1.0288, 'grad_norm': 0.6399758321736293, 'learning_rate': 2.4838276729896884e-06, 'epoch': 0.78}
{'loss': 1.011, 'grad_norm': 0.6517575298292445, 'learning_rate': 2.4756137847837025e-06, 'epoch': 0.78}
{'loss': 0.9383, 'grad_norm': 0.551206181194156, 'learning_rate': 2.467411581479786e-06, 'epoch': 0.78}
{'loss': 0.9501, 'grad_norm': 0.8965274242422118, 'learning_rate': 2.45922107581545e-06, 'epoch': 0.78}
{'loss': 0.9552, 'grad_norm': 0.5763334273617686, 'learning_rate': 2.4510422805100366e-06, 'epoch': 0.78}
{'loss': 0.9719, 'grad_norm': 0.6647137600336149, 'learning_rate': 2.4428752082647044e-06, 'epoch': 0.78}
{'loss': 1.003, 'grad_norm': 0.6384664045517076, 'learning_rate': 2.4347198717624054e-06, 'epoch': 0.78}
{'loss': 0.9782, 'grad_norm': 0.6079254359526111, 'learning_rate': 2.426576283667873e-06, 'epoch': 0.78}
{'loss': 1.0303, 'grad_norm': 0.7875592573377943, 'learning_rate': 2.418444456627589e-06, 'epoch': 0.78}
{'loss': 0.9634, 'grad_norm': 0.637618507248536, 'learning_rate': 2.4103244032697717e-06, 'epoch': 0.78}
{'loss': 0.9717, 'grad_norm': 0.7355841866261356, 'learning_rate': 2.4022161362043574e-06, 'epoch': 0.78}
{'loss': 0.947, 'grad_norm': 0.5006162965582425, 'learning_rate': 2.3941196680229794e-06, 'epoch': 0.78}
{'loss': 0.9888, 'grad_norm': 0.6520993768285375, 'learning_rate': 2.3860350112989473e-06, 'epoch': 0.78}
{'loss': 0.9411, 'grad_norm': 0.6447514775212917, 'learning_rate': 2.3779621785872252e-06, 'epoch': 0.78}
{'loss': 0.9279, 'grad_norm': 0.53783376422805, 'learning_rate': 2.3699011824244234e-06, 'epoch': 0.78}
{'loss': 1.0189, 'grad_norm': 0.5847939410469344, 'learning_rate': 2.3618520353287644e-06, 'epoch': 0.79}
{'loss': 0.9853, 'grad_norm': 0.7143045522800034, 'learning_rate': 2.3538147498000695e-06, 'epoch': 0.79}
{'loss': 0.9651, 'grad_norm': 0.7959560064316212, 'learning_rate': 2.3457893383197415e-06, 'epoch': 0.79}
{'loss': 0.9808, 'grad_norm': 0.557515672105191, 'learning_rate': 2.3377758133507455e-06, 'epoch': 0.79}
{'loss': 0.9975, 'grad_norm': 0.5828084029503313, 'learning_rate': 2.32977418733758e-06, 'epoch': 0.79}
{'loss': 0.9753, 'grad_norm': 0.7085093740362657, 'learning_rate': 2.321784472706279e-06, 'epoch': 0.79}
{'loss': 0.9739, 'grad_norm': 0.6915943081381957, 'learning_rate': 2.3138066818643647e-06, 'epoch': 0.79}
{'loss': 0.9627, 'grad_norm': 0.6116752139880035, 'learning_rate': 2.30584082720085e-06, 'epoch': 0.79}
{'loss': 0.9867, 'grad_norm': 0.7831206019004778, 'learning_rate': 2.297886921086211e-06, 'epoch': 0.79}
{'loss': 0.977, 'grad_norm': 0.6165025753076052, 'learning_rate': 2.2899449758723657e-06, 'epoch': 0.79}
{'loss': 1.0098, 'grad_norm': 0.6256658221183938, 'learning_rate': 2.282015003892659e-06, 'epoch': 0.79}
{'loss': 0.9323, 'grad_norm': 0.5736926697543469, 'learning_rate': 2.2740970174618405e-06, 'epoch': 0.79}
{'loss': 0.9657, 'grad_norm': 0.5652709847494767, 'learning_rate': 2.2661910288760545e-06, 'epoch': 0.79}
{'loss': 0.9929, 'grad_norm': 0.6773612237394716, 'learning_rate': 2.258297050412804e-06, 'epoch': 0.79}
{'loss': 0.9792, 'grad_norm': 0.5884723819960219, 'learning_rate': 2.2504150943309455e-06, 'epoch': 0.79}
{'loss': 0.9608, 'grad_norm': 0.6024669269159217, 'learning_rate': 2.242545172870665e-06, 'epoch': 0.79}
{'loss': 0.943, 'grad_norm': 0.5508705008670635, 'learning_rate': 2.2346872982534584e-06, 'epoch': 0.79}
{'loss': 0.9336, 'grad_norm': 0.6412520967300702, 'learning_rate': 2.2268414826821117e-06, 'epoch': 0.79}
{'loss': 0.9773, 'grad_norm': 0.6156297065866788, 'learning_rate': 2.2190077383406938e-06, 'epoch': 0.79}
{'loss': 0.96, 'grad_norm': 0.5958419303599019, 'learning_rate': 2.211186077394516e-06, 'epoch': 0.79}
{'loss': 0.9761, 'grad_norm': 0.6058270677444302, 'learning_rate': 2.2033765119901294e-06, 'epoch': 0.79}
{'loss': 0.9473, 'grad_norm': 0.5948314584136887, 'learning_rate': 2.1955790542553036e-06, 'epoch': 0.79}
{'loss': 0.9557, 'grad_norm': 0.6327923225158012, 'learning_rate': 2.1877937162990015e-06, 'epoch': 0.79}
{'loss': 0.9564, 'grad_norm': 0.5643353039900354, 'learning_rate': 2.180020510211367e-06, 'epoch': 0.79}
{'loss': 0.965, 'grad_norm': 0.6891952337146537, 'learning_rate': 2.172259448063704e-06, 'epoch': 0.79}
{'loss': 0.9613, 'grad_norm': 0.6113967875704308, 'learning_rate': 2.1645105419084587e-06, 'epoch': 0.79}
{'loss': 1.0242, 'grad_norm': 0.5072028132792695, 'learning_rate': 2.1567738037791998e-06, 'epoch': 0.8}
{'loss': 0.9551, 'grad_norm': 0.6120064038255645, 'learning_rate': 2.1490492456905964e-06, 'epoch': 0.8}
{'loss': 0.9559, 'grad_norm': 0.5667147103695912, 'learning_rate': 2.141336879638406e-06, 'epoch': 0.8}
{'loss': 0.9408, 'grad_norm': 0.7254772339885234, 'learning_rate': 2.133636717599451e-06, 'epoch': 0.8}
{'loss': 0.9993, 'grad_norm': 0.7443529957526854, 'learning_rate': 2.1259487715316e-06, 'epoch': 0.8}
{'loss': 0.9819, 'grad_norm': 0.6879063740859258, 'learning_rate': 2.118273053373757e-06, 'epoch': 0.8}
{'loss': 0.9884, 'grad_norm': 0.6263152712463378, 'learning_rate': 2.1106095750458332e-06, 'epoch': 0.8}
{'loss': 0.9788, 'grad_norm': 0.6674850404749542, 'learning_rate': 2.1029583484487315e-06, 'epoch': 0.8}
{'loss': 0.974, 'grad_norm': 0.5653553701624449, 'learning_rate': 2.0953193854643274e-06, 'epoch': 0.8}
{'loss': 0.9386, 'grad_norm': 0.5631557087827868, 'learning_rate': 2.0876926979554545e-06, 'epoch': 0.8}
{'loss': 1.0271, 'grad_norm': 0.6175635133496414, 'learning_rate': 2.080078297765884e-06, 'epoch': 0.8}
{'loss': 0.9884, 'grad_norm': 0.6127367743005787, 'learning_rate': 2.0724761967202987e-06, 'epoch': 0.8}
{'loss': 1.008, 'grad_norm': 0.6237967755623953, 'learning_rate': 2.0648864066242937e-06, 'epoch': 0.8}
{'loss': 1.0181, 'grad_norm': 0.597416993931541, 'learning_rate': 2.0573089392643362e-06, 'epoch': 0.8}
{'loss': 0.9611, 'grad_norm': 0.6237345374709056, 'learning_rate': 2.0497438064077603e-06, 'epoch': 0.8}
{'loss': 0.9711, 'grad_norm': 0.6163978160783421, 'learning_rate': 2.0421910198027452e-06, 'epoch': 0.8}
{'loss': 1.0165, 'grad_norm': 0.6352725747732899, 'learning_rate': 2.0346505911782956e-06, 'epoch': 0.8}
{'loss': 0.9814, 'grad_norm': 0.6285068036755517, 'learning_rate': 2.0271225322442255e-06, 'epoch': 0.8}
{'loss': 0.9957, 'grad_norm': 0.5844966581092197, 'learning_rate': 2.019606854691145e-06, 'epoch': 0.8}
{'loss': 1.0162, 'grad_norm': 0.688004915183263, 'learning_rate': 2.01210357019043e-06, 'epoch': 0.8}
{'loss': 1.0155, 'grad_norm': 0.6174946333551462, 'learning_rate': 2.004612690394212e-06, 'epoch': 0.8}
{'loss': 0.9876, 'grad_norm': 0.5649222087652178, 'learning_rate': 1.997134226935361e-06, 'epoch': 0.8}
{'loss': 0.9849, 'grad_norm': 0.5994125209791301, 'learning_rate': 1.9896681914274616e-06, 'epoch': 0.8}
{'loss': 1.0054, 'grad_norm': 0.5829006930925987, 'learning_rate': 1.982214595464804e-06, 'epoch': 0.8}
{'loss': 0.9697, 'grad_norm': 0.8198849193691553, 'learning_rate': 1.9747734506223525e-06, 'epoch': 0.8}
{'loss': 0.94, 'grad_norm': 0.6505661895070426, 'learning_rate': 1.967344768455747e-06, 'epoch': 0.8}
{'loss': 0.9909, 'grad_norm': 0.6037219789379844, 'learning_rate': 1.9599285605012643e-06, 'epoch': 0.81}
{'loss': 0.9692, 'grad_norm': 0.6892105672807699, 'learning_rate': 1.952524838275811e-06, 'epoch': 0.81}
{'loss': 1.0015, 'grad_norm': 0.7053833476597322, 'learning_rate': 1.945133613276907e-06, 'epoch': 0.81}
{'loss': 0.9649, 'grad_norm': 0.6862389074011092, 'learning_rate': 1.937754896982663e-06, 'epoch': 0.81}
{'loss': 0.9322, 'grad_norm': 0.6160536124954601, 'learning_rate': 1.9303887008517618e-06, 'epoch': 0.81}
{'loss': 0.9611, 'grad_norm': 0.7082566851939996, 'learning_rate': 1.923035036323452e-06, 'epoch': 0.81}
{'loss': 0.9537, 'grad_norm': 0.6107460906526585, 'learning_rate': 1.9156939148175125e-06, 'epoch': 0.81}
{'loss': 0.9727, 'grad_norm': 0.5718936738726884, 'learning_rate': 1.9083653477342467e-06, 'epoch': 0.81}
{'loss': 0.994, 'grad_norm': 0.7196314988511543, 'learning_rate': 1.9010493464544621e-06, 'epoch': 0.81}
{'loss': 0.9524, 'grad_norm': 0.5267032614996646, 'learning_rate': 1.8937459223394517e-06, 'epoch': 0.81}
{'loss': 0.9841, 'grad_norm': 0.6675906265887669, 'learning_rate': 1.8864550867309771e-06, 'epoch': 0.81}
{'loss': 1.0087, 'grad_norm': 0.5628310997872426, 'learning_rate': 1.8791768509512487e-06, 'epoch': 0.81}
{'loss': 0.9535, 'grad_norm': 0.6297972536667408, 'learning_rate': 1.871911226302917e-06, 'epoch': 0.81}
{'loss': 0.9893, 'grad_norm': 0.5968533289341479, 'learning_rate': 1.8646582240690414e-06, 'epoch': 0.81}
{'loss': 1.0133, 'grad_norm': 0.6913230210588116, 'learning_rate': 1.8574178555130818e-06, 'epoch': 0.81}
{'loss': 0.984, 'grad_norm': 0.6329911749611137, 'learning_rate': 1.8501901318788773e-06, 'epoch': 0.81}
{'loss': 1.0217, 'grad_norm': 0.7134566833722891, 'learning_rate': 1.8429750643906331e-06, 'epoch': 0.81}
{'loss': 1.0083, 'grad_norm': 0.6039320379965237, 'learning_rate': 1.835772664252895e-06, 'epoch': 0.81}
{'loss': 0.9237, 'grad_norm': 0.7707760674713117, 'learning_rate': 1.8285829426505453e-06, 'epoch': 0.81}
{'loss': 0.9932, 'grad_norm': 0.6142017829531758, 'learning_rate': 1.8214059107487726e-06, 'epoch': 0.81}
{'loss': 0.9314, 'grad_norm': 0.6908693808009394, 'learning_rate': 1.8142415796930568e-06, 'epoch': 0.81}
{'loss': 1.0179, 'grad_norm': 0.6860333437025724, 'learning_rate': 1.8070899606091586e-06, 'epoch': 0.81}
{'loss': 0.9219, 'grad_norm': 0.8468505179609797, 'learning_rate': 1.799951064603095e-06, 'epoch': 0.81}
{'loss': 0.9868, 'grad_norm': 0.603731190180376, 'learning_rate': 1.7928249027611255e-06, 'epoch': 0.81}
{'loss': 0.9764, 'grad_norm': 0.6202181885152518, 'learning_rate': 1.7857114861497337e-06, 'epoch': 0.81}
{'loss': 0.9606, 'grad_norm': 0.5995546859881006, 'learning_rate': 1.7786108258156154e-06, 'epoch': 0.81}
{'loss': 0.9753, 'grad_norm': 0.5623611543105036, 'learning_rate': 1.7715229327856498e-06, 'epoch': 0.82}
{'loss': 0.9865, 'grad_norm': 0.5643912083577225, 'learning_rate': 1.7644478180668945e-06, 'epoch': 0.82}
{'loss': 0.9748, 'grad_norm': 0.5852626315893521, 'learning_rate': 1.7573854926465582e-06, 'epoch': 0.82}
{'loss': 0.9888, 'grad_norm': 0.5991400851964206, 'learning_rate': 1.7503359674919929e-06, 'epoch': 0.82}
{'loss': 0.9946, 'grad_norm': 0.6336941082537348, 'learning_rate': 1.7432992535506687e-06, 'epoch': 0.82}
{'loss': 0.9421, 'grad_norm': 0.6629028252209362, 'learning_rate': 1.736275361750167e-06, 'epoch': 0.82}
{'loss': 0.9938, 'grad_norm': 0.6639860594153991, 'learning_rate': 1.7292643029981525e-06, 'epoch': 0.82}
{'loss': 0.9523, 'grad_norm': 0.6165467541290538, 'learning_rate': 1.7222660881823594e-06, 'epoch': 0.82}
{'loss': 0.9694, 'grad_norm': 0.6609220358732832, 'learning_rate': 1.7152807281705809e-06, 'epoch': 0.82}
{'loss': 0.9443, 'grad_norm': 0.6121356161607054, 'learning_rate': 1.708308233810644e-06, 'epoch': 0.82}
{'loss': 0.9842, 'grad_norm': 0.6958592766839867, 'learning_rate': 1.701348615930397e-06, 'epoch': 0.82}
{'loss': 0.9271, 'grad_norm': 0.6154891041429096, 'learning_rate': 1.6944018853376898e-06, 'epoch': 0.82}
{'loss': 0.9279, 'grad_norm': 0.6035668663810022, 'learning_rate': 1.6874680528203657e-06, 'epoch': 0.82}
{'loss': 0.9288, 'grad_norm': 0.5402399261361683, 'learning_rate': 1.6805471291462316e-06, 'epoch': 0.82}
{'loss': 1.0003, 'grad_norm': 0.6206151771533449, 'learning_rate': 1.67363912506305e-06, 'epoch': 0.82}
{'loss': 0.9649, 'grad_norm': 0.5855115357792535, 'learning_rate': 1.66674405129852e-06, 'epoch': 0.82}
{'loss': 0.9591, 'grad_norm': 0.6256178509191602, 'learning_rate': 1.6598619185602616e-06, 'epoch': 0.82}
{'loss': 0.9917, 'grad_norm': 0.7338841505347726, 'learning_rate': 1.6529927375357957e-06, 'epoch': 0.82}
{'loss': 1.0153, 'grad_norm': 0.5845329913083344, 'learning_rate': 1.6461365188925304e-06, 'epoch': 0.82}
{'loss': 0.9765, 'grad_norm': 0.6529622740364378, 'learning_rate': 1.6392932732777489e-06, 'epoch': 0.82}
{'loss': 1.0203, 'grad_norm': 0.6150949727911089, 'learning_rate': 1.6324630113185835e-06, 'epoch': 0.82}
{'loss': 0.9543, 'grad_norm': 0.6790560735122615, 'learning_rate': 1.625645743622003e-06, 'epoch': 0.82}
{'loss': 1.0084, 'grad_norm': 0.5826035238424184, 'learning_rate': 1.6188414807747999e-06, 'epoch': 0.82}
{'loss': 0.9455, 'grad_norm': 0.6051415675862872, 'learning_rate': 1.6120502333435695e-06, 'epoch': 0.82}
{'loss': 1.003, 'grad_norm': 0.6148625094295649, 'learning_rate': 1.6052720118746923e-06, 'epoch': 0.82}
{'loss': 0.9545, 'grad_norm': 0.6662293402562888, 'learning_rate': 1.5985068268943283e-06, 'epoch': 0.82}
{'loss': 0.9556, 'grad_norm': 0.8454156006452792, 'learning_rate': 1.5917546889083834e-06, 'epoch': 0.83}
{'loss': 0.9947, 'grad_norm': 0.565317033546172, 'learning_rate': 1.5850156084025091e-06, 'epoch': 0.83}
{'loss': 0.9522, 'grad_norm': 0.6893395482401365, 'learning_rate': 1.578289595842074e-06, 'epoch': 0.83}
{'loss': 0.9418, 'grad_norm': 0.5643344597605359, 'learning_rate': 1.5715766616721584e-06, 'epoch': 0.83}
{'loss': 0.984, 'grad_norm': 0.6218608789509192, 'learning_rate': 1.5648768163175277e-06, 'epoch': 0.83}
{'loss': 1.0078, 'grad_norm': 0.6163104455969795, 'learning_rate': 1.5581900701826226e-06, 'epoch': 0.83}
{'loss': 0.9807, 'grad_norm': 0.5996955320177376, 'learning_rate': 1.5515164336515465e-06, 'epoch': 0.83}
{'loss': 0.9934, 'grad_norm': 0.6003116192266743, 'learning_rate': 1.5448559170880373e-06, 'epoch': 0.83}
{'loss': 1.0098, 'grad_norm': 0.6963901505854925, 'learning_rate': 1.5382085308354633e-06, 'epoch': 0.83}
{'loss': 0.9493, 'grad_norm': 0.5722722932401019, 'learning_rate': 1.5315742852167992e-06, 'epoch': 0.83}
{'loss': 0.9897, 'grad_norm': 0.6340283016508719, 'learning_rate': 1.5249531905346138e-06, 'epoch': 0.83}
{'loss': 0.9192, 'grad_norm': 0.6341840346434835, 'learning_rate': 1.5183452570710522e-06, 'epoch': 0.83}
{'loss': 0.9363, 'grad_norm': 0.5073998248433557, 'learning_rate': 1.511750495087827e-06, 'epoch': 0.83}
{'loss': 0.9938, 'grad_norm': 0.6246198687098375, 'learning_rate': 1.5051689148261895e-06, 'epoch': 0.83}
{'loss': 0.9293, 'grad_norm': 0.5925059473559567, 'learning_rate': 1.4986005265069204e-06, 'epoch': 0.83}
{'loss': 0.9466, 'grad_norm': 0.5240581680349536, 'learning_rate': 1.4920453403303249e-06, 'epoch': 0.83}
{'loss': 0.9661, 'grad_norm': 0.6319821311724018, 'learning_rate': 1.4855033664761898e-06, 'epoch': 0.83}
{'loss': 1.0104, 'grad_norm': 0.664107239129161, 'learning_rate': 1.4789746151037942e-06, 'epoch': 0.83}
{'loss': 1.0252, 'grad_norm': 0.6448918236230913, 'learning_rate': 1.4724590963518803e-06, 'epoch': 0.83}
{'loss': 1.0466, 'grad_norm': 0.643851445022246, 'learning_rate': 1.4659568203386464e-06, 'epoch': 0.83}
{'loss': 0.9729, 'grad_norm': 0.6627697931039199, 'learning_rate': 1.4594677971617178e-06, 'epoch': 0.83}
{'loss': 0.9797, 'grad_norm': 0.6443861781715987, 'learning_rate': 1.452992036898142e-06, 'epoch': 0.83}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B00XLX3W9O.jpg, using default black image.
{'loss': 0.9784, 'grad_norm': 0.6003692987698848, 'learning_rate': 1.446529549604373e-06, 'epoch': 0.83}
{'loss': 0.9956, 'grad_norm': 0.5946618987640419, 'learning_rate': 1.4400803453162482e-06, 'epoch': 0.83}
{'loss': 0.9751, 'grad_norm': 0.6408728200162193, 'learning_rate': 1.4336444340489775e-06, 'epoch': 0.83}
{'loss': 0.9329, 'grad_norm': 0.5945837680764335, 'learning_rate': 1.4272218257971327e-06, 'epoch': 0.83}
{'loss': 1.0015, 'grad_norm': 0.6936547151147788, 'learning_rate': 1.4208125305346232e-06, 'epoch': 0.84}
{'loss': 0.9889, 'grad_norm': 0.5821696428031844, 'learning_rate': 1.4144165582146819e-06, 'epoch': 0.84}
{'loss': 1.0118, 'grad_norm': 0.5978519968972804, 'learning_rate': 1.40803391876986e-06, 'epoch': 0.84}
{'loss': 1.0033, 'grad_norm': 0.8183013034960476, 'learning_rate': 1.4016646221119912e-06, 'epoch': 0.84}
{'loss': 0.9694, 'grad_norm': 0.611634801448319, 'learning_rate': 1.395308678132199e-06, 'epoch': 0.84}
{'loss': 1.0158, 'grad_norm': 0.57566268983064, 'learning_rate': 1.3889660967008656e-06, 'epoch': 0.84}
{'loss': 0.9779, 'grad_norm': 0.6638184952601746, 'learning_rate': 1.3826368876676278e-06, 'epoch': 0.84}
{'loss': 0.9308, 'grad_norm': 0.5765064122738314, 'learning_rate': 1.3763210608613497e-06, 'epoch': 0.84}
{'loss': 1.0241, 'grad_norm': 0.713479978802229, 'learning_rate': 1.370018626090116e-06, 'epoch': 0.84}
{'loss': 1.0003, 'grad_norm': 0.6593922456130245, 'learning_rate': 1.3637295931412153e-06, 'epoch': 0.84}
{'loss': 0.9575, 'grad_norm': 0.850116229904879, 'learning_rate': 1.3574539717811231e-06, 'epoch': 0.84}
{'loss': 0.9743, 'grad_norm': 0.6000505026540054, 'learning_rate': 1.3511917717554846e-06, 'epoch': 0.84}
{'loss': 1.0006, 'grad_norm': 0.6362661353981027, 'learning_rate': 1.3449430027891096e-06, 'epoch': 0.84}
{'loss': 0.9455, 'grad_norm': 0.5391986317289147, 'learning_rate': 1.338707674585945e-06, 'epoch': 0.84}
{'loss': 0.9671, 'grad_norm': 0.6181478680820647, 'learning_rate': 1.332485796829065e-06, 'epoch': 0.84}
{'loss': 0.9886, 'grad_norm': 0.593911143901168, 'learning_rate': 1.3262773791806617e-06, 'epoch': 0.84}
{'loss': 0.9938, 'grad_norm': 0.6436014533715819, 'learning_rate': 1.3200824312820137e-06, 'epoch': 0.84}
{'loss': 0.962, 'grad_norm': 0.6116338912893784, 'learning_rate': 1.3139009627534927e-06, 'epoch': 0.84}
{'loss': 0.9633, 'grad_norm': 0.743764245007484, 'learning_rate': 1.3077329831945295e-06, 'epoch': 0.84}
{'loss': 0.983, 'grad_norm': 0.6001179591411439, 'learning_rate': 1.3015785021836159e-06, 'epoch': 0.84}
{'loss': 0.9396, 'grad_norm': 0.6134741171041772, 'learning_rate': 1.295437529278275e-06, 'epoch': 0.84}
{'loss': 0.9649, 'grad_norm': 0.6173185072950593, 'learning_rate': 1.2893100740150522e-06, 'epoch': 0.84}
{'loss': 1.0275, 'grad_norm': 0.6419956643641789, 'learning_rate': 1.2831961459095088e-06, 'epoch': 0.84}
{'loss': 0.9632, 'grad_norm': 0.7359261277724198, 'learning_rate': 1.2770957544561868e-06, 'epoch': 0.84}
{'loss': 0.9095, 'grad_norm': 0.49970298794655305, 'learning_rate': 1.2710089091286148e-06, 'epoch': 0.84}
{'loss': 0.9805, 'grad_norm': 0.6367150237509385, 'learning_rate': 1.2649356193792873e-06, 'epoch': 0.84}
{'loss': 0.9482, 'grad_norm': 0.5681570977737169, 'learning_rate': 1.2588758946396417e-06, 'epoch': 0.85}
{'loss': 1.018, 'grad_norm': 0.6087117182705994, 'learning_rate': 1.2528297443200489e-06, 'epoch': 0.85}
{'loss': 0.9777, 'grad_norm': 0.560883551310168, 'learning_rate': 1.246797177809812e-06, 'epoch': 0.85}
{'loss': 0.9712, 'grad_norm': 0.5329291320328414, 'learning_rate': 1.2407782044771222e-06, 'epoch': 0.85}
{'loss': 0.9682, 'grad_norm': 0.703053117056233, 'learning_rate': 1.23477283366907e-06, 'epoch': 0.85}
WARNING: tokenization mismatch: 0 vs. 852. (ignored)
number of rounds:  1
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a top consultant specialising in advising tax firms and have the following skills and qualities.\n\nKNOWLEDGE: Consultant in a top consulting firm specialising in tax consulting, senior strategist, digital expert.\n\nCHARACTERISTICS: Customer-focused, empathetic, solution-oriented, personable, persuasive, creative.\n\nTASK: Use your knowledge to develop 10 measures to encourage clients to submit their documents digitally instead of by post. The measures should be formulated in such a way that the client recognises the advantages of digital filing. The law firm is digitised and can accept digital documents.\n\nOUTPUT: A list of the 10 actions, each with the name of the action as a heading and 2 short additional bullet points.\n\nOUTPUT LANGUAGE: German ASSISTANT: 1. Persönlicher Kontakt und Beratung:\n\t* Persönliche Beratung und Unterstützung bei der Umstellung auf digitales Einreichen\n\t* Betonung der Vorteile, wie Zeit- und Kosteneinsparungen\n2. Schulung und Unterstützung:\n\t* Schulungen für die digitale Einreichung von Dokumenten\n\t* Anleitung zur Nutzung von Tools und Software\n3. Anreize schaffen:\n\t* Ermäßigung bei der Beauftragung digitaler Dienstleistungen\n\t* Sonderangebote für Kunden, die ihre Dokumente digital einreichen\n4. Informationen bereitstellen:\n\t* Veröffentlichung von Leitfäden und Handbüchern für die digitale Einreichung von Dokumenten\n\t* FAQ-Liste für häufig gestellte Fragen zum digitalen Einreichen\n5. Klare Kommunikation:\n\t* Verständliche Kommunikation der Vorteile der digitalen Einreichung\n\t* Bereitstellung von Informationen über die Sicherheit der digitalen Übermittlung\n6. Einfache Zugänglichkeit:\n\t* Vereinfachung des digitalen Einreichungsprozesses durch intuitive Online-Plattformen\n\t* Bereitstellung von Unterstützung für den Fall technischer Schwierigkeiten\n7. Zeitersparnis betonen:\n\t* Betonung der Vorteile von Zeitersparnis durch digitales Einreichen\n\t* Erinnerungen an Fristen und den Nutzen der pünktlichen Einreichung\n8. Umweltbewusstsein:\n\t* Betonung des Umweltvorteils durch digitales Einreichen von Dokumenten\n\t* Verweis auf die Möglichkeit, Papierverbrauch zu reduzieren\n9. Kosteneffizienz:\n\t* Betonung der Vorteile von Kosteneinsparungen durch digitales Einreichen\n\t* Verweis auf die Möglichkeit, Papier- und Portokosten zu sparen\n10. Feedback einholen:\n* Umfrage zur Bewertung des digitalen Einreichungsprozesses\n* Analyse der Ergebnisse zur Verbesserung der digitalen Dienstleistungen"]
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a top consultant specialising in advising tax firms and have the following skills and qualities.

KNOWLEDGE: Consultant in a top consulting firm specialising in tax consulting, senior strategist, digital expert.

CHARACTERISTICS: Customer-focused, empathetic, solution-oriented, personable, persuasive, creative.

TASK: Use your knowledge to develop 10 measures to encourage clients to submit their documents digitally instead of by post. The measures should be formulated in such a way that the client recognises the advantages of digital filing. The law firm is digitised and can accept digital documents.

OUTPUT: A list of the 10 actions, each with the name of the action as a heading and 2 short additional bullet points.

OUTPUT LANGUAGE: German ASSISTANT: 1. Persönlicher Kontakt und Beratung:
	* Persönliche Beratung und Unterstützung bei der Umstellung auf digitales Einreichen
	* Betonung der Vorteile, wie Zeit- und Kosteneinsparungen
2. Schulung und Unterstützung:
	* Schulungen für die digitale Einreichung von Dokumenten
	* Anleitung zur Nutzung von Tools und Software
3. Anreize schaffen:
	* Ermäßigung bei der Beauftragung digitaler Dienstleistungen
	* Sonderangebote für Kunden, die ihre Dokumente digital einreichen
4. Informationen bereitstellen:
	* Veröffentlichung von Leitfäden und Handbüchern für die digitale Einreichung von Dokumenten
	* FAQ-Liste für häufig gestellte Fragen zum digitalen Einreichen
5. Klare Kommunikation:
	* Verständliche Kommunikation der Vorteile der digitalen Einreichung
	* Bereitstellung von Informationen über die Sicherheit der digitalen Übermittlung
6. Einfache Zugänglichkeit:
	* Vereinfachung des digitalen Einreichungsprozesses durch intuitive Online-Plattformen
	* Bereitstellung von Unterstützung für den Fall technischer Schwierigkeiten
7. Zeitersparnis betonen:
	* Betonung der Vorteile von Zeitersparnis durch digitales Einreichen
	* Erinnerungen an Fristen und den Nutzen der pünktlichen Einreichung
8. Umweltbewusstsein:
	* Betonung des Umweltvorteils durch digitales Einreichen von Dokumenten
	* Verweis auf die Möglichkeit, Papierverbrauch zu reduzieren
9. Kosteneffizienz:
	* Betonung der Vorteile von Kosteneinsparungen durch digitales Einreichen
	* Verweis auf die Möglichkeit, Papier- und Portokosten zu sparen
10. Feedback einholen:
* Umfrage zur Bewertung des digitalen Einreichungsprozesses
* Analyse der Ergebnisse zur Verbesserung der digitalen Dienstleistungen<|endoftext|>
tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])
tensor([   32,  8537,  1022,   257, 11040,  2836,   290,   281, 11666,  4430,
         8796,    13,   383,  8796,  3607,  7613,    11,  6496,    11,   290,
        23507,  7429,   284,   262,  2836,   338,  2683,    13,  1294,  1137,
           25, 24994,  8808,  8643,    25,   921,   389,   257,  1353, 17028,
         2041,  1710,   287, 30341,  1687,  9611,   290,   423,   262,  1708,
         4678,   290, 14482,    13,   198,   198, 29132,  3913, 30465,  8264,
           25, 21651,   415,   287,   257,  1353, 18158,  4081,  2041,  1710,
          287,  1687, 18158,    11,  4664, 25651,    11,  4875,  5887,    13,
          198,   198, 38019,  2246,  5781,  8808, 19505,    25, 22092,    12,
        18143,    11,   795,  8071,  6587,    11,  4610,    12, 17107,    11,
         1048,   540,    11, 40116,    11,  7325,    13,   198,   198,    51,
         1921,    42,    25,  5765,   534,  3725,   284,  1205,   838,  5260,
          284,  7898,  7534,   284,  9199,   511,  4963, 34491,  2427,   286,
          416,  1281,    13,   383,  5260,   815,   307, 34391,   287,   884,
          257,   835,   326,   262,  5456,  3018,  2696,   262, 13391,   286,
         4875, 12180,    13,   383,  1099,  4081,   318, 16839,  1417,   290,
          460,  2453,  4875,  4963,    13,   198,   198,  2606,  7250,  3843,
           25,   317,  1351,   286,   262,   838,  4028,    11,  1123,   351,
          262,  1438,   286,   262,  2223,   355,   257,  9087,   290,   362,
         1790,  3224, 10492,  2173,    13,   198,   198,  2606,  7250,  3843,
          406, 15567,    52, 11879,    25,  2679, 24994,  8808,  8643,    25,
          352,    13,  9467, 48863,   677,   372,   509,   756,   461,    83,
         3318,  4312,   265,  2150,    25,   198,   197,     9,  9467, 48863,
          677,   258,  4312,   265,  2150,  3318,   791,   353,   301,  9116,
        22877,  2150,   307,    72,  4587, 21039,   301,   695,  2150,   257,
         3046,  4875,   274,   412,   259,   260, 41437,   198,   197,     9,
         5147,   261,  2150,  4587,   569,   419,    68,   576,    11,   266,
          494, 47447,    12,  3318,   509,   455,  1734,  1040,  1845,  2150,
          268,   198,    17,    13,  3059,   377,  2150,  3318,   791,   353,
          301,  9116, 22877,  2150,    25,   198,   197,     9,  3059,   377,
         2150,   268,   277, 25151,  4656, 16839,  1000,   412,   259,   260,
          488,  2150, 18042,   360,   482,  1713,   268,   198,   197,     9,
         1052,   293,   270,  2150,  1976,   333, 11959,    89,  2150, 18042,
        20003,  3318, 10442,   198,    18,    13,  1052,   260,  1096,  5513,
         2001,   268,    25,   198,   197,     9,  5256,    76, 11033, 39683,
          328,  2150,   307,    72,  4587, 32831,   701, 22562,  2150,  4875,
          263,   360,  2013,   301,   293,   396,  2150,   268,   198,   197,
            9,   311,  8623,   858,    65,  1258,   277, 25151, 45099,   268,
           11,  4656,  1312,    71,   260,   360,   482,  1713,    68,  4875,
          304,   259,   260, 41437,   198,    19,    13,  6188,   268, 45303,
          270,   301, 40635,    25,   198,   197,     9,  4643,  9101,   487,
          298, 33467,  2150, 18042,  1004,   270,    69, 11033,  6559,  3318,
         7157,    65,  9116,  2044,    77,   277, 25151,  4656, 16839,  1000,
          412,   259,   260,   488,  2150, 18042,   360,   482,  1713,   268,
          198,   197,     9, 18749,    12,  8053,    68,   277, 25151,   289,
        11033,  3046,   328, 10521,   695,   660,  1305, 11286,  1976,   388,
         4875,   268,   412,   259,   260, 41437,   198,    20,    13, 14770,
          533,   509,  2002,   403,  1134,   341,    25,   198,   197,     9,
         4643,   301, 11033,   358,   677,   258,   509,  2002,   403,  1134,
          341,  4587,   569,   419,    68,   576,  4587,  4875,   268,   412,
          259,   260,   488,  2150,   198,   197,     9, 37951,   270,   301,
          695,  2150, 18042,  6188,   268,  6184,   120,   527,  4656, 28799,
          372, 29361,  4587,  4875,   268, 49363,   527, 20124,    75,  2150,
          198,    21,    13,   412, 10745,  4891,  1168,  1018, 11033,   782,
        33467,   365,   270,    25,   198,   197,     9,   569,   567, 10745,
          620,  2150,   748,  4875,   268,   412,   259,   260,   488,  2150,
           82,  1676,    89, 44667,   288,  2575, 19933,  7467,    12,  3646,
         1078,   687,   268,   198,   197,     9, 37951,   270,   301,   695,
         2150, 18042,   791,   353,   301,  9116, 22877,  2150,   277, 25151,
         2853,  7218,  1579, 24645, 20469,   959,   328,   365,   270,   268,
          198,    22,    13, 47447,   364,    79,  1501,   271,   731, 34481,
           25,   198,   197,     9,  5147,   261,  2150,  4587,   569,   419,
           68,   576, 18042, 47447,   364,    79,  1501,   271,   288,  2575,
         4875,   274,   412,   259,   260, 41437,   198,   197,     9,  5256,
         5083,  2150,   268,   281,  1305,   396,   268,  3318,  2853, 11959,
         4801,  4587,   279,  9116,    77, 21841,   677,   831,   412,   259,
          260,   488,  2150,   198,    23,    13, 21039,    86,  2120,    65,
          413,   385,   301, 20719,    25,   198,   197,     9,  5147,   261,
         2150,   748, 21039,    86,  2120,    85,   419,    68,  4487,   288,
         2575,  4875,   274,   412,   259,   260, 41437, 18042,   360,   482,
         1713,   268,   198,   197,     9,  4643,   732,   271,   257,  3046,
         4656,   337,  9101,  4743,   488,   365,   270,    11, 14185,   959,
          332, 16057,   794,  1976,    84,  2027, 49746,   918,   198,    24,
           13,   509,   455,  1734,   487,   528,  2013,    89,    25,   198,
          197,     9,  5147,   261,  2150,  4587,   569,   419,    68,   576,
        18042,   509,   455,  1734,  1040,  1845,  2150,   268,   288,  2575,
         4875,   274,   412,   259,   260, 41437,   198,   197,     9,  4643,
          732,   271,   257,  3046,  4656,   337,  9101,  4743,   488,   365,
          270,    11, 14185,   959,    12,  3318,  4347,   482,   455,   268,
         1976,    84,   599,  5757,   198,   940,    13, 37774,   304,   259,
         3937,   268,    25,   198,     9, 21039,  8310,   496,  1976,   333,
          347,   413,   861,  2150,   748,  4875,   268,   412,   259,   260,
          488,  2150,    82,  1676,    89, 44667,   198,     9, 16213,   325,
         4587,  5256,   469,  9374, 20782,  1976,   333, 49973,   408,   263,
         2150,  4587,  4875,   268,   360,  2013,   301,   293,   396,  2150,
          268, 50256])
{'loss': 0.9811, 'grad_norm': 0.5620436103306532, 'learning_rate': 1.2287810747116224e-06, 'epoch': 0.85}
{'loss': 0.9734, 'grad_norm': 0.6242926969207916, 'learning_rate': 1.2228029369096094e-06, 'epoch': 0.85}
{'loss': 1.0224, 'grad_norm': 0.7099137894624248, 'learning_rate': 1.216838429546704e-06, 'epoch': 0.85}
{'loss': 0.9954, 'grad_norm': 0.5993965711418784, 'learning_rate': 1.2108875618854122e-06, 'epoch': 0.85}
{'loss': 0.955, 'grad_norm': 0.5639020580719406, 'learning_rate': 1.204950343167065e-06, 'epoch': 0.85}
{'loss': 0.9651, 'grad_norm': 0.5918958934125925, 'learning_rate': 1.1990267826117874e-06, 'epoch': 0.85}
{'loss': 0.961, 'grad_norm': 0.6260661039414037, 'learning_rate': 1.1931168894184974e-06, 'epoch': 0.85}
{'loss': 0.9486, 'grad_norm': 0.6321450272594479, 'learning_rate': 1.187220672764897e-06, 'epoch': 0.85}
{'loss': 0.9807, 'grad_norm': 0.6046564907854437, 'learning_rate': 1.1813381418074388e-06, 'epoch': 0.85}
{'loss': 0.9689, 'grad_norm': 0.6453814480970399, 'learning_rate': 1.1754693056813272e-06, 'epoch': 0.85}
{'loss': 1.0057, 'grad_norm': 0.6192706502704164, 'learning_rate': 1.169614173500494e-06, 'epoch': 0.85}
{'loss': 0.9425, 'grad_norm': 0.5609928037534281, 'learning_rate': 1.1637727543576027e-06, 'epoch': 0.85}
WARNING: tokenization mismatch: 0 vs. 1653. (ignored)
number of rounds:  2
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: Du bist ein Personalmarketing-Experte mit den folgenden Kenntnissen und Eigenschaften.\n\nKENNTNISSE: Personalmarketing, Social Media Marketing, Facebook-Marketing, Kampagnenentwicklung, Zielgruppenanalyse, Content-Strategie, Werbeanzeigen, Performance-Messung, Personalgewinnung, Steuerfachangestellte.\n\nEIGENSCHAFTEN: Kreativ, strategisch, analytisch, kommunikativ, zielorientiert, detailverliebt, teamorientiert.\n\nAUFGABE: Entwickle eine erfolgreiche Personalmarketing-Strategie für die Gewinnung von Steuerfachangestellten über Facebook. Erstelle eine Tabelle mit allen Maßnahmen und weise jeder Maßnahme den zuständigen Spezialisten in einer Marketingagentur zu. Achte dabei auf Zielgruppenanalyse, Content-Strategie, Werbeanzeigen und Performance-Messung.\n\nOUTPUT: Eine Tabelle mit allen Maßnahmen für eine erfolgreiche Personalmarketing-Kampagne zur Gewinnung von Steuerfachangestellten auf Facebook, die die Verantwortlichkeiten der Spezialisten in einer Marketingagentur aufzeigt, einschließlich Zielgruppenanalyse, Content-Strategie, Werbeanzeigen und Performance-Messung. ASSISTANT: | Maßnahme | Beschreibung | Zuständiger Spezialist |\n| --- | --- | --- |\n| Zielgruppenanalyse | Analyse der demografischen Daten, Interessen und Verhaltensweisen der potenziellen Bewerber. | Marktanalyst |\n| Erstellung von Personas | Entwicklung von fiktiven, repräsentativen Bewerberprofilen zur besseren Zielgruppenansprache. | Personalmarketing-Experte |\n| Content-Strategie | Planung von relevantem, ansprechendem und zielgruppenspezifischem Content. | Content-Stratege |\n| Redaktionsplan | Erstellung eines Zeitplans für die Veröffentlichung von Inhalten auf Facebook. | Social Media Manager |\n| Erstellung von Werbeanzeigen | Design und Texten von ansprechenden, zielgruppenspezifischen Facebook-Werbeanzeigen. | Art Director & Copywriter |\n| Auswahl von Targeting-Optionen | Festlegung der Zielgruppenparameter für die Facebook-Werbekampagnen. | Facebook-Marketing-Experte |\n| Budgetierung und Zeitplanung | Festlegung des Budgets und der Laufzeit für die Facebook-Werbekampagnen. | Media Planner |\n| Erstellung von Landing Pages | Gestaltung und Implementierung von spezifischen Landing Pages für die Bewerbung. | Web-Designer |\n| Performance-Messung | Überwachung und Analyse der Kampagnenleistung, einschließlich KPIs wie Klicks und Bewerbungen. | Data Analyst |\n| A/B-Testing | Durchführung von A/B-Tests, um die Effektivität von Anzeigen und Landing Pages zu optimieren. | Conversion-Optimierungsexperte |\n| Community-Management | Interaktion mit der Zielgruppe auf Facebook, Beantwortung von Fragen und Moderation von Diskussionen. | Community Manager |\n| Reporting und Optimierung | Regelmäßige Berichterstattung über die Kampagnenergebnisse und Anpassung der Strategie. | Performance Marketing-Manager |", 'USER: Weiter. ASSISTANT: Hier sind einige zusätzliche Maßnahmen, die Sie in Ihre Personalmarketing-Strategie für die Gewinnung von Steuerfachangestellten über Facebook einbeziehen können:\n\n| Maßnahme | Beschreibung | Zuständiger Spezialist |\n| --- | --- | --- |\n| Video-Content | Erstellung von Video-Content, wie Interviews mit aktuellen Mitarbeitern oder Berufsalltagsvideos. | Videoproduzent |\n| Influencer-Marketing | Zusammenarbeit mit Influencern aus der Branche, um Ihre Arbeitgebermarke zu stärken. | Influencer-Marketing-Experte |\n| Anpassung von Stellenanzeigen | Anpassung der Stellenanzeigen auf Facebook, um die Zielgruppe besser anzusprechen. | Personalmarketing-Experte |\n| Mitarbeiter-Testimonials | Teilen von Erfahrungsberichten und Zitaten der Mitarbeiter auf Facebook, um Authentizität zu schaffen. | Content-Stratege |\n| Virtuelle Karriere-Events | Durchführung von virtuellen Karriere-Events oder Informationsveranstaltungen auf Facebook. | Event-Manager |\n| Interaktive Umfragen und Quiz | Nutzung von interaktiven Umfragen und Quiz auf Facebook, um das Engagement zu erhöhen. | Social Media Manager |\n| Remarketing-Kampagnen | Einsatz von Remarketing-Anzeigen, um die Personen erneut anzusprechen, die bereits interessiert waren. | Facebook-Marketing-Experte |\n| Monitoring von Wettbewerbern | Beobachtung der Personalmarketing-Aktivitäten der Wettbewerber auf Facebook und Ableitung von Optimierungspotenzialen. | Marktanalyst |\n| Integration von Chatbots | Implementierung von Chatbots auf der Facebook-Seite und der Landing Page zur Automatisierung des Bewerbungsprozesses. | Chatbot-Entwickler |\n| Employer Branding-Kampagne | Entwicklung einer Employer Branding-Kampagne, die die Unternehmenskultur und -werte hervorhebt. | Employer Branding-Experte |\n\nMit diesen erweiterten Maßnahmen können Sie eine noch umfassendere Personalmarketing-Strategie entwickeln, die die Chancen erhöht, qualifizierte Steuerfachangestellte über Facebook zu gewinnen.']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: Du bist ein Personalmarketing-Experte mit den folgenden Kenntnissen und Eigenschaften.

KENNTNISSE: Personalmarketing, Social Media Marketing, Facebook-Marketing, Kampagnenentwicklung, Zielgruppenanalyse, Content-Strategie, Werbeanzeigen, Performance-Messung, Personalgewinnung, Steuerfachangestellte.

EIGENSCHAFTEN: Kreativ, strategisch, analytisch, kommunikativ, zielorientiert, detailverliebt, teamorientiert.

AUFGABE: Entwickle eine erfolgreiche Personalmarketing-Strategie für die Gewinnung von Steuerfachangestellten über Facebook. Erstelle eine Tabelle mit allen Maßnahmen und weise jeder Maßnahme den zuständigen Spezialisten in einer Marketingagentur zu. Achte dabei auf Zielgruppenanalyse, Content-Strategie, Werbeanzeigen und Performance-Messung.

OUTPUT: Eine Tabelle mit allen Maßnahmen für eine erfolgreiche Personalmarketing-Kampagne zur Gewinnung von Steuerfachangestellten auf Facebook, die die Verantwortlichkeiten der Spezialisten in einer Marketingagentur aufzeigt, einschließlich Zielgruppenanalyse, Content-Strategie, Werbeanzeigen und Performance-Messung. ASSISTANT: | Maßnahme | Beschreibung | Zuständiger Spezialist |
| --- | --- | --- |
| Zielgruppenanalyse | Analyse der demografischen Daten, Interessen und Verhaltensweisen der potenziellen Bewerber. | Marktanalyst |
| Erstellung von Personas | Entwicklung von fiktiven, repräsentativen Bewerberprofilen zur besseren Zielgruppenansprache. | Personalmarketing-Experte |
| Content-Strategie | Planung von relevantem, ansprechendem und zielgruppenspezifischem Content. | Content-Stratege |
| Redaktionsplan | Erstellung eines Zeitplans für die Veröffentlichung von Inhalten auf Facebook. | Social Media Manager |
| Erstellung von Werbeanzeigen | Design und Texten von ansprechenden, zielgruppenspezifischen Facebook-Werbeanzeigen. | Art Director & Copywriter |
| Auswahl von Targeting-Optionen | Festlegung der Zielgruppenparameter für die Facebook-Werbekampagnen. | Facebook-Marketing-Experte |
| Budgetierung und Zeitplanung | Festlegung des Budgets und der Laufzeit für die Facebook-Werbekampagnen. | Media Planner |
| Erstellung von Landing Pages | Gestaltung und Implementierung von spezifischen Landing Pages für die Bewerbung. | Web-Designer |
| Performance-Messung | Überwachung und Analyse der Kampagnenleistung, einschließlich KPIs wie Klicks und Bewerbungen. | Data Analyst |
| A/B-Testing | Durchführung von A/B-Tests, um die Effektivität von Anzeigen und Landing Pages zu optimieren. | Conversion-Optimierungsexperte |
| Community-Management | Interaktion mit der Zielgruppe auf Facebook, Beantwortung von Fragen und Moderation von Diskussionen. | Community Manager |
| Reporting und Optimierung | Regelmäßige Berichterstattung über die Kampagnenergebnisse und Anpassung der Strategie. | Performance Marketing-Manager |<|endoftext|>USER: Weiter. ASSISTANT: Hier sind einige zusätzliche Maßnahmen, die Sie in Ihre Personalmarketing-Strategie für die Gewinnung von Steuerfachangestellten über Facebook einbeziehen können:

| Maßnahme | Beschreibung | Zuständiger Spezialist |
| --- | --- | --- |
| Video-Content | Erstellung von Video-Content, wie Interviews mit aktuellen Mitarbeitern oder Berufsalltagsvideos. | Videoproduzent |
| Influencer-Marketing | Zusammenarbeit mit Influencern aus der Branche, um Ihre Arbeitgebermarke zu stärken. | Influencer-Marketing-Experte |
| Anpassung von Stellenanzeigen | Anpassung der Stellenanzeigen auf Facebook, um die Zielgruppe besser anzusprechen. | Personalmarketing-Experte |
| Mitarbeiter-Testimonials | Teilen von Erfahrungsberichten und Zitaten der Mitarbeiter auf Facebook, um Authentizität zu schaffen. | Content-Stratege |
| Virtuelle Karriere-Events | Durchführung von virtuellen Karriere-Events oder Informationsveranstaltungen auf Facebook. | Event-Manager |
| Interaktive Umfragen und Quiz | Nutzung von interaktiven Umfragen und Quiz auf Facebook, um das Engagement zu erhöhen. | Social Media Manager |
| Remarketing-Kampagnen | Einsatz von Remarketing-Anzeigen, um die Personen erneut anzusprechen, die bereits interessiert waren. | Facebook-Marketing-Experte |
| Monitoring von Wettbewerbern | Beobachtung der Personalmarketing-Aktivitäten der Wettbewerber auf Facebook und Ableitung von Optimierungspotenzialen. | Marktanalyst |
| Integration von Chatbots | Implementierung von Chatbots auf der Facebook-Seite und der Landing Page zur Automatisierung des Bewerbungsprozesses. | Chatbot-Entwickler |
| Employer Branding-Kampagne | Entwicklung einer Employer Branding-Kampagne, die die Unternehmenskultur und -werte hervorhebt. | Employer Branding-Experte |

Mit diesen erweiterten Maßnahmen können Sie eine noch umfassendere Personalmarketing-Strategie entwickeln, die die Chancen erhöht, qualifizierte Steuerfachangestellte über Facebook zu gewinnen.<|endoftext|>
tensor([-100, -100, -100,  ..., -100, -100, -100])
tensor([   32,  8537,  1022,  ...,   268,    13, 50256])
{'loss': 0.9178, 'grad_norm': 0.5828989078581549, 'learning_rate': 1.1579450573240058e-06, 'epoch': 0.85}
{'loss': 0.9317, 'grad_norm': 0.5445579977977113, 'learning_rate': 1.1521310914497518e-06, 'epoch': 0.85}
{'loss': 0.9164, 'grad_norm': 0.7342805808561638, 'learning_rate': 1.1463308657635718e-06, 'epoch': 0.85}
{'loss': 0.9601, 'grad_norm': 0.6209743566042941, 'learning_rate': 1.140544389272853e-06, 'epoch': 0.85}
{'loss': 0.9812, 'grad_norm': 0.592059540569818, 'learning_rate': 1.1347716709636282e-06, 'epoch': 0.85}
{'loss': 0.9469, 'grad_norm': 0.7492582419511935, 'learning_rate': 1.129012719800575e-06, 'epoch': 0.85}
{'loss': 0.982, 'grad_norm': 0.634308747809852, 'learning_rate': 1.1232675447269803e-06, 'epoch': 0.85}
{'loss': 0.9509, 'grad_norm': 0.6927022907377933, 'learning_rate': 1.1175361546647413e-06, 'epoch': 0.85}
{'loss': 0.9835, 'grad_norm': 0.6354774482120158, 'learning_rate': 1.1118185585143536e-06, 'epoch': 0.85}
{'loss': 1.007, 'grad_norm': 0.6304231610507405, 'learning_rate': 1.1061147651548855e-06, 'epoch': 0.86}
{'loss': 1.0048, 'grad_norm': 0.7250003087315108, 'learning_rate': 1.1004247834439697e-06, 'epoch': 0.86}
{'loss': 0.9636, 'grad_norm': 0.6372369321246402, 'learning_rate': 1.0947486222177928e-06, 'epoch': 0.86}
{'loss': 0.9985, 'grad_norm': 0.6311283362053883, 'learning_rate': 1.0890862902910849e-06, 'epoch': 0.86}
{'loss': 0.9693, 'grad_norm': 0.5857624163495222, 'learning_rate': 1.0834377964570863e-06, 'epoch': 0.86}
{'loss': 1.018, 'grad_norm': 0.6854075085941902, 'learning_rate': 1.0778031494875574e-06, 'epoch': 0.86}
{'loss': 0.9428, 'grad_norm': 0.7200066812631326, 'learning_rate': 1.072182358132755e-06, 'epoch': 0.86}
{'loss': 0.9442, 'grad_norm': 0.643319549116963, 'learning_rate': 1.066575431121417e-06, 'epoch': 0.86}
{'loss': 1.0241, 'grad_norm': 0.6128873992840407, 'learning_rate': 1.0609823771607487e-06, 'epoch': 0.86}
{'loss': 0.9374, 'grad_norm': 0.6222200715669646, 'learning_rate': 1.055403204936416e-06, 'epoch': 0.86}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/163114006X.jpg, using default black image.
{'loss': 1.0289, 'grad_norm': 0.56357039507671, 'learning_rate': 1.0498379231125278e-06, 'epoch': 0.86}
{'loss': 0.9645, 'grad_norm': 0.6888415460508217, 'learning_rate': 1.0442865403316117e-06, 'epoch': 0.86}
{'loss': 0.9774, 'grad_norm': 0.6043390569992985, 'learning_rate': 1.0387490652146236e-06, 'epoch': 0.86}
{'loss': 0.9989, 'grad_norm': 0.6519923970994962, 'learning_rate': 1.0332255063609177e-06, 'epoch': 0.86}
{'loss': 1.0299, 'grad_norm': 0.6097212659244697, 'learning_rate': 1.027715872348234e-06, 'epoch': 0.86}
{'loss': 0.9833, 'grad_norm': 0.6336431685718575, 'learning_rate': 1.0222201717326885e-06, 'epoch': 0.86}
{'loss': 1.0258, 'grad_norm': 0.7244798518116073, 'learning_rate': 1.0167384130487667e-06, 'epoch': 0.86}
{'loss': 1.0281, 'grad_norm': 0.6165550040795109, 'learning_rate': 1.0112706048092924e-06, 'epoch': 0.86}
{'loss': 0.9358, 'grad_norm': 0.645201709994885, 'learning_rate': 1.00581675550543e-06, 'epoch': 0.86}
{'loss': 1.0207, 'grad_norm': 0.5906489989653323, 'learning_rate': 1.0003768736066722e-06, 'epoch': 0.86}
{'loss': 0.9615, 'grad_norm': 0.6163054267505541, 'learning_rate': 9.949509675608115e-07, 'epoch': 0.86}
{'loss': 1.0063, 'grad_norm': 0.6860275194801218, 'learning_rate': 9.895390457939414e-07, 'epoch': 0.86}
{'loss': 1.0062, 'grad_norm': 0.5669003986040508, 'learning_rate': 9.84141116710442e-07, 'epoch': 0.86}
{'loss': 0.9411, 'grad_norm': 0.6460936548170079, 'learning_rate': 9.787571886929604e-07, 'epoch': 0.86}
{'loss': 0.9409, 'grad_norm': 0.5973475154184891, 'learning_rate': 9.733872701023938e-07, 'epoch': 0.86}
{'loss': 0.9922, 'grad_norm': 0.6326609302874683, 'learning_rate': 9.680313692778976e-07, 'epoch': 0.86}
{'loss': 0.9815, 'grad_norm': 0.596106522958676, 'learning_rate': 9.626894945368492e-07, 'epoch': 0.87}
{'loss': 1.0075, 'grad_norm': 0.6071065599899474, 'learning_rate': 9.573616541748464e-07, 'epoch': 0.87}
{'loss': 0.9649, 'grad_norm': 0.5926559144400547, 'learning_rate': 9.520478564656898e-07, 'epoch': 0.87}
{'loss': 0.9731, 'grad_norm': 0.6097328373496939, 'learning_rate': 9.467481096613829e-07, 'epoch': 0.87}
{'loss': 0.9633, 'grad_norm': 0.6829881588401411, 'learning_rate': 9.414624219920953e-07, 'epoch': 0.87}
{'loss': 0.9869, 'grad_norm': 0.5824041770287808, 'learning_rate': 9.361908016661703e-07, 'epoch': 0.87}
{'loss': 0.931, 'grad_norm': 0.5721393954552187, 'learning_rate': 9.309332568701079e-07, 'epoch': 0.87}
{'loss': 0.9884, 'grad_norm': 0.6439839471976515, 'learning_rate': 9.256897957685463e-07, 'epoch': 0.87}
{'loss': 0.9919, 'grad_norm': 0.5969760045079417, 'learning_rate': 9.204604265042505e-07, 'epoch': 0.87}
{'loss': 0.979, 'grad_norm': 0.547433286498043, 'learning_rate': 9.15245157198108e-07, 'epoch': 0.87}
{'loss': 0.9508, 'grad_norm': 0.5996931536108414, 'learning_rate': 9.10043995949108e-07, 'epoch': 0.87}
{'loss': 0.9787, 'grad_norm': 0.6504124075547933, 'learning_rate': 9.04856950834323e-07, 'epoch': 0.87}
{'loss': 0.9559, 'grad_norm': 0.6939295829538404, 'learning_rate': 8.996840299089149e-07, 'epoch': 0.87}
{'loss': 0.9489, 'grad_norm': 0.5525905489241858, 'learning_rate': 8.945252412061056e-07, 'epoch': 0.87}
{'loss': 0.9725, 'grad_norm': 0.6286769044388992, 'learning_rate': 8.893805927371724e-07, 'epoch': 0.87}
{'loss': 1.0127, 'grad_norm': 0.6802880277410578, 'learning_rate': 8.842500924914299e-07, 'epoch': 0.87}
{'loss': 0.9678, 'grad_norm': 0.7276362215586937, 'learning_rate': 8.791337484362305e-07, 'epoch': 0.87}
{'loss': 0.9588, 'grad_norm': 0.5020674493491378, 'learning_rate': 8.740315685169364e-07, 'epoch': 0.87}
{'loss': 1.0331, 'grad_norm': 0.6673361449267754, 'learning_rate': 8.689435606569086e-07, 'epoch': 0.87}
{'loss': 0.949, 'grad_norm': 0.667820197991247, 'learning_rate': 8.638697327575108e-07, 'epoch': 0.87}
{'loss': 0.9833, 'grad_norm': 0.5809093056273172, 'learning_rate': 8.588100926980802e-07, 'epoch': 0.87}
{'loss': 0.9866, 'grad_norm': 0.5356837941151203, 'learning_rate': 8.537646483359185e-07, 'epoch': 0.87}
{'loss': 0.9399, 'grad_norm': 0.49301616233056367, 'learning_rate': 8.487334075062914e-07, 'epoch': 0.87}
{'loss': 1.0018, 'grad_norm': 0.6229910850923973, 'learning_rate': 8.437163780224011e-07, 'epoch': 0.87}
{'loss': 0.9493, 'grad_norm': 0.6657472381515878, 'learning_rate': 8.387135676753755e-07, 'epoch': 0.87}
{'loss': 0.9866, 'grad_norm': 0.735186850633563, 'learning_rate': 8.337249842342721e-07, 'epoch': 0.87}
{'loss': 1.0576, 'grad_norm': 0.6246238996888805, 'learning_rate': 8.287506354460484e-07, 'epoch': 0.88}
{'loss': 0.9535, 'grad_norm': 0.6162028112992076, 'learning_rate': 8.237905290355563e-07, 'epoch': 0.88}
{'loss': 0.96, 'grad_norm': 0.5863290477980165, 'learning_rate': 8.188446727055311e-07, 'epoch': 0.88}
{'loss': 0.9889, 'grad_norm': 0.5348186607349338, 'learning_rate': 8.139130741365819e-07, 'epoch': 0.88}
{'loss': 0.9917, 'grad_norm': 0.6039774530763019, 'learning_rate': 8.08995740987173e-07, 'epoch': 0.88}
{'loss': 1.0069, 'grad_norm': 0.6888778854683602, 'learning_rate': 8.040926808936112e-07, 'epoch': 0.88}
{'loss': 0.9645, 'grad_norm': 0.5222773156033089, 'learning_rate': 7.99203901470047e-07, 'epoch': 0.88}
{'loss': 0.9857, 'grad_norm': 0.6508298031416574, 'learning_rate': 7.943294103084487e-07, 'epoch': 0.88}
{'loss': 0.9721, 'grad_norm': 0.6519304410502796, 'learning_rate': 7.894692149785954e-07, 'epoch': 0.88}
{'loss': 0.9728, 'grad_norm': 0.7844624006882456, 'learning_rate': 7.846233230280698e-07, 'epoch': 0.88}
{'loss': 1.027, 'grad_norm': 0.6115962852913072, 'learning_rate': 7.797917419822377e-07, 'epoch': 0.88}
{'loss': 0.9666, 'grad_norm': 0.6347223459605812, 'learning_rate': 7.749744793442448e-07, 'epoch': 0.88}
{'loss': 1.0062, 'grad_norm': 0.5941527841872078, 'learning_rate': 7.701715425949952e-07, 'epoch': 0.88}
{'loss': 0.9728, 'grad_norm': 0.6628491337764534, 'learning_rate': 7.653829391931533e-07, 'epoch': 0.88}
{'loss': 0.9602, 'grad_norm': 0.576917977904092, 'learning_rate': 7.606086765751209e-07, 'epoch': 0.88}
{'loss': 0.944, 'grad_norm': 0.5805087632013792, 'learning_rate': 7.55848762155027e-07, 'epoch': 0.88}
{'loss': 0.9643, 'grad_norm': 0.6284358372066116, 'learning_rate': 7.511032033247256e-07, 'epoch': 0.88}
{'loss': 0.9275, 'grad_norm': 0.6564676929468839, 'learning_rate': 7.463720074537728e-07, 'epoch': 0.88}
{'loss': 0.9775, 'grad_norm': 0.5984273972679672, 'learning_rate': 7.416551818894158e-07, 'epoch': 0.88}
{'loss': 0.9065, 'grad_norm': 0.7471191576671627, 'learning_rate': 7.369527339565951e-07, 'epoch': 0.88}
{'loss': 0.9935, 'grad_norm': 0.5546948732373314, 'learning_rate': 7.322646709579173e-07, 'epoch': 0.88}
{'loss': 0.981, 'grad_norm': 0.6121306845009121, 'learning_rate': 7.275910001736497e-07, 'epoch': 0.88}
{'loss': 0.969, 'grad_norm': 0.5981370984645256, 'learning_rate': 7.229317288617144e-07, 'epoch': 0.88}
{'loss': 0.9995, 'grad_norm': 0.5946952502043792, 'learning_rate': 7.182868642576679e-07, 'epoch': 0.88}
{'loss': 1.0307, 'grad_norm': 0.6204882574056632, 'learning_rate': 7.13656413574696e-07, 'epoch': 0.88}
{'loss': 1.0219, 'grad_norm': 0.5906719259322678, 'learning_rate': 7.090403840035942e-07, 'epoch': 0.88}
{'loss': 1.0157, 'grad_norm': 0.673910573662615, 'learning_rate': 7.044387827127752e-07, 'epoch': 0.89}
{'loss': 0.9947, 'grad_norm': 0.652751050636928, 'learning_rate': 6.99851616848235e-07, 'epoch': 0.89}
{'loss': 0.9848, 'grad_norm': 0.6051079263460379, 'learning_rate': 6.952788935335541e-07, 'epoch': 0.89}
{'loss': 0.9812, 'grad_norm': 0.5936366357992136, 'learning_rate': 6.907206198698912e-07, 'epoch': 0.89}
{'loss': 0.9886, 'grad_norm': 0.7739634467557431, 'learning_rate': 6.861768029359595e-07, 'epoch': 0.89}
{'loss': 0.9809, 'grad_norm': 0.6030875631441467, 'learning_rate': 6.816474497880177e-07, 'epoch': 0.89}
{'loss': 0.9896, 'grad_norm': 0.5181385387598235, 'learning_rate': 6.77132567459875e-07, 'epoch': 0.89}
{'loss': 0.998, 'grad_norm': 0.6333684445524618, 'learning_rate': 6.726321629628585e-07, 'epoch': 0.89}
{'loss': 0.976, 'grad_norm': 0.5789882407793028, 'learning_rate': 6.681462432858154e-07, 'epoch': 0.89}
{'loss': 0.9836, 'grad_norm': 0.6858761071818434, 'learning_rate': 6.636748153951e-07, 'epoch': 0.89}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/1780048319.jpg, using default black image.
{'loss': 0.9421, 'grad_norm': 0.6249921901007741, 'learning_rate': 6.592178862345622e-07, 'epoch': 0.89}
{'loss': 0.9518, 'grad_norm': 0.6263484519951733, 'learning_rate': 6.547754627255332e-07, 'epoch': 0.89}
{'loss': 0.9905, 'grad_norm': 0.6115389765282041, 'learning_rate': 6.503475517668168e-07, 'epoch': 0.89}
{'loss': 1.0007, 'grad_norm': 0.5627134116474735, 'learning_rate': 6.459341602346858e-07, 'epoch': 0.89}
{'loss': 0.9697, 'grad_norm': 0.6165818418014429, 'learning_rate': 6.415352949828601e-07, 'epoch': 0.89}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/789748479.jpg, using default black image.
{'loss': 0.9568, 'grad_norm': 0.6200931936083276, 'learning_rate': 6.371509628425021e-07, 'epoch': 0.89}
{'loss': 1.0135, 'grad_norm': 0.6458711043617934, 'learning_rate': 6.327811706222097e-07, 'epoch': 0.89}
{'loss': 0.9977, 'grad_norm': 0.6202598335223449, 'learning_rate': 6.284259251079939e-07, 'epoch': 0.89}
{'loss': 0.9838, 'grad_norm': 0.5692591996189994, 'learning_rate': 6.240852330632796e-07, 'epoch': 0.89}
{'loss': 1.0291, 'grad_norm': 0.7134463530499273, 'learning_rate': 6.197591012288918e-07, 'epoch': 0.89}
{'loss': 0.9952, 'grad_norm': 0.5821548477133206, 'learning_rate': 6.154475363230417e-07, 'epoch': 0.89}
{'loss': 0.9672, 'grad_norm': 0.6043237394867481, 'learning_rate': 6.111505450413202e-07, 'epoch': 0.89}
{'loss': 0.9761, 'grad_norm': 0.5844855694116314, 'learning_rate': 6.068681340566896e-07, 'epoch': 0.89}
{'loss': 1.0119, 'grad_norm': 0.6386246931371321, 'learning_rate': 6.026003100194633e-07, 'epoch': 0.89}
{'loss': 1.0085, 'grad_norm': 0.6183307826289944, 'learning_rate': 5.983470795573088e-07, 'epoch': 0.89}
{'loss': 0.9622, 'grad_norm': 0.637752652601371, 'learning_rate': 5.941084492752236e-07, 'epoch': 0.89}
{'loss': 0.9637, 'grad_norm': 0.5495437648344154, 'learning_rate': 5.898844257555392e-07, 'epoch': 0.9}
{'loss': 0.9828, 'grad_norm': 0.9182159252182037, 'learning_rate': 5.856750155578983e-07, 'epoch': 0.9}
{'loss': 1.0202, 'grad_norm': 0.6087636305197285, 'learning_rate': 5.81480225219252e-07, 'epoch': 0.9}
{'loss': 0.9544, 'grad_norm': 0.6713821016092584, 'learning_rate': 5.773000612538505e-07, 'epoch': 0.9}
{'loss': 1.0303, 'grad_norm': 0.7778808462670869, 'learning_rate': 5.731345301532265e-07, 'epoch': 0.9}
{'loss': 0.9782, 'grad_norm': 0.6243325375930766, 'learning_rate': 5.68983638386188e-07, 'epoch': 0.9}
{'loss': 0.9723, 'grad_norm': 0.6283197520456106, 'learning_rate': 5.648473923988129e-07, 'epoch': 0.9}
{'loss': 1.0002, 'grad_norm': 0.6004873466996744, 'learning_rate': 5.607257986144321e-07, 'epoch': 0.9}
{'loss': 0.9788, 'grad_norm': 0.6340403790573459, 'learning_rate': 5.566188634336212e-07, 'epoch': 0.9}
{'loss': 0.9963, 'grad_norm': 0.6596532624978454, 'learning_rate': 5.525265932341984e-07, 'epoch': 0.9}
{'loss': 0.9105, 'grad_norm': 0.4798793966158745, 'learning_rate': 5.484489943712013e-07, 'epoch': 0.9}
{'loss': 0.9852, 'grad_norm': 0.800787289085281, 'learning_rate': 5.443860731768869e-07, 'epoch': 0.9}
{'loss': 1.0006, 'grad_norm': 0.6787595196682968, 'learning_rate': 5.403378359607181e-07, 'epoch': 0.9}
{'loss': 1.0081, 'grad_norm': 0.5774206994215375, 'learning_rate': 5.36304289009355e-07, 'epoch': 0.9}
{'loss': 0.975, 'grad_norm': 0.5245020534479107, 'learning_rate': 5.322854385866439e-07, 'epoch': 0.9}
{'loss': 0.936, 'grad_norm': 0.5806120515119535, 'learning_rate': 5.282812909336077e-07, 'epoch': 0.9}
{'loss': 0.9384, 'grad_norm': 0.6166777315389456, 'learning_rate': 5.242918522684392e-07, 'epoch': 0.9}
{'loss': 0.9945, 'grad_norm': 0.5604617701092138, 'learning_rate': 5.203171287864872e-07, 'epoch': 0.9}
{'loss': 0.8917, 'grad_norm': 0.5191529144539713, 'learning_rate': 5.163571266602485e-07, 'epoch': 0.9}
{'loss': 0.9545, 'grad_norm': 0.5916094205511423, 'learning_rate': 5.124118520393606e-07, 'epoch': 0.9}
{'loss': 1.0122, 'grad_norm': 0.5977265069252041, 'learning_rate': 5.084813110505871e-07, 'epoch': 0.9}
{'loss': 0.9547, 'grad_norm': 0.5472922634831229, 'learning_rate': 5.045655097978131e-07, 'epoch': 0.9}
{'loss': 0.9947, 'grad_norm': 0.5929452119446347, 'learning_rate': 5.006644543620342e-07, 'epoch': 0.9}
{'loss': 1.0047, 'grad_norm': 0.5695477990150665, 'learning_rate': 4.967781508013459e-07, 'epoch': 0.9}
{'loss': 0.9891, 'grad_norm': 0.5392758500007634, 'learning_rate': 4.929066051509346e-07, 'epoch': 0.9}
{'loss': 1.0317, 'grad_norm': 0.5671097729603974, 'learning_rate': 4.890498234230689e-07, 'epoch': 0.9}
{'loss': 0.9788, 'grad_norm': 0.6065199877468974, 'learning_rate': 4.852078116070902e-07, 'epoch': 0.91}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/1616384670.jpg, using default black image.
{'loss': 0.973, 'grad_norm': 0.7006114692192819, 'learning_rate': 4.813805756694035e-07, 'epoch': 0.91}
{'loss': 0.9641, 'grad_norm': 0.6517332901781028, 'learning_rate': 4.775681215534656e-07, 'epoch': 0.91}
{'loss': 0.9702, 'grad_norm': 0.6261383523883729, 'learning_rate': 4.7377045517978173e-07, 'epoch': 0.91}
{'loss': 1.0027, 'grad_norm': 0.7366262737368584, 'learning_rate': 4.6998758244588995e-07, 'epoch': 0.91}
{'loss': 0.9789, 'grad_norm': 0.5671777750895678, 'learning_rate': 4.662195092263566e-07, 'epoch': 0.91}
{'loss': 0.9849, 'grad_norm': 0.6837572934496698, 'learning_rate': 4.6246624137276206e-07, 'epoch': 0.91}
{'loss': 0.9153, 'grad_norm': 0.6435748871479748, 'learning_rate': 4.587277847136984e-07, 'epoch': 0.91}
{'loss': 0.9988, 'grad_norm': 0.5822871434797443, 'learning_rate': 4.550041450547549e-07, 'epoch': 0.91}
{'loss': 0.9978, 'grad_norm': 0.6872183852353289, 'learning_rate': 4.512953281785104e-07, 'epoch': 0.91}
{'loss': 0.9516, 'grad_norm': 0.5840321822654966, 'learning_rate': 4.476013398445289e-07, 'epoch': 0.91}
{'loss': 1.0142, 'grad_norm': 0.7691177420688474, 'learning_rate': 4.4392218578934164e-07, 'epoch': 0.91}
{'loss': 0.9331, 'grad_norm': 0.5580394365263855, 'learning_rate': 4.4025787172644495e-07, 'epoch': 0.91}
{'loss': 0.9496, 'grad_norm': 0.7307471481560793, 'learning_rate': 4.366084033462914e-07, 'epoch': 0.91}
{'loss': 1.0305, 'grad_norm': 0.654152430325703, 'learning_rate': 4.329737863162753e-07, 'epoch': 0.91}
{'loss': 0.9941, 'grad_norm': 0.6080718399226103, 'learning_rate': 4.2935402628073166e-07, 'epoch': 0.91}
{'loss': 0.9777, 'grad_norm': 0.6205729447365491, 'learning_rate': 4.2574912886092166e-07, 'epoch': 0.91}
{'loss': 0.9824, 'grad_norm': 0.6251931690346584, 'learning_rate': 4.221590996550251e-07, 'epoch': 0.91}
{'loss': 1.0142, 'grad_norm': 0.5726042122165893, 'learning_rate': 4.1858394423813563e-07, 'epoch': 0.91}
{'loss': 1.0131, 'grad_norm': 0.6649330656844066, 'learning_rate': 4.1502366816224327e-07, 'epoch': 0.91}
{'loss': 0.9658, 'grad_norm': 0.6198922675520614, 'learning_rate': 4.1147827695623643e-07, 'epoch': 0.91}
{'loss': 0.9901, 'grad_norm': 0.8006689606390504, 'learning_rate': 4.0794777612588543e-07, 'epoch': 0.91}
{'loss': 1.0289, 'grad_norm': 0.6159397864457247, 'learning_rate': 4.044321711538368e-07, 'epoch': 0.91}
{'loss': 0.9798, 'grad_norm': 0.6953998579356917, 'learning_rate': 4.00931467499609e-07, 'epoch': 0.91}
{'loss': 1.0066, 'grad_norm': 0.6298052954492314, 'learning_rate': 3.974456705995733e-07, 'epoch': 0.91}
{'loss': 0.9795, 'grad_norm': 0.6077273609189071, 'learning_rate': 3.9397478586695513e-07, 'epoch': 0.91}
{'loss': 0.9732, 'grad_norm': 0.6577991192654611, 'learning_rate': 3.90518818691823e-07, 'epoch': 0.92}
{'loss': 0.9769, 'grad_norm': 0.6540256625096043, 'learning_rate': 3.8707777444107697e-07, 'epoch': 0.92}
{'loss': 0.985, 'grad_norm': 0.6236098028824505, 'learning_rate': 3.8365165845844266e-07, 'epoch': 0.92}
{'loss': 0.983, 'grad_norm': 0.5707919620312021, 'learning_rate': 3.8024047606446736e-07, 'epoch': 0.92}
{'loss': 0.9946, 'grad_norm': 0.5938204357345975, 'learning_rate': 3.768442325565036e-07, 'epoch': 0.92}
{'loss': 0.9966, 'grad_norm': 0.6536396773720776, 'learning_rate': 3.7346293320870363e-07, 'epoch': 0.92}
{'loss': 0.9801, 'grad_norm': 0.6046850858128014, 'learning_rate': 3.700965832720171e-07, 'epoch': 0.92}
{'loss': 0.9901, 'grad_norm': 0.6777298201982963, 'learning_rate': 3.6674518797417236e-07, 'epoch': 0.92}
{'loss': 0.9539, 'grad_norm': 0.6309234029591835, 'learning_rate': 3.6340875251967946e-07, 'epoch': 0.92}
{'loss': 1.0014, 'grad_norm': 0.575965997492819, 'learning_rate': 3.6008728208981157e-07, 'epoch': 0.92}
{'loss': 0.9509, 'grad_norm': 0.5086598953366889, 'learning_rate': 3.5678078184260834e-07, 'epoch': 0.92}
{'loss': 0.9785, 'grad_norm': 0.830110633958478, 'learning_rate': 3.5348925691285675e-07, 'epoch': 0.92}
{'loss': 1.0062, 'grad_norm': 0.6075203837936684, 'learning_rate': 3.502127124120891e-07, 'epoch': 0.92}
{'loss': 0.971, 'grad_norm': 0.5906741080739123, 'learning_rate': 3.4695115342857524e-07, 'epoch': 0.92}
{'loss': 0.9651, 'grad_norm': 0.6629588527558117, 'learning_rate': 3.437045850273113e-07, 'epoch': 0.92}
{'loss': 1.0011, 'grad_norm': 0.5990405001624568, 'learning_rate': 3.404730122500155e-07, 'epoch': 0.92}
{'loss': 0.9315, 'grad_norm': 0.6494413903383905, 'learning_rate': 3.3725644011512125e-07, 'epoch': 0.92}
{'loss': 1.0059, 'grad_norm': 0.587635573997994, 'learning_rate': 3.3405487361776177e-07, 'epoch': 0.92}
{'loss': 1.02, 'grad_norm': 0.5799571968062824, 'learning_rate': 3.308683177297711e-07, 'epoch': 0.92}
{'loss': 0.9615, 'grad_norm': 0.6887296040762916, 'learning_rate': 3.2769677739966975e-07, 'epoch': 0.92}
{'loss': 0.9604, 'grad_norm': 0.6268013970454956, 'learning_rate': 3.245402575526646e-07, 'epoch': 0.92}
{'loss': 0.9784, 'grad_norm': 0.6143578410576502, 'learning_rate': 3.2139876309063233e-07, 'epoch': 0.92}
{'loss': 0.9702, 'grad_norm': 0.565763866405759, 'learning_rate': 3.182722988921161e-07, 'epoch': 0.92}
{'loss': 0.9214, 'grad_norm': 0.59682362061855, 'learning_rate': 3.151608698123232e-07, 'epoch': 0.92}
{'loss': 1.0005, 'grad_norm': 0.7144601002533703, 'learning_rate': 3.1206448068310635e-07, 'epoch': 0.92}
{'loss': 0.9994, 'grad_norm': 0.6254827635041192, 'learning_rate': 3.0898313631296586e-07, 'epoch': 0.92}
{'loss': 0.957, 'grad_norm': 0.6365542809547271, 'learning_rate': 3.0591684148703617e-07, 'epoch': 0.93}
{'loss': 1.024, 'grad_norm': 0.6868902929441474, 'learning_rate': 3.0286560096708275e-07, 'epoch': 0.93}
{'loss': 0.9789, 'grad_norm': 0.6421041693858953, 'learning_rate': 2.998294194914897e-07, 'epoch': 0.93}
{'loss': 0.9289, 'grad_norm': 0.5475829212934785, 'learning_rate': 2.968083017752599e-07, 'epoch': 0.93}
{'loss': 0.9668, 'grad_norm': 0.6387452321118525, 'learning_rate': 2.938022525099982e-07, 'epoch': 0.93}
{'loss': 0.9313, 'grad_norm': 0.5909109449346862, 'learning_rate': 2.908112763639137e-07, 'epoch': 0.93}
{'loss': 1.0052, 'grad_norm': 0.5356421030468427, 'learning_rate': 2.878353779818044e-07, 'epoch': 0.93}
{'loss': 0.9374, 'grad_norm': 0.5343456371871333, 'learning_rate': 2.848745619850546e-07, 'epoch': 0.93}
{'loss': 0.9579, 'grad_norm': 0.5938659395625834, 'learning_rate': 2.8192883297162634e-07, 'epoch': 0.93}
{'loss': 0.9793, 'grad_norm': 0.5809822567447156, 'learning_rate': 2.7899819551605256e-07, 'epoch': 0.93}
{'loss': 1.0086, 'grad_norm': 0.5965445188667969, 'learning_rate': 2.760826541694328e-07, 'epoch': 0.93}
{'loss': 0.9864, 'grad_norm': 0.8129869474293413, 'learning_rate': 2.7318221345941865e-07, 'epoch': 0.93}
{'loss': 0.992, 'grad_norm': 0.5927686370648702, 'learning_rate': 2.7029687789021377e-07, 'epoch': 0.93}
{'loss': 1.0047, 'grad_norm': 0.6991895406831502, 'learning_rate': 2.67426651942565e-07, 'epoch': 0.93}
{'loss': 1.0076, 'grad_norm': 0.6276042904886157, 'learning_rate': 2.645715400737536e-07, 'epoch': 0.93}
{'loss': 1.0302, 'grad_norm': 0.6871390699864894, 'learning_rate': 2.6173154671758847e-07, 'epoch': 0.93}
{'loss': 0.9675, 'grad_norm': 0.5588710143213207, 'learning_rate': 2.589066762844039e-07, 'epoch': 0.93}
{'loss': 0.992, 'grad_norm': 0.7052717766819356, 'learning_rate': 2.5609693316104745e-07, 'epoch': 0.93}
{'loss': 0.9899, 'grad_norm': 0.6356259570746547, 'learning_rate': 2.5330232171087433e-07, 'epoch': 0.93}
{'loss': 0.9878, 'grad_norm': 0.5844878925676241, 'learning_rate': 2.5052284627374077e-07, 'epoch': 0.93}
{'loss': 0.9953, 'grad_norm': 0.770132324947622, 'learning_rate': 2.477585111659997e-07, 'epoch': 0.93}
{'loss': 0.9647, 'grad_norm': 0.6786838618115966, 'learning_rate': 2.4500932068049046e-07, 'epoch': 0.93}
{'loss': 1.0042, 'grad_norm': 0.6626334462502365, 'learning_rate': 2.422752790865346e-07, 'epoch': 0.93}
{'loss': 0.9889, 'grad_norm': 0.6049959024219517, 'learning_rate': 2.3955639062992696e-07, 'epoch': 0.93}
{'loss': 0.9856, 'grad_norm': 0.5768766299780317, 'learning_rate': 2.3685265953293345e-07, 'epoch': 0.93}
{'loss': 0.9797, 'grad_norm': 0.7047105935928806, 'learning_rate': 2.3416408999427876e-07, 'epoch': 0.93}
{'loss': 0.9927, 'grad_norm': 0.6129385927246788, 'learning_rate': 2.3149068618914417e-07, 'epoch': 0.94}
{'loss': 0.9546, 'grad_norm': 0.6192276341121122, 'learning_rate': 2.2883245226915652e-07, 'epoch': 0.94}
{'loss': 1.0117, 'grad_norm': 0.612918404773844, 'learning_rate': 2.2618939236238924e-07, 'epoch': 0.94}
{'loss': 1.0173, 'grad_norm': 0.6589496081380479, 'learning_rate': 2.2356151057334908e-07, 'epoch': 0.94}
{'loss': 0.994, 'grad_norm': 0.6026179201566239, 'learning_rate': 2.209488109829727e-07, 'epoch': 0.94}
{'loss': 0.9928, 'grad_norm': 0.5673426563767232, 'learning_rate': 2.1835129764861907e-07, 'epoch': 0.94}
{'loss': 0.9588, 'grad_norm': 0.7681122202644249, 'learning_rate': 2.1576897460406477e-07, 'epoch': 0.94}
{'loss': 0.9907, 'grad_norm': 0.600943648391607, 'learning_rate': 2.1320184585949532e-07, 'epoch': 0.94}
{'loss': 0.9884, 'grad_norm': 0.6885995383716325, 'learning_rate': 2.106499154015018e-07, 'epoch': 0.94}
{'loss': 0.965, 'grad_norm': 0.6072029953568507, 'learning_rate': 2.0811318719307194e-07, 'epoch': 0.94}
{'loss': 0.9253, 'grad_norm': 0.6065364666221862, 'learning_rate': 2.0559166517358787e-07, 'epoch': 0.94}
{'loss': 0.9681, 'grad_norm': 0.5418379198912997, 'learning_rate': 2.0308535325881616e-07, 'epoch': 0.94}
{'loss': 1.0015, 'grad_norm': 0.6928236890727585, 'learning_rate': 2.0059425534090128e-07, 'epoch': 0.94}
{'loss': 0.9422, 'grad_norm': 0.7727590628744134, 'learning_rate': 1.981183752883631e-07, 'epoch': 0.94}
{'loss': 0.9802, 'grad_norm': 0.5953983498536349, 'learning_rate': 1.9565771694608937e-07, 'epoch': 0.94}
{'loss': 0.9463, 'grad_norm': 0.590536038269084, 'learning_rate': 1.9321228413532788e-07, 'epoch': 0.94}
{'loss': 0.965, 'grad_norm': 0.606814676924353, 'learning_rate': 1.907820806536842e-07, 'epoch': 0.94}
{'loss': 0.9528, 'grad_norm': 0.6010132712350428, 'learning_rate': 1.883671102751128e-07, 'epoch': 0.94}
{'loss': 0.9765, 'grad_norm': 0.6157624060103914, 'learning_rate': 1.859673767499115e-07, 'epoch': 0.94}
{'loss': 0.9128, 'grad_norm': 0.5789593618589504, 'learning_rate': 1.83582883804716e-07, 'epoch': 0.94}
{'loss': 0.9892, 'grad_norm': 0.6669142201070501, 'learning_rate': 1.8121363514249534e-07, 'epoch': 0.94}
{'loss': 0.9567, 'grad_norm': 0.6045036713032907, 'learning_rate': 1.7885963444254528e-07, 'epoch': 0.94}
{'loss': 1.0, 'grad_norm': 0.670528170712991, 'learning_rate': 1.7652088536048052e-07, 'epoch': 0.94}
{'loss': 1.0156, 'grad_norm': 0.6298825455950194, 'learning_rate': 1.7419739152823468e-07, 'epoch': 0.94}
{'loss': 0.9804, 'grad_norm': 0.6022665670906386, 'learning_rate': 1.7188915655404814e-07, 'epoch': 0.94}
{'loss': 0.9537, 'grad_norm': 0.5428317894321634, 'learning_rate': 1.695961840224636e-07, 'epoch': 0.94}
{'loss': 0.9881, 'grad_norm': 0.6019784107031855, 'learning_rate': 1.6731847749432705e-07, 'epoch': 0.95}
{'loss': 0.9376, 'grad_norm': 0.6120813340732854, 'learning_rate': 1.6505604050677249e-07, 'epoch': 0.95}
{'loss': 0.944, 'grad_norm': 0.6104556328165001, 'learning_rate': 1.6280887657322276e-07, 'epoch': 0.95}
{'loss': 0.9252, 'grad_norm': 0.4733611163629358, 'learning_rate': 1.6057698918338526e-07, 'epoch': 0.95}
{'loss': 0.9689, 'grad_norm': 0.6383995615539546, 'learning_rate': 1.5836038180324198e-07, 'epoch': 0.95}
{'loss': 0.9503, 'grad_norm': 0.5846727312126312, 'learning_rate': 1.561590578750438e-07, 'epoch': 0.95}
{'loss': 0.9344, 'grad_norm': 0.5959293332237883, 'learning_rate': 1.5397302081731069e-07, 'epoch': 0.95}
{'loss': 0.9686, 'grad_norm': 0.526602958611142, 'learning_rate': 1.518022740248215e-07, 'epoch': 0.95}
{'loss': 0.9415, 'grad_norm': 0.6520409990421291, 'learning_rate': 1.4964682086861082e-07, 'epoch': 0.95}
{'loss': 1.0123, 'grad_norm': 0.676113597627537, 'learning_rate': 1.475066646959611e-07, 'epoch': 0.95}
{'loss': 1.0112, 'grad_norm': 0.6301676210486009, 'learning_rate': 1.4538180883040264e-07, 'epoch': 0.95}
{'loss': 0.9811, 'grad_norm': 0.599095131425653, 'learning_rate': 1.4327225657170485e-07, 'epoch': 0.95}
{'loss': 0.985, 'grad_norm': 0.6441894927237368, 'learning_rate': 1.411780111958694e-07, 'epoch': 0.95}
{'loss': 0.9741, 'grad_norm': 0.6445024133541545, 'learning_rate': 1.3909907595512806e-07, 'epoch': 0.95}
{'loss': 0.971, 'grad_norm': 0.64646276577269, 'learning_rate': 1.3703545407793951e-07, 'epoch': 0.95}
{'loss': 0.9386, 'grad_norm': 0.6355664880492109, 'learning_rate': 1.34987148768978e-07, 'epoch': 0.95}
{'loss': 0.9792, 'grad_norm': 0.6729991143458421, 'learning_rate': 1.3295416320913357e-07, 'epoch': 0.95}
{'loss': 1.0232, 'grad_norm': 0.8964007482643824, 'learning_rate': 1.3093650055550855e-07, 'epoch': 0.95}
{'loss': 1.025, 'grad_norm': 0.7187011385337339, 'learning_rate': 1.2893416394140323e-07, 'epoch': 0.95}
{'loss': 0.9114, 'grad_norm': 0.5159419748830152, 'learning_rate': 1.269471564763247e-07, 'epoch': 0.95}
{'loss': 0.9557, 'grad_norm': 0.7332316869493695, 'learning_rate': 1.2497548124597026e-07, 'epoch': 0.95}
{'loss': 0.9644, 'grad_norm': 0.676244006117855, 'learning_rate': 1.2301914131222726e-07, 'epoch': 0.95}
{'loss': 0.9762, 'grad_norm': 0.5940441630506369, 'learning_rate': 1.2107813971317106e-07, 'epoch': 0.95}
{'loss': 0.9395, 'grad_norm': 0.5766628500940424, 'learning_rate': 1.1915247946305498e-07, 'epoch': 0.95}
{'loss': 0.9625, 'grad_norm': 0.6075908421996085, 'learning_rate': 1.1724216355231022e-07, 'epoch': 0.95}
{'loss': 0.9397, 'grad_norm': 0.681740775141803, 'learning_rate': 1.1534719494753821e-07, 'epoch': 0.95}
{'loss': 1.0014, 'grad_norm': 0.5731987090293542, 'learning_rate': 1.1346757659150498e-07, 'epoch': 0.96}
{'loss': 0.9824, 'grad_norm': 0.6256383837377146, 'learning_rate': 1.116033114031434e-07, 'epoch': 0.96}
{'loss': 0.9111, 'grad_norm': 0.7059032973747932, 'learning_rate': 1.0975440227753764e-07, 'epoch': 0.96}
{'loss': 1.0234, 'grad_norm': 0.6446888464416556, 'learning_rate': 1.0792085208593095e-07, 'epoch': 0.96}
{'loss': 0.9952, 'grad_norm': 0.6737967466183887, 'learning_rate': 1.061026636757101e-07, 'epoch': 0.96}
{'loss': 0.9621, 'grad_norm': 0.5632413866457605, 'learning_rate': 1.0429983987041092e-07, 'epoch': 0.96}
{'loss': 0.9753, 'grad_norm': 0.8035097982354942, 'learning_rate': 1.0251238346970393e-07, 'epoch': 0.96}
{'loss': 0.9304, 'grad_norm': 0.6041852099188637, 'learning_rate': 1.007402972493976e-07, 'epoch': 0.96}
{'loss': 0.9544, 'grad_norm': 0.6655787120697733, 'learning_rate': 9.898358396143171e-08, 'epoch': 0.96}
{'loss': 0.9727, 'grad_norm': 0.6590614327153931, 'learning_rate': 9.72422463338718e-08, 'epoch': 0.96}
{'loss': 1.0056, 'grad_norm': 0.6205945512310779, 'learning_rate': 9.55162870709081e-08, 'epoch': 0.96}
{'loss': 0.9915, 'grad_norm': 0.5618995382069222, 'learning_rate': 9.380570885284546e-08, 'epoch': 0.96}
{'loss': 0.9254, 'grad_norm': 0.6725967123524936, 'learning_rate': 9.211051433610674e-08, 'epoch': 0.96}
{'loss': 1.0017, 'grad_norm': 0.6440493410279007, 'learning_rate': 9.04307061532217e-08, 'epoch': 0.96}
{'loss': 0.9574, 'grad_norm': 0.6451820520454731, 'learning_rate': 8.876628691282918e-08, 'epoch': 0.96}
{'loss': 0.9828, 'grad_norm': 0.6445021689801699, 'learning_rate': 8.711725919966718e-08, 'epoch': 0.96}
{'loss': 0.9069, 'grad_norm': 0.6239418563082679, 'learning_rate': 8.54836255745728e-08, 'epoch': 0.96}
{'loss': 0.9768, 'grad_norm': 0.6704330552934749, 'learning_rate': 8.386538857447779e-08, 'epoch': 0.96}
{'loss': 0.9867, 'grad_norm': 0.6575275250070055, 'learning_rate': 8.226255071240308e-08, 'epoch': 0.96}
{'loss': 0.9873, 'grad_norm': 0.6270149814500665, 'learning_rate': 8.067511447745535e-08, 'epoch': 0.96}
{'loss': 0.9943, 'grad_norm': 0.770217898782451, 'learning_rate': 7.910308233482488e-08, 'epoch': 0.96}
{'loss': 0.975, 'grad_norm': 0.582691591716036, 'learning_rate': 7.754645672577776e-08, 'epoch': 0.96}
{'loss': 1.0151, 'grad_norm': 0.5507760833658486, 'learning_rate': 7.600524006765808e-08, 'epoch': 0.96}
{'loss': 0.9189, 'grad_norm': 0.6747833252467901, 'learning_rate': 7.447943475387797e-08, 'epoch': 0.96}
{'loss': 0.973, 'grad_norm': 0.6122837165078332, 'learning_rate': 7.296904315391873e-08, 'epoch': 0.96}
{'loss': 0.9382, 'grad_norm': 0.48074813862615634, 'learning_rate': 7.147406761332298e-08, 'epoch': 0.96}
{'loss': 0.9974, 'grad_norm': 0.6797984900931578, 'learning_rate': 6.999451045369587e-08, 'epoch': 0.97}
{'loss': 0.934, 'grad_norm': 0.568491423936571, 'learning_rate': 6.853037397269724e-08, 'epoch': 0.97}
{'loss': 0.9404, 'grad_norm': 0.5880019947985643, 'learning_rate': 6.70816604440383e-08, 'epoch': 0.97}
{'loss': 0.9544, 'grad_norm': 0.7561601151314108, 'learning_rate': 6.564837211748054e-08, 'epoch': 0.97}
{'loss': 0.997, 'grad_norm': 0.621596818001587, 'learning_rate': 6.42305112188335e-08, 'epoch': 0.97}
{'loss': 0.9976, 'grad_norm': 0.6217736822397611, 'learning_rate': 6.282807994994477e-08, 'epoch': 0.97}
{'loss': 1.011, 'grad_norm': 0.6033477124493667, 'learning_rate': 6.144108048870335e-08, 'epoch': 0.97}
{'loss': 0.9618, 'grad_norm': 0.5960870262034341, 'learning_rate': 6.00695149890329e-08, 'epoch': 0.97}
{'loss': 0.966, 'grad_norm': 0.5995449039486599, 'learning_rate': 5.871338558088857e-08, 'epoch': 0.97}
{'loss': 0.9932, 'grad_norm': 0.6159453392368457, 'learning_rate': 5.7372694370254614e-08, 'epoch': 0.97}
{'loss': 0.9991, 'grad_norm': 0.5879627639170395, 'learning_rate': 5.6047443439141146e-08, 'epoch': 0.97}
{'loss': 0.9832, 'grad_norm': 0.6082088454399697, 'learning_rate': 5.47376348455797e-08, 'epoch': 0.97}
{'loss': 0.9774, 'grad_norm': 0.5738842806524898, 'learning_rate': 5.344327062362098e-08, 'epoch': 0.97}
{'loss': 0.9542, 'grad_norm': 0.6605914545406864, 'learning_rate': 5.216435278333376e-08, 'epoch': 0.97}
{'loss': 1.0021, 'grad_norm': 0.6862938040837555, 'learning_rate': 5.0900883310794903e-08, 'epoch': 0.97}
{'loss': 0.978, 'grad_norm': 0.6022120194826467, 'learning_rate': 4.9652864168096e-08, 'epoch': 0.97}
{'loss': 1.015, 'grad_norm': 0.5608393377296821, 'learning_rate': 4.84202972933312e-08, 'epoch': 0.97}
{'loss': 1.0152, 'grad_norm': 0.8500988656677095, 'learning_rate': 4.720318460060047e-08, 'epoch': 0.97}
{'loss': 1.0008, 'grad_norm': 0.6262402300933849, 'learning_rate': 4.6001527980004125e-08, 'epoch': 0.97}
{'loss': 1.0024, 'grad_norm': 0.6235788394159845, 'learning_rate': 4.4815329297639434e-08, 'epoch': 0.97}
{'loss': 1.0044, 'grad_norm': 0.7310959266182194, 'learning_rate': 4.364459039559843e-08, 'epoch': 0.97}
{'loss': 0.9737, 'grad_norm': 0.6297907094058767, 'learning_rate': 4.248931309196791e-08, 'epoch': 0.97}
{'loss': 0.9613, 'grad_norm': 0.5242312377935885, 'learning_rate': 4.134949918081832e-08, 'epoch': 0.97}
{'loss': 0.9653, 'grad_norm': 0.7669895754261515, 'learning_rate': 4.022515043221154e-08, 'epoch': 0.97}
{'loss': 0.9975, 'grad_norm': 0.6415432141865423, 'learning_rate': 3.9116268592189755e-08, 'epoch': 0.97}
{'loss': 0.951, 'grad_norm': 0.66073396269602, 'learning_rate': 3.802285538277772e-08, 'epoch': 0.97}
{'loss': 1.0079, 'grad_norm': 0.6214215449968047, 'learning_rate': 3.69449125019794e-08, 'epoch': 0.98}
{'loss': 0.9923, 'grad_norm': 0.6444792481552521, 'learning_rate': 3.588244162377019e-08, 'epoch': 0.98}
{'loss': 0.9706, 'grad_norm': 0.6284627312234267, 'learning_rate': 3.483544439810249e-08, 'epoch': 0.98}
{'loss': 0.9823, 'grad_norm': 0.6463861735450702, 'learning_rate': 3.3803922450897917e-08, 'epoch': 0.98}
{'loss': 0.9752, 'grad_norm': 0.6857250021051735, 'learning_rate': 3.2787877384045095e-08, 'epoch': 0.98}
{'loss': 1.0277, 'grad_norm': 0.6374061187992036, 'learning_rate': 3.178731077539743e-08, 'epoch': 0.98}
{'loss': 1.0099, 'grad_norm': 0.8403157161239463, 'learning_rate': 3.080222417877421e-08, 'epoch': 0.98}
{'loss': 0.9198, 'grad_norm': 0.5743806454652994, 'learning_rate': 2.983261912395397e-08, 'epoch': 0.98}
{'loss': 1.0006, 'grad_norm': 0.6365024145525336, 'learning_rate': 2.8878497116671124e-08, 'epoch': 0.98}
{'loss': 0.999, 'grad_norm': 0.5828566198196163, 'learning_rate': 2.7939859638617118e-08, 'epoch': 0.98}
{'loss': 0.998, 'grad_norm': 0.5923620743503124, 'learning_rate': 2.7016708147439285e-08, 'epoch': 0.98}
{'loss': 0.9754, 'grad_norm': 0.6178781038785746, 'learning_rate': 2.6109044076733092e-08, 'epoch': 0.98}
{'loss': 0.9995, 'grad_norm': 0.5742920862031949, 'learning_rate': 2.5216868836043242e-08, 'epoch': 0.98}
{'loss': 0.9838, 'grad_norm': 0.6339382166479693, 'learning_rate': 2.434018381086589e-08, 'epoch': 0.98}
{'loss': 0.9833, 'grad_norm': 0.6138290721143168, 'learning_rate': 2.3478990362634235e-08, 'epoch': 0.98}
{'loss': 0.9839, 'grad_norm': 0.6521608667249519, 'learning_rate': 2.263328982872959e-08, 'epoch': 0.98}
{'loss': 0.9826, 'grad_norm': 0.5967609687117522, 'learning_rate': 2.1803083522471402e-08, 'epoch': 0.98}
{'loss': 0.9514, 'grad_norm': 0.5956885846601488, 'learning_rate': 2.098837273311838e-08, 'epoch': 0.98}
WARNING: tokenization mismatch: 0 vs. 1666. (ignored)
number of rounds:  2
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are an innovative tax advisory firm with the following knowledge and traits.\n\nKNOWLEDGE: Tax advisor, junior tax advisor, senior tax advisor, financial strategist, tax regulations.\n\nTRAITS: Empathy, innovation, solution orientation, professionalism, communication, client focus.\n\nTASK: Use your knowledge to develop an internal strategy document. We are a tax advisory firm looking to identify 10 creative ways to improve client satisfaction and loyalty. Focus on ideas that are tailored to the needs of tax advisors and enhance the overall client experience.\n\nOUTPUT: A table in German containing 10 creative strategies to improve client satisfaction and loyalty for a tax advisory firm, including a brief description for each. ASSISTANT: Tabelle: 10 kreative Strategien zur Steigerung der Kundenzufriedenheit und -loyalität in einer Steuerberatungskanzlei\n\n| Nr. | Strategie | Beschreibung |\n| --- | --- | --- |\n| 1 | Personalisierter Service | Jeder Kunde erhält einen dedizierten Steuerberater, der auf seine individuellen Bedürfnisse und Anliegen eingeht. |\n| 2 | Proaktive Steuerplanung | Regelmäßige Updates und Empfehlungen zur Steueroptimierung, basierend auf aktuellen Gesetzesänderungen und Kundenzielen. |\n| 3 | Umfassende Schulungsangebote | Kostenlose Workshops und Webinare, um das Steuerwissen der Kunden zu erweitern und den Umgang mit Steuerthemen zu erleichtern. |\n| 4 | Digitale Plattform | Eine benutzerfreundliche Online-Plattform, die den Kunden den Zugriff auf ihre Steuerdokumente und den Kontakt zum Berater erleichtert. |\n| 5 | Einführung von Steuer-Coaching | Persönliche Coaching-Sitzungen, um den Kunden dabei zu unterstützen, ihre steuerlichen Ziele und Möglichkeiten besser zu verstehen. |\n| 6 | Schnelle Reaktionszeiten | Verbindliches Versprechen, innerhalb von 24 Stunden auf Kundenanfragen zu reagieren, um eine effiziente Kommunikation zu gewährleisten. |\n| 7 | Transparente Preisgestaltung | Klare und faire Preisstrukturen, die den Kunden im Voraus bekannt sind, um böse Überraschungen zu vermeiden. |\n| 8 | Individuelle Jahresgespräche | Regelmäßige persönliche Jahresgespräche, um auf die Bedürfnisse und Ziele der Kunden einzugehen und die Zusammenarbeit zu stärken. |\n| 9 | Kunden-Feedback-System | Einrichtung eines einfachen Feedback-Systems, um Kundenmeinungen und Verbesserungsvorschläge aktiv einzuholen und umzusetzen. |\n| 10 | Steuer-Newsletter und Informationsangebot | Monatlicher Newsletter mit aktuellen Steuerinformationen und Tipps, der den Kunden einen Mehrwert bietet und sie auf dem Laufenden hält. |", 'USER: Bitte etwas kreativer und auf bezugnehmend auf die zwischenmenschliche Ebene. ASSISTANT: Tabelle: 10 kreative Strategien zur Steigerung der Kundenzufriedenheit und -loyalität in einer Steuerberatungskanzlei mit Fokus auf zwischenmenschlicher Ebene\n\n| Nr. | Strategie | Beschreibung |\n| --- | --- | --- |\n| 1 | Kunden-Events | Organisation von regelmäßigen, informellen Veranstaltungen, um den persönlichen Kontakt zwischen Klienten und Beratern zu fördern. |\n| 2 | Persönliche Geburtstagsgrüße | Individuelle Geburtstagskarten oder -nachrichten für jeden Kunden, um Wertschätzung zu zeigen und Beziehungen zu stärken. |\n| 3 | Kundenbefragung & Anpassung | Aktives Einholen von Kundenmeinungen zur individuellen Betreuung und Anpassung unserer Leistungen entsprechend der Kundenbedürfnisse. |\n| 4 | Teamvorstellung & Empathie | Vorstellung unserer Berater auf der Firmenwebsite und in sozialen Medien, um eine persönliche und empathische Beziehung zum Kunden aufzubauen. |\n| 5 | Kunden-Mentoring-Programm | Schaffung eines Programms, bei dem langjährige Kunden als Mentoren für Neukunden fungieren, um Vertrauen und Loyalität zu fördern. |\n| 6 | "Tag der offenen Tür" | Einladung der Kunden zu einem "Tag der offenen Tür" in unserer Kanzlei, um ihnen einen persönlichen Einblick in unsere Arbeitsweise zu geben. |\n| 7 | Individuelle Erfolgsgeschichten | Erstellung von individuellen Erfolgsgeschichten für jeden Kunden, um ihre steuerlichen Erfolge hervorzuheben und ihre Loyalität zu stärken. |\n| 8 | Gemeinsame soziale Projekte | Zusammenarbeit mit Kunden an sozialen Projekten und Spendenaktionen, um gemeinsame Werte zu teilen und die Zusammenarbeit zu fördern. |\n| 9 | Flexibilität in der Kommunikation | Anbieten verschiedener Kommunikationswege (Telefon, E-Mail, Videoanruf, etc.), um auf die individuellen Bedürfnisse der Kunden einzugehen. |\n| 10 | Jährliches Kunden-Dankeschön | Überraschung der Kunden mit einer kleinen Aufmerksamkeit oder einem Dankeschön-Event, um die Wertschätzung für ihre Treue auszudrücken. |']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are an innovative tax advisory firm with the following knowledge and traits.

KNOWLEDGE: Tax advisor, junior tax advisor, senior tax advisor, financial strategist, tax regulations.

TRAITS: Empathy, innovation, solution orientation, professionalism, communication, client focus.

TASK: Use your knowledge to develop an internal strategy document. We are a tax advisory firm looking to identify 10 creative ways to improve client satisfaction and loyalty. Focus on ideas that are tailored to the needs of tax advisors and enhance the overall client experience.

OUTPUT: A table in German containing 10 creative strategies to improve client satisfaction and loyalty for a tax advisory firm, including a brief description for each. ASSISTANT: Tabelle: 10 kreative Strategien zur Steigerung der Kundenzufriedenheit und -loyalität in einer Steuerberatungskanzlei

| Nr. | Strategie | Beschreibung |
| --- | --- | --- |
| 1 | Personalisierter Service | Jeder Kunde erhält einen dedizierten Steuerberater, der auf seine individuellen Bedürfnisse und Anliegen eingeht. |
| 2 | Proaktive Steuerplanung | Regelmäßige Updates und Empfehlungen zur Steueroptimierung, basierend auf aktuellen Gesetzesänderungen und Kundenzielen. |
| 3 | Umfassende Schulungsangebote | Kostenlose Workshops und Webinare, um das Steuerwissen der Kunden zu erweitern und den Umgang mit Steuerthemen zu erleichtern. |
| 4 | Digitale Plattform | Eine benutzerfreundliche Online-Plattform, die den Kunden den Zugriff auf ihre Steuerdokumente und den Kontakt zum Berater erleichtert. |
| 5 | Einführung von Steuer-Coaching | Persönliche Coaching-Sitzungen, um den Kunden dabei zu unterstützen, ihre steuerlichen Ziele und Möglichkeiten besser zu verstehen. |
| 6 | Schnelle Reaktionszeiten | Verbindliches Versprechen, innerhalb von 24 Stunden auf Kundenanfragen zu reagieren, um eine effiziente Kommunikation zu gewährleisten. |
| 7 | Transparente Preisgestaltung | Klare und faire Preisstrukturen, die den Kunden im Voraus bekannt sind, um böse Überraschungen zu vermeiden. |
| 8 | Individuelle Jahresgespräche | Regelmäßige persönliche Jahresgespräche, um auf die Bedürfnisse und Ziele der Kunden einzugehen und die Zusammenarbeit zu stärken. |
| 9 | Kunden-Feedback-System | Einrichtung eines einfachen Feedback-Systems, um Kundenmeinungen und Verbesserungsvorschläge aktiv einzuholen und umzusetzen. |
| 10 | Steuer-Newsletter und Informationsangebot | Monatlicher Newsletter mit aktuellen Steuerinformationen und Tipps, der den Kunden einen Mehrwert bietet und sie auf dem Laufenden hält. |<|endoftext|>USER: Bitte etwas kreativer und auf bezugnehmend auf die zwischenmenschliche Ebene. ASSISTANT: Tabelle: 10 kreative Strategien zur Steigerung der Kundenzufriedenheit und -loyalität in einer Steuerberatungskanzlei mit Fokus auf zwischenmenschlicher Ebene

| Nr. | Strategie | Beschreibung |
| --- | --- | --- |
| 1 | Kunden-Events | Organisation von regelmäßigen, informellen Veranstaltungen, um den persönlichen Kontakt zwischen Klienten und Beratern zu fördern. |
| 2 | Persönliche Geburtstagsgrüße | Individuelle Geburtstagskarten oder -nachrichten für jeden Kunden, um Wertschätzung zu zeigen und Beziehungen zu stärken. |
| 3 | Kundenbefragung & Anpassung | Aktives Einholen von Kundenmeinungen zur individuellen Betreuung und Anpassung unserer Leistungen entsprechend der Kundenbedürfnisse. |
| 4 | Teamvorstellung & Empathie | Vorstellung unserer Berater auf der Firmenwebsite und in sozialen Medien, um eine persönliche und empathische Beziehung zum Kunden aufzubauen. |
| 5 | Kunden-Mentoring-Programm | Schaffung eines Programms, bei dem langjährige Kunden als Mentoren für Neukunden fungieren, um Vertrauen und Loyalität zu fördern. |
| 6 | "Tag der offenen Tür" | Einladung der Kunden zu einem "Tag der offenen Tür" in unserer Kanzlei, um ihnen einen persönlichen Einblick in unsere Arbeitsweise zu geben. |
| 7 | Individuelle Erfolgsgeschichten | Erstellung von individuellen Erfolgsgeschichten für jeden Kunden, um ihre steuerlichen Erfolge hervorzuheben und ihre Loyalität zu stärken. |
| 8 | Gemeinsame soziale Projekte | Zusammenarbeit mit Kunden an sozialen Projekten und Spendenaktionen, um gemeinsame Werte zu teilen und die Zusammenarbeit zu fördern. |
| 9 | Flexibilität in der Kommunikation | Anbieten verschiedener Kommunikationswege (Telefon, E-Mail, Videoanruf, etc.), um auf die individuellen Bedürfnisse der Kunden einzugehen. |
| 10 | Jährliches Kunden-Dankeschön | Überraschung der Kunden mit einer kleinen Aufmerksamkeit oder einem Dankeschön-Event, um die Wertschätzung für ihre Treue auszudrücken. |<|endoftext|>
tensor([-100, -100, -100,  ..., -100, -100, -100])
tensor([   32,  8537,  1022,  ...,    13,   930, 50256])
{'loss': 1.0132, 'grad_norm': 0.6522705381164952, 'learning_rate': 2.0189158725867353e-08, 'epoch': 0.98}
{'loss': 0.995, 'grad_norm': 0.7431060670296993, 'learning_rate': 1.9405442741844415e-08, 'epoch': 0.98}
{'loss': 0.9755, 'grad_norm': 0.6133002083359835, 'learning_rate': 1.8637225998114904e-08, 'epoch': 0.98}
{'loss': 0.9302, 'grad_norm': 0.5938921465487, 'learning_rate': 1.7884509687668972e-08, 'epoch': 0.98}
{'loss': 0.9615, 'grad_norm': 0.46291429444872867, 'learning_rate': 1.714729497942935e-08, 'epoch': 0.98}
{'loss': 0.9471, 'grad_norm': 0.5388808443154901, 'learning_rate': 1.6425583018244706e-08, 'epoch': 0.98}
{'loss': 0.9613, 'grad_norm': 0.7396218621857781, 'learning_rate': 1.57193749248874e-08, 'epoch': 0.98}
{'loss': 0.9952, 'grad_norm': 0.7701535048844813, 'learning_rate': 1.5028671796055715e-08, 'epoch': 0.98}
{'loss': 0.9998, 'grad_norm': 0.6766770026388146, 'learning_rate': 1.435347470436832e-08, 'epoch': 0.99}
{'loss': 0.9677, 'grad_norm': 0.6063655687030977, 'learning_rate': 1.3693784698363133e-08, 'epoch': 0.99}
{'loss': 0.9535, 'grad_norm': 0.6488244226946905, 'learning_rate': 1.3049602802498451e-08, 'epoch': 0.99}
{'loss': 0.9919, 'grad_norm': 0.6149741098232451, 'learning_rate': 1.2420930017148503e-08, 'epoch': 0.99}
{'loss': 0.9517, 'grad_norm': 0.665240946021197, 'learning_rate': 1.1807767318602337e-08, 'epoch': 0.99}
{'loss': 1.0018, 'grad_norm': 0.6672894839558483, 'learning_rate': 1.1210115659063825e-08, 'epoch': 0.99}
{'loss': 0.9802, 'grad_norm': 0.6220953407324353, 'learning_rate': 1.0627975966649439e-08, 'epoch': 0.99}
{'loss': 0.951, 'grad_norm': 0.5714924871871458, 'learning_rate': 1.0061349145383814e-08, 'epoch': 0.99}
{'loss': 0.9755, 'grad_norm': 0.569053069943293, 'learning_rate': 9.510236075205292e-09, 'epoch': 0.99}
{'loss': 0.9925, 'grad_norm': 0.6683734648155272, 'learning_rate': 8.974637611955939e-09, 'epoch': 0.99}
{'loss': 0.9949, 'grad_norm': 0.7231474777924864, 'learning_rate': 8.454554587388198e-09, 'epoch': 0.99}
{'loss': 0.9464, 'grad_norm': 0.6971197599338874, 'learning_rate': 7.949987809158232e-09, 'epoch': 0.99}
{'loss': 1.0036, 'grad_norm': 0.610939720045454, 'learning_rate': 7.460938060825929e-09, 'epoch': 0.99}
{'loss': 0.995, 'grad_norm': 0.5958667971879353, 'learning_rate': 6.987406101855998e-09, 'epoch': 0.99}
{'loss': 0.982, 'grad_norm': 0.6738062630603875, 'learning_rate': 6.5293926676135434e-09, 'epoch': 0.99}
{'loss': 0.9396, 'grad_norm': 0.5095517651019821, 'learning_rate': 6.086898469365166e-09, 'epoch': 0.99}
{'loss': 0.9912, 'grad_norm': 0.5677104029578375, 'learning_rate': 5.6599241942767445e-09, 'epoch': 0.99}
{'loss': 0.9593, 'grad_norm': 0.6452799524775139, 'learning_rate': 5.248470505412328e-09, 'epoch': 0.99}
{'loss': 0.9284, 'grad_norm': 0.7166114307789013, 'learning_rate': 4.8525380417330234e-09, 'epoch': 0.99}
{'loss': 0.9906, 'grad_norm': 0.5717196761835813, 'learning_rate': 4.472127418099215e-09, 'epoch': 0.99}
{'loss': 0.9576, 'grad_norm': 0.47014176746488445, 'learning_rate': 4.1072392252639034e-09, 'epoch': 0.99}
{'loss': 1.0219, 'grad_norm': 0.6139631178058887, 'learning_rate': 3.757874029874931e-09, 'epoch': 0.99}
{'loss': 0.9712, 'grad_norm': 0.6480154772186278, 'learning_rate': 3.424032374476083e-09, 'epoch': 0.99}
{'loss': 0.921, 'grad_norm': 0.6039399949509022, 'learning_rate': 3.105714777501545e-09, 'epoch': 0.99}
{'loss': 0.9701, 'grad_norm': 0.7090553274825967, 'learning_rate': 2.802921733278119e-09, 'epoch': 0.99}
{'loss': 0.9078, 'grad_norm': 0.7355887570402256, 'learning_rate': 2.5156537120263335e-09, 'epoch': 0.99}
{'loss': 0.9612, 'grad_norm': 0.6467718733241309, 'learning_rate': 2.2439111598537844e-09, 'epoch': 1.0}
{'loss': 0.987, 'grad_norm': 0.6164593792343896, 'learning_rate': 1.987694498760684e-09, 'epoch': 1.0}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/1743790104.jpg, using default black image.
{'loss': 0.9794, 'grad_norm': 0.624906695385421, 'learning_rate': 1.747004126635421e-09, 'epoch': 1.0}
{'loss': 0.9837, 'grad_norm': 0.593435136403605, 'learning_rate': 1.5218404172545609e-09, 'epoch': 1.0}
{'loss': 0.9997, 'grad_norm': 0.5828996602141916, 'learning_rate': 1.3122037202828452e-09, 'epoch': 1.0}
{'loss': 0.9519, 'grad_norm': 0.5075520579076009, 'learning_rate': 1.1180943612754124e-09, 'epoch': 1.0}
{'loss': 1.0171, 'grad_norm': 0.5773332771810394, 'learning_rate': 9.39512641668916e-10, 'epoch': 1.0}
{'loss': 0.9871, 'grad_norm': 0.6124123579407863, 'learning_rate': 7.764588387915161e-10, 'epoch': 1.0}
{'loss': 0.9956, 'grad_norm': 0.5931288928728178, 'learning_rate': 6.289332058551089e-10, 'epoch': 1.0}
{'loss': 0.9588, 'grad_norm': 0.5711274204252006, 'learning_rate': 4.969359719586563e-10, 'epoch': 1.0}
{'loss': 0.9468, 'grad_norm': 0.6223440253262038, 'learning_rate': 3.804673420837457e-10, 'epoch': 1.0}
{'loss': 0.9879, 'grad_norm': 0.6933284221891803, 'learning_rate': 2.795274971001405e-10, 'epoch': 1.0}
{'loss': 0.9959, 'grad_norm': 0.6581498304915055, 'learning_rate': 1.941165937602296e-10, 'epoch': 1.0}
2024-09-30 04:14:55,801 | INFO: saving checkpoint ...
{'train_runtime': 65517.9094, 'train_samples_per_second': 10.154, 'train_steps_per_second': 0.04, 'train_loss': 1.0275548887555532, 'epoch': 1.0}
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-7l9hc9mi[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-2l97n6ym[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-7xsipoc3[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-w1m5feme[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-2l97n6ym/logs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-7xsipoc3/logs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-w1m5feme/logs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-7l9hc9mi/logs[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-ivhw2gjk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-ivhw2gjk/logs[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-ry635sxo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-ry635sxo/logs[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-zvjbg821[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-zvjbg821/logs[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-fd4vhmk3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-fd4vhmk3/logs[0m
[2024-09-30 04:15:37,851] [INFO] [launch.py:351:main] Process 2001411 exits successfully.
[2024-09-30 04:15:38,854] [INFO] [launch.py:351:main] Process 2001412 exits successfully.
[2024-09-30 04:15:38,855] [INFO] [launch.py:351:main] Process 2001415 exits successfully.
[2024-09-30 04:15:38,855] [INFO] [launch.py:351:main] Process 2001413 exits successfully.
[2024-09-30 04:15:38,855] [INFO] [launch.py:351:main] Process 2001417 exits successfully.
[2024-09-30 04:15:38,856] [INFO] [launch.py:351:main] Process 2001414 exits successfully.
[2024-09-30 04:15:38,856] [INFO] [launch.py:351:main] Process 2001416 exits successfully.
[2024-09-30 04:15:42,861] [INFO] [launch.py:351:main] Process 2001410 exits successfully.
=== JOB_STATISTICS ===
=== current date     : Mon Sep 30 04:15:45 CEST 2024
= Job-ID             : 2073121 on alex
= Job-Name           : finetune_phi_new
= Job-Command        : /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/train/train_phi_new.slurm
= Initial workdir    : /home/hpc/b211dd/b211dd20/compression/tinyllava_framework
= Queue/Partition    : a100
= Slurm account      : b211dd with QOS=normal
= Features           : a100_80
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 18:19:06
= Total RAM usage    : 142.6 GiB of assigned  GiB (%)
= Node list          : a0632
= Subm/Elig/Start/End: 2024-09-29T09:56:36 / 2024-09-29T09:56:36 / 2024-09-29T09:56:39 / 2024-09-30T04:15:45
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           34.8G   104.9G   209.7G        N/A      61K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-80GB, 00000000:0E:00.0, 2001410, 57 %, 14 %, 77368 MiB, 65822647 ms
NVIDIA A100-SXM4-80GB, 00000000:13:00.0, 2001411, 58 %, 13 %, 79444 MiB, 65811797 ms
NVIDIA A100-SXM4-80GB, 00000000:49:00.0, 2001412, 58 %, 12 %, 80782 MiB, 65811975 ms
NVIDIA A100-SXM4-80GB, 00000000:4F:00.0, 2001413, 56 %, 12 %, 76946 MiB, 65812469 ms
NVIDIA A100-SXM4-80GB, 00000000:90:00.0, 2001414, 56 %, 12 %, 77248 MiB, 65812641 ms
NVIDIA A100-SXM4-80GB, 00000000:96:00.0, 2001415, 55 %, 12 %, 54594 MiB, 65818786 ms
NVIDIA A100-SXM4-80GB, 00000000:CC:00.0, 2001416, 58 %, 12 %, 64338 MiB, 65818492 ms
NVIDIA A100-SXM4-80GB, 00000000:D1:00.0, 2001417, 59 %, 12 %, 67048 MiB, 65818056 ms
