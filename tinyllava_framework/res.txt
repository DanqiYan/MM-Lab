### Starting TaskPrologue of job 2073121 on a0632 at Sun Sep 29 09:57:10 CEST 2024
Running on cores 0-127 with governor ondemand
Sun Sep 29 09:57:10 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:0E:00.0 Off |                    0 |
| N/A   35C    P0             62W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:13:00.0 Off |                    0 |
| N/A   35C    P0             64W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:49:00.0 Off |                    0 |
| N/A   34C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:4F:00.0 Off |                    0 |
| N/A   37C    P0             65W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100-SXM4-80GB          On  |   00000000:90:00.0 Off |                    0 |
| N/A   36C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100-SXM4-80GB          On  |   00000000:96:00.0 Off |                    0 |
| N/A   34C    P0             61W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100-SXM4-80GB          On  |   00000000:CC:00.0 Off |                    0 |
| N/A   35C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100-SXM4-80GB          On  |   00000000:D1:00.0 Off |                    0 |
| N/A   35C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

a0632.nhr.fau.de
Sun Sep 29 09:57:13 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.28.03              Driver Version: 560.28.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:0E:00.0 Off |                    0 |
| N/A   35C    P0             62W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:13:00.0 Off |                    0 |
| N/A   35C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:49:00.0 Off |                    0 |
| N/A   34C    P0             63W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:4F:00.0 Off |                    0 |
| N/A   37C    P0             69W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100-SXM4-80GB          On  |   00000000:90:00.0 Off |                    0 |
| N/A   37C    P0             83W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100-SXM4-80GB          On  |   00000000:96:00.0 Off |                    0 |
| N/A   34C    P0             66W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100-SXM4-80GB          On  |   00000000:CC:00.0 Off |                    0 |
| N/A   35C    P0             67W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100-SXM4-80GB          On  |   00000000:D1:00.0 Off |                    0 |
| N/A   35C    P0             75W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
[2024-09-29 09:57:41,216] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2024-09-29 09:58:10,757] [WARNING] [runner.py:212:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-09-29 09:58:10,758] [INFO] [runner.py:585:main] cmd = /home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29501 --enable_each_rank_log=None /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py --deepspeed /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json --data_path /home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json --image_folder /home/atuin/b211dd/b211dd20/dataset --is_multimodal True --conv_version phi --model_name_or_path microsoft/phi-2 --vision_tower google/siglip-so400m-patch14-384 --vision_tower2  --connector_type mlp2x_gelu --mm_vision_select_layer -2 --image_aspect_ratio square --attn_implementation flash_attention_2 --fp16 True --training_recipe common --tune_type_llm full --tune_type_vision_tower frozen --tune_vision_tower_from_layer 0 --tune_type_connector full --group_by_modality_length True --pretrained_model_path /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain --output_dir /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full --num_train_epochs 1 --per_device_train_batch_size 8 --per_device_eval_batch_size 4 --gradient_accumulation_steps 4 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 False --model_max_length 3072 --gradient_checkpointing True --dataloader_num_workers 8 --lazy_preprocess True --report_to wandb --tokenizer_use_fast False --run_name tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full
[2024-09-29 09:58:12,836] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2024-09-29 09:58:15,622] [INFO] [launch.py:139:main] 0 TORCH_NCCL_ASYNC_ERROR_HANDLING=1
[2024-09-29 09:58:15,623] [INFO] [launch.py:139:main] 0 TORCH_NCCL_BLOCKING_WAIT=1
[2024-09-29 09:58:15,623] [INFO] [launch.py:139:main] 0 NCCL_TIMEOUT=1800
[2024-09-29 09:58:15,623] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-09-29 09:58:15,623] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-09-29 09:58:15,623] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-09-29 09:58:15,623] [INFO] [launch.py:164:main] dist_world_size=8
[2024-09-29 09:58:15,623] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-09-29 09:58:15,624] [INFO] [launch.py:256:main] process 2001410 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=0', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,625] [INFO] [launch.py:256:main] process 2001411 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=1', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,626] [INFO] [launch.py:256:main] process 2001412 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=2', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,627] [INFO] [launch.py:256:main] process 2001413 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=3', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,627] [INFO] [launch.py:256:main] process 2001414 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=4', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,629] [INFO] [launch.py:256:main] process 2001415 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=5', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,629] [INFO] [launch.py:256:main] process 2001416 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=6', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:15,630] [INFO] [launch.py:256:main] process 2001417 spawned with command: ['/home/atuin/b211dd/b211dd20/software/private/conda/envs/compression/bin/python3.10', '-u', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/tinyllava/train/train.py', '--local_rank=7', '--deepspeed', '/home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/zero3.json', '--data_path', '/home/atuin/b211dd/b211dd20/dataset/text_files/llava_v1_5_mix665k.json', '--image_folder', '/home/atuin/b211dd/b211dd20/dataset', '--is_multimodal', 'True', '--conv_version', 'phi', '--model_name_or_path', 'microsoft/phi-2', '--vision_tower', 'google/siglip-so400m-patch14-384', '--vision_tower2', '', '--connector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--image_aspect_ratio', 'square', '--attn_implementation', 'flash_attention_2', '--fp16', 'True', '--training_recipe', 'common', '--tune_type_llm', 'full', '--tune_type_vision_tower', 'frozen', '--tune_vision_tower_from_layer', '0', '--tune_type_connector', 'full', '--group_by_modality_length', 'True', '--pretrained_model_path', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain', '--output_dir', '/home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'False', '--model_max_length', '3072', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '8', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--tokenizer_use_fast', 'False', '--run_name', 'tiny-llava-phi-2-siglip-so400m-patch14-384-base-finetune_full']
[2024-09-29 09:58:40,273] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:40,370] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:40,392] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:40,394] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
[2024-09-29 09:58:46,749] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:46,777] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:46,804] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-29 09:58:46,837] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/hpc/b211dd/b211dd20/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.

nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.
[2024-09-29 09:59:09,185] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,186] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,186] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,186] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,186] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-09-29 09:59:09,186] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,186] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,188] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-09-29 09:59:09,188] [INFO] [comm.py:652:init_distributed] cdb=None
Before loading, model is on device: cpu
Before loading, model is on device: cpu
Before loading, model is on device: cpu
Before loading, model is on device: cpu
Before loading, model is on device: cpu
[2024-09-29 10:01:41,892] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
Before loading, model is on device: cpu
Before loading, model is on device: cpu
Before loading, model is on device: cpu
[2024-09-29 10:02:03,157] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,157] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,157] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,157] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,158] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,158] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:03,159] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:10,782] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 453, num_elems = 2.78B
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
 /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
loading language model from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/language_model
[2024-09-29 10:02:21,587] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,461] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,462] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,462] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,462] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,462] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,462] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:24,463] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[2024-09-29 10:02:26,697] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 901, num_elems = 3.21B
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
 /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading vision tower from  /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/vision_tower
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
After loading, model is on device: cuda:7
After loading, model is on device: cuda:2
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...
Loading connector from /home/atuin/b211dd/b211dd20/tinyllava/checkpoints/llava_factory/tiny-llava-phi-2-siglip-so400m-patch14-384-base-pretrain/connector/pytorch_model.bin...After loading, model is on device: cuda:0After loading, model is on device: cuda:4

After loading, model is on device: cuda:6

After loading, model is on device: cuda:3
After loading, model is on device: cuda:5
After loading, model is on device: cuda:1
2024-09-29 10:02:52,404 | INFO: Total Parameters: 9507840, Total Trainable Parameters: 9507840
2024-09-29 10:02:52,404 | INFO: Trainable Parameters:
language_model.model.embed_tokens.weight: 0 parameters
language_model.model.layers.0.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.0.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.0.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.0.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.0.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.0.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.0.self_attn.dense.weight: 0 parameters
language_model.model.layers.0.self_attn.dense.bias: 0 parameters
language_model.model.layers.0.mlp.fc1.weight: 0 parameters
language_model.model.layers.0.mlp.fc1.bias: 0 parameters
language_model.model.layers.0.mlp.fc2.weight: 0 parameters
language_model.model.layers.0.mlp.fc2.bias: 0 parameters
language_model.model.layers.0.input_layernorm.weight: 0 parameters
language_model.model.layers.0.input_layernorm.bias: 0 parameters
language_model.model.layers.1.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.1.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.1.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.1.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.1.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.1.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.1.self_attn.dense.weight: 0 parameters
language_model.model.layers.1.self_attn.dense.bias: 0 parameters
language_model.model.layers.1.mlp.fc1.weight: 0 parameters
language_model.model.layers.1.mlp.fc1.bias: 0 parameters
language_model.model.layers.1.mlp.fc2.weight: 0 parameters
language_model.model.layers.1.mlp.fc2.bias: 0 parameters
language_model.model.layers.1.input_layernorm.weight: 0 parameters
language_model.model.layers.1.input_layernorm.bias: 0 parameters
language_model.model.layers.2.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.2.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.2.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.2.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.2.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.2.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.2.self_attn.dense.weight: 0 parameters
language_model.model.layers.2.self_attn.dense.bias: 0 parameters
language_model.model.layers.2.mlp.fc1.weight: 0 parameters
language_model.model.layers.2.mlp.fc1.bias: 0 parameters
language_model.model.layers.2.mlp.fc2.weight: 0 parameters
language_model.model.layers.2.mlp.fc2.bias: 0 parameters
language_model.model.layers.2.input_layernorm.weight: 0 parameters
language_model.model.layers.2.input_layernorm.bias: 0 parameters
language_model.model.layers.3.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.3.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.3.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.3.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.3.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.3.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.3.self_attn.dense.weight: 0 parameters
language_model.model.layers.3.self_attn.dense.bias: 0 parameters
language_model.model.layers.3.mlp.fc1.weight: 0 parameters
language_model.model.layers.3.mlp.fc1.bias: 0 parameters
language_model.model.layers.3.mlp.fc2.weight: 0 parameters
language_model.model.layers.3.mlp.fc2.bias: 0 parameters
language_model.model.layers.3.input_layernorm.weight: 0 parameters
language_model.model.layers.3.input_layernorm.bias: 0 parameters
language_model.model.layers.4.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.4.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.4.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.4.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.4.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.4.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.4.self_attn.dense.weight: 0 parameters
language_model.model.layers.4.self_attn.dense.bias: 0 parameters
language_model.model.layers.4.mlp.fc1.weight: 0 parameters
language_model.model.layers.4.mlp.fc1.bias: 0 parameters
language_model.model.layers.4.mlp.fc2.weight: 0 parameters
language_model.model.layers.4.mlp.fc2.bias: 0 parameters
language_model.model.layers.4.input_layernorm.weight: 0 parameters
language_model.model.layers.4.input_layernorm.bias: 0 parameters
language_model.model.layers.5.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.5.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.5.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.5.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.5.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.5.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.5.self_attn.dense.weight: 0 parameters
language_model.model.layers.5.self_attn.dense.bias: 0 parameters
language_model.model.layers.5.mlp.fc1.weight: 0 parameters
language_model.model.layers.5.mlp.fc1.bias: 0 parameters
language_model.model.layers.5.mlp.fc2.weight: 0 parameters
language_model.model.layers.5.mlp.fc2.bias: 0 parameters
language_model.model.layers.5.input_layernorm.weight: 0 parameters
language_model.model.layers.5.input_layernorm.bias: 0 parameters
language_model.model.layers.6.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.6.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.6.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.6.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.6.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.6.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.6.self_attn.dense.weight: 0 parameters
language_model.model.layers.6.self_attn.dense.bias: 0 parameters
language_model.model.layers.6.mlp.fc1.weight: 0 parameters
language_model.model.layers.6.mlp.fc1.bias: 0 parameters
language_model.model.layers.6.mlp.fc2.weight: 0 parameters
language_model.model.layers.6.mlp.fc2.bias: 0 parameters
language_model.model.layers.6.input_layernorm.weight: 0 parameters
language_model.model.layers.6.input_layernorm.bias: 0 parameters
language_model.model.layers.7.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.7.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.7.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.7.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.7.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.7.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.7.self_attn.dense.weight: 0 parameters
language_model.model.layers.7.self_attn.dense.bias: 0 parameters
language_model.model.layers.7.mlp.fc1.weight: 0 parameters
language_model.model.layers.7.mlp.fc1.bias: 0 parameters
language_model.model.layers.7.mlp.fc2.weight: 0 parameters
language_model.model.layers.7.mlp.fc2.bias: 0 parameters
language_model.model.layers.7.input_layernorm.weight: 0 parameters
language_model.model.layers.7.input_layernorm.bias: 0 parameters
language_model.model.layers.8.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.8.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.8.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.8.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.8.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.8.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.8.self_attn.dense.weight: 0 parameters
language_model.model.layers.8.self_attn.dense.bias: 0 parameters
language_model.model.layers.8.mlp.fc1.weight: 0 parameters
language_model.model.layers.8.mlp.fc1.bias: 0 parameters
language_model.model.layers.8.mlp.fc2.weight: 0 parameters
language_model.model.layers.8.mlp.fc2.bias: 0 parameters
language_model.model.layers.8.input_layernorm.weight: 0 parameters
language_model.model.layers.8.input_layernorm.bias: 0 parameters
language_model.model.layers.9.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.9.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.9.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.9.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.9.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.9.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.9.self_attn.dense.weight: 0 parameters
language_model.model.layers.9.self_attn.dense.bias: 0 parameters
language_model.model.layers.9.mlp.fc1.weight: 0 parameters
language_model.model.layers.9.mlp.fc1.bias: 0 parameters
language_model.model.layers.9.mlp.fc2.weight: 0 parameters
language_model.model.layers.9.mlp.fc2.bias: 0 parameters
language_model.model.layers.9.input_layernorm.weight: 0 parameters
language_model.model.layers.9.input_layernorm.bias: 0 parameters
language_model.model.layers.10.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.10.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.10.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.10.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.10.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.10.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.10.self_attn.dense.weight: 0 parameters
language_model.model.layers.10.self_attn.dense.bias: 0 parameters
language_model.model.layers.10.mlp.fc1.weight: 0 parameters
language_model.model.layers.10.mlp.fc1.bias: 0 parameters
language_model.model.layers.10.mlp.fc2.weight: 0 parameters
language_model.model.layers.10.mlp.fc2.bias: 0 parameters
language_model.model.layers.10.input_layernorm.weight: 0 parameters
language_model.model.layers.10.input_layernorm.bias: 0 parameters
language_model.model.layers.11.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.11.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.11.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.11.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.11.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.11.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.11.self_attn.dense.weight: 0 parameters
language_model.model.layers.11.self_attn.dense.bias: 0 parameters
language_model.model.layers.11.mlp.fc1.weight: 0 parameters
language_model.model.layers.11.mlp.fc1.bias: 0 parameters
language_model.model.layers.11.mlp.fc2.weight: 0 parameters
language_model.model.layers.11.mlp.fc2.bias: 0 parameters
language_model.model.layers.11.input_layernorm.weight: 0 parameters
language_model.model.layers.11.input_layernorm.bias: 0 parameters
language_model.model.layers.12.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.12.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.12.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.12.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.12.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.12.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.12.self_attn.dense.weight: 0 parameters
language_model.model.layers.12.self_attn.dense.bias: 0 parameters
language_model.model.layers.12.mlp.fc1.weight: 0 parameters
language_model.model.layers.12.mlp.fc1.bias: 0 parameters
language_model.model.layers.12.mlp.fc2.weight: 0 parameters
language_model.model.layers.12.mlp.fc2.bias: 0 parameters
language_model.model.layers.12.input_layernorm.weight: 0 parameters
language_model.model.layers.12.input_layernorm.bias: 0 parameters
language_model.model.layers.13.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.13.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.13.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.13.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.13.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.13.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.13.self_attn.dense.weight: 0 parameters
language_model.model.layers.13.self_attn.dense.bias: 0 parameters
language_model.model.layers.13.mlp.fc1.weight: 0 parameters
language_model.model.layers.13.mlp.fc1.bias: 0 parameters
language_model.model.layers.13.mlp.fc2.weight: 0 parameters
language_model.model.layers.13.mlp.fc2.bias: 0 parameters
language_model.model.layers.13.input_layernorm.weight: 0 parameters
language_model.model.layers.13.input_layernorm.bias: 0 parameters
language_model.model.layers.14.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.14.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.14.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.14.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.14.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.14.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.14.self_attn.dense.weight: 0 parameters
language_model.model.layers.14.self_attn.dense.bias: 0 parameters
language_model.model.layers.14.mlp.fc1.weight: 0 parameters
language_model.model.layers.14.mlp.fc1.bias: 0 parameters
language_model.model.layers.14.mlp.fc2.weight: 0 parameters
language_model.model.layers.14.mlp.fc2.bias: 0 parameters
language_model.model.layers.14.input_layernorm.weight: 0 parameters
language_model.model.layers.14.input_layernorm.bias: 0 parameters
language_model.model.layers.15.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.15.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.15.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.15.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.15.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.15.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.15.self_attn.dense.weight: 0 parameters
language_model.model.layers.15.self_attn.dense.bias: 0 parameters
language_model.model.layers.15.mlp.fc1.weight: 0 parameters
language_model.model.layers.15.mlp.fc1.bias: 0 parameters
language_model.model.layers.15.mlp.fc2.weight: 0 parameters
language_model.model.layers.15.mlp.fc2.bias: 0 parameters
language_model.model.layers.15.input_layernorm.weight: 0 parameters
language_model.model.layers.15.input_layernorm.bias: 0 parameters
language_model.model.layers.16.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.16.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.16.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.16.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.16.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.16.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.16.self_attn.dense.weight: 0 parameters
language_model.model.layers.16.self_attn.dense.bias: 0 parameters
language_model.model.layers.16.mlp.fc1.weight: 0 parameters
language_model.model.layers.16.mlp.fc1.bias: 0 parameters
language_model.model.layers.16.mlp.fc2.weight: 0 parameters
language_model.model.layers.16.mlp.fc2.bias: 0 parameters
language_model.model.layers.16.input_layernorm.weight: 0 parameters
language_model.model.layers.16.input_layernorm.bias: 0 parameters
language_model.model.layers.17.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.17.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.17.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.17.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.17.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.17.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.17.self_attn.dense.weight: 0 parameters
language_model.model.layers.17.self_attn.dense.bias: 0 parameters
language_model.model.layers.17.mlp.fc1.weight: 0 parameters
language_model.model.layers.17.mlp.fc1.bias: 0 parameters
language_model.model.layers.17.mlp.fc2.weight: 0 parameters
language_model.model.layers.17.mlp.fc2.bias: 0 parameters
language_model.model.layers.17.input_layernorm.weight: 0 parameters
language_model.model.layers.17.input_layernorm.bias: 0 parameters
language_model.model.layers.18.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.18.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.18.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.18.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.18.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.18.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.18.self_attn.dense.weight: 0 parameters
language_model.model.layers.18.self_attn.dense.bias: 0 parameters
language_model.model.layers.18.mlp.fc1.weight: 0 parameters
language_model.model.layers.18.mlp.fc1.bias: 0 parameters
language_model.model.layers.18.mlp.fc2.weight: 0 parameters
language_model.model.layers.18.mlp.fc2.bias: 0 parameters
language_model.model.layers.18.input_layernorm.weight: 0 parameters
language_model.model.layers.18.input_layernorm.bias: 0 parameters
language_model.model.layers.19.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.19.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.19.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.19.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.19.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.19.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.19.self_attn.dense.weight: 0 parameters
language_model.model.layers.19.self_attn.dense.bias: 0 parameters
language_model.model.layers.19.mlp.fc1.weight: 0 parameters
language_model.model.layers.19.mlp.fc1.bias: 0 parameters
language_model.model.layers.19.mlp.fc2.weight: 0 parameters
language_model.model.layers.19.mlp.fc2.bias: 0 parameters
language_model.model.layers.19.input_layernorm.weight: 0 parameters
language_model.model.layers.19.input_layernorm.bias: 0 parameters
language_model.model.layers.20.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.20.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.20.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.20.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.20.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.20.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.20.self_attn.dense.weight: 0 parameters
language_model.model.layers.20.self_attn.dense.bias: 0 parameters
language_model.model.layers.20.mlp.fc1.weight: 0 parameters
language_model.model.layers.20.mlp.fc1.bias: 0 parameters
language_model.model.layers.20.mlp.fc2.weight: 0 parameters
language_model.model.layers.20.mlp.fc2.bias: 0 parameters
language_model.model.layers.20.input_layernorm.weight: 0 parameters
language_model.model.layers.20.input_layernorm.bias: 0 parameters
language_model.model.layers.21.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.21.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.21.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.21.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.21.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.21.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.21.self_attn.dense.weight: 0 parameters
language_model.model.layers.21.self_attn.dense.bias: 0 parameters
language_model.model.layers.21.mlp.fc1.weight: 0 parameters
language_model.model.layers.21.mlp.fc1.bias: 0 parameters
language_model.model.layers.21.mlp.fc2.weight: 0 parameters
language_model.model.layers.21.mlp.fc2.bias: 0 parameters
language_model.model.layers.21.input_layernorm.weight: 0 parameters
language_model.model.layers.21.input_layernorm.bias: 0 parameters
language_model.model.layers.22.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.22.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.22.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.22.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.22.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.22.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.22.self_attn.dense.weight: 0 parameters
language_model.model.layers.22.self_attn.dense.bias: 0 parameters
language_model.model.layers.22.mlp.fc1.weight: 0 parameters
language_model.model.layers.22.mlp.fc1.bias: 0 parameters
language_model.model.layers.22.mlp.fc2.weight: 0 parameters
language_model.model.layers.22.mlp.fc2.bias: 0 parameters
language_model.model.layers.22.input_layernorm.weight: 0 parameters
language_model.model.layers.22.input_layernorm.bias: 0 parameters
language_model.model.layers.23.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.23.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.23.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.23.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.23.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.23.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.23.self_attn.dense.weight: 0 parameters
language_model.model.layers.23.self_attn.dense.bias: 0 parameters
language_model.model.layers.23.mlp.fc1.weight: 0 parameters
language_model.model.layers.23.mlp.fc1.bias: 0 parameters
language_model.model.layers.23.mlp.fc2.weight: 0 parameters
language_model.model.layers.23.mlp.fc2.bias: 0 parameters
language_model.model.layers.23.input_layernorm.weight: 0 parameters
language_model.model.layers.23.input_layernorm.bias: 0 parameters
language_model.model.layers.24.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.24.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.24.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.24.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.24.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.24.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.24.self_attn.dense.weight: 0 parameters
language_model.model.layers.24.self_attn.dense.bias: 0 parameters
language_model.model.layers.24.mlp.fc1.weight: 0 parameters
language_model.model.layers.24.mlp.fc1.bias: 0 parameters
language_model.model.layers.24.mlp.fc2.weight: 0 parameters
language_model.model.layers.24.mlp.fc2.bias: 0 parameters
language_model.model.layers.24.input_layernorm.weight: 0 parameters
language_model.model.layers.24.input_layernorm.bias: 0 parameters
language_model.model.layers.25.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.25.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.25.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.25.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.25.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.25.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.25.self_attn.dense.weight: 0 parameters
language_model.model.layers.25.self_attn.dense.bias: 0 parameters
language_model.model.layers.25.mlp.fc1.weight: 0 parameters
language_model.model.layers.25.mlp.fc1.bias: 0 parameters
language_model.model.layers.25.mlp.fc2.weight: 0 parameters
language_model.model.layers.25.mlp.fc2.bias: 0 parameters
language_model.model.layers.25.input_layernorm.weight: 0 parameters
language_model.model.layers.25.input_layernorm.bias: 0 parameters
language_model.model.layers.26.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.26.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.26.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.26.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.26.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.26.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.26.self_attn.dense.weight: 0 parameters
language_model.model.layers.26.self_attn.dense.bias: 0 parameters
language_model.model.layers.26.mlp.fc1.weight: 0 parameters
language_model.model.layers.26.mlp.fc1.bias: 0 parameters
language_model.model.layers.26.mlp.fc2.weight: 0 parameters
language_model.model.layers.26.mlp.fc2.bias: 0 parameters
language_model.model.layers.26.input_layernorm.weight: 0 parameters
language_model.model.layers.26.input_layernorm.bias: 0 parameters
language_model.model.layers.27.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.27.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.27.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.27.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.27.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.27.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.27.self_attn.dense.weight: 0 parameters
language_model.model.layers.27.self_attn.dense.bias: 0 parameters
language_model.model.layers.27.mlp.fc1.weight: 0 parameters
language_model.model.layers.27.mlp.fc1.bias: 0 parameters
language_model.model.layers.27.mlp.fc2.weight: 0 parameters
language_model.model.layers.27.mlp.fc2.bias: 0 parameters
language_model.model.layers.27.input_layernorm.weight: 0 parameters
language_model.model.layers.27.input_layernorm.bias: 0 parameters
language_model.model.layers.28.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.28.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.28.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.28.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.28.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.28.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.28.self_attn.dense.weight: 0 parameters
language_model.model.layers.28.self_attn.dense.bias: 0 parameters
language_model.model.layers.28.mlp.fc1.weight: 0 parameters
language_model.model.layers.28.mlp.fc1.bias: 0 parameters
language_model.model.layers.28.mlp.fc2.weight: 0 parameters
language_model.model.layers.28.mlp.fc2.bias: 0 parameters
language_model.model.layers.28.input_layernorm.weight: 0 parameters
language_model.model.layers.28.input_layernorm.bias: 0 parameters
language_model.model.layers.29.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.29.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.29.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.29.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.29.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.29.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.29.self_attn.dense.weight: 0 parameters
language_model.model.layers.29.self_attn.dense.bias: 0 parameters
language_model.model.layers.29.mlp.fc1.weight: 0 parameters
language_model.model.layers.29.mlp.fc1.bias: 0 parameters
language_model.model.layers.29.mlp.fc2.weight: 0 parameters
language_model.model.layers.29.mlp.fc2.bias: 0 parameters
language_model.model.layers.29.input_layernorm.weight: 0 parameters
language_model.model.layers.29.input_layernorm.bias: 0 parameters
language_model.model.layers.30.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.30.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.30.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.30.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.30.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.30.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.30.self_attn.dense.weight: 0 parameters
language_model.model.layers.30.self_attn.dense.bias: 0 parameters
language_model.model.layers.30.mlp.fc1.weight: 0 parameters
language_model.model.layers.30.mlp.fc1.bias: 0 parameters
language_model.model.layers.30.mlp.fc2.weight: 0 parameters
language_model.model.layers.30.mlp.fc2.bias: 0 parameters
language_model.model.layers.30.input_layernorm.weight: 0 parameters
language_model.model.layers.30.input_layernorm.bias: 0 parameters
language_model.model.layers.31.self_attn.q_proj.weight: 0 parameters
language_model.model.layers.31.self_attn.q_proj.bias: 0 parameters
language_model.model.layers.31.self_attn.k_proj.weight: 0 parameters
language_model.model.layers.31.self_attn.k_proj.bias: 0 parameters
language_model.model.layers.31.self_attn.v_proj.weight: 0 parameters
language_model.model.layers.31.self_attn.v_proj.bias: 0 parameters
language_model.model.layers.31.self_attn.dense.weight: 0 parameters
language_model.model.layers.31.self_attn.dense.bias: 0 parameters
language_model.model.layers.31.mlp.fc1.weight: 0 parameters
language_model.model.layers.31.mlp.fc1.bias: 0 parameters
language_model.model.layers.31.mlp.fc2.weight: 0 parameters
language_model.model.layers.31.mlp.fc2.bias: 0 parameters
language_model.model.layers.31.input_layernorm.weight: 0 parameters
language_model.model.layers.31.input_layernorm.bias: 0 parameters
language_model.model.final_layernorm.weight: 0 parameters
language_model.model.final_layernorm.bias: 0 parameters
language_model.lm_head.weight: 0 parameters
language_model.lm_head.bias: 0 parameters
connector._connector.0.weight: 2949120 parameters
connector._connector.0.bias: 2560 parameters
connector._connector.2.weight: 6553600 parameters
connector._connector.2.bias: 2560 parameters
2024-09-29 10:02:52,445 | WARNING: Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Parameter Offload: Total persistent parameters: 1324480 in 540 params
{'loss': 2.1311, 'grad_norm': 0.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 2.571, 'grad_norm': 0.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 2.5851, 'grad_norm': 0.0, 'learning_rate': 0.0, 'epoch': 0.0}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/486209652.jpg, using default black image.
{'loss': 2.7469, 'grad_norm': 0.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 2.1317, 'grad_norm': 11.500918563362376, 'learning_rate': 2.564102564102564e-07, 'epoch': 0.0}
{'loss': 2.5399, 'grad_norm': 11.500918563362376, 'learning_rate': 2.564102564102564e-07, 'epoch': 0.0}
{'loss': 2.4438, 'grad_norm': 15.194850208161542, 'learning_rate': 5.128205128205128e-07, 'epoch': 0.0}
{'loss': 2.5443, 'grad_norm': 15.952488348640381, 'learning_rate': 7.692307692307694e-07, 'epoch': 0.0}
{'loss': 2.4876, 'grad_norm': 15.732378037671344, 'learning_rate': 1.0256410256410257e-06, 'epoch': 0.0}
{'loss': 2.4707, 'grad_norm': 16.092473992884667, 'learning_rate': 1.282051282051282e-06, 'epoch': 0.0}
{'loss': 2.2081, 'grad_norm': 12.176329786735536, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.0}
{'loss': 2.1078, 'grad_norm': 11.904213092189122, 'learning_rate': 1.794871794871795e-06, 'epoch': 0.0}
{'loss': 1.7224, 'grad_norm': 6.203296163394181, 'learning_rate': 2.0512820512820513e-06, 'epoch': 0.01}
{'loss': 1.9509, 'grad_norm': 8.170176727973981, 'learning_rate': 2.307692307692308e-06, 'epoch': 0.01}
{'loss': 1.4607, 'grad_norm': 2.8036423982200263, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.01}
{'loss': 1.6218, 'grad_norm': 3.927399820623878, 'learning_rate': 2.8205128205128207e-06, 'epoch': 0.01}
{'loss': 1.3961, 'grad_norm': 2.4557999727178736, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.01}
{'loss': 1.2361, 'grad_norm': 1.8858317538454439, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.01}
{'loss': 1.471, 'grad_norm': 3.329878648717035, 'learning_rate': 3.58974358974359e-06, 'epoch': 0.01}
{'loss': 1.4036, 'grad_norm': 3.027479749638866, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.01}
{'loss': 1.4684, 'grad_norm': 3.1241202375247035, 'learning_rate': 4.102564102564103e-06, 'epoch': 0.01}
{'loss': 1.3199, 'grad_norm': 2.735205048328577, 'learning_rate': 4.358974358974359e-06, 'epoch': 0.01}
{'loss': 1.4371, 'grad_norm': 2.5576495418916534, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.01}
{'loss': 1.3723, 'grad_norm': 2.06636954684189, 'learning_rate': 4.871794871794872e-06, 'epoch': 0.01}
{'loss': 1.4146, 'grad_norm': 2.691034969312412, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.01}
{'loss': 1.3785, 'grad_norm': 1.890451145236368, 'learning_rate': 5.384615384615385e-06, 'epoch': 0.01}
{'loss': 1.3599, 'grad_norm': 1.4078163370060603, 'learning_rate': 5.641025641025641e-06, 'epoch': 0.01}
{'loss': 1.3642, 'grad_norm': 1.1941629603190567, 'learning_rate': 5.897435897435898e-06, 'epoch': 0.01}
{'loss': 1.3261, 'grad_norm': 1.2265560480596154, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.01}
{'loss': 1.2852, 'grad_norm': 1.438621043671899, 'learning_rate': 6.410256410256412e-06, 'epoch': 0.01}
{'loss': 1.1797, 'grad_norm': 1.1230937766146882, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}
{'loss': 1.3367, 'grad_norm': 1.1979056935876566, 'learning_rate': 6.923076923076923e-06, 'epoch': 0.01}
{'loss': 1.3612, 'grad_norm': 1.0838552356576454, 'learning_rate': 7.17948717948718e-06, 'epoch': 0.01}
{'loss': 1.2844, 'grad_norm': 1.0614379090603236, 'learning_rate': 7.435897435897437e-06, 'epoch': 0.01}
{'loss': 1.2825, 'grad_norm': 1.4741066229791735, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.01}
{'loss': 1.2732, 'grad_norm': 1.0606573185790027, 'learning_rate': 7.948717948717949e-06, 'epoch': 0.01}
{'loss': 1.2876, 'grad_norm': 1.1511381692539497, 'learning_rate': 8.205128205128205e-06, 'epoch': 0.01}
{'loss': 1.2717, 'grad_norm': 1.1196581488731112, 'learning_rate': 8.461538461538462e-06, 'epoch': 0.01}
{'loss': 1.2389, 'grad_norm': 1.3903131308595376, 'learning_rate': 8.717948717948719e-06, 'epoch': 0.02}
{'loss': 1.1983, 'grad_norm': 1.0085583343858315, 'learning_rate': 8.974358974358976e-06, 'epoch': 0.02}
{'loss': 1.2536, 'grad_norm': 1.4504685867460978, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.02}
{'loss': 1.2064, 'grad_norm': 0.9730167949543925, 'learning_rate': 9.487179487179487e-06, 'epoch': 0.02}
{'loss': 1.2435, 'grad_norm': 1.174810227305119, 'learning_rate': 9.743589743589744e-06, 'epoch': 0.02}
{'loss': 1.2105, 'grad_norm': 0.8288282514876404, 'learning_rate': 1e-05, 'epoch': 0.02}
{'loss': 1.2276, 'grad_norm': 1.1568145756289023, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.02}
{'loss': 1.2542, 'grad_norm': 0.9582325311666592, 'learning_rate': 1.0512820512820514e-05, 'epoch': 0.02}
{'loss': 1.2475, 'grad_norm': 0.9931918276866886, 'learning_rate': 1.076923076923077e-05, 'epoch': 0.02}
{'loss': 1.1965, 'grad_norm': 1.0556187446331258, 'learning_rate': 1.1025641025641028e-05, 'epoch': 0.02}
{'loss': 1.1925, 'grad_norm': 0.8438898738900166, 'learning_rate': 1.1282051282051283e-05, 'epoch': 0.02}
{'loss': 1.171, 'grad_norm': 1.0354292008918287, 'learning_rate': 1.1538461538461538e-05, 'epoch': 0.02}
{'loss': 1.2156, 'grad_norm': 0.8908024363771476, 'learning_rate': 1.1794871794871796e-05, 'epoch': 0.02}
{'loss': 1.1671, 'grad_norm': 1.014826338641746, 'learning_rate': 1.2051282051282051e-05, 'epoch': 0.02}
{'loss': 1.198, 'grad_norm': 0.9382109768445511, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.02}
{'loss': 1.199, 'grad_norm': 0.8358804503960547, 'learning_rate': 1.2564102564102565e-05, 'epoch': 0.02}
{'loss': 1.2132, 'grad_norm': 1.0464586415905914, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.02}
{'loss': 1.1608, 'grad_norm': 1.1372527621164836, 'learning_rate': 1.3076923076923078e-05, 'epoch': 0.02}
{'loss': 1.1888, 'grad_norm': 0.9483684329047496, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.02}
{'loss': 1.1845, 'grad_norm': 1.0970508096745104, 'learning_rate': 1.3589743589743592e-05, 'epoch': 0.02}
{'loss': 1.143, 'grad_norm': 1.0637968080631883, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.02}
{'loss': 1.1728, 'grad_norm': 1.0860921171555864, 'learning_rate': 1.4102564102564105e-05, 'epoch': 0.02}
{'loss': 1.2028, 'grad_norm': 1.1981072185674089, 'learning_rate': 1.435897435897436e-05, 'epoch': 0.02}
{'loss': 1.2583, 'grad_norm': 0.8175549677140056, 'learning_rate': 1.4615384615384615e-05, 'epoch': 0.02}
{'loss': 1.1995, 'grad_norm': 1.1662783226424804, 'learning_rate': 1.4871794871794874e-05, 'epoch': 0.02}
{'loss': 1.1771, 'grad_norm': 0.9174381528195285, 'learning_rate': 1.5128205128205129e-05, 'epoch': 0.02}
{'loss': 1.2152, 'grad_norm': 0.8274148081275002, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.03}
{'loss': 1.1588, 'grad_norm': 1.1901400675198879, 'learning_rate': 1.5641025641025644e-05, 'epoch': 0.03}
{'loss': 1.2206, 'grad_norm': 0.9404578478569944, 'learning_rate': 1.5897435897435897e-05, 'epoch': 0.03}
{'loss': 1.1482, 'grad_norm': 0.8648273896980069, 'learning_rate': 1.6153846153846154e-05, 'epoch': 0.03}
{'loss': 1.2018, 'grad_norm': 0.9141445930010452, 'learning_rate': 1.641025641025641e-05, 'epoch': 0.03}
{'loss': 1.1646, 'grad_norm': 0.8490087810930925, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.03}
{'loss': 1.1835, 'grad_norm': 0.9753771246809725, 'learning_rate': 1.6923076923076924e-05, 'epoch': 0.03}
{'loss': 1.1928, 'grad_norm': 1.5718246362816242, 'learning_rate': 1.717948717948718e-05, 'epoch': 0.03}
{'loss': 1.1052, 'grad_norm': 0.6879528753063061, 'learning_rate': 1.7435897435897438e-05, 'epoch': 0.03}
{'loss': 1.2436, 'grad_norm': 0.9184993957238011, 'learning_rate': 1.7692307692307694e-05, 'epoch': 0.03}
{'loss': 1.1519, 'grad_norm': 0.7988895124816803, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.03}
{'loss': 1.1165, 'grad_norm': 0.7075463354675736, 'learning_rate': 1.8205128205128208e-05, 'epoch': 0.03}
{'loss': 1.1936, 'grad_norm': 0.8098423780146206, 'learning_rate': 1.8461538461538465e-05, 'epoch': 0.03}
{'loss': 1.157, 'grad_norm': 0.8870141373591414, 'learning_rate': 1.8717948717948718e-05, 'epoch': 0.03}
{'loss': 1.1787, 'grad_norm': 0.9922516706623165, 'learning_rate': 1.8974358974358975e-05, 'epoch': 0.03}
{'loss': 1.1749, 'grad_norm': 0.8475661486157011, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.03}
{'loss': 1.1198, 'grad_norm': 0.9085851820503784, 'learning_rate': 1.9487179487179488e-05, 'epoch': 0.03}
{'loss': 1.1637, 'grad_norm': 0.757090513902173, 'learning_rate': 1.9743589743589745e-05, 'epoch': 0.03}
{'loss': 1.1914, 'grad_norm': 1.000636406724171, 'learning_rate': 2e-05, 'epoch': 0.03}
{'loss': 1.2017, 'grad_norm': 0.7922579714872521, 'learning_rate': 1.9999992235312136e-05, 'epoch': 0.03}
{'loss': 1.1955, 'grad_norm': 0.8960579850356747, 'learning_rate': 1.9999968941260596e-05, 'epoch': 0.03}
{'loss': 1.0729, 'grad_norm': 0.7495940352606297, 'learning_rate': 1.9999930117881548e-05, 'epoch': 0.03}
{'loss': 1.2019, 'grad_norm': 0.796665461716586, 'learning_rate': 1.99998757652353e-05, 'epoch': 0.03}
{'loss': 1.1465, 'grad_norm': 0.7863031354618817, 'learning_rate': 1.999980588340624e-05, 'epoch': 0.03}
{'loss': 1.1306, 'grad_norm': 0.7206271242204582, 'learning_rate': 1.9999720472502902e-05, 'epoch': 0.03}
{'loss': 1.148, 'grad_norm': 1.103874626403496, 'learning_rate': 1.9999619532657915e-05, 'epoch': 0.03}
{'loss': 1.1493, 'grad_norm': 0.9353683463918591, 'learning_rate': 1.9999503064028043e-05, 'epoch': 0.04}
{'loss': 1.1526, 'grad_norm': 0.9316110108472156, 'learning_rate': 1.9999371066794146e-05, 'epoch': 0.04}
{'loss': 1.1682, 'grad_norm': 0.9282744732853953, 'learning_rate': 1.999922354116121e-05, 'epoch': 0.04}
{'loss': 1.1559, 'grad_norm': 1.0899132206592754, 'learning_rate': 1.9999060487358333e-05, 'epoch': 0.04}
{'loss': 1.1722, 'grad_norm': 0.8678452310666057, 'learning_rate': 1.9998881905638727e-05, 'epoch': 0.04}
{'loss': 1.1602, 'grad_norm': 0.8825486102993694, 'learning_rate': 1.999868779627972e-05, 'epoch': 0.04}
{'loss': 1.1385, 'grad_norm': 1.1411254212831694, 'learning_rate': 1.9998478159582747e-05, 'epoch': 0.04}
{'loss': 1.1765, 'grad_norm': 0.8510220735506286, 'learning_rate': 1.9998252995873367e-05, 'epoch': 0.04}
{'loss': 1.1697, 'grad_norm': 0.8009120123466015, 'learning_rate': 1.9998012305501243e-05, 'epoch': 0.04}
{'loss': 1.1688, 'grad_norm': 1.0349455642014682, 'learning_rate': 1.999775608884015e-05, 'epoch': 0.04}
{'loss': 1.1932, 'grad_norm': 0.8312254515622064, 'learning_rate': 1.9997484346287973e-05, 'epoch': 0.04}
{'loss': 1.0832, 'grad_norm': 0.8333339383185524, 'learning_rate': 1.9997197078266723e-05, 'epoch': 0.04}
{'loss': 1.1021, 'grad_norm': 0.9342580533912854, 'learning_rate': 1.99968942852225e-05, 'epoch': 0.04}
{'loss': 1.1677, 'grad_norm': 0.8590630795946502, 'learning_rate': 1.9996575967625525e-05, 'epoch': 0.04}
{'loss': 1.119, 'grad_norm': 1.0010947478628942, 'learning_rate': 1.999624212597013e-05, 'epoch': 0.04}
{'loss': 1.0894, 'grad_norm': 0.8668876491852764, 'learning_rate': 1.9995892760774738e-05, 'epoch': 0.04}
{'loss': 1.1283, 'grad_norm': 1.1041879867420503, 'learning_rate': 1.9995527872581903e-05, 'epoch': 0.04}
{'loss': 1.1765, 'grad_norm': 0.941733647333841, 'learning_rate': 1.9995147461958267e-05, 'epoch': 0.04}
{'loss': 1.1231, 'grad_norm': 0.8702670557784051, 'learning_rate': 1.999475152949459e-05, 'epoch': 0.04}
{'loss': 1.1293, 'grad_norm': 1.0092560737554561, 'learning_rate': 1.9994340075805724e-05, 'epoch': 0.04}
{'loss': 1.1363, 'grad_norm': 0.7725766542905332, 'learning_rate': 1.9993913101530635e-05, 'epoch': 0.04}
{'loss': 1.0962, 'grad_norm': 0.6837353574568258, 'learning_rate': 1.9993470607332387e-05, 'epoch': 0.04}
{'loss': 1.1642, 'grad_norm': 1.0399712450146108, 'learning_rate': 1.9993012593898146e-05, 'epoch': 0.04}
[2024-09-29 10:51:54,539] [WARNING] [stage3.py:2102:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 1.025, 'grad_norm': 0.6813040680656794, 'learning_rate': 1.9992539061939175e-05, 'epoch': 0.04}
{'loss': 1.1589, 'grad_norm': 0.8294737630185115, 'learning_rate': 1.9992050012190845e-05, 'epoch': 0.04}
{'loss': 1.1406, 'grad_norm': 0.7742802688441371, 'learning_rate': 1.9991545445412614e-05, 'epoch': 0.04}
{'loss': 1.0999, 'grad_norm': 0.7203363163697513, 'learning_rate': 1.9991025362388044e-05, 'epoch': 0.05}
{'loss': 1.055, 'grad_norm': 0.8791329725092238, 'learning_rate': 1.9990489763924796e-05, 'epoch': 0.05}
{'loss': 1.1264, 'grad_norm': 0.9010867919870005, 'learning_rate': 1.9989938650854618e-05, 'epoch': 0.05}
{'loss': 1.1606, 'grad_norm': 0.8701067197994433, 'learning_rate': 1.9989372024033352e-05, 'epoch': 0.05}
{'loss': 1.1499, 'grad_norm': 1.0170271777298225, 'learning_rate': 1.9988789884340938e-05, 'epoch': 0.05}
{'loss': 1.0828, 'grad_norm': 0.9337632879669121, 'learning_rate': 1.9988192232681398e-05, 'epoch': 0.05}
{'loss': 1.1152, 'grad_norm': 1.0182939669775424, 'learning_rate': 1.9987579069982856e-05, 'epoch': 0.05}
{'loss': 1.0958, 'grad_norm': 1.3794981266500683, 'learning_rate': 1.9986950397197503e-05, 'epoch': 0.05}
{'loss': 1.1577, 'grad_norm': 0.8367160373661572, 'learning_rate': 1.998630621530164e-05, 'epoch': 0.05}
{'loss': 1.1615, 'grad_norm': 0.8237467350530235, 'learning_rate': 1.9985646525295634e-05, 'epoch': 0.05}
{'loss': 1.124, 'grad_norm': 0.8114990384263512, 'learning_rate': 1.9984971328203945e-05, 'epoch': 0.05}
{'loss': 1.1305, 'grad_norm': 1.0732575956793995, 'learning_rate': 1.9984280625075115e-05, 'epoch': 0.05}
{'loss': 1.1084, 'grad_norm': 0.76946406179752, 'learning_rate': 1.998357441698176e-05, 'epoch': 0.05}
{'loss': 1.1036, 'grad_norm': 0.7946457009217975, 'learning_rate': 1.9982852705020572e-05, 'epoch': 0.05}
{'loss': 1.0732, 'grad_norm': 0.8110751785640041, 'learning_rate': 1.9982115490312334e-05, 'epoch': 0.05}
{'loss': 1.1396, 'grad_norm': 0.9409847422041133, 'learning_rate': 1.9981362774001886e-05, 'epoch': 0.05}
{'loss': 1.0608, 'grad_norm': 0.6664986524480616, 'learning_rate': 1.9980594557258158e-05, 'epoch': 0.05}
{'loss': 1.1565, 'grad_norm': 0.8059141938322925, 'learning_rate': 1.9979810841274135e-05, 'epoch': 0.05}
{'loss': 1.1151, 'grad_norm': 0.8507930718449693, 'learning_rate': 1.9979011627266884e-05, 'epoch': 0.05}
{'loss': 1.1671, 'grad_norm': 1.2955399374408028, 'learning_rate': 1.997819691647753e-05, 'epoch': 0.05}
{'loss': 1.1283, 'grad_norm': 0.7435328579097426, 'learning_rate': 1.9977366710171274e-05, 'epoch': 0.05}
{'loss': 1.1206, 'grad_norm': 0.8550140876003057, 'learning_rate': 1.9976521009637366e-05, 'epoch': 0.05}
{'loss': 1.1539, 'grad_norm': 1.302847790103462, 'learning_rate': 1.9975659816189137e-05, 'epoch': 0.05}
{'loss': 1.0551, 'grad_norm': 0.6189701406434679, 'learning_rate': 1.9974783131163957e-05, 'epoch': 0.05}
{'loss': 1.0987, 'grad_norm': 0.6946483723589896, 'learning_rate': 1.997389095592327e-05, 'epoch': 0.05}
{'loss': 1.0864, 'grad_norm': 1.2862684132105466, 'learning_rate': 1.9972983291852565e-05, 'epoch': 0.05}
{'loss': 1.1446, 'grad_norm': 0.8426358929115972, 'learning_rate': 1.9972060140361384e-05, 'epoch': 0.06}
{'loss': 1.073, 'grad_norm': 0.6563037212992007, 'learning_rate': 1.9971121502883332e-05, 'epoch': 0.06}
{'loss': 1.1623, 'grad_norm': 0.8325113318200621, 'learning_rate': 1.997016738087605e-05, 'epoch': 0.06}
{'loss': 1.1159, 'grad_norm': 1.034815338197381, 'learning_rate': 1.9969197775821227e-05, 'epoch': 0.06}
{'loss': 1.1052, 'grad_norm': 0.9887177655925012, 'learning_rate': 1.9968212689224603e-05, 'epoch': 0.06}
{'loss': 1.1354, 'grad_norm': 0.917844793357237, 'learning_rate': 1.9967212122615958e-05, 'epoch': 0.06}
{'loss': 1.1075, 'grad_norm': 1.178411776189521, 'learning_rate': 1.9966196077549106e-05, 'epoch': 0.06}
{'loss': 1.1547, 'grad_norm': 0.8962351422596587, 'learning_rate': 1.99651645556019e-05, 'epoch': 0.06}
{'loss': 1.0724, 'grad_norm': 0.7059738175371578, 'learning_rate': 1.996411755837623e-05, 'epoch': 0.06}
{'loss': 1.1269, 'grad_norm': 0.732483183756749, 'learning_rate': 1.996305508749802e-05, 'epoch': 0.06}
{'loss': 1.1136, 'grad_norm': 0.8444025465309594, 'learning_rate': 1.9961977144617225e-05, 'epoch': 0.06}
{'loss': 1.1356, 'grad_norm': 0.7983599976024582, 'learning_rate': 1.996088373140781e-05, 'epoch': 0.06}
{'loss': 1.1986, 'grad_norm': 1.0820116818720944, 'learning_rate': 1.995977484956779e-05, 'epoch': 0.06}
{'loss': 1.1648, 'grad_norm': 0.8238906410126323, 'learning_rate': 1.9958650500819183e-05, 'epoch': 0.06}
{'loss': 1.0806, 'grad_norm': 0.7453641577002988, 'learning_rate': 1.9957510686908034e-05, 'epoch': 0.06}
{'loss': 1.0614, 'grad_norm': 0.745258250794238, 'learning_rate': 1.9956355409604402e-05, 'epoch': 0.06}
{'loss': 1.1155, 'grad_norm': 0.8107190195630929, 'learning_rate': 1.9955184670702363e-05, 'epoch': 0.06}
{'loss': 1.0961, 'grad_norm': 0.7511085996141929, 'learning_rate': 1.9953998472019996e-05, 'epoch': 0.06}
{'loss': 1.1187, 'grad_norm': 0.8502964474688878, 'learning_rate': 1.9952796815399403e-05, 'epoch': 0.06}
{'loss': 1.0743, 'grad_norm': 0.6297513650229071, 'learning_rate': 1.9951579702706668e-05, 'epoch': 0.06}
{'loss': 1.0637, 'grad_norm': 0.7226606042290785, 'learning_rate': 1.9950347135831907e-05, 'epoch': 0.06}
{'loss': 1.0973, 'grad_norm': 0.694313053237523, 'learning_rate': 1.994909911668921e-05, 'epoch': 0.06}
{'loss': 1.1656, 'grad_norm': 0.8511428273480721, 'learning_rate': 1.994783564721667e-05, 'epoch': 0.06}
{'loss': 1.1318, 'grad_norm': 0.8737111749546125, 'learning_rate': 1.994655672937638e-05, 'epoch': 0.06}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/689852649.jpg, using default black image.
{'loss': 1.0889, 'grad_norm': 0.7370938282138371, 'learning_rate': 1.994526236515442e-05, 'epoch': 0.06}
{'loss': 1.1274, 'grad_norm': 0.7530988155968226, 'learning_rate': 1.9943952556560863e-05, 'epoch': 0.06}
{'loss': 1.0627, 'grad_norm': 0.7343236805038299, 'learning_rate': 1.9942627305629747e-05, 'epoch': 0.07}
{'loss': 1.1544, 'grad_norm': 1.1307111260394889, 'learning_rate': 1.9941286614419113e-05, 'epoch': 0.07}
{'loss': 1.1311, 'grad_norm': 0.8815714185654165, 'learning_rate': 1.9939930485010968e-05, 'epoch': 0.07}
{'loss': 1.073, 'grad_norm': 1.1831539244032563, 'learning_rate': 1.99385589195113e-05, 'epoch': 0.07}
{'loss': 1.122, 'grad_norm': 0.8408024116758853, 'learning_rate': 1.9937171920050057e-05, 'epoch': 0.07}
{'loss': 1.0816, 'grad_norm': 0.7198520227918059, 'learning_rate': 1.9935769488781167e-05, 'epoch': 0.07}
{'loss': 1.0894, 'grad_norm': 0.7442511340605552, 'learning_rate': 1.993435162788252e-05, 'epoch': 0.07}
{'loss': 1.0954, 'grad_norm': 0.6818308863893933, 'learning_rate': 1.9932918339555965e-05, 'epoch': 0.07}
{'loss': 1.0282, 'grad_norm': 0.5841991379766391, 'learning_rate': 1.9931469626027305e-05, 'epoch': 0.07}
{'loss': 1.1462, 'grad_norm': 0.739835712294903, 'learning_rate': 1.9930005489546308e-05, 'epoch': 0.07}
{'loss': 1.0918, 'grad_norm': 0.7971409439289936, 'learning_rate': 1.9928525932386678e-05, 'epoch': 0.07}
{'loss': 1.1069, 'grad_norm': 0.7497780379103866, 'learning_rate': 1.9927030956846083e-05, 'epoch': 0.07}
{'loss': 1.1357, 'grad_norm': 0.9816120263597556, 'learning_rate': 1.9925520565246125e-05, 'epoch': 0.07}
{'loss': 1.1539, 'grad_norm': 0.7412294335524454, 'learning_rate': 1.9923994759932344e-05, 'epoch': 0.07}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/1848094388.jpg, using default black image.
{'loss': 1.1098, 'grad_norm': 0.7157218887553107, 'learning_rate': 1.9922453543274223e-05, 'epoch': 0.07}
{'loss': 1.1172, 'grad_norm': 0.9752342870972952, 'learning_rate': 1.9920896917665178e-05, 'epoch': 0.07}
{'loss': 1.1231, 'grad_norm': 0.8302225483543563, 'learning_rate': 1.9919324885522548e-05, 'epoch': 0.07}
WARNING: tokenization mismatch: 0 vs. 634. (ignored)
number of rounds:  1
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a cutting-edge copywriting agency with the following knowledge and traits.\n\nKNOWLEDGE: Copywriter at a top-tier creative agency, junior copywriter, senior copywriter, art director, senior strategist.\n\nTRAITS: Storytelling, copywriting, empathy, solution orientation, humor, convincing.\n\nTASK: Use your knowledge to write a LinkedIn Post. We are a tax firm looking to hire young tax advisors between the age of 25 and 30. Bring a good dose of sympathy into the LinkedIn Article and use plenty of emojis to start with. Start the Linked In post with an exciting question. Use the language of the target group. Dont mention the targeted age. \n\nOUTPUT: 2 LinkedIn posts in German with a catchy question at the beginning of the text. Hashtags at the end of the text. ASSISTANT: Post 1:\n\n Hey, ihr Steuerprofis da drauen! \n\nHabt ihr Bock, Teil einer jungen, dynamischen Steuerberatungskanzlei zu werden? \n\nWir suchen motivierte Kpfe, die unser Team verstrken und sich mit uns zusammen weiterentwickeln wollen! \n\nIhr seid auf der Suche nach einem Arbeitsplatz mit coolen Kollegen und spannenden Aufgaben?  Dann seid ihr bei uns genau richtig! \n\n#Steuerberatung #Karriere #Traumjob #Team #Weiterentwicklung #Jobangebot\n\nPost 2:\n\n Hallo ihr Steuerexperten! \n\nIhr seid jung, motiviert und habt Bock auf eine neue Herausforderung? \n\nDann seid ihr bei uns genau richtig! Wir sind auf der Suche nach Steuerberatern, die unser Team mit frischen Ideen und kreativen Lsungen bereichern! \n\nEuch erwartet ein Arbeitsplatz in einem dynamischen Umfeld mit spannenden Aufgaben und netten Kollegen! \n\nInteressiert? Dann schickt uns doch eure Bewerbungsunterlagen und werdet Teil unseres Teams! \n\n#Jobangebot #Steuerberatung #Karriere #Traumjob #Team #Weiterentwicklung"]
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a cutting-edge copywriting agency with the following knowledge and traits.

KNOWLEDGE: Copywriter at a top-tier creative agency, junior copywriter, senior copywriter, art director, senior strategist.

TRAITS: Storytelling, copywriting, empathy, solution orientation, humor, convincing.

TASK: Use your knowledge to write a LinkedIn Post. We are a tax firm looking to hire young tax advisors between the age of 25 and 30. Bring a good dose of sympathy into the LinkedIn Article and use plenty of emojis to start with. Start the Linked In post with an exciting question. Use the language of the target group. Dont mention the targeted age. 

OUTPUT: 2 LinkedIn posts in German with a catchy question at the beginning of the text. Hashtags at the end of the text. ASSISTANT: Post 1:

 Hey, ihr Steuerprofis da drauen! 

Habt ihr Bock, Teil einer jungen, dynamischen Steuerberatungskanzlei zu werden? 

Wir suchen motivierte Kpfe, die unser Team verstrken und sich mit uns zusammen weiterentwickeln wollen! 

Ihr seid auf der Suche nach einem Arbeitsplatz mit coolen Kollegen und spannenden Aufgaben?  Dann seid ihr bei uns genau richtig! 

#Steuerberatung #Karriere #Traumjob #Team #Weiterentwicklung #Jobangebot

Post 2:

 Hallo ihr Steuerexperten! 

Ihr seid jung, motiviert und habt Bock auf eine neue Herausforderung? 

Dann seid ihr bei uns genau richtig! Wir sind auf der Suche nach Steuerberatern, die unser Team mit frischen Ideen und kreativen Lsungen bereichern! 

Euch erwartet ein Arbeitsplatz in einem dynamischen Umfeld mit spannenden Aufgaben und netten Kollegen! 

Interessiert? Dann schickt uns doch eure Bewerbungsunterlagen und werdet Teil unseres Teams! 

#Jobangebot #Steuerberatung #Karriere #Traumjob #Team #Weiterentwicklung<|endoftext|>
tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])
tensor([   32,  8537,  1022,   257, 11040,  2836,   290,   281, 11666,  4430,
         8796,    13,   383,  8796,  3607,  7613,    11,  6496,    11,   290,
        23507,  7429,   284,   262,  2836,   338,  2683,    13,  1294,  1137,
           25, 24994,  8808,  8643,    25,   921,   389,   257,  7720,    12,
        14907,  4866, 16502,  4086,   351,   262,  1708,  3725,   290, 12796,
           13,   198,   198, 29132,  3913, 30465,  8264,    25, 17393, 16002,
          379,   257,  1353,    12, 24948,  7325,  4086,    11, 13430,  4866,
        16002,    11,  4664,  4866, 16002,    11,  1242,  3437,    11,  4664,
        25651,    13,   198,   198,    51,  3861, 29722,    25,  8362, 18072,
           11,  4866, 16502,    11, 21452,    11,  4610, 12852,    11, 14733,
           11, 17101,    13,   198,   198,    51,  1921,    42,    25,  5765,
          534,  3725,   284,  3551,   257, 27133,  2947,    13,   775,   389,
          257,  1687,  4081,  2045,   284, 11078,  1862,  1687, 32456,  1022,
          262,  2479,   286,  1679,   290,  1542,    13, 24347,   257,   922,
        10742,   286, 20242,   656,   262, 27133, 10172,   290,   779,  6088,
          286,   795, 13210,   271,   284,   923,   351,    13,  7253,   262,
         7502,   276,   554,  1281,   351,   281,  7895,  1808,    13,  5765,
          262,  3303,   286,   262,  2496,  1448,    13,  2094, 18265,    83,
         3068,   262,  7977,  2479,    13,   220,   198,   198,  2606,  7250,
         3843,    25,   362, 27133,  6851,   287,  2679,   351,   257, 46124,
         1808,   379,   262,  3726,   286,   262,  2420,    13, 21059, 31499,
          379,   262,   886,   286,   262,  2420,    13, 24994,  8808,  8643,
           25,  2947,   352,    25,   198,   198, 41840,   233, 14690,    11,
         1312, 11840,  2441, 15573,  5577,   271, 12379, 28841,    84, 39683,
          268,     0, 12520,    97,   241,   198,   198,    39,   397,    83,
         1312, 11840,   347,   735,    11,  1665,   346,   304,  7274, 34799,
          268,    11,  6382,  2304,   831,  2441, 15573,   527,   265,  2150,
         8135, 35410,   293,    72,  1976,    84,   266,   263,  6559,    30,
        12520,   248,   222,   198,   198,    54,   343,  6522,   831,  6556,
          959,   660,   509,  9101,    79,  5036,    11,  4656,   555,  2655,
         4816,  3326,   301, 11033,    81,  3464,  3318,   264,   488, 10255,
         5576,  1976,   385,   321,  3653,   356,   270,  9100, 22664,  7750,
           77,   266, 29952,     0, 12520,   240,    94,   198,   198,    40,
        11840,   384,   312,   257,  3046,  4587, 47352,   258,   299,   620,
          304,  7749,   943,  1350,   896,   489, 27906, 10255,  3608,   268,
        25910,  1455,   268,  3318,   599,  1236,   437,   268,   317,  3046,
           70,   397,   268,    30, 12520,    97,   251,   360,  1236,   384,
          312,  1312, 11840,   307,    72,  5576,  2429,   559,  5527,    83,
          328,     0, 30325,   236,   198,   198,     2,  7447, 15573,   527,
          265,  2150,  1303, 37753,   380,   567,  1303, 15721,   388, 21858,
         1303, 15592,  1303,  1135,   270,  9100, 16239,    75,  2150,  1303,
        33308,   858, 13645,   198,   198,  6307,   362,    25,   198,   198,
        41840,   233,  4789,    78,  1312, 11840,  2441,   518, 21510,   525,
         1452,     0, 12520,    97,   241,   198,   198,    40, 11840,   384,
          312, 34799,    11,  6556,    72,   861,  3318,   387, 18347,   347,
          735,   257,  3046,   304,   500,   497,   518,  2332,  8717,    69,
         2875,  2150,    30, 12520,   248,   222,   198,   198,    35,  1236,
          384,   312,  1312, 11840,   307,    72,  5576,  2429,   559,  5527,
           83,   328,     0,   370,   343,   264,   521,   257,  3046,  4587,
        47352,   258,   299,   620,  2441, 15573,   527,  9205,    11,  4656,
          555,  2655,  4816, 10255,  1216,  2304,   831, 16714,   268,  3318,
          479,   630,  1469,   406,  9101,  9854,   268, 45303,   291,  2881,
            0, 12520,   240,    94,   198,   198,    36,   794,  1931, 24657,
          316,   304,   259,   943,  1350,   896,   489, 27906,   287,   304,
         7749,  6382,  2304,   831, 21039, 16265, 10255,   599,  1236,   437,
          268,   317,  3046,    70,   397,   268,  3318,  2010,  1452, 25910,
         1455,   268,     0, 12520,    97,   251,   198,   198,  5317,    68,
          601,    72,   861,    30,   360,  1236,  5513,   624,    83,  5576,
          466,   354,   304,   495,   347,   413, 23552,  2150, 19155,   353,
           75, 11286,  3318,   266,   263, 15255,  1665,   346, 38478,   411,
        24690,     0, 30325,   236,   198,   198,     2, 33308,   858, 13645,
         1303,  7447, 15573,   527,   265,  2150,  1303, 37753,   380,   567,
         1303, 15721,   388, 21858,  1303, 15592,  1303,  1135,   270,  9100,
        16239,    75,  2150, 50256])
{'loss': 1.0311, 'grad_norm': 1.0208694646365413, 'learning_rate': 1.99177374492876e-05, 'epoch': 0.07}
{'loss': 1.1503, 'grad_norm': 0.8044441953998831, 'learning_rate': 1.9916134611425522e-05, 'epoch': 0.07}
{'loss': 1.1011, 'grad_norm': 0.7059301010620765, 'learning_rate': 1.991451637442543e-05, 'epoch': 0.07}
{'loss': 1.0816, 'grad_norm': 0.8221211787002897, 'learning_rate': 1.9912882740800336e-05, 'epoch': 0.07}
{'loss': 1.0559, 'grad_norm': 0.7834456764064142, 'learning_rate': 1.9911233713087172e-05, 'epoch': 0.07}
{'loss': 1.0892, 'grad_norm': 0.7028601151398524, 'learning_rate': 1.990956929384678e-05, 'epoch': 0.07}
{'loss': 1.1206, 'grad_norm': 0.7708511819133175, 'learning_rate': 1.9907889485663897e-05, 'epoch': 0.07}
{'loss': 1.1053, 'grad_norm': 0.881163336471337, 'learning_rate': 1.9906194291147155e-05, 'epoch': 0.07}
{'loss': 1.0596, 'grad_norm': 1.10403986348602, 'learning_rate': 1.9904483712929094e-05, 'epoch': 0.07}
{'loss': 1.1213, 'grad_norm': 0.8487782438312305, 'learning_rate': 1.990275775366613e-05, 'epoch': 0.08}
{'loss': 1.1116, 'grad_norm': 0.9252778988880065, 'learning_rate': 1.990101641603857e-05, 'epoch': 0.08}
{'loss': 1.1409, 'grad_norm': 0.8322562797352064, 'learning_rate': 1.9899259702750604e-05, 'epoch': 0.08}
{'loss': 1.0361, 'grad_norm': 0.6330977561088555, 'learning_rate': 1.9897487616530296e-05, 'epoch': 0.08}
{'loss': 1.0913, 'grad_norm': 0.8244168708105503, 'learning_rate': 1.9895700160129593e-05, 'epoch': 0.08}
{'loss': 1.11, 'grad_norm': 0.7734820284284006, 'learning_rate': 1.9893897336324292e-05, 'epoch': 0.08}
{'loss': 1.1091, 'grad_norm': 0.7555625060822526, 'learning_rate': 1.9892079147914072e-05, 'epoch': 0.08}
{'loss': 1.0849, 'grad_norm': 0.7807005707909944, 'learning_rate': 1.9890245597722465e-05, 'epoch': 0.08}
{'loss': 1.0904, 'grad_norm': 0.8188293946419887, 'learning_rate': 1.988839668859686e-05, 'epoch': 0.08}
{'loss': 1.1113, 'grad_norm': 0.796504526208317, 'learning_rate': 1.9886532423408495e-05, 'epoch': 0.08}
{'loss': 1.0936, 'grad_norm': 0.8966658555429223, 'learning_rate': 1.9884652805052465e-05, 'epoch': 0.08}
{'loss': 1.1124, 'grad_norm': 0.83323559703552, 'learning_rate': 1.988275783644769e-05, 'epoch': 0.08}
{'loss': 1.0838, 'grad_norm': 0.8176029335199703, 'learning_rate': 1.988084752053695e-05, 'epoch': 0.08}
{'loss': 1.1038, 'grad_norm': 0.8486429751272434, 'learning_rate': 1.9878921860286832e-05, 'epoch': 0.08}
{'loss': 1.0646, 'grad_norm': 1.0058870318715698, 'learning_rate': 1.9876980858687777e-05, 'epoch': 0.08}
{'loss': 1.086, 'grad_norm': 0.7542461432002412, 'learning_rate': 1.987502451875403e-05, 'epoch': 0.08}
{'loss': 1.0253, 'grad_norm': 0.8797728298251637, 'learning_rate': 1.9873052843523676e-05, 'epoch': 0.08}
{'loss': 1.1573, 'grad_norm': 0.806501713947676, 'learning_rate': 1.98710658360586e-05, 'epoch': 0.08}
{'loss': 1.0705, 'grad_norm': 0.7963044767856686, 'learning_rate': 1.9869063499444495e-05, 'epoch': 0.08}
{'loss': 1.1037, 'grad_norm': 0.9665440061208103, 'learning_rate': 1.9867045836790867e-05, 'epoch': 0.08}
{'loss': 1.1388, 'grad_norm': 1.1845196113237617, 'learning_rate': 1.9865012851231022e-05, 'epoch': 0.08}
{'loss': 1.1213, 'grad_norm': 0.8930705242333112, 'learning_rate': 1.986296454592206e-05, 'epoch': 0.08}
{'loss': 1.1008, 'grad_norm': 0.8657455462400904, 'learning_rate': 1.9860900924044873e-05, 'epoch': 0.08}
{'loss': 1.1004, 'grad_norm': 0.860019407171008, 'learning_rate': 1.9858821988804132e-05, 'epoch': 0.08}
{'loss': 1.1066, 'grad_norm': 0.8400634662366953, 'learning_rate': 1.98567277434283e-05, 'epoch': 0.08}
{'loss': 1.1316, 'grad_norm': 0.7908554778713497, 'learning_rate': 1.98546181911696e-05, 'epoch': 0.08}
{'loss': 1.1234, 'grad_norm': 0.7522963864802967, 'learning_rate': 1.985249333530404e-05, 'epoch': 0.09}
{'loss': 1.0813, 'grad_norm': 0.7732305246179221, 'learning_rate': 1.9850353179131392e-05, 'epoch': 0.09}
{'loss': 1.142, 'grad_norm': 0.7530932185701008, 'learning_rate': 1.984819772597518e-05, 'epoch': 0.09}
{'loss': 1.0814, 'grad_norm': 0.8160704597345371, 'learning_rate': 1.984602697918269e-05, 'epoch': 0.09}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/446605794.jpg, using default black image.
{'loss': 1.1079, 'grad_norm': 0.8872593314622155, 'learning_rate': 1.9843840942124956e-05, 'epoch': 0.09}
{'loss': 1.1231, 'grad_norm': 0.7991722197572618, 'learning_rate': 1.984163961819676e-05, 'epoch': 0.09}
{'loss': 1.0657, 'grad_norm': 0.6328784942829293, 'learning_rate': 1.9839423010816616e-05, 'epoch': 0.09}
{'loss': 1.0311, 'grad_norm': 0.7990974766300654, 'learning_rate': 1.9837191123426777e-05, 'epoch': 0.09}
{'loss': 1.1182, 'grad_norm': 0.7586655342793619, 'learning_rate': 1.983494395949323e-05, 'epoch': 0.09}
{'loss': 1.1063, 'grad_norm': 0.7225031010587031, 'learning_rate': 1.9832681522505676e-05, 'epoch': 0.09}
{'loss': 1.1033, 'grad_norm': 0.7171083420860583, 'learning_rate': 1.983040381597754e-05, 'epoch': 0.09}
{'loss': 1.1056, 'grad_norm': 0.7768975313494911, 'learning_rate': 1.9828110843445954e-05, 'epoch': 0.09}
{'loss': 1.0701, 'grad_norm': 0.7441306404625339, 'learning_rate': 1.9825802608471767e-05, 'epoch': 0.09}
{'loss': 1.0925, 'grad_norm': 0.7313006660134455, 'learning_rate': 1.982347911463952e-05, 'epoch': 0.09}
{'loss': 1.114, 'grad_norm': 0.9308880635118574, 'learning_rate': 1.982114036555746e-05, 'epoch': 0.09}
{'loss': 1.1029, 'grad_norm': 0.7030538450383524, 'learning_rate': 1.9818786364857506e-05, 'epoch': 0.09}
{'loss': 1.1027, 'grad_norm': 0.9511358530366596, 'learning_rate': 1.9816417116195287e-05, 'epoch': 0.09}
{'loss': 1.0802, 'grad_norm': 0.8390389283327452, 'learning_rate': 1.9814032623250093e-05, 'epoch': 0.09}
{'loss': 1.0723, 'grad_norm': 0.6952194359925513, 'learning_rate': 1.9811632889724888e-05, 'epoch': 0.09}
{'loss': 1.0501, 'grad_norm': 0.7499472481534596, 'learning_rate': 1.9809217919346318e-05, 'epoch': 0.09}
{'loss': 1.0449, 'grad_norm': 0.8855587609955647, 'learning_rate': 1.9806787715864674e-05, 'epoch': 0.09}
{'loss': 1.0897, 'grad_norm': 0.7567325328844758, 'learning_rate': 1.9804342283053916e-05, 'epoch': 0.09}
{'loss': 1.0948, 'grad_norm': 0.8796474096959896, 'learning_rate': 1.980188162471164e-05, 'epoch': 0.09}
{'loss': 1.1309, 'grad_norm': 1.0274841499640996, 'learning_rate': 1.97994057446591e-05, 'epoch': 0.09}
{'loss': 1.0921, 'grad_norm': 0.6930548886132913, 'learning_rate': 1.9796914646741187e-05, 'epoch': 0.09}
{'loss': 1.1009, 'grad_norm': 0.7561978297509842, 'learning_rate': 1.9794408334826415e-05, 'epoch': 0.09}
{'loss': 1.0833, 'grad_norm': 0.7979096811067921, 'learning_rate': 1.9791886812806932e-05, 'epoch': 0.1}
{'loss': 1.1099, 'grad_norm': 0.6976409282006543, 'learning_rate': 1.9789350084598504e-05, 'epoch': 0.1}
{'loss': 1.0787, 'grad_norm': 0.7949958422889325, 'learning_rate': 1.9786798154140507e-05, 'epoch': 0.1}
{'loss': 1.0935, 'grad_norm': 0.683681341613188, 'learning_rate': 1.9784231025395936e-05, 'epoch': 0.1}
{'loss': 1.145, 'grad_norm': 1.0259235003833402, 'learning_rate': 1.9781648702351383e-05, 'epoch': 0.1}
{'loss': 1.0957, 'grad_norm': 0.7390389434012941, 'learning_rate': 1.977905118901703e-05, 'epoch': 0.1}
{'loss': 1.0425, 'grad_norm': 0.7511110888168064, 'learning_rate': 1.977643848942665e-05, 'epoch': 0.1}
{'loss': 1.0661, 'grad_norm': 0.8135572461224176, 'learning_rate': 1.9773810607637612e-05, 'epoch': 0.1}
{'loss': 1.073, 'grad_norm': 0.8902087898571732, 'learning_rate': 1.9771167547730844e-05, 'epoch': 0.1}
{'loss': 1.1392, 'grad_norm': 0.9411861111136541, 'learning_rate': 1.976850931381086e-05, 'epoch': 0.1}
{'loss': 1.1015, 'grad_norm': 0.9009020512278415, 'learning_rate': 1.9765835910005726e-05, 'epoch': 0.1}
{'loss': 1.0935, 'grad_norm': 0.7184037713550764, 'learning_rate': 1.9763147340467067e-05, 'epoch': 0.1}
{'loss': 1.1115, 'grad_norm': 0.9472525868440689, 'learning_rate': 1.9760443609370074e-05, 'epoch': 0.1}
{'loss': 1.0075, 'grad_norm': 0.6196129167703973, 'learning_rate': 1.9757724720913466e-05, 'epoch': 0.1}
{'loss': 1.0536, 'grad_norm': 0.7643023828048607, 'learning_rate': 1.975499067931951e-05, 'epoch': 0.1}
{'loss': 1.0246, 'grad_norm': 0.6684088960867153, 'learning_rate': 1.9752241488834002e-05, 'epoch': 0.1}
{'loss': 1.0553, 'grad_norm': 0.7410639936341947, 'learning_rate': 1.974947715372626e-05, 'epoch': 0.1}
{'loss': 1.0924, 'grad_norm': 0.8328898325315277, 'learning_rate': 1.9746697678289128e-05, 'epoch': 0.1}
{'loss': 1.052, 'grad_norm': 0.7482797325946193, 'learning_rate': 1.9743903066838954e-05, 'epoch': 0.1}
{'loss': 1.0996, 'grad_norm': 0.9548786000789317, 'learning_rate': 1.9741093323715597e-05, 'epoch': 0.1}
{'loss': 1.0975, 'grad_norm': 0.9059277856518027, 'learning_rate': 1.9738268453282414e-05, 'epoch': 0.1}
{'loss': 1.0743, 'grad_norm': 0.8720022255505309, 'learning_rate': 1.973542845992625e-05, 'epoch': 0.1}
{'loss': 1.0824, 'grad_norm': 0.7680278521847306, 'learning_rate': 1.9732573348057437e-05, 'epoch': 0.1}
{'loss': 1.1034, 'grad_norm': 0.6909649616503132, 'learning_rate': 1.9729703122109788e-05, 'epoch': 0.1}
{'loss': 1.081, 'grad_norm': 0.7724488745719673, 'learning_rate': 1.9726817786540584e-05, 'epoch': 0.1}
{'loss': 1.0505, 'grad_norm': 0.7879046365069943, 'learning_rate': 1.9723917345830568e-05, 'epoch': 0.1}
{'loss': 1.1062, 'grad_norm': 0.7738580757917669, 'learning_rate': 1.9721001804483947e-05, 'epoch': 0.11}
{'loss': 1.1151, 'grad_norm': 0.727644019047147, 'learning_rate': 1.9718071167028376e-05, 'epoch': 0.11}
WARNING: tokenization mismatch: 0 vs. 1848. (ignored)
number of rounds:  3
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a cutting-edge copywriting agency with the following knowledge and traits.\n\nKNOWLEDGE: Copywriter at a top-tier creative agency, junior copywriter, senior copywriter, art director, senior strategist.\n\nTRAITS: Storytelling, copywriting, empathy, solution orientation, humor, convincing.\n\nTASK: Use your knowledge to write a LinkedIn Post. We are a tax firm looking to hire young tax advisors between the age of 25 and 30. Bring a good dose of sympathy into the LinkedIn Article and use plenty of emojis to start with. Start the Linked In post with an exciting question. Use the language of the target group. Dont mention the targeted age. \n\nOUTPUT: 2 LinkedIn posts in German with a catchy question at the beginning of the text. Hashtags at the end of the text. ASSISTANT: Post 1:\n\n Hey Leute! Hast du krzlich dein Studium im Bereich Steuerwesen abgeschlossen und suchst jetzt nach einem Job, der dich fordert und frdert? \n\nDann bist du bei uns genau richtig! Wir suchen junge Steuerberater, die Lust haben, in einem dynamischen Team zu arbeiten und ihre Fhigkeiten unter Beweis zu stellen. \n\nBei uns erwarten dich spannende Projekte und ein tolles Arbeitsumfeld, in dem du dich weiterentwickeln und wachsen kannst. \n\nInteressiert? Dann bewirb dich jetzt und werde Teil unseres Teams! \n\n#Steuerberatung #Karriere #Job #Bewerbung #Teamwork\n\nPost 2:\n\n Hallo zusammen! Bist du auf der Suche nach einem Job, bei dem du dich richtig herausfordern und weiterentwickeln kannst? \n\nDann haben wir vielleicht das passende Angebot fr dich! Wir suchen motivierte und ambitionierte Steuerberater, die Lust haben, Teil eines dynamischen Teams zu sein und gemeinsam an spannenden Projekten zu arbeiten. \n\nBei uns erwartet dich nicht nur eine tolle Arbeitsatmosphre, sondern auch die Mglichkeit, dich fachlich und persnlich weiterzuentwickeln. \n\nAlso, worauf wartest du? Bewirb dich jetzt und starte deine Karriere bei uns! \n\n#Steuerberatung #Karriere #Job #Bewerbung #Teamwork", 'USER: Schreibe den Text spannender. ASSISTANT: Post 1:\n\n Hey Leute! Hast du krzlich dein Studium im Bereich Steuerwesen abgeschlossen und bist bereit fr die nchste Herausforderung? \n\nDann haben wir genau das Richtige fr dich! Wir suchen junge, ambitionierte Steuerberater, die Lust haben, ihre Karriere auf das nchste Level zu bringen. \n\nUnser Team arbeitet an den spannendsten Projekten und bietet ein Arbeitsumfeld, das dich tglich fordert und frdert. Bei uns kannst du deine Fhigkeiten unter Beweis stellen und dich persnlich und fachlich weiterentwickeln. \n\nDu mchtest Teil unseres Teams werden und an den neuesten Herausforderungen im Steuerwesen mitwirken? Dann zgere nicht und bewirb dich jetzt bei uns! \n\n#Steuerberatung #Karriere #Job #Bewerbung #Teamwork\n\nPost 2:\n\n Hallo zusammen! Bist du bereit fr eine neue Herausforderung in deiner Karriere als Steuerberater? \n\nDann bist du bei uns genau richtig! Wir suchen motivierte und talentierte Steuerberater, die Teil eines dynamischen Teams werden mchten. Wir arbeiten an den anspruchsvollsten Projekten und bieten ein Arbeitsumfeld, das dich tglich aufs Neue herausfordert. \n\nDu mchtest deine Fhigkeiten unter Beweis stellen und dich fachlich sowie persnlich weiterentwickeln? Dann bewirb dich jetzt bei uns und werde Teil unseres Erfolgsteams! \n\nVerpasse nicht die Chance, deine Karriere auf das nchste Level zu bringen und an den neuesten Trends und Entwicklungen im Steuerwesen mitzuwirken. Wir freuen uns auf deine Bewerbung! \n\n#Steuerberatung #Karriere #Job #Bewerbung #Teamwork', 'USER: Schreibe den Text objektiv und sachlich. ASSISTANT: Post 1:\n\nGuten Tag,\n\nWir sind auf der Suche nach jungen, talentierten Steuerberatern, die ihr Studium im Bereich Steuerwesen erfolgreich abgeschlossen haben. Die Position ist offen fr alle, die eine Leidenschaft fr das Steuerrecht haben und eine Karriere in diesem Bereich anstreben.\n\nAls Teil unseres Teams arbeiten Sie an verschiedenen Projekten und erweitern stetig Ihre Fhigkeiten und Kenntnisse. Wir bieten ein hervorragendes Arbeitsumfeld, das auf Zusammenarbeit und Teamwork basiert, um sicherzustellen, dass Sie Ihre Arbeit so effektiv wie mglich erledigen knnen.\n\nWenn Sie Interesse haben und Teil unseres Teams werden mchten, senden Sie uns bitte Ihre Bewerbung.\n\nVielen Dank.\n\nPost 2:\n\nGuten Tag,\n\nWir sind auf der Suche nach motivierten und talentierten Steuerberatern, die an einer Karriere in diesem Bereich interessiert sind. Als Teil unseres Teams arbeiten Sie an verschiedenen Projekten, um Ihre Fhigkeiten und Kenntnisse zu erweitern.\n\nWir bieten ein hervorragendes Arbeitsumfeld, das auf Zusammenarbeit und Teamwork basiert, um sicherzustellen, dass Sie Ihre Arbeit so effektiv wie mglich erledigen knnen. Wenn Sie bereit sind, sich dieser Herausforderung zu stellen und Ihre Karriere auf das nchste Level zu bringen, dann senden Sie uns bitte Ihre Bewerbung.\n\nVielen Dank.']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a cutting-edge copywriting agency with the following knowledge and traits.

KNOWLEDGE: Copywriter at a top-tier creative agency, junior copywriter, senior copywriter, art director, senior strategist.

TRAITS: Storytelling, copywriting, empathy, solution orientation, humor, convincing.

TASK: Use your knowledge to write a LinkedIn Post. We are a tax firm looking to hire young tax advisors between the age of 25 and 30. Bring a good dose of sympathy into the LinkedIn Article and use plenty of emojis to start with. Start the Linked In post with an exciting question. Use the language of the target group. Dont mention the targeted age. 

OUTPUT: 2 LinkedIn posts in German with a catchy question at the beginning of the text. Hashtags at the end of the text. ASSISTANT: Post 1:

 Hey Leute! Hast du krzlich dein Studium im Bereich Steuerwesen abgeschlossen und suchst jetzt nach einem Job, der dich fordert und frdert? 

Dann bist du bei uns genau richtig! Wir suchen junge Steuerberater, die Lust haben, in einem dynamischen Team zu arbeiten und ihre Fhigkeiten unter Beweis zu stellen. 

Bei uns erwarten dich spannende Projekte und ein tolles Arbeitsumfeld, in dem du dich weiterentwickeln und wachsen kannst. 

Interessiert? Dann bewirb dich jetzt und werde Teil unseres Teams! 

#Steuerberatung #Karriere #Job #Bewerbung #Teamwork

Post 2:

 Hallo zusammen! Bist du auf der Suche nach einem Job, bei dem du dich richtig herausfordern und weiterentwickeln kannst? 

Dann haben wir vielleicht das passende Angebot fr dich! Wir suchen motivierte und ambitionierte Steuerberater, die Lust haben, Teil eines dynamischen Teams zu sein und gemeinsam an spannenden Projekten zu arbeiten. 

Bei uns erwartet dich nicht nur eine tolle Arbeitsatmosphre, sondern auch die Mglichkeit, dich fachlich und persnlich weiterzuentwickeln. 

Also, worauf wartest du? Bewirb dich jetzt und starte deine Karriere bei uns! 

#Steuerberatung #Karriere #Job #Bewerbung #Teamwork<|endoftext|>USER: Schreibe den Text spannender. ASSISTANT: Post 1:

 Hey Leute! Hast du krzlich dein Studium im Bereich Steuerwesen abgeschlossen und bist bereit fr die nchste Herausforderung? 

Dann haben wir genau das Richtige fr dich! Wir suchen junge, ambitionierte Steuerberater, die Lust haben, ihre Karriere auf das nchste Level zu bringen. 

Unser Team arbeitet an den spannendsten Projekten und bietet ein Arbeitsumfeld, das dich tglich fordert und frdert. Bei uns kannst du deine Fhigkeiten unter Beweis stellen und dich persnlich und fachlich weiterentwickeln. 

Du mchtest Teil unseres Teams werden und an den neuesten Herausforderungen im Steuerwesen mitwirken? Dann zgere nicht und bewirb dich jetzt bei uns! 

#Steuerberatung #Karriere #Job #Bewerbung #Teamwork

Post 2:

 Hallo zusammen! Bist du bereit fr eine neue Herausforderung in deiner Karriere als Steuerberater? 

Dann bist du bei uns genau richtig! Wir suchen motivierte und talentierte Steuerberater, die Teil eines dynamischen Teams werden mchten. Wir arbeiten an den anspruchsvollsten Projekten und bieten ein Arbeitsumfeld, das dich tglich aufs Neue herausfordert. 

Du mchtest deine Fhigkeiten unter Beweis stellen und dich fachlich sowie persnlich weiterentwickeln? Dann bewirb dich jetzt bei uns und werde Teil unseres Erfolgsteams! 

Verpasse nicht die Chance, deine Karriere auf das nchste Level zu bringen und an den neuesten Trends und Entwicklungen im Steuerwesen mitzuwirken. Wir freuen uns auf deine Bewerbung! 

#Steuerberatung #Karriere #Job #Bewerbung #Teamwork<|endoftext|>USER: Schreibe den Text objektiv und sachlich. ASSISTANT: Post 1:

Guten Tag,

Wir sind auf der Suche nach jungen, talentierten Steuerberatern, die ihr Studium im Bereich Steuerwesen erfolgreich abgeschlossen haben. Die Position ist offen fr alle, die eine Leidenschaft fr das Steuerrecht haben und eine Karriere in diesem Bereich anstreben.

Als Teil unseres Teams arbeiten Sie an verschiedenen Projekten und erweitern stetig Ihre Fhigkeiten und Kenntnisse. Wir bieten ein hervorragendes Arbeitsumfeld, das auf Zusammenarbeit und Teamwork basiert, um sicherzustellen, dass Sie Ihre Arbeit so effektiv wie mglich erledigen knnen.

Wenn Sie Interesse haben und Teil unseres Teams werden mchten, senden Sie uns bitte Ihre Bewerbung.

Vielen Dank.

Post 2:

Guten Tag,

Wir sind auf der Suche nach motivierten und talentierten Steuerberatern, die an einer Karriere in diesem Bereich interessiert sind. Als Teil unseres Teams arbeiten Sie an verschiedenen Projekten, um Ihre Fhigkeiten und Kenntnisse zu erweitern.

Wir bieten ein hervorragendes Arbeitsumfeld, das auf Zusammenarbeit und Teamwork basiert, um sicherzustellen, dass Sie Ihre Arbeit so effektiv wie mglich erledigen knnen. Wenn Sie bereit sind, sich dieser Herausforderung zu stellen und Ihre Karriere auf das nchste Level zu bringen, dann senden Sie uns bitte Ihre Bewerbung.

Vielen Dank.<|endoftext|>
tensor([-100, -100, -100,  ..., -100, -100, -100])
tensor([   32,  8537,  1022,  ...,   962,    13, 50256])
{'loss': 1.0934, 'grad_norm': 0.7381077541451235, 'learning_rate': 1.971512543801495e-05, 'epoch': 0.11}
{'loss': 1.1416, 'grad_norm': 0.7400346259481622, 'learning_rate': 1.9712164622018197e-05, 'epoch': 0.11}
{'loss': 1.059, 'grad_norm': 0.7297727953540027, 'learning_rate': 1.9709188723636088e-05, 'epoch': 0.11}
{'loss': 1.0688, 'grad_norm': 0.618438582025112, 'learning_rate': 1.9706197747490004e-05, 'epoch': 0.11}
{'loss': 1.0937, 'grad_norm': 0.9276793521566691, 'learning_rate': 1.9703191698224742e-05, 'epoch': 0.11}
{'loss': 1.0343, 'grad_norm': 0.789724257572966, 'learning_rate': 1.9700170580508514e-05, 'epoch': 0.11}
{'loss': 1.0352, 'grad_norm': 0.7681314876834093, 'learning_rate': 1.969713439903292e-05, 'epoch': 0.11}
{'loss': 1.0849, 'grad_norm': 0.6940436360295327, 'learning_rate': 1.9694083158512965e-05, 'epoch': 0.11}
{'loss': 1.0927, 'grad_norm': 0.7300627255809791, 'learning_rate': 1.9691016863687037e-05, 'epoch': 0.11}
{'loss': 1.1028, 'grad_norm': 1.30745236992854, 'learning_rate': 1.9687935519316897e-05, 'epoch': 0.11}
{'loss': 1.0803, 'grad_norm': 0.8861408121275104, 'learning_rate': 1.9684839130187678e-05, 'epoch': 0.11}
{'loss': 1.0745, 'grad_norm': 0.6488484204565603, 'learning_rate': 1.9681727701107885e-05, 'epoch': 0.11}
{'loss': 1.0858, 'grad_norm': 0.7731074262900204, 'learning_rate': 1.967860123690937e-05, 'epoch': 0.11}
{'loss': 1.0882, 'grad_norm': 0.7625521902456478, 'learning_rate': 1.967545974244734e-05, 'epoch': 0.11}
{'loss': 1.1305, 'grad_norm': 0.8018392405662744, 'learning_rate': 1.9672303222600333e-05, 'epoch': 0.11}
{'loss': 1.02, 'grad_norm': 0.6786539213168595, 'learning_rate': 1.9669131682270232e-05, 'epoch': 0.11}
{'loss': 1.1107, 'grad_norm': 0.6709539176106469, 'learning_rate': 1.966594512638224e-05, 'epoch': 0.11}
{'loss': 1.0759, 'grad_norm': 0.7532862189734922, 'learning_rate': 1.966274355988488e-05, 'epoch': 0.11}
{'loss': 1.1274, 'grad_norm': 0.9322225011918127, 'learning_rate': 1.9659526987749987e-05, 'epoch': 0.11}
{'loss': 1.0356, 'grad_norm': 0.7651400896929041, 'learning_rate': 1.965629541497269e-05, 'epoch': 0.11}
{'loss': 1.0915, 'grad_norm': 0.7150398516799674, 'learning_rate': 1.9653048846571427e-05, 'epoch': 0.11}
{'loss': 1.0323, 'grad_norm': 0.9588246958489997, 'learning_rate': 1.964978728758791e-05, 'epoch': 0.11}
{'loss': 1.0369, 'grad_norm': 0.6500063289000394, 'learning_rate': 1.9646510743087144e-05, 'epoch': 0.11}
{'loss': 1.0918, 'grad_norm': 0.7825472802389383, 'learning_rate': 1.9643219218157395e-05, 'epoch': 0.11}
{'loss': 1.0855, 'grad_norm': 0.6712944775471203, 'learning_rate': 1.963991271791019e-05, 'epoch': 0.12}
{'loss': 1.1079, 'grad_norm': 0.7122725086673315, 'learning_rate': 1.9636591247480323e-05, 'epoch': 0.12}
{'loss': 1.1423, 'grad_norm': 0.6935589463866658, 'learning_rate': 1.963325481202583e-05, 'epoch': 0.12}
{'loss': 1.095, 'grad_norm': 0.8656823542827099, 'learning_rate': 1.9629903416727987e-05, 'epoch': 0.12}
{'loss': 1.021, 'grad_norm': 0.6758504286602871, 'learning_rate': 1.96265370667913e-05, 'epoch': 0.12}
{'loss': 1.0964, 'grad_norm': 0.6810851357019646, 'learning_rate': 1.9623155767443498e-05, 'epoch': 0.12}
{'loss': 1.0558, 'grad_norm': 0.572033782040267, 'learning_rate': 1.9619759523935532e-05, 'epoch': 0.12}
{'loss': 1.0417, 'grad_norm': 0.7501350877170958, 'learning_rate': 1.961634834154156e-05, 'epoch': 0.12}
{'loss': 1.0965, 'grad_norm': 0.9690215081615736, 'learning_rate': 1.9612922225558924e-05, 'epoch': 0.12}
{'loss': 1.1319, 'grad_norm': 0.6834527736968877, 'learning_rate': 1.960948118130818e-05, 'epoch': 0.12}
{'loss': 1.0738, 'grad_norm': 0.7968181381435251, 'learning_rate': 1.9606025214133046e-05, 'epoch': 0.12}
{'loss': 1.0763, 'grad_norm': 0.7152685697987412, 'learning_rate': 1.960255432940043e-05, 'epoch': 0.12}
{'loss': 0.9733, 'grad_norm': 0.6398186060115495, 'learning_rate': 1.9599068532500394e-05, 'epoch': 0.12}
{'loss': 1.0667, 'grad_norm': 0.7770328194892007, 'learning_rate': 1.9595567828846166e-05, 'epoch': 0.12}
{'loss': 1.0836, 'grad_norm': 0.7330809440294644, 'learning_rate': 1.9592052223874115e-05, 'epoch': 0.12}
{'loss': 1.0456, 'grad_norm': 0.7569948699463053, 'learning_rate': 1.9588521723043764e-05, 'epoch': 0.12}
{'loss': 1.0742, 'grad_norm': 1.0359157962380237, 'learning_rate': 1.9584976331837758e-05, 'epoch': 0.12}
{'loss': 1.0911, 'grad_norm': 0.7004542247399373, 'learning_rate': 1.9581416055761865e-05, 'epoch': 0.12}
{'loss': 1.1096, 'grad_norm': 0.897743323303143, 'learning_rate': 1.9577840900344974e-05, 'epoch': 0.12}
{'loss': 1.0959, 'grad_norm': 0.9720734107059558, 'learning_rate': 1.957425087113908e-05, 'epoch': 0.12}
{'loss': 1.0521, 'grad_norm': 0.8265397673265659, 'learning_rate': 1.9570645973719273e-05, 'epoch': 0.12}
{'loss': 1.0584, 'grad_norm': 0.6185821458645567, 'learning_rate': 1.9567026213683728e-05, 'epoch': 0.12}
{'loss': 1.0992, 'grad_norm': 0.8777330451201291, 'learning_rate': 1.956339159665371e-05, 'epoch': 0.12}
{'loss': 1.0494, 'grad_norm': 0.8057583405700551, 'learning_rate': 1.9559742128273558e-05, 'epoch': 0.12}
{'loss': 1.0881, 'grad_norm': 0.7892783987827682, 'learning_rate': 1.9556077814210662e-05, 'epoch': 0.12}
{'loss': 1.0913, 'grad_norm': 0.9120592399905557, 'learning_rate': 1.955239866015547e-05, 'epoch': 0.12}
{'loss': 1.1053, 'grad_norm': 0.7707480585206191, 'learning_rate': 1.954870467182149e-05, 'epoch': 0.13}
{'loss': 1.0479, 'grad_norm': 0.6516796860487318, 'learning_rate': 1.9544995854945248e-05, 'epoch': 0.13}
{'loss': 1.0782, 'grad_norm': 0.731778455173256, 'learning_rate': 1.9541272215286304e-05, 'epoch': 0.13}
{'loss': 1.0691, 'grad_norm': 0.6923055945930106, 'learning_rate': 1.9537533758627242e-05, 'epoch': 0.13}
{'loss': 1.1177, 'grad_norm': 0.8743450943962022, 'learning_rate': 1.9533780490773645e-05, 'epoch': 0.13}
{'loss': 1.0799, 'grad_norm': 0.6777993310175452, 'learning_rate': 1.953001241755411e-05, 'epoch': 0.13}
{'loss': 1.1002, 'grad_norm': 0.7347128655981072, 'learning_rate': 1.952622954482022e-05, 'epoch': 0.13}
{'loss': 1.1074, 'grad_norm': 0.6873486765082767, 'learning_rate': 1.9522431878446536e-05, 'epoch': 0.13}
{'loss': 1.0551, 'grad_norm': 0.7571789476538456, 'learning_rate': 1.95186194243306e-05, 'epoch': 0.13}
{'loss': 1.1055, 'grad_norm': 0.6796306391162752, 'learning_rate': 1.9514792188392914e-05, 'epoch': 0.13}
{'loss': 1.1086, 'grad_norm': 0.8243069739131775, 'learning_rate': 1.9510950176576933e-05, 'epoch': 0.13}
{'loss': 1.0363, 'grad_norm': 0.7671882149396344, 'learning_rate': 1.950709339484907e-05, 'epoch': 0.13}
{'loss': 1.1056, 'grad_norm': 0.8132989484213967, 'learning_rate': 1.9503221849198655e-05, 'epoch': 0.13}
{'loss': 1.0646, 'grad_norm': 0.6889207607066952, 'learning_rate': 1.9499335545637968e-05, 'epoch': 0.13}
{'loss': 1.0913, 'grad_norm': 0.8005125527399798, 'learning_rate': 1.9495434490202188e-05, 'epoch': 0.13}
{'loss': 1.1105, 'grad_norm': 0.8282863749036379, 'learning_rate': 1.9491518688949417e-05, 'epoch': 0.13}
{'loss': 1.1295, 'grad_norm': 1.0616050594116937, 'learning_rate': 1.948758814796064e-05, 'epoch': 0.13}
{'loss': 1.0628, 'grad_norm': 0.6980383348588578, 'learning_rate': 1.9483642873339753e-05, 'epoch': 0.13}
{'loss': 1.0781, 'grad_norm': 0.6980804864902397, 'learning_rate': 1.9479682871213515e-05, 'epoch': 0.13}
{'loss': 1.0702, 'grad_norm': 0.6407257467113332, 'learning_rate': 1.947570814773156e-05, 'epoch': 0.13}
{'loss': 1.0979, 'grad_norm': 0.9211129968448061, 'learning_rate': 1.9471718709066392e-05, 'epoch': 0.13}
{'loss': 1.0787, 'grad_norm': 0.7138822409619473, 'learning_rate': 1.9467714561413358e-05, 'epoch': 0.13}
{'loss': 1.0532, 'grad_norm': 0.6716393327579468, 'learning_rate': 1.9463695710990648e-05, 'epoch': 0.13}
{'loss': 1.0727, 'grad_norm': 0.9216946954135632, 'learning_rate': 1.9459662164039283e-05, 'epoch': 0.13}
{'loss': 1.0873, 'grad_norm': 0.7673035669871862, 'learning_rate': 1.9455613926823115e-05, 'epoch': 0.13}
{'loss': 1.0854, 'grad_norm': 0.7528101437691421, 'learning_rate': 1.9451551005628803e-05, 'epoch': 0.13}
{'loss': 1.0859, 'grad_norm': 0.733207245177654, 'learning_rate': 1.9447473406765803e-05, 'epoch': 0.14}
{'loss': 1.0816, 'grad_norm': 0.9683676733891138, 'learning_rate': 1.9443381136566382e-05, 'epoch': 0.14}
{'loss': 1.1481, 'grad_norm': 0.8770910334930253, 'learning_rate': 1.943927420138557e-05, 'epoch': 0.14}
{'loss': 1.066, 'grad_norm': 0.6046392603757554, 'learning_rate': 1.9435152607601187e-05, 'epoch': 0.14}
{'loss': 1.081, 'grad_norm': 0.795487277907255, 'learning_rate': 1.9431016361613816e-05, 'epoch': 0.14}
{'loss': 1.0169, 'grad_norm': 1.2883670861732683, 'learning_rate': 1.9426865469846773e-05, 'epoch': 0.14}
{'loss': 1.0568, 'grad_norm': 0.9241371157283754, 'learning_rate': 1.942269993874615e-05, 'epoch': 0.14}
{'loss': 0.9997, 'grad_norm': 0.8068484228237819, 'learning_rate': 1.9418519774780748e-05, 'epoch': 0.14}
{'loss': 1.1029, 'grad_norm': 0.7300988966049295, 'learning_rate': 1.9414324984442102e-05, 'epoch': 0.14}
{'loss': 1.0445, 'grad_norm': 0.7806966498562714, 'learning_rate': 1.9410115574244462e-05, 'epoch': 0.14}
{'loss': 1.0965, 'grad_norm': 0.6687153964965965, 'learning_rate': 1.9405891550724778e-05, 'epoch': 0.14}
{'loss': 1.0908, 'grad_norm': 0.7524587821436384, 'learning_rate': 1.9401652920442694e-05, 'epoch': 0.14}
{'loss': 1.098, 'grad_norm': 0.7439315772441042, 'learning_rate': 1.939739968998054e-05, 'epoch': 0.14}
{'loss': 1.1095, 'grad_norm': 0.7682185618162202, 'learning_rate': 1.939313186594331e-05, 'epoch': 0.14}
{'loss': 1.111, 'grad_norm': 0.8458543667605736, 'learning_rate': 1.938884945495868e-05, 'epoch': 0.14}
{'loss': 1.0708, 'grad_norm': 0.7342657339410855, 'learning_rate': 1.938455246367696e-05, 'epoch': 0.14}
{'loss': 1.0382, 'grad_norm': 0.6068628072191339, 'learning_rate': 1.938024089877111e-05, 'epoch': 0.14}
{'loss': 1.0689, 'grad_norm': 0.6414753032176651, 'learning_rate': 1.9375914766936723e-05, 'epoch': 0.14}
{'loss': 1.0172, 'grad_norm': 0.6826169944769872, 'learning_rate': 1.937157407489201e-05, 'epoch': 0.14}
{'loss': 1.0577, 'grad_norm': 0.6962040970900581, 'learning_rate': 1.936721882937779e-05, 'epoch': 0.14}
{'loss': 1.0765, 'grad_norm': 0.7777577194982378, 'learning_rate': 1.93628490371575e-05, 'epoch': 0.14}
{'loss': 1.0631, 'grad_norm': 0.7816563517299374, 'learning_rate': 1.9358464705017143e-05, 'epoch': 0.14}
{'loss': 1.0971, 'grad_norm': 0.8090705039956799, 'learning_rate': 1.9354065839765316e-05, 'epoch': 0.14}
{'loss': 1.0255, 'grad_norm': 0.6478431667103933, 'learning_rate': 1.9349652448233187e-05, 'epoch': 0.14}
{'loss': 1.1169, 'grad_norm': 0.7108395794457908, 'learning_rate': 1.934522453727447e-05, 'epoch': 0.14}
{'loss': 1.0713, 'grad_norm': 0.7206719932632865, 'learning_rate': 1.934078211376544e-05, 'epoch': 0.14}
{'loss': 1.0333, 'grad_norm': 0.9866996807522259, 'learning_rate': 1.93363251846049e-05, 'epoch': 0.15}
{'loss': 1.0406, 'grad_norm': 0.9778189814286284, 'learning_rate': 1.9331853756714185e-05, 'epoch': 0.15}
{'loss': 1.0729, 'grad_norm': 0.7217065421876827, 'learning_rate': 1.9327367837037142e-05, 'epoch': 0.15}
{'loss': 1.1014, 'grad_norm': 0.6928642685824905, 'learning_rate': 1.9322867432540126e-05, 'epoch': 0.15}
{'loss': 1.0518, 'grad_norm': 0.7624693872091893, 'learning_rate': 1.9318352550211986e-05, 'epoch': 0.15}
{'loss': 1.083, 'grad_norm': 0.8188117833018594, 'learning_rate': 1.9313823197064042e-05, 'epoch': 0.15}
{'loss': 1.085, 'grad_norm': 0.8002625169853382, 'learning_rate': 1.9309279380130112e-05, 'epoch': 0.15}
{'loss': 1.044, 'grad_norm': 0.7276706740260288, 'learning_rate': 1.930472110646645e-05, 'epoch': 0.15}
{'loss': 1.0667, 'grad_norm': 0.6174180758516699, 'learning_rate': 1.930014838315177e-05, 'epoch': 0.15}
{'loss': 1.0525, 'grad_norm': 1.0750787751253355, 'learning_rate': 1.9295561217287226e-05, 'epoch': 0.15}
{'loss': 1.1002, 'grad_norm': 0.6942559840817998, 'learning_rate': 1.9290959615996407e-05, 'epoch': 0.15}
{'loss': 1.0835, 'grad_norm': 0.6302606879058844, 'learning_rate': 1.9286343586425307e-05, 'epoch': 0.15}
{'loss': 1.1065, 'grad_norm': 0.8638329094151225, 'learning_rate': 1.9281713135742333e-05, 'epoch': 0.15}
{'loss': 1.0687, 'grad_norm': 0.702144606580031, 'learning_rate': 1.9277068271138287e-05, 'epoch': 0.15}
{'loss': 1.0377, 'grad_norm': 0.6551866940102926, 'learning_rate': 1.927240899982635e-05, 'epoch': 0.15}
{'loss': 1.0626, 'grad_norm': 0.9166818187112935, 'learning_rate': 1.9267735329042086e-05, 'epoch': 0.15}
{'loss': 1.0716, 'grad_norm': 0.738254842227204, 'learning_rate': 1.926304726604341e-05, 'epoch': 0.15}
{'loss': 1.0595, 'grad_norm': 0.8168143860383463, 'learning_rate': 1.925834481811059e-05, 'epoch': 0.15}
{'loss': 1.1287, 'grad_norm': 0.712468019867862, 'learning_rate': 1.925362799254623e-05, 'epoch': 0.15}
{'loss': 1.0325, 'grad_norm': 0.7873339362539418, 'learning_rate': 1.9248896796675277e-05, 'epoch': 0.15}
{'loss': 1.059, 'grad_norm': 0.9838100533024999, 'learning_rate': 1.9244151237844975e-05, 'epoch': 0.15}
{'loss': 1.0679, 'grad_norm': 0.6858465854224887, 'learning_rate': 1.923939132342488e-05, 'epoch': 0.15}
{'loss': 1.0929, 'grad_norm': 0.9648395196082058, 'learning_rate': 1.923461706080685e-05, 'epoch': 0.15}
{'loss': 1.073, 'grad_norm': 0.6898179444823292, 'learning_rate': 1.9229828457405005e-05, 'epoch': 0.15}
{'loss': 1.0661, 'grad_norm': 0.8530478022588336, 'learning_rate': 1.922502552065576e-05, 'epoch': 0.15}
{'loss': 1.0513, 'grad_norm': 0.7565847611225293, 'learning_rate': 1.9220208258017763e-05, 'epoch': 0.15}
{'loss': 1.0512, 'grad_norm': 0.8045865198265434, 'learning_rate': 1.921537667697193e-05, 'epoch': 0.16}
{'loss': 1.0865, 'grad_norm': 0.7306098601949753, 'learning_rate': 1.9210530785021405e-05, 'epoch': 0.16}
{'loss': 1.0351, 'grad_norm': 0.6993000999961191, 'learning_rate': 1.920567058969155e-05, 'epoch': 0.16}
{'loss': 1.0971, 'grad_norm': 0.9291726604170596, 'learning_rate': 1.9200796098529956e-05, 'epoch': 0.16}
{'loss': 1.0025, 'grad_norm': 0.6882360389619914, 'learning_rate': 1.9195907319106394e-05, 'epoch': 0.16}
{'loss': 1.0937, 'grad_norm': 0.7725244869663538, 'learning_rate': 1.919100425901283e-05, 'epoch': 0.16}
{'loss': 1.0515, 'grad_norm': 0.712176324150179, 'learning_rate': 1.918608692586342e-05, 'epoch': 0.16}
{'loss': 1.0659, 'grad_norm': 0.7720229956910016, 'learning_rate': 1.9181155327294468e-05, 'epoch': 0.16}
{'loss': 1.124, 'grad_norm': 0.8351980320822215, 'learning_rate': 1.9176209470964446e-05, 'epoch': 0.16}
{'loss': 0.9906, 'grad_norm': 0.8173437035750054, 'learning_rate': 1.9171249364553956e-05, 'epoch': 0.16}
{'loss': 1.0639, 'grad_norm': 0.7099099642886433, 'learning_rate': 1.916627501576573e-05, 'epoch': 0.16}
{'loss': 1.0595, 'grad_norm': 0.767791795860926, 'learning_rate': 1.9161286432324628e-05, 'epoch': 0.16}
{'loss': 1.0952, 'grad_norm': 0.905952247106095, 'learning_rate': 1.9156283621977603e-05, 'epoch': 0.16}
{'loss': 1.0534, 'grad_norm': 0.8010851796975885, 'learning_rate': 1.915126659249371e-05, 'epoch': 0.16}
{'loss': 1.1044, 'grad_norm': 0.7243980614956973, 'learning_rate': 1.914623535166408e-05, 'epoch': 0.16}
{'loss': 1.1086, 'grad_norm': 0.7766719857268419, 'learning_rate': 1.9141189907301922e-05, 'epoch': 0.16}
{'loss': 1.0661, 'grad_norm': 0.7856566410094732, 'learning_rate': 1.913613026724249e-05, 'epoch': 0.16}
{'loss': 1.0835, 'grad_norm': 0.9241670025642069, 'learning_rate': 1.9131056439343095e-05, 'epoch': 0.16}
{'loss': 1.0771, 'grad_norm': 0.669332045212886, 'learning_rate': 1.9125968431483068e-05, 'epoch': 0.16}
{'loss': 1.0632, 'grad_norm': 0.824309711466627, 'learning_rate': 1.912086625156377e-05, 'epoch': 0.16}
{'loss': 1.1136, 'grad_norm': 0.8640814198623725, 'learning_rate': 1.911574990750857e-05, 'epoch': 0.16}
{'loss': 1.1004, 'grad_norm': 0.8504911204473383, 'learning_rate': 1.9110619407262828e-05, 'epoch': 0.16}
{'loss': 1.0685, 'grad_norm': 0.7932101500083143, 'learning_rate': 1.9105474758793897e-05, 'epoch': 0.16}
{'loss': 1.0707, 'grad_norm': 0.6961652074447361, 'learning_rate': 1.9100315970091088e-05, 'epoch': 0.16}
{'loss': 1.0456, 'grad_norm': 0.7442162173200018, 'learning_rate': 1.909514304916568e-05, 'epoch': 0.16}
{'loss': 1.0643, 'grad_norm': 1.0096369285550582, 'learning_rate': 1.9089956004050893e-05, 'epoch': 0.16}
{'loss': 1.0837, 'grad_norm': 0.9724301337884564, 'learning_rate': 1.908475484280189e-05, 'epoch': 0.17}
{'loss': 1.0974, 'grad_norm': 0.8141895190902648, 'learning_rate': 1.907953957349575e-05, 'epoch': 0.17}
{'loss': 1.0626, 'grad_norm': 0.6654068544506153, 'learning_rate': 1.9074310204231457e-05, 'epoch': 0.17}
{'loss': 1.0808, 'grad_norm': 1.0858978294094082, 'learning_rate': 1.9069066743129893e-05, 'epoch': 0.17}
{'loss': 1.0717, 'grad_norm': 0.7327872013587482, 'learning_rate': 1.9063809198333832e-05, 'epoch': 0.17}
{'loss': 1.1101, 'grad_norm': 0.6246726727246313, 'learning_rate': 1.905853757800791e-05, 'epoch': 0.17}
{'loss': 0.9792, 'grad_norm': 0.5563209219384116, 'learning_rate': 1.905325189033862e-05, 'epoch': 0.17}
{'loss': 1.0668, 'grad_norm': 0.7655529813875223, 'learning_rate': 1.904795214353431e-05, 'epoch': 0.17}
{'loss': 1.0763, 'grad_norm': 0.877823030989622, 'learning_rate': 1.9042638345825155e-05, 'epoch': 0.17}
{'loss': 1.0771, 'grad_norm': 0.7252535048683348, 'learning_rate': 1.9037310505463153e-05, 'epoch': 0.17}
{'loss': 1.0742, 'grad_norm': 0.6684451776401658, 'learning_rate': 1.9031968630722104e-05, 'epoch': 0.17}
{'loss': 1.0611, 'grad_norm': 0.7837648031069505, 'learning_rate': 1.902661272989761e-05, 'epoch': 0.17}
{'loss': 1.0435, 'grad_norm': 0.7415476092741071, 'learning_rate': 1.9021242811307044e-05, 'epoch': 0.17}
{'loss': 1.0355, 'grad_norm': 0.8258269560697109, 'learning_rate': 1.9015858883289556e-05, 'epoch': 0.17}
{'loss': 0.9959, 'grad_norm': 1.0381891734155062, 'learning_rate': 1.901046095420606e-05, 'epoch': 0.17}
{'loss': 1.0917, 'grad_norm': 0.6558285093235696, 'learning_rate': 1.9005049032439193e-05, 'epoch': 0.17}
{'loss': 1.0238, 'grad_norm': 0.8410876770063463, 'learning_rate': 1.899962312639333e-05, 'epoch': 0.17}
{'loss': 1.0797, 'grad_norm': 0.6738857877173515, 'learning_rate': 1.899418324449457e-05, 'epoch': 0.17}
{'loss': 1.014, 'grad_norm': 0.9334541059983709, 'learning_rate': 1.8988729395190712e-05, 'epoch': 0.17}
{'loss': 1.0799, 'grad_norm': 0.6663370262270489, 'learning_rate': 1.898326158695124e-05, 'epoch': 0.17}
{'loss': 1.0237, 'grad_norm': 0.6755821259033848, 'learning_rate': 1.8977779828267314e-05, 'epoch': 0.17}
{'loss': 1.0707, 'grad_norm': 0.7502561664080277, 'learning_rate': 1.897228412765177e-05, 'epoch': 0.17}
{'loss': 1.0828, 'grad_norm': 0.6876884759067551, 'learning_rate': 1.8966774493639084e-05, 'epoch': 0.17}
{'loss': 1.0398, 'grad_norm': 0.7208480702963431, 'learning_rate': 1.896125093478538e-05, 'epoch': 0.17}
{'loss': 1.0684, 'grad_norm': 0.7570276134853489, 'learning_rate': 1.895571345966839e-05, 'epoch': 0.17}
{'loss': 1.1091, 'grad_norm': 0.6966238430232915, 'learning_rate': 1.8950162076887477e-05, 'epoch': 0.17}
{'loss': 1.0781, 'grad_norm': 0.7596757142588006, 'learning_rate': 1.8944596795063584e-05, 'epoch': 0.18}
{'loss': 1.0704, 'grad_norm': 0.6995192434431878, 'learning_rate': 1.8939017622839253e-05, 'epoch': 0.18}
{'loss': 1.0693, 'grad_norm': 0.7305540981218758, 'learning_rate': 1.8933424568878586e-05, 'epoch': 0.18}
{'loss': 1.1043, 'grad_norm': 0.7406337850441155, 'learning_rate': 1.8927817641867244e-05, 'epoch': 0.18}
{'loss': 1.0275, 'grad_norm': 0.8816491269033422, 'learning_rate': 1.8922196850512446e-05, 'epoch': 0.18}
{'loss': 1.0398, 'grad_norm': 0.6177082741352041, 'learning_rate': 1.8916562203542916e-05, 'epoch': 0.18}
{'loss': 1.0786, 'grad_norm': 0.7426152851876905, 'learning_rate': 1.8910913709708918e-05, 'epoch': 0.18}
{'loss': 1.067, 'grad_norm': 1.2533677715278941, 'learning_rate': 1.8905251377782206e-05, 'epoch': 0.18}
{'loss': 1.0794, 'grad_norm': 0.6375000282140525, 'learning_rate': 1.889957521655603e-05, 'epoch': 0.18}
{'loss': 1.0091, 'grad_norm': 1.3502475934373548, 'learning_rate': 1.8893885234845117e-05, 'epoch': 0.18}
{'loss': 1.0062, 'grad_norm': 0.6128540767480691, 'learning_rate': 1.888818144148565e-05, 'epoch': 0.18}
{'loss': 1.0617, 'grad_norm': 0.6920055377925008, 'learning_rate': 1.8882463845335263e-05, 'epoch': 0.18}
{'loss': 1.0278, 'grad_norm': 0.7864954246944714, 'learning_rate': 1.8876732455273022e-05, 'epoch': 0.18}
{'loss': 1.0639, 'grad_norm': 0.696637580837172, 'learning_rate': 1.8870987280199428e-05, 'epoch': 0.18}
{'loss': 1.0343, 'grad_norm': 0.6893132591746595, 'learning_rate': 1.8865228329036372e-05, 'epoch': 0.18}
{'loss': 0.9891, 'grad_norm': 0.6423929623201581, 'learning_rate': 1.885945561072715e-05, 'epoch': 0.18}
{'loss': 1.065, 'grad_norm': 0.6646523779022522, 'learning_rate': 1.885366913423643e-05, 'epoch': 0.18}
{'loss': 1.0562, 'grad_norm': 0.7099891555215144, 'learning_rate': 1.8847868908550252e-05, 'epoch': 0.18}
{'loss': 1.105, 'grad_norm': 0.7014551096221899, 'learning_rate': 1.8842054942676e-05, 'epoch': 0.18}
{'loss': 1.0314, 'grad_norm': 0.6868413412905661, 'learning_rate': 1.88362272456424e-05, 'epoch': 0.18}
{'loss': 1.074, 'grad_norm': 0.8711553814935402, 'learning_rate': 1.8830385826499507e-05, 'epoch': 0.18}
{'loss': 1.1399, 'grad_norm': 0.6839794323463465, 'learning_rate': 1.8824530694318675e-05, 'epoch': 0.18}
{'loss': 1.0969, 'grad_norm': 0.6613612576893945, 'learning_rate': 1.8818661858192562e-05, 'epoch': 0.18}
{'loss': 1.0662, 'grad_norm': 0.8794383960301989, 'learning_rate': 1.8812779327235106e-05, 'epoch': 0.18}
{'loss': 1.069, 'grad_norm': 0.7186413372195484, 'learning_rate': 1.88068831105815e-05, 'epoch': 0.18}
{'loss': 1.0613, 'grad_norm': 0.8172987624765374, 'learning_rate': 1.8800973217388215e-05, 'epoch': 0.18}
{'loss': 1.0036, 'grad_norm': 0.7213262623284804, 'learning_rate': 1.879504965683294e-05, 'epoch': 0.19}
{'loss': 1.1019, 'grad_norm': 0.6835373147356358, 'learning_rate': 1.878911243811459e-05, 'epoch': 0.19}
{'loss': 1.0888, 'grad_norm': 0.7145901258921168, 'learning_rate': 1.8783161570453295e-05, 'epoch': 0.19}
{'loss': 1.0124, 'grad_norm': 0.7425611190604025, 'learning_rate': 1.8777197063090394e-05, 'epoch': 0.19}
{'loss': 1.0155, 'grad_norm': 0.7064866913130958, 'learning_rate': 1.877121892528838e-05, 'epoch': 0.19}
{'loss': 1.0486, 'grad_norm': 0.6540815588550795, 'learning_rate': 1.8765227166330933e-05, 'epoch': 0.19}
{'loss': 1.1166, 'grad_norm': 0.6988671648970236, 'learning_rate': 1.875922179552288e-05, 'epoch': 0.19}
{'loss': 1.0299, 'grad_norm': 0.6046354954776383, 'learning_rate': 1.875320282219019e-05, 'epoch': 0.19}
{'loss': 1.0425, 'grad_norm': 0.697831192579153, 'learning_rate': 1.874717025567995e-05, 'epoch': 0.19}
{'loss': 1.0705, 'grad_norm': 0.6792568191660227, 'learning_rate': 1.8741124105360363e-05, 'epoch': 0.19}
{'loss': 1.1026, 'grad_norm': 1.680358193198635, 'learning_rate': 1.8735064380620717e-05, 'epoch': 0.19}
{'loss': 1.0321, 'grad_norm': 0.7370696773806582, 'learning_rate': 1.8728991090871387e-05, 'epoch': 0.19}
{'loss': 1.1101, 'grad_norm': 0.8303209070502701, 'learning_rate': 1.8722904245543817e-05, 'epoch': 0.19}
{'loss': 1.1009, 'grad_norm': 0.6778532406181718, 'learning_rate': 1.8716803854090495e-05, 'epoch': 0.19}
{'loss': 1.0762, 'grad_norm': 0.718075565084593, 'learning_rate': 1.871068992598495e-05, 'epoch': 0.19}
{'loss': 1.0883, 'grad_norm': 0.729015296131081, 'learning_rate': 1.8704562470721728e-05, 'epoch': 0.19}
{'loss': 1.0241, 'grad_norm': 0.7621960407031612, 'learning_rate': 1.8698421497816386e-05, 'epoch': 0.19}
{'loss': 1.0759, 'grad_norm': 0.8213606421421794, 'learning_rate': 1.8692267016805473e-05, 'epoch': 0.19}
{'loss': 1.065, 'grad_norm': 0.641099673873712, 'learning_rate': 1.868609903724651e-05, 'epoch': 0.19}
{'loss': 1.0677, 'grad_norm': 0.9072795520111221, 'learning_rate': 1.867991756871799e-05, 'epoch': 0.19}
{'loss': 1.0356, 'grad_norm': 0.6525589253111703, 'learning_rate': 1.867372262081934e-05, 'epoch': 0.19}
{'loss': 1.0777, 'grad_norm': 0.6488388348578339, 'learning_rate': 1.8667514203170934e-05, 'epoch': 0.19}
{'loss': 1.0867, 'grad_norm': 0.8154661981007113, 'learning_rate': 1.8661292325414058e-05, 'epoch': 0.19}
{'loss': 1.0899, 'grad_norm': 0.6530670065606805, 'learning_rate': 1.8655056997210893e-05, 'epoch': 0.19}
{'loss': 1.0066, 'grad_norm': 0.6565664496507466, 'learning_rate': 1.864880822824452e-05, 'epoch': 0.19}
{'loss': 1.0346, 'grad_norm': 0.8303973680003904, 'learning_rate': 1.864254602821888e-05, 'epoch': 0.19}
{'loss': 1.0704, 'grad_norm': 0.9931671212353609, 'learning_rate': 1.8636270406858786e-05, 'epoch': 0.2}
{'loss': 1.0454, 'grad_norm': 0.679421356703112, 'learning_rate': 1.862998137390989e-05, 'epoch': 0.2}
{'loss': 1.0711, 'grad_norm': 0.7350907386512165, 'learning_rate': 1.8623678939138652e-05, 'epoch': 0.2}
{'loss': 1.088, 'grad_norm': 0.7652870013690307, 'learning_rate': 1.8617363112332376e-05, 'epoch': 0.2}
{'loss': 1.0306, 'grad_norm': 0.8615977662925481, 'learning_rate': 1.8611033903299136e-05, 'epoch': 0.2}
{'loss': 1.0352, 'grad_norm': 0.6293366115074446, 'learning_rate': 1.8604691321867804e-05, 'epoch': 0.2}
{'loss': 1.0867, 'grad_norm': 0.8423855824018035, 'learning_rate': 1.8598335377888012e-05, 'epoch': 0.2}
{'loss': 1.045, 'grad_norm': 0.7974431111400824, 'learning_rate': 1.8591966081230142e-05, 'epoch': 0.2}
{'loss': 1.0413, 'grad_norm': 0.7905577223693246, 'learning_rate': 1.858558344178532e-05, 'epoch': 0.2}
{'loss': 1.1083, 'grad_norm': 0.6655642792748495, 'learning_rate': 1.857918746946538e-05, 'epoch': 0.2}
{'loss': 1.0206, 'grad_norm': 0.7119303994453569, 'learning_rate': 1.857277817420287e-05, 'epoch': 0.2}
{'loss': 1.0671, 'grad_norm': 0.7315151061720626, 'learning_rate': 1.8566355565951023e-05, 'epoch': 0.2}
{'loss': 1.0759, 'grad_norm': 0.72756233029176, 'learning_rate': 1.8559919654683756e-05, 'epoch': 0.2}
{'loss': 1.0608, 'grad_norm': 1.0419792490768822, 'learning_rate': 1.855347045039563e-05, 'epoch': 0.2}
{'loss': 1.0449, 'grad_norm': 0.6707803719841293, 'learning_rate': 1.854700796310186e-05, 'epoch': 0.2}
{'loss': 1.0923, 'grad_norm': 0.6617360601345328, 'learning_rate': 1.8540532202838286e-05, 'epoch': 0.2}
{'loss': 0.9832, 'grad_norm': 0.7493806395633092, 'learning_rate': 1.8534043179661357e-05, 'epoch': 0.2}
{'loss': 1.0458, 'grad_norm': 0.6838596006470198, 'learning_rate': 1.8527540903648122e-05, 'epoch': 0.2}
{'loss': 1.052, 'grad_norm': 0.8868195204492947, 'learning_rate': 1.852102538489621e-05, 'epoch': 0.2}
{'loss': 1.0474, 'grad_norm': 0.7528283999513676, 'learning_rate': 1.851449663352381e-05, 'epoch': 0.2}
{'loss': 1.0374, 'grad_norm': 0.8252299490020097, 'learning_rate': 1.8507954659669677e-05, 'epoch': 0.2}
{'loss': 1.0557, 'grad_norm': 0.9730692768509442, 'learning_rate': 1.850139947349308e-05, 'epoch': 0.2}
{'loss': 1.0508, 'grad_norm': 0.7096935992372633, 'learning_rate': 1.849483108517381e-05, 'epoch': 0.2}
{'loss': 1.0127, 'grad_norm': 0.6456121225183634, 'learning_rate': 1.8488249504912173e-05, 'epoch': 0.2}
{'loss': 1.0149, 'grad_norm': 0.6106007747766944, 'learning_rate': 1.848165474292895e-05, 'epoch': 0.2}
{'loss': 1.0271, 'grad_norm': 0.6826428004005691, 'learning_rate': 1.847504680946539e-05, 'epoch': 0.2}
{'loss': 1.0648, 'grad_norm': 0.8787322826220035, 'learning_rate': 1.8468425714783206e-05, 'epoch': 0.21}
{'loss': 1.1249, 'grad_norm': 0.8759856085263917, 'learning_rate': 1.846179146916454e-05, 'epoch': 0.21}
{'loss': 1.0584, 'grad_norm': 0.6277402638923606, 'learning_rate': 1.8455144082911965e-05, 'epoch': 0.21}
{'loss': 1.1099, 'grad_norm': 0.7838922036133605, 'learning_rate': 1.8448483566348456e-05, 'epoch': 0.21}
{'loss': 1.0544, 'grad_norm': 0.7416638753843536, 'learning_rate': 1.8441809929817382e-05, 'epoch': 0.21}
{'loss': 1.076, 'grad_norm': 0.8304777568464565, 'learning_rate': 1.8435123183682475e-05, 'epoch': 0.21}
{'loss': 1.0275, 'grad_norm': 0.684539895668691, 'learning_rate': 1.8428423338327847e-05, 'epoch': 0.21}
{'loss': 1.075, 'grad_norm': 0.8434233222416198, 'learning_rate': 1.842171040415793e-05, 'epoch': 0.21}
{'loss': 1.115, 'grad_norm': 0.8767329347925734, 'learning_rate': 1.8414984391597492e-05, 'epoch': 0.21}
{'loss': 1.0416, 'grad_norm': 0.6620744660891419, 'learning_rate': 1.8408245311091618e-05, 'epoch': 0.21}
{'loss': 1.0782, 'grad_norm': 0.8293137483138809, 'learning_rate': 1.8401493173105675e-05, 'epoch': 0.21}
{'loss': 0.9961, 'grad_norm': 1.0536943596378947, 'learning_rate': 1.8394727988125308e-05, 'epoch': 0.21}
{'loss': 1.0786, 'grad_norm': 0.7155986152570001, 'learning_rate': 1.8387949766656434e-05, 'epoch': 0.21}
{'loss': 1.0631, 'grad_norm': 0.7297607744021917, 'learning_rate': 1.8381158519225204e-05, 'epoch': 0.21}
{'loss': 1.0629, 'grad_norm': 0.6471329880244164, 'learning_rate': 1.8374354256378e-05, 'epoch': 0.21}
{'loss': 1.0494, 'grad_norm': 0.6962993816250508, 'learning_rate': 1.8367536988681422e-05, 'epoch': 0.21}
{'loss': 1.0342, 'grad_norm': 0.6517649384865625, 'learning_rate': 1.8360706726722253e-05, 'epoch': 0.21}
{'loss': 1.0494, 'grad_norm': 0.8773495593998893, 'learning_rate': 1.8353863481107473e-05, 'epoch': 0.21}
{'loss': 1.0765, 'grad_norm': 0.6637325731731538, 'learning_rate': 1.8347007262464206e-05, 'epoch': 0.21}
{'loss': 1.0582, 'grad_norm': 0.9261675143906243, 'learning_rate': 1.8340138081439743e-05, 'epoch': 0.21}
{'loss': 1.0649, 'grad_norm': 0.7054965389421608, 'learning_rate': 1.833325594870148e-05, 'epoch': 0.21}
{'loss': 1.0699, 'grad_norm': 0.844411827926739, 'learning_rate': 1.8326360874936952e-05, 'epoch': 0.21}
{'loss': 1.0213, 'grad_norm': 0.6494998231402305, 'learning_rate': 1.8319452870853772e-05, 'epoch': 0.21}
{'loss': 1.0593, 'grad_norm': 0.697842094467651, 'learning_rate': 1.8312531947179634e-05, 'epoch': 0.21}
{'loss': 1.043, 'grad_norm': 1.0925402820671397, 'learning_rate': 1.8305598114662312e-05, 'epoch': 0.21}
{'loss': 1.0479, 'grad_norm': 0.6322569389831901, 'learning_rate': 1.8298651384069605e-05, 'epoch': 0.21}
{'loss': 1.0416, 'grad_norm': 0.9019735977888549, 'learning_rate': 1.829169176618936e-05, 'epoch': 0.22}
{'loss': 1.039, 'grad_norm': 0.6756093417192514, 'learning_rate': 1.828471927182942e-05, 'epoch': 0.22}
{'loss': 1.0798, 'grad_norm': 0.7184069995954747, 'learning_rate': 1.8277733911817642e-05, 'epoch': 0.22}
{'loss': 1.0835, 'grad_norm': 0.6806838198943702, 'learning_rate': 1.827073569700185e-05, 'epoch': 0.22}
{'loss': 1.0711, 'grad_norm': 0.7601142912949538, 'learning_rate': 1.8263724638249834e-05, 'epoch': 0.22}
{'loss': 1.0802, 'grad_norm': 0.75745219292965, 'learning_rate': 1.825670074644933e-05, 'epoch': 0.22}
{'loss': 1.0296, 'grad_norm': 0.6250666949588811, 'learning_rate': 1.824966403250801e-05, 'epoch': 0.22}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/373283342.jpg, using default black image.
{'loss': 1.0584, 'grad_norm': 0.7371513542706195, 'learning_rate': 1.8242614507353446e-05, 'epoch': 0.22}
{'loss': 1.0359, 'grad_norm': 1.000449070317538, 'learning_rate': 1.823555218193311e-05, 'epoch': 0.22}
{'loss': 1.0503, 'grad_norm': 0.835514330083275, 'learning_rate': 1.8228477067214352e-05, 'epoch': 0.22}
{'loss': 0.9619, 'grad_norm': 0.5834109879081617, 'learning_rate': 1.8221389174184385e-05, 'epoch': 0.22}
{'loss': 1.025, 'grad_norm': 0.6856837127826892, 'learning_rate': 1.8214288513850267e-05, 'epoch': 0.22}
{'loss': 1.0275, 'grad_norm': 0.7814704430132434, 'learning_rate': 1.820717509723888e-05, 'epoch': 0.22}
{'loss': 0.9941, 'grad_norm': 0.705472453335301, 'learning_rate': 1.8200048935396908e-05, 'epoch': 0.22}
{'loss': 0.976, 'grad_norm': 0.5517252081016054, 'learning_rate': 1.8192910039390844e-05, 'epoch': 0.22}
{'loss': 1.0145, 'grad_norm': 0.6524331507185516, 'learning_rate': 1.8185758420306947e-05, 'epoch': 0.22}
{'loss': 1.0249, 'grad_norm': 0.6584021357114368, 'learning_rate': 1.817859408925123e-05, 'epoch': 0.22}
{'loss': 1.067, 'grad_norm': 0.6607510497878483, 'learning_rate': 1.8171417057349457e-05, 'epoch': 0.22}
{'loss': 1.0588, 'grad_norm': 0.6431054993166074, 'learning_rate': 1.8164227335747108e-05, 'epoch': 0.22}
{'loss': 1.0484, 'grad_norm': 0.7358092075439627, 'learning_rate': 1.815702493560937e-05, 'epoch': 0.22}
{'loss': 1.0157, 'grad_norm': 0.6116707695614549, 'learning_rate': 1.8149809868121125e-05, 'epoch': 0.22}
{'loss': 1.052, 'grad_norm': 0.6439495844204428, 'learning_rate': 1.814258214448692e-05, 'epoch': 0.22}
{'loss': 1.0715, 'grad_norm': 0.8156292529941386, 'learning_rate': 1.813534177593096e-05, 'epoch': 0.22}
{'loss': 1.0747, 'grad_norm': 0.7624432687453557, 'learning_rate': 1.8128088773697086e-05, 'epoch': 0.22}
{'loss': 1.0853, 'grad_norm': 0.7882028022805609, 'learning_rate': 1.8120823149048753e-05, 'epoch': 0.22}
{'loss': 1.0679, 'grad_norm': 0.719478392198198, 'learning_rate': 1.8113544913269025e-05, 'epoch': 0.22}
{'loss': 1.0187, 'grad_norm': 0.5608879035119798, 'learning_rate': 1.8106254077660552e-05, 'epoch': 0.23}
{'loss': 1.0595, 'grad_norm': 0.7846980145069397, 'learning_rate': 1.809895065354554e-05, 'epoch': 0.23}
{'loss': 1.029, 'grad_norm': 0.7197617783289435, 'learning_rate': 1.8091634652265755e-05, 'epoch': 0.23}
{'loss': 1.0553, 'grad_norm': 0.6483700705792586, 'learning_rate': 1.808430608518249e-05, 'epoch': 0.23}
{'loss': 1.0959, 'grad_norm': 0.7126922410349971, 'learning_rate': 1.807696496367655e-05, 'epoch': 0.23}
{'loss': 1.0609, 'grad_norm': 0.7718728422102348, 'learning_rate': 1.8069611299148236e-05, 'epoch': 0.23}
{'loss': 1.0658, 'grad_norm': 0.6564574644215877, 'learning_rate': 1.806224510301734e-05, 'epoch': 0.23}
{'loss': 1.0922, 'grad_norm': 0.7400660794902236, 'learning_rate': 1.8054866386723096e-05, 'epoch': 0.23}
{'loss': 0.9979, 'grad_norm': 0.5835883652627034, 'learning_rate': 1.804747516172419e-05, 'epoch': 0.23}
{'loss': 1.0408, 'grad_norm': 0.8938785344454068, 'learning_rate': 1.804007143949874e-05, 'epoch': 0.23}
{'loss': 1.0078, 'grad_norm': 0.6966798259728552, 'learning_rate': 1.8032655231544253e-05, 'epoch': 0.23}
{'loss': 1.031, 'grad_norm': 0.8014495817225443, 'learning_rate': 1.8025226549377647e-05, 'epoch': 0.23}
{'loss': 1.0516, 'grad_norm': 0.8304807670488099, 'learning_rate': 1.8017785404535198e-05, 'epoch': 0.23}
{'loss': 1.0669, 'grad_norm': 0.5997066430930277, 'learning_rate': 1.801033180857254e-05, 'epoch': 0.23}
{'loss': 1.061, 'grad_norm': 0.735179371862848, 'learning_rate': 1.8002865773064644e-05, 'epoch': 0.23}
{'loss': 1.1054, 'grad_norm': 0.7889067659263339, 'learning_rate': 1.799538730960579e-05, 'epoch': 0.23}
{'loss': 1.0661, 'grad_norm': 0.6305279648680645, 'learning_rate': 1.7987896429809573e-05, 'epoch': 0.23}
{'loss': 0.9989, 'grad_norm': 0.6042324412557468, 'learning_rate': 1.7980393145308857e-05, 'epoch': 0.23}
{'loss': 1.0461, 'grad_norm': 0.6448312911128952, 'learning_rate': 1.7972877467755777e-05, 'epoch': 0.23}
{'loss': 0.9848, 'grad_norm': 0.7104523524794767, 'learning_rate': 1.796534940882171e-05, 'epoch': 0.23}
{'loss': 1.0452, 'grad_norm': 0.6139825336793494, 'learning_rate': 1.795780898019726e-05, 'epoch': 0.23}
{'loss': 1.0386, 'grad_norm': 0.7273903417623161, 'learning_rate': 1.7950256193592243e-05, 'epoch': 0.23}
{'loss': 1.0342, 'grad_norm': 0.9112703927653955, 'learning_rate': 1.7942691060735666e-05, 'epoch': 0.23}
{'loss': 1.0824, 'grad_norm': 0.6428469377771601, 'learning_rate': 1.7935113593375707e-05, 'epoch': 0.23}
{'loss': 1.0612, 'grad_norm': 0.7457990950315229, 'learning_rate': 1.79275238032797e-05, 'epoch': 0.23}
{'loss': 1.0575, 'grad_norm': 0.8839861984189358, 'learning_rate': 1.791992170223412e-05, 'epoch': 0.23}
{'loss': 1.0532, 'grad_norm': 0.7335193338086194, 'learning_rate': 1.791230730204455e-05, 'epoch': 0.24}
{'loss': 1.0203, 'grad_norm': 0.7359844222041801, 'learning_rate': 1.7904680614535675e-05, 'epoch': 0.24}
{'loss': 1.0216, 'grad_norm': 0.6708346482535381, 'learning_rate': 1.789704165155127e-05, 'epoch': 0.24}
{'loss': 1.107, 'grad_norm': 0.6746783723519685, 'learning_rate': 1.7889390424954168e-05, 'epoch': 0.24}
{'loss': 1.0032, 'grad_norm': 0.6456645784836221, 'learning_rate': 1.7881726946626244e-05, 'epoch': 0.24}
{'loss': 1.0658, 'grad_norm': 0.762952127779777, 'learning_rate': 1.78740512284684e-05, 'epoch': 0.24}
{'loss': 1.007, 'grad_norm': 0.5792352267513662, 'learning_rate': 1.7866363282400555e-05, 'epoch': 0.24}
{'loss': 1.0454, 'grad_norm': 0.7077259248649825, 'learning_rate': 1.7858663120361597e-05, 'epoch': 0.24}
{'loss': 1.0844, 'grad_norm': 0.6034926612842328, 'learning_rate': 1.7850950754309405e-05, 'epoch': 0.24}
{'loss': 1.0511, 'grad_norm': 0.6720990193814523, 'learning_rate': 1.7843226196220803e-05, 'epoch': 0.24}
{'loss': 1.0585, 'grad_norm': 0.6347490062500935, 'learning_rate': 1.7835489458091544e-05, 'epoch': 0.24}
{'loss': 1.0746, 'grad_norm': 0.7044722964073883, 'learning_rate': 1.7827740551936296e-05, 'epoch': 0.24}
{'loss': 1.0929, 'grad_norm': 0.7646401213340384, 'learning_rate': 1.7819979489788638e-05, 'epoch': 0.24}
{'loss': 1.0627, 'grad_norm': 0.6269719178611638, 'learning_rate': 1.7812206283701002e-05, 'epoch': 0.24}
{'loss': 1.0409, 'grad_norm': 0.843879214032902, 'learning_rate': 1.78044209457447e-05, 'epoch': 0.24}
{'loss': 1.0146, 'grad_norm': 0.6667806707333386, 'learning_rate': 1.7796623488009875e-05, 'epoch': 0.24}
{'loss': 1.0601, 'grad_norm': 0.685262913659662, 'learning_rate': 1.7788813922605488e-05, 'epoch': 0.24}
{'loss': 1.0428, 'grad_norm': 0.7288408942295551, 'learning_rate': 1.7780992261659305e-05, 'epoch': 0.24}
{'loss': 1.0399, 'grad_norm': 0.8040077666569057, 'learning_rate': 1.777315851731789e-05, 'epoch': 0.24}
{'loss': 1.09, 'grad_norm': 0.7293222690272798, 'learning_rate': 1.7765312701746543e-05, 'epoch': 0.24}
{'loss': 1.0388, 'grad_norm': 0.8041846922723379, 'learning_rate': 1.7757454827129338e-05, 'epoch': 0.24}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/964811367.jpg, using default black image.
{'loss': 1.0641, 'grad_norm': 0.7351932394041831, 'learning_rate': 1.7749584905669057e-05, 'epoch': 0.24}
{'loss': 1.0341, 'grad_norm': 0.5363419714829295, 'learning_rate': 1.7741702949587196e-05, 'epoch': 0.24}
{'loss': 1.0775, 'grad_norm': 0.7475991260365471, 'learning_rate': 1.7733808971123946e-05, 'epoch': 0.24}
{'loss': 1.0797, 'grad_norm': 0.6895810239668672, 'learning_rate': 1.7725902982538162e-05, 'epoch': 0.24}
{'loss': 1.032, 'grad_norm': 0.6917190482390009, 'learning_rate': 1.7717984996107346e-05, 'epoch': 0.24}
{'loss': 0.9849, 'grad_norm': 0.6677046975604193, 'learning_rate': 1.7710055024127637e-05, 'epoch': 0.25}
{'loss': 1.0367, 'grad_norm': 0.6505502813220048, 'learning_rate': 1.770211307891379e-05, 'epoch': 0.25}
{'loss': 1.0994, 'grad_norm': 0.8530991840362953, 'learning_rate': 1.769415917279915e-05, 'epoch': 0.25}
{'loss': 1.0416, 'grad_norm': 1.0229918381520267, 'learning_rate': 1.7686193318135635e-05, 'epoch': 0.25}
{'loss': 1.0647, 'grad_norm': 0.669215268011065, 'learning_rate': 1.7678215527293724e-05, 'epoch': 0.25}
{'loss': 1.025, 'grad_norm': 0.7166489835141806, 'learning_rate': 1.767022581266242e-05, 'epoch': 0.25}
{'loss': 1.0565, 'grad_norm': 0.6023853877859643, 'learning_rate': 1.766222418664926e-05, 'epoch': 0.25}
{'loss': 1.0094, 'grad_norm': 0.7080542451244437, 'learning_rate': 1.7654210661680263e-05, 'epoch': 0.25}
{'loss': 1.0945, 'grad_norm': 0.7500522801798609, 'learning_rate': 1.7646185250199936e-05, 'epoch': 0.25}
{'loss': 1.0647, 'grad_norm': 0.5694070192752515, 'learning_rate': 1.763814796467124e-05, 'epoch': 0.25}
{'loss': 0.9835, 'grad_norm': 0.7061568236376357, 'learning_rate': 1.7630098817575578e-05, 'epoch': 0.25}
{'loss': 1.0605, 'grad_norm': 0.6817954905284068, 'learning_rate': 1.7622037821412775e-05, 'epoch': 0.25}
{'loss': 1.0882, 'grad_norm': 0.7022569156098588, 'learning_rate': 1.7613964988701057e-05, 'epoch': 0.25}
{'loss': 1.0353, 'grad_norm': 0.6038158925781556, 'learning_rate': 1.7605880331977022e-05, 'epoch': 0.25}
{'loss': 1.0497, 'grad_norm': 0.6735862828464498, 'learning_rate': 1.7597783863795644e-05, 'epoch': 0.25}
{'loss': 0.9759, 'grad_norm': 0.5857358959655005, 'learning_rate': 1.7589675596730233e-05, 'epoch': 0.25}
{'loss': 1.1261, 'grad_norm': 0.7618569707656822, 'learning_rate': 1.7581555543372413e-05, 'epoch': 0.25}
{'loss': 0.9876, 'grad_norm': 0.6398699869759904, 'learning_rate': 1.7573423716332128e-05, 'epoch': 0.25}
{'loss': 1.0519, 'grad_norm': 0.6611416276535096, 'learning_rate': 1.7565280128237595e-05, 'epoch': 0.25}
{'loss': 1.0541, 'grad_norm': 0.5719055467233932, 'learning_rate': 1.75571247917353e-05, 'epoch': 0.25}
{'loss': 1.0603, 'grad_norm': 0.753256916526505, 'learning_rate': 1.754895771948997e-05, 'epoch': 0.25}
{'loss': 1.0201, 'grad_norm': 0.6333520048480303, 'learning_rate': 1.7540778924184553e-05, 'epoch': 0.25}
{'loss': 1.1014, 'grad_norm': 0.723153656063506, 'learning_rate': 1.7532588418520215e-05, 'epoch': 0.25}
{'loss': 1.0637, 'grad_norm': 0.6332387777411288, 'learning_rate': 1.75243862152163e-05, 'epoch': 0.25}
{'loss': 1.083, 'grad_norm': 0.6561322807625906, 'learning_rate': 1.7516172327010314e-05, 'epoch': 0.25}
{'loss': 1.0936, 'grad_norm': 0.6614026608060132, 'learning_rate': 1.7507946766657914e-05, 'epoch': 0.25}
{'loss': 1.0299, 'grad_norm': 0.6891672569966607, 'learning_rate': 1.749970954693288e-05, 'epoch': 0.26}
{'loss': 1.0365, 'grad_norm': 0.6309524042137561, 'learning_rate': 1.7491460680627105e-05, 'epoch': 0.26}
{'loss': 1.0197, 'grad_norm': 0.6371786377451678, 'learning_rate': 1.7483200180550554e-05, 'epoch': 0.26}
{'loss': 1.0038, 'grad_norm': 0.816913056206016, 'learning_rate': 1.747492805953128e-05, 'epoch': 0.26}
{'loss': 0.9702, 'grad_norm': 0.5835232609690091, 'learning_rate': 1.7466644330415362e-05, 'epoch': 0.26}
{'loss': 0.9552, 'grad_norm': 0.6234125918225983, 'learning_rate': 1.745834900606692e-05, 'epoch': 0.26}
{'loss': 1.0663, 'grad_norm': 0.7575445466831865, 'learning_rate': 1.7450042099368066e-05, 'epoch': 0.26}
{'loss': 1.0464, 'grad_norm': 0.7700430456417705, 'learning_rate': 1.7441723623218917e-05, 'epoch': 0.26}
{'loss': 1.07, 'grad_norm': 0.7017249601618654, 'learning_rate': 1.7433393590537543e-05, 'epoch': 0.26}
{'loss': 1.0507, 'grad_norm': 0.6185091660753486, 'learning_rate': 1.7425052014259965e-05, 'epoch': 0.26}
{'loss': 1.0194, 'grad_norm': 0.5950374280255533, 'learning_rate': 1.7416698907340128e-05, 'epoch': 0.26}
{'loss': 1.0171, 'grad_norm': 0.68057017671305, 'learning_rate': 1.740833428274989e-05, 'epoch': 0.26}
{'loss': 0.9635, 'grad_norm': 0.6218915780365962, 'learning_rate': 1.739995815347899e-05, 'epoch': 0.26}
{'loss': 1.0323, 'grad_norm': 0.951787727256531, 'learning_rate': 1.739157053253503e-05, 'epoch': 0.26}
{'loss': 1.0806, 'grad_norm': 0.7202876675605869, 'learning_rate': 1.7383171432943466e-05, 'epoch': 0.26}
{'loss': 1.0018, 'grad_norm': 0.5369959454348707, 'learning_rate': 1.7374760867747574e-05, 'epoch': 0.26}
{'loss': 1.0407, 'grad_norm': 0.7318336092995615, 'learning_rate': 1.7366338850008432e-05, 'epoch': 0.26}
{'loss': 1.024, 'grad_norm': 0.7069449417159651, 'learning_rate': 1.7357905392804918e-05, 'epoch': 0.26}
{'loss': 1.0777, 'grad_norm': 0.6759697860704713, 'learning_rate': 1.7349460509233654e-05, 'epoch': 0.26}
{'loss': 1.0597, 'grad_norm': 0.6375899365373922, 'learning_rate': 1.7341004212409026e-05, 'epoch': 0.26}
{'loss': 1.0464, 'grad_norm': 0.5929164184796245, 'learning_rate': 1.7332536515463126e-05, 'epoch': 0.26}
{'loss': 1.0382, 'grad_norm': 0.6849055314916005, 'learning_rate': 1.7324057431545768e-05, 'epoch': 0.26}
{'loss': 1.0629, 'grad_norm': 0.6884472547292326, 'learning_rate': 1.7315566973824433e-05, 'epoch': 0.26}
{'loss': 1.0607, 'grad_norm': 0.9381315502576761, 'learning_rate': 1.730706515548427e-05, 'epoch': 0.26}
{'loss': 1.0085, 'grad_norm': 0.6208700447818668, 'learning_rate': 1.729855198972808e-05, 'epoch': 0.26}
{'loss': 1.0516, 'grad_norm': 0.6685849244807673, 'learning_rate': 1.729002748977628e-05, 'epoch': 0.26}
{'loss': 1.0573, 'grad_norm': 0.6319765467521201, 'learning_rate': 1.7281491668866874e-05, 'epoch': 0.27}
{'loss': 1.0208, 'grad_norm': 0.813173384688696, 'learning_rate': 1.7272944540255468e-05, 'epoch': 0.27}
{'loss': 1.0587, 'grad_norm': 0.7929498389778942, 'learning_rate': 1.7264386117215216e-05, 'epoch': 0.27}
{'loss': 1.0224, 'grad_norm': 0.6590505786234875, 'learning_rate': 1.7255816413036818e-05, 'epoch': 0.27}
{'loss': 1.0718, 'grad_norm': 0.6245121082232035, 'learning_rate': 1.7247235441028486e-05, 'epoch': 0.27}
{'loss': 1.0075, 'grad_norm': 0.6774917305011977, 'learning_rate': 1.7238643214515934e-05, 'epoch': 0.27}
{'loss': 1.0457, 'grad_norm': 0.6070368300489043, 'learning_rate': 1.7230039746842352e-05, 'epoch': 0.27}
{'loss': 1.0774, 'grad_norm': 0.6838884706014944, 'learning_rate': 1.7221425051368394e-05, 'epoch': 0.27}
{'loss': 0.9845, 'grad_norm': 0.603083368940308, 'learning_rate': 1.721279914147214e-05, 'epoch': 0.27}
{'loss': 1.0265, 'grad_norm': 0.6617611289845267, 'learning_rate': 1.7204162030549093e-05, 'epoch': 0.27}
{'loss': 1.0964, 'grad_norm': 0.7597212424661676, 'learning_rate': 1.719551373201214e-05, 'epoch': 0.27}
{'loss': 1.0226, 'grad_norm': 0.8181875060134001, 'learning_rate': 1.7186854259291558e-05, 'epoch': 0.27}
{'loss': 0.9265, 'grad_norm': 0.613377471323283, 'learning_rate': 1.717818362583496e-05, 'epoch': 0.27}
{'loss': 1.0489, 'grad_norm': 0.7655872120696608, 'learning_rate': 1.71695018451073e-05, 'epoch': 0.27}
{'loss': 1.0139, 'grad_norm': 0.5854417211262439, 'learning_rate': 1.7160808930590845e-05, 'epoch': 0.27}
{'loss': 1.0377, 'grad_norm': 0.8558376749821918, 'learning_rate': 1.7152104895785147e-05, 'epoch': 0.27}
{'loss': 0.9829, 'grad_norm': 0.7480077920891904, 'learning_rate': 1.7143389754207026e-05, 'epoch': 0.27}
{'loss': 1.0725, 'grad_norm': 0.6498396225096149, 'learning_rate': 1.7134663519390557e-05, 'epoch': 0.27}
{'loss': 1.0346, 'grad_norm': 0.7137394288484974, 'learning_rate': 1.7125926204887034e-05, 'epoch': 0.27}
{'loss': 1.0537, 'grad_norm': 0.6877807978301521, 'learning_rate': 1.7117177824264962e-05, 'epoch': 0.27}
{'loss': 1.026, 'grad_norm': 0.7468275561260104, 'learning_rate': 1.7108418391110033e-05, 'epoch': 0.27}
{'loss': 1.0722, 'grad_norm': 0.7091203339667894, 'learning_rate': 1.7099647919025096e-05, 'epoch': 0.27}
{'loss': 0.9801, 'grad_norm': 0.6356436293669759, 'learning_rate': 1.709086642163015e-05, 'epoch': 0.27}
{'loss': 0.9766, 'grad_norm': 0.566372168921956, 'learning_rate': 1.708207391256231e-05, 'epoch': 0.27}
{'loss': 1.0363, 'grad_norm': 0.8119511472274226, 'learning_rate': 1.7073270405475796e-05, 'epoch': 0.27}
{'loss': 1.0395, 'grad_norm': 0.6763380915011614, 'learning_rate': 1.70644559140419e-05, 'epoch': 0.27}
{'loss': 1.0409, 'grad_norm': 0.6791366227764568, 'learning_rate': 1.705563045194898e-05, 'epoch': 0.28}
{'loss': 1.0357, 'grad_norm': 0.6984697854402095, 'learning_rate': 1.704679403290243e-05, 'epoch': 0.28}
{'loss': 1.0604, 'grad_norm': 0.6978038804761337, 'learning_rate': 1.7037946670624652e-05, 'epoch': 0.28}
{'loss': 0.9979, 'grad_norm': 0.6416012020898623, 'learning_rate': 1.7029088378855055e-05, 'epoch': 0.28}
{'loss': 1.0666, 'grad_norm': 0.6937030686097252, 'learning_rate': 1.7020219171350004e-05, 'epoch': 0.28}
{'loss': 1.029, 'grad_norm': 0.6630340221908616, 'learning_rate': 1.701133906188283e-05, 'epoch': 0.28}
{'loss': 1.0245, 'grad_norm': 0.6512930692972727, 'learning_rate': 1.700244806424379e-05, 'epoch': 0.28}
{'loss': 1.0559, 'grad_norm': 0.6607613145361414, 'learning_rate': 1.699354619224004e-05, 'epoch': 0.28}
{'loss': 1.0163, 'grad_norm': 0.7195035385209527, 'learning_rate': 1.6984633459695646e-05, 'epoch': 0.28}
{'loss': 1.0174, 'grad_norm': 0.6265600170439196, 'learning_rate': 1.697570988045151e-05, 'epoch': 0.28}
{'loss': 1.0349, 'grad_norm': 0.9385563921230843, 'learning_rate': 1.69667754683654e-05, 'epoch': 0.28}
{'loss': 1.1226, 'grad_norm': 0.7461438903719771, 'learning_rate': 1.6957830237311904e-05, 'epoch': 0.28}
{'loss': 0.9602, 'grad_norm': 0.49076434610489234, 'learning_rate': 1.6948874201182402e-05, 'epoch': 0.28}
{'loss': 1.0166, 'grad_norm': 0.740225310256475, 'learning_rate': 1.6939907373885062e-05, 'epoch': 0.28}
{'loss': 1.0417, 'grad_norm': 0.7600476228292138, 'learning_rate': 1.6930929769344807e-05, 'epoch': 0.28}
{'loss': 1.0531, 'grad_norm': 0.6558193069721996, 'learning_rate': 1.692194140150329e-05, 'epoch': 0.28}
{'loss': 0.9954, 'grad_norm': 0.4882302322911157, 'learning_rate': 1.6912942284318898e-05, 'epoch': 0.28}
{'loss': 1.0317, 'grad_norm': 0.6612717883681241, 'learning_rate': 1.690393243176668e-05, 'epoch': 0.28}
{'loss': 1.0226, 'grad_norm': 0.8060398710397991, 'learning_rate': 1.6894911857838394e-05, 'epoch': 0.28}
{'loss': 0.9918, 'grad_norm': 0.5966822216327022, 'learning_rate': 1.6885880576542417e-05, 'epoch': 0.28}
{'loss': 0.9547, 'grad_norm': 0.590794523329434, 'learning_rate': 1.6876838601903765e-05, 'epoch': 0.28}
{'loss': 1.0548, 'grad_norm': 0.6425702538448843, 'learning_rate': 1.6867785947964065e-05, 'epoch': 0.28}
{'loss': 1.0539, 'grad_norm': 0.7165864875457717, 'learning_rate': 1.685872262878152e-05, 'epoch': 0.28}
{'loss': 1.0611, 'grad_norm': 0.6709473715647655, 'learning_rate': 1.68496486584309e-05, 'epoch': 0.28}
{'loss': 0.9883, 'grad_norm': 0.5952211929495601, 'learning_rate': 1.6840564051003517e-05, 'epoch': 0.28}
{'loss': 1.025, 'grad_norm': 0.6507344713561573, 'learning_rate': 1.6831468820607192e-05, 'epoch': 0.28}
{'loss': 1.0432, 'grad_norm': 0.6909005639527445, 'learning_rate': 1.6822362981366257e-05, 'epoch': 0.29}
{'loss': 1.0917, 'grad_norm': 0.6259679499810875, 'learning_rate': 1.681324654742151e-05, 'epoch': 0.29}
{'loss': 0.9788, 'grad_norm': 0.6486993894007891, 'learning_rate': 1.6804119532930202e-05, 'epoch': 0.29}
{'loss': 1.0909, 'grad_norm': 0.6074966264321537, 'learning_rate': 1.6794981952066018e-05, 'epoch': 0.29}
{'loss': 1.1074, 'grad_norm': 0.6927551857576996, 'learning_rate': 1.6785833819019052e-05, 'epoch': 0.29}
{'loss': 0.9851, 'grad_norm': 0.7205737192454833, 'learning_rate': 1.677667514799578e-05, 'epoch': 0.29}
{'loss': 1.0245, 'grad_norm': 0.9028815397729549, 'learning_rate': 1.676750595321905e-05, 'epoch': 0.29}
{'loss': 1.0528, 'grad_norm': 0.6019263777307088, 'learning_rate': 1.675832624892805e-05, 'epoch': 0.29}
{'loss': 1.0538, 'grad_norm': 0.6286781964599776, 'learning_rate': 1.674913604937828e-05, 'epoch': 0.29}
{'loss': 1.0256, 'grad_norm': 0.6036331894310997, 'learning_rate': 1.6739935368841555e-05, 'epoch': 0.29}
{'loss': 1.0647, 'grad_norm': 0.7935185243334218, 'learning_rate': 1.6730724221605955e-05, 'epoch': 0.29}
{'loss': 1.0524, 'grad_norm': 0.6618451203769097, 'learning_rate': 1.6721502621975813e-05, 'epoch': 0.29}
{'loss': 1.0224, 'grad_norm': 0.6551056371312549, 'learning_rate': 1.6712270584271703e-05, 'epoch': 0.29}
{'loss': 1.0467, 'grad_norm': 0.9424961056581798, 'learning_rate': 1.67030281228304e-05, 'epoch': 0.29}
{'loss': 1.0337, 'grad_norm': 0.7149569365755962, 'learning_rate': 1.6693775252004866e-05, 'epoch': 0.29}
{'loss': 0.9827, 'grad_norm': 0.5737440883215751, 'learning_rate': 1.668451198616424e-05, 'epoch': 0.29}
{'loss': 1.0226, 'grad_norm': 0.6772461296467579, 'learning_rate': 1.667523833969379e-05, 'epoch': 0.29}
{'loss': 1.0845, 'grad_norm': 0.7284852650404654, 'learning_rate': 1.666595432699491e-05, 'epoch': 0.29}
{'loss': 1.0088, 'grad_norm': 0.6614987359753495, 'learning_rate': 1.6656659962485097e-05, 'epoch': 0.29}
{'loss': 0.975, 'grad_norm': 0.5911748105989083, 'learning_rate': 1.6647355260597915e-05, 'epoch': 0.29}
{'loss': 1.0309, 'grad_norm': 0.6590636345368293, 'learning_rate': 1.6638040235782983e-05, 'epoch': 0.29}
{'loss': 1.0408, 'grad_norm': 0.5477713367982489, 'learning_rate': 1.662871490250596e-05, 'epoch': 0.29}
{'loss': 1.0418, 'grad_norm': 0.6254530221903697, 'learning_rate': 1.66193792752485e-05, 'epoch': 0.29}
{'loss': 1.056, 'grad_norm': 0.7269330450596965, 'learning_rate': 1.661003336850825e-05, 'epoch': 0.29}
{'loss': 1.0326, 'grad_norm': 0.7014636941888415, 'learning_rate': 1.660067719679882e-05, 'epoch': 0.29}
{'loss': 1.0775, 'grad_norm': 0.6601736509983228, 'learning_rate': 1.6591310774649766e-05, 'epoch': 0.29}
{'loss': 1.0178, 'grad_norm': 0.7824628360308022, 'learning_rate': 1.6581934116606554e-05, 'epoch': 0.3}
{'loss': 1.0694, 'grad_norm': 0.7047053813080617, 'learning_rate': 1.657254723723054e-05, 'epoch': 0.3}
{'loss': 1.0296, 'grad_norm': 0.7380994230023024, 'learning_rate': 1.6563150151098973e-05, 'epoch': 0.3}
{'loss': 1.0585, 'grad_norm': 0.6377854076789212, 'learning_rate': 1.655374287280494e-05, 'epoch': 0.3}
{'loss': 1.0304, 'grad_norm': 0.7172305777666783, 'learning_rate': 1.654432541695735e-05, 'epoch': 0.3}
{'loss': 1.0144, 'grad_norm': 0.5869729518908663, 'learning_rate': 1.653489779818093e-05, 'epoch': 0.3}
{'loss': 1.0383, 'grad_norm': 0.6440959952766252, 'learning_rate': 1.652546003111618e-05, 'epoch': 0.3}
{'loss': 0.9919, 'grad_norm': 0.6033874931423374, 'learning_rate': 1.6516012130419366e-05, 'epoch': 0.3}
{'loss': 1.0358, 'grad_norm': 0.6600360328191589, 'learning_rate': 1.6506554110762483e-05, 'epoch': 0.3}
{'loss': 0.9732, 'grad_norm': 0.6152014240345752, 'learning_rate': 1.6497085986833252e-05, 'epoch': 0.3}
{'loss': 1.0336, 'grad_norm': 0.7052314702004796, 'learning_rate': 1.6487607773335074e-05, 'epoch': 0.3}
{'loss': 1.028, 'grad_norm': 0.7177162789583019, 'learning_rate': 1.6478119484987026e-05, 'epoch': 0.3}
{'loss': 1.0055, 'grad_norm': 0.6431546177722852, 'learning_rate': 1.6468621136523823e-05, 'epoch': 0.3}
{'loss': 1.0222, 'grad_norm': 0.5205025599459266, 'learning_rate': 1.6459112742695807e-05, 'epoch': 0.3}
{'loss': 0.9757, 'grad_norm': 0.8216090452535448, 'learning_rate': 1.644959431826893e-05, 'epoch': 0.3}
{'loss': 0.9991, 'grad_norm': 0.5617102278667548, 'learning_rate': 1.6440065878024697e-05, 'epoch': 0.3}
{'loss': 1.0355, 'grad_norm': 0.6478101795969619, 'learning_rate': 1.643052743676019e-05, 'epoch': 0.3}
{'loss': 1.0746, 'grad_norm': 0.701935221253157, 'learning_rate': 1.642097900928801e-05, 'epoch': 0.3}
{'loss': 1.0345, 'grad_norm': 0.8574415765401365, 'learning_rate': 1.641142061043627e-05, 'epoch': 0.3}
{'loss': 1.0174, 'grad_norm': 0.6124561169839909, 'learning_rate': 1.6401852255048564e-05, 'epoch': 0.3}
{'loss': 1.0463, 'grad_norm': 0.7440548810079161, 'learning_rate': 1.6392273957983955e-05, 'epoch': 0.3}
{'loss': 1.0494, 'grad_norm': 0.666281409545103, 'learning_rate': 1.6382685734116934e-05, 'epoch': 0.3}
{'loss': 1.0082, 'grad_norm': 0.5988740817353009, 'learning_rate': 1.637308759833742e-05, 'epoch': 0.3}
{'loss': 1.0242, 'grad_norm': 0.6595896121241991, 'learning_rate': 1.636347956555072e-05, 'epoch': 0.3}
{'loss': 1.0016, 'grad_norm': 0.6640185945219595, 'learning_rate': 1.63538616506775e-05, 'epoch': 0.3}
{'loss': 1.0554, 'grad_norm': 0.8007561019420826, 'learning_rate': 1.634423386865379e-05, 'epoch': 0.3}
{'loss': 1.0535, 'grad_norm': 0.7135053132187607, 'learning_rate': 1.633459623443093e-05, 'epoch': 0.31}
{'loss': 1.0402, 'grad_norm': 0.6364179156300149, 'learning_rate': 1.6324948762975567e-05, 'epoch': 0.31}
{'loss': 1.0719, 'grad_norm': 0.6495574656937406, 'learning_rate': 1.6315291469269617e-05, 'epoch': 0.31}
{'loss': 1.0037, 'grad_norm': 0.8015031421304212, 'learning_rate': 1.6305624368310265e-05, 'epoch': 0.31}
{'loss': 1.0457, 'grad_norm': 0.6461319582217047, 'learning_rate': 1.6295947475109904e-05, 'epoch': 0.31}
{'loss': 1.0292, 'grad_norm': 0.7268489121489999, 'learning_rate': 1.628626080469615e-05, 'epoch': 0.31}
{'loss': 1.0203, 'grad_norm': 0.6603049756491235, 'learning_rate': 1.6276564372111797e-05, 'epoch': 0.31}
{'loss': 1.0419, 'grad_norm': 0.7173550154126006, 'learning_rate': 1.62668581924148e-05, 'epoch': 0.31}
{'loss': 1.0135, 'grad_norm': 0.6130770379100645, 'learning_rate': 1.6257142280678247e-05, 'epoch': 0.31}
{'loss': 1.0262, 'grad_norm': 0.616635912750426, 'learning_rate': 1.6247416651990343e-05, 'epoch': 0.31}
{'loss': 1.023, 'grad_norm': 0.5904440814165528, 'learning_rate': 1.6237681321454387e-05, 'epoch': 0.31}
{'loss': 1.0005, 'grad_norm': 0.6430746266622328, 'learning_rate': 1.6227936304188738e-05, 'epoch': 0.31}
{'loss': 0.9947, 'grad_norm': 0.6071582936714575, 'learning_rate': 1.6218181615326795e-05, 'epoch': 0.31}
{'loss': 1.0024, 'grad_norm': 0.6156033182592079, 'learning_rate': 1.620841727001699e-05, 'epoch': 0.31}
{'loss': 1.0069, 'grad_norm': 0.6301335673882701, 'learning_rate': 1.619864328342273e-05, 'epoch': 0.31}
{'loss': 0.9254, 'grad_norm': 0.52868411983304, 'learning_rate': 1.6188859670722414e-05, 'epoch': 0.31}
{'loss': 1.0549, 'grad_norm': 0.7567248662331858, 'learning_rate': 1.6179066447109376e-05, 'epoch': 0.31}
{'loss': 0.9668, 'grad_norm': 0.5959608518525223, 'learning_rate': 1.6169263627791886e-05, 'epoch': 0.31}
{'loss': 1.0445, 'grad_norm': 0.6403446290059777, 'learning_rate': 1.615945122799311e-05, 'epoch': 0.31}
{'loss': 0.9882, 'grad_norm': 0.638495526547517, 'learning_rate': 1.614962926295109e-05, 'epoch': 0.31}
{'loss': 1.0548, 'grad_norm': 0.6383085476461366, 'learning_rate': 1.6139797747918725e-05, 'epoch': 0.31}
{'loss': 0.9971, 'grad_norm': 0.6582267771841166, 'learning_rate': 1.612995669816375e-05, 'epoch': 0.31}
{'loss': 1.0407, 'grad_norm': 0.7992469036343585, 'learning_rate': 1.6120106128968686e-05, 'epoch': 0.31}
{'loss': 1.0522, 'grad_norm': 0.5987617457983763, 'learning_rate': 1.611024605563087e-05, 'epoch': 0.31}
{'loss': 1.0224, 'grad_norm': 0.5913647647164563, 'learning_rate': 1.6100376493462368e-05, 'epoch': 0.31}
{'loss': 1.0208, 'grad_norm': 0.7104862459396072, 'learning_rate': 1.609049745779e-05, 'epoch': 0.31}
{'loss': 1.0182, 'grad_norm': 0.5670721084586159, 'learning_rate': 1.608060896395529e-05, 'epoch': 0.32}
{'loss': 1.0267, 'grad_norm': 0.653418358198294, 'learning_rate': 1.6070711027314446e-05, 'epoch': 0.32}
{'loss': 1.0157, 'grad_norm': 0.5847048807411045, 'learning_rate': 1.6060803663238357e-05, 'epoch': 0.32}
{'loss': 0.9794, 'grad_norm': 0.5365063679336561, 'learning_rate': 1.6050886887112535e-05, 'epoch': 0.32}
{'loss': 0.9289, 'grad_norm': 0.5395780609153045, 'learning_rate': 1.604096071433711e-05, 'epoch': 0.32}
{'loss': 1.0246, 'grad_norm': 0.642043101948626, 'learning_rate': 1.6031025160326814e-05, 'epoch': 0.32}
{'loss': 1.0313, 'grad_norm': 0.6005916495788423, 'learning_rate': 1.6021080240510943e-05, 'epoch': 0.32}
{'loss': 1.0369, 'grad_norm': 0.6116419855815607, 'learning_rate': 1.6011125970333333e-05, 'epoch': 0.32}
{'loss': 1.0052, 'grad_norm': 0.8492847429260697, 'learning_rate': 1.6001162365252348e-05, 'epoch': 0.32}
{'loss': 0.9882, 'grad_norm': 0.6722796129941255, 'learning_rate': 1.5991189440740838e-05, 'epoch': 0.32}
{'loss': 1.0535, 'grad_norm': 0.6788835297602154, 'learning_rate': 1.598120721228614e-05, 'epoch': 0.32}
{'loss': 1.003, 'grad_norm': 0.6262162574051855, 'learning_rate': 1.5971215695390026e-05, 'epoch': 0.32}
{'loss': 1.0267, 'grad_norm': 0.6429803573332119, 'learning_rate': 1.5961214905568705e-05, 'epoch': 0.32}
{'loss': 1.0563, 'grad_norm': 0.7169491868104276, 'learning_rate': 1.5951204858352772e-05, 'epoch': 0.32}
{'loss': 0.9604, 'grad_norm': 0.5833894029472556, 'learning_rate': 1.5941185569287206e-05, 'epoch': 0.32}
{'loss': 1.0261, 'grad_norm': 0.6195511478045364, 'learning_rate': 1.593115705393134e-05, 'epoch': 0.32}
{'loss': 0.9826, 'grad_norm': 0.6918660253771649, 'learning_rate': 1.5921119327858835e-05, 'epoch': 0.32}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B00XIZWWNC.jpg, using default black image.
{'loss': 1.0686, 'grad_norm': 0.68993374839641, 'learning_rate': 1.5911072406657646e-05, 'epoch': 0.32}
{'loss': 1.0313, 'grad_norm': 0.7038489248044336, 'learning_rate': 1.590101630593002e-05, 'epoch': 0.32}
{'loss': 1.0282, 'grad_norm': 0.6496183461845372, 'learning_rate': 1.5890951041292453e-05, 'epoch': 0.32}
{'loss': 1.0355, 'grad_norm': 0.6564892054706524, 'learning_rate': 1.5880876628375668e-05, 'epoch': 0.32}
{'loss': 0.9457, 'grad_norm': 0.7099913662186039, 'learning_rate': 1.5870793082824604e-05, 'epoch': 0.32}
{'loss': 1.0528, 'grad_norm': 0.6895794631160992, 'learning_rate': 1.5860700420298377e-05, 'epoch': 0.32}
{'loss': 1.0038, 'grad_norm': 0.6654874538991506, 'learning_rate': 1.5850598656470265e-05, 'epoch': 0.32}
{'loss': 1.0329, 'grad_norm': 0.683010226650052, 'learning_rate': 1.5840487807027665e-05, 'epoch': 0.32}
{'loss': 0.9589, 'grad_norm': 0.700849180808656, 'learning_rate': 1.583036788767211e-05, 'epoch': 0.32}
{'loss': 1.0156, 'grad_norm': 0.7012519223138362, 'learning_rate': 1.5820238914119195e-05, 'epoch': 0.33}
{'loss': 1.0679, 'grad_norm': 0.679356234149585, 'learning_rate': 1.5810100902098582e-05, 'epoch': 0.33}
{'loss': 1.0447, 'grad_norm': 0.7710342090934473, 'learning_rate': 1.5799953867353975e-05, 'epoch': 0.33}
{'loss': 1.0116, 'grad_norm': 0.6355636615812728, 'learning_rate': 1.5789797825643086e-05, 'epoch': 0.33}
{'loss': 1.0254, 'grad_norm': 0.6042141551595931, 'learning_rate': 1.5779632792737608e-05, 'epoch': 0.33}
{'loss': 1.0121, 'grad_norm': 0.6173766661569375, 'learning_rate': 1.5769458784423206e-05, 'epoch': 0.33}
{'loss': 1.0357, 'grad_norm': 0.615676742321625, 'learning_rate': 1.575927581649948e-05, 'epoch': 0.33}
{'loss': 0.9822, 'grad_norm': 0.6724105820821091, 'learning_rate': 1.574908390477995e-05, 'epoch': 0.33}
{'loss': 1.0579, 'grad_norm': 0.6762192497300444, 'learning_rate': 1.5738883065092005e-05, 'epoch': 0.33}
{'loss': 1.001, 'grad_norm': 0.5944410794339222, 'learning_rate': 1.572867331327692e-05, 'epoch': 0.33}
{'loss': 0.9536, 'grad_norm': 0.6159654573202986, 'learning_rate': 1.5718454665189806e-05, 'epoch': 0.33}
{'loss': 1.0164, 'grad_norm': 0.7032377389419299, 'learning_rate': 1.5708227136699578e-05, 'epoch': 0.33}
{'loss': 1.0523, 'grad_norm': 0.6085768863271752, 'learning_rate': 1.569799074368895e-05, 'epoch': 0.33}
{'loss': 1.0789, 'grad_norm': 0.6304371505735171, 'learning_rate': 1.5687745502054407e-05, 'epoch': 0.33}
{'loss': 1.0447, 'grad_norm': 0.644376461256362, 'learning_rate': 1.567749142770617e-05, 'epoch': 0.33}
{'loss': 1.0037, 'grad_norm': 0.6536283126162018, 'learning_rate': 1.5667228536568167e-05, 'epoch': 0.33}
{'loss': 1.0003, 'grad_norm': 0.594262288276893, 'learning_rate': 1.565695684457803e-05, 'epoch': 0.33}
{'loss': 0.9983, 'grad_norm': 0.708874800556974, 'learning_rate': 1.5646676367687067e-05, 'epoch': 0.33}
{'loss': 1.0224, 'grad_norm': 0.6293878305486622, 'learning_rate': 1.5636387121860207e-05, 'epoch': 0.33}
{'loss': 1.0751, 'grad_norm': 0.7849709586224458, 'learning_rate': 1.5626089123076004e-05, 'epoch': 0.33}
{'loss': 1.0374, 'grad_norm': 0.676867288864616, 'learning_rate': 1.561578238732661e-05, 'epoch': 0.33}
{'loss': 1.0408, 'grad_norm': 0.7052038711047849, 'learning_rate': 1.5605466930617747e-05, 'epoch': 0.33}
{'loss': 1.0805, 'grad_norm': 0.7750261289162643, 'learning_rate': 1.559514276896867e-05, 'epoch': 0.33}
{'loss': 1.0315, 'grad_norm': 0.7263666589257308, 'learning_rate': 1.5584809918412158e-05, 'epoch': 0.33}
{'loss': 1.0595, 'grad_norm': 0.7022842508734469, 'learning_rate': 1.5574468394994486e-05, 'epoch': 0.33}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B00XLZW19O.jpg, using default black image.
{'loss': 1.0135, 'grad_norm': 0.6906066736837777, 'learning_rate': 1.556411821477539e-05, 'epoch': 0.33}
{'loss': 1.0444, 'grad_norm': 0.8586205619477189, 'learning_rate': 1.5553759393828058e-05, 'epoch': 0.34}
{'loss': 1.0331, 'grad_norm': 0.691597058000698, 'learning_rate': 1.554339194823909e-05, 'epoch': 0.34}
{'loss': 1.1107, 'grad_norm': 0.7950012825529754, 'learning_rate': 1.553301589410848e-05, 'epoch': 0.34}
{'loss': 1.0444, 'grad_norm': 0.6695239574769489, 'learning_rate': 1.5522631247549598e-05, 'epoch': 0.34}
{'loss': 0.9895, 'grad_norm': 0.559765019293593, 'learning_rate': 1.5512238024689144e-05, 'epoch': 0.34}
{'loss': 1.0439, 'grad_norm': 0.6787759902976854, 'learning_rate': 1.550183624166715e-05, 'epoch': 0.34}
{'loss': 0.9708, 'grad_norm': 0.5460843663769529, 'learning_rate': 1.5491425914636934e-05, 'epoch': 0.34}
{'loss': 1.0501, 'grad_norm': 0.676781195536997, 'learning_rate': 1.548100705976508e-05, 'epoch': 0.34}
{'loss': 0.9983, 'grad_norm': 0.6178552200388209, 'learning_rate': 1.5470579693231432e-05, 'epoch': 0.34}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/7503145099.jpg, using default black image.
{'loss': 1.0595, 'grad_norm': 0.6412289266389256, 'learning_rate': 1.5460143831229026e-05, 'epoch': 0.34}
{'loss': 1.006, 'grad_norm': 0.6955505484452242, 'learning_rate': 1.544969948996411e-05, 'epoch': 0.34}
{'loss': 1.0626, 'grad_norm': 0.7867888646716183, 'learning_rate': 1.5439246685656093e-05, 'epoch': 0.34}
{'loss': 1.0026, 'grad_norm': 0.6321767929354977, 'learning_rate': 1.5428785434537527e-05, 'epoch': 0.34}
{'loss': 1.0548, 'grad_norm': 0.6220262932262938, 'learning_rate': 1.541831575285408e-05, 'epoch': 0.34}
{'loss': 1.0529, 'grad_norm': 0.8043145515640643, 'learning_rate': 1.540783765686452e-05, 'epoch': 0.34}
{'loss': 1.0142, 'grad_norm': 0.7302891330683139, 'learning_rate': 1.539735116284067e-05, 'epoch': 0.34}
{'loss': 1.0189, 'grad_norm': 0.5662765487401931, 'learning_rate': 1.53868562870674e-05, 'epoch': 0.34}
{'loss': 1.0399, 'grad_norm': 0.6674401178739328, 'learning_rate': 1.5376353045842604e-05, 'epoch': 0.34}
{'loss': 1.024, 'grad_norm': 0.7240566429991597, 'learning_rate': 1.5365841455477158e-05, 'epoch': 0.34}
{'loss': 1.0095, 'grad_norm': 0.6493579481593151, 'learning_rate': 1.5355321532294897e-05, 'epoch': 0.34}
{'loss': 1.0566, 'grad_norm': 0.6685638379015726, 'learning_rate': 1.5344793292632614e-05, 'epoch': 0.34}
{'loss': 1.0538, 'grad_norm': 0.717106990576832, 'learning_rate': 1.5334256752840007e-05, 'epoch': 0.34}
{'loss': 1.0181, 'grad_norm': 0.644197277829697, 'learning_rate': 1.532371192927966e-05, 'epoch': 0.34}
{'loss': 1.025, 'grad_norm': 0.6324450375945606, 'learning_rate': 1.531315883832703e-05, 'epoch': 0.34}
{'loss': 1.0639, 'grad_norm': 0.77092208961409, 'learning_rate': 1.5302597496370408e-05, 'epoch': 0.34}
{'loss': 1.0352, 'grad_norm': 0.669045549982356, 'learning_rate': 1.5292027919810898e-05, 'epoch': 0.34}
{'loss': 0.9909, 'grad_norm': 0.591243357172302, 'learning_rate': 1.528145012506239e-05, 'epoch': 0.35}
{'loss': 1.0541, 'grad_norm': 0.625374186070888, 'learning_rate': 1.5270864128551542e-05, 'epoch': 0.35}
{'loss': 1.0658, 'grad_norm': 0.6140162676256526, 'learning_rate': 1.5260269946717746e-05, 'epoch': 0.35}
{'loss': 1.0591, 'grad_norm': 0.6889990794903965, 'learning_rate': 1.5249667596013102e-05, 'epoch': 0.35}
{'loss': 0.9553, 'grad_norm': 0.5281399797981602, 'learning_rate': 1.5239057092902404e-05, 'epoch': 0.35}
{'loss': 1.0132, 'grad_norm': 0.4887908422921261, 'learning_rate': 1.5228438453863095e-05, 'epoch': 0.35}
{'loss': 0.9931, 'grad_norm': 1.165161470659745, 'learning_rate': 1.5217811695385263e-05, 'epoch': 0.35}
{'loss': 1.0059, 'grad_norm': 0.6408020665260992, 'learning_rate': 1.5207176833971598e-05, 'epoch': 0.35}
{'loss': 1.006, 'grad_norm': 0.6254213130109775, 'learning_rate': 1.5196533886137376e-05, 'epoch': 0.35}
{'loss': 1.0477, 'grad_norm': 0.7900529090020757, 'learning_rate': 1.5185882868410431e-05, 'epoch': 0.35}
{'loss': 1.0414, 'grad_norm': 0.6341044457823676, 'learning_rate': 1.517522379733113e-05, 'epoch': 0.35}
{'loss': 1.0449, 'grad_norm': 0.7558212699070208, 'learning_rate': 1.5164556689452346e-05, 'epoch': 0.35}
{'loss': 1.0398, 'grad_norm': 0.6868692384490322, 'learning_rate': 1.5153881561339426e-05, 'epoch': 0.35}
{'loss': 0.9988, 'grad_norm': 0.6339175617137094, 'learning_rate': 1.5143198429570181e-05, 'epoch': 0.35}
{'loss': 1.0522, 'grad_norm': 0.6305982578292554, 'learning_rate': 1.5132507310734847e-05, 'epoch': 0.35}
{'loss': 0.9951, 'grad_norm': 0.7348280119088334, 'learning_rate': 1.512180822143607e-05, 'epoch': 0.35}
{'loss': 1.0755, 'grad_norm': 0.6298805297142472, 'learning_rate': 1.5111101178288858e-05, 'epoch': 0.35}
{'loss': 1.0345, 'grad_norm': 0.6308427325332511, 'learning_rate': 1.5100386197920585e-05, 'epoch': 0.35}
{'loss': 0.9846, 'grad_norm': 0.6522538309813382, 'learning_rate': 1.5089663296970952e-05, 'epoch': 0.35}
{'loss': 1.0217, 'grad_norm': 0.7747905471418632, 'learning_rate': 1.5078932492091942e-05, 'epoch': 0.35}
{'loss': 1.05, 'grad_norm': 0.7051565058462588, 'learning_rate': 1.506819379994784e-05, 'epoch': 0.35}
{'loss': 1.0191, 'grad_norm': 0.6062349937567342, 'learning_rate': 1.5057447237215152e-05, 'epoch': 0.35}
{'loss': 1.062, 'grad_norm': 0.7915249104881865, 'learning_rate': 1.5046692820582625e-05, 'epoch': 0.35}
{'loss': 1.0044, 'grad_norm': 0.5569247511841974, 'learning_rate': 1.5035930566751198e-05, 'epoch': 0.35}
{'loss': 0.9673, 'grad_norm': 0.5190856778281258, 'learning_rate': 1.5025160492433976e-05, 'epoch': 0.35}
{'loss': 1.0553, 'grad_norm': 0.5910425898639451, 'learning_rate': 1.5014382614356213e-05, 'epoch': 0.35}
{'loss': 1.0711, 'grad_norm': 0.6979346422669129, 'learning_rate': 1.5003596949255284e-05, 'epoch': 0.36}
{'loss': 1.0188, 'grad_norm': 0.6007299598013282, 'learning_rate': 1.499280351388065e-05, 'epoch': 0.36}
{'loss': 1.0569, 'grad_norm': 0.6857809476885325, 'learning_rate': 1.498200232499384e-05, 'epoch': 0.36}
{'loss': 1.0489, 'grad_norm': 0.6164841218505749, 'learning_rate': 1.497119339936843e-05, 'epoch': 0.36}
{'loss': 0.9826, 'grad_norm': 0.6506211387523044, 'learning_rate': 1.496037675379001e-05, 'epoch': 0.36}
{'loss': 1.0038, 'grad_norm': 0.6787079320727597, 'learning_rate': 1.494955240505615e-05, 'epoch': 0.36}
{'loss': 1.0387, 'grad_norm': 0.659269815709303, 'learning_rate': 1.4938720369976385e-05, 'epoch': 0.36}
{'loss': 0.975, 'grad_norm': 0.584605283831487, 'learning_rate': 1.4927880665372197e-05, 'epoch': 0.36}
{'loss': 0.983, 'grad_norm': 0.6496794498178543, 'learning_rate': 1.4917033308076967e-05, 'epoch': 0.36}
{'loss': 1.0115, 'grad_norm': 0.6089369108670133, 'learning_rate': 1.490617831493596e-05, 'epoch': 0.36}
{'loss': 1.0696, 'grad_norm': 0.6765327863748698, 'learning_rate': 1.489531570280631e-05, 'epoch': 0.36}
{'loss': 1.0032, 'grad_norm': 0.5246630271524799, 'learning_rate': 1.4884445488556972e-05, 'epoch': 0.36}
{'loss': 0.9958, 'grad_norm': 0.5455394047715547, 'learning_rate': 1.4873567689068708e-05, 'epoch': 0.36}
{'loss': 1.0349, 'grad_norm': 0.6670227870128881, 'learning_rate': 1.4862682321234064e-05, 'epoch': 0.36}
{'loss': 0.9485, 'grad_norm': 0.6113635256484945, 'learning_rate': 1.4851789401957338e-05, 'epoch': 0.36}
{'loss': 1.0245, 'grad_norm': 0.6834252874722647, 'learning_rate': 1.484088894815455e-05, 'epoch': 0.36}
{'loss': 1.0311, 'grad_norm': 0.6755358102820957, 'learning_rate': 1.4829980976753426e-05, 'epoch': 0.36}
{'loss': 0.9898, 'grad_norm': 0.6118676143100829, 'learning_rate': 1.4819065504693365e-05, 'epoch': 0.36}
{'loss': 1.0012, 'grad_norm': 0.6896171420691666, 'learning_rate': 1.4808142548925417e-05, 'epoch': 0.36}
{'loss': 0.9704, 'grad_norm': 0.5565580413115702, 'learning_rate': 1.4797212126412243e-05, 'epoch': 0.36}
{'loss': 1.0365, 'grad_norm': 0.7431268945605842, 'learning_rate': 1.4786274254128112e-05, 'epoch': 0.36}
{'loss': 1.0432, 'grad_norm': 0.6258052676935871, 'learning_rate': 1.4775328949058856e-05, 'epoch': 0.36}
{'loss': 1.0176, 'grad_norm': 0.6128183452020007, 'learning_rate': 1.4764376228201848e-05, 'epoch': 0.36}
{'loss': 0.9972, 'grad_norm': 0.7233508907711577, 'learning_rate': 1.4753416108565985e-05, 'epoch': 0.36}
{'loss': 0.9754, 'grad_norm': 0.6165733531410976, 'learning_rate': 1.4742448607171644e-05, 'epoch': 0.36}
{'loss': 1.0301, 'grad_norm': 0.640536133810166, 'learning_rate': 1.4731473741050673e-05, 'epoch': 0.36}
{'loss': 1.0512, 'grad_norm': 0.6854880202305382, 'learning_rate': 1.472049152724635e-05, 'epoch': 0.37}
{'loss': 1.0183, 'grad_norm': 0.8533557899589735, 'learning_rate': 1.470950198281337e-05, 'epoch': 0.37}
{'loss': 0.9961, 'grad_norm': 0.6463560700307635, 'learning_rate': 1.4698505124817811e-05, 'epoch': 0.37}
{'loss': 1.0238, 'grad_norm': 0.6048216815047492, 'learning_rate': 1.4687500970337103e-05, 'epoch': 0.37}
{'loss': 1.0221, 'grad_norm': 0.6322443850280474, 'learning_rate': 1.4676489536460015e-05, 'epoch': 0.37}
{'loss': 1.0111, 'grad_norm': 0.5751841018162253, 'learning_rate': 1.4665470840286614e-05, 'epoch': 0.37}
{'loss': 0.9361, 'grad_norm': 0.6707366835278444, 'learning_rate': 1.4654444898928249e-05, 'epoch': 0.37}
{'loss': 1.071, 'grad_norm': 0.6798726056530225, 'learning_rate': 1.4643411729507517e-05, 'epoch': 0.37}
{'loss': 0.9739, 'grad_norm': 0.7714225004485951, 'learning_rate': 1.4632371349158241e-05, 'epoch': 0.37}
{'loss': 0.9876, 'grad_norm': 0.5883021406799448, 'learning_rate': 1.4621323775025444e-05, 'epoch': 0.37}
{'loss': 1.003, 'grad_norm': 0.5168305527242757, 'learning_rate': 1.4610269024265317e-05, 'epoch': 0.37}
{'loss': 1.0086, 'grad_norm': 0.6035809274541322, 'learning_rate': 1.4599207114045202e-05, 'epoch': 0.37}
{'loss': 0.9667, 'grad_norm': 0.6435490463186108, 'learning_rate': 1.4588138061543551e-05, 'epoch': 0.37}
{'loss': 0.9568, 'grad_norm': 0.633668031594375, 'learning_rate': 1.4577061883949912e-05, 'epoch': 0.37}
{'loss': 1.0091, 'grad_norm': 0.6205897816566852, 'learning_rate': 1.4565978598464895e-05, 'epoch': 0.37}
{'loss': 1.0571, 'grad_norm': 0.6070703532018585, 'learning_rate': 1.455488822230016e-05, 'epoch': 0.37}
{'loss': 0.9942, 'grad_norm': 0.6526657382344639, 'learning_rate': 1.454379077267836e-05, 'epoch': 0.37}
{'loss': 1.0177, 'grad_norm': 0.6444757001544428, 'learning_rate': 1.4532686266833143e-05, 'epoch': 0.37}
{'loss': 1.015, 'grad_norm': 0.5951681327505296, 'learning_rate': 1.4521574722009115e-05, 'epoch': 0.37}
{'loss': 1.0634, 'grad_norm': 0.7526285887949645, 'learning_rate': 1.4510456155461807e-05, 'epoch': 0.37}
{'loss': 1.013, 'grad_norm': 0.6048495364457335, 'learning_rate': 1.4499330584457667e-05, 'epoch': 0.37}
{'loss': 1.0549, 'grad_norm': 0.6593299669062531, 'learning_rate': 1.4488198026274007e-05, 'epoch': 0.37}
{'loss': 1.0547, 'grad_norm': 0.5845154489902996, 'learning_rate': 1.4477058498198993e-05, 'epoch': 0.37}
{'loss': 1.0414, 'grad_norm': 0.6573251761770388, 'learning_rate': 1.446591201753162e-05, 'epoch': 0.37}
{'loss': 0.947, 'grad_norm': 0.5437585104659637, 'learning_rate': 1.4454758601581675e-05, 'epoch': 0.37}
{'loss': 1.0352, 'grad_norm': 0.6783086011286077, 'learning_rate': 1.4443598267669723e-05, 'epoch': 0.37}
{'loss': 1.0525, 'grad_norm': 0.6268065411816888, 'learning_rate': 1.4432431033127056e-05, 'epoch': 0.38}
{'loss': 0.9956, 'grad_norm': 0.5869340261560289, 'learning_rate': 1.4421256915295697e-05, 'epoch': 0.38}
{'loss': 1.0367, 'grad_norm': 0.6221025946434058, 'learning_rate': 1.4410075931528356e-05, 'epoch': 0.38}
{'loss': 1.0215, 'grad_norm': 0.5906780719527885, 'learning_rate': 1.4398888099188396e-05, 'epoch': 0.38}
{'loss': 1.0084, 'grad_norm': 0.574222851006929, 'learning_rate': 1.4387693435649826e-05, 'epoch': 0.38}
{'loss': 1.0192, 'grad_norm': 0.6348027785481283, 'learning_rate': 1.4376491958297263e-05, 'epoch': 0.38}
{'loss': 1.0053, 'grad_norm': 0.601758083279067, 'learning_rate': 1.4365283684525895e-05, 'epoch': 0.38}
{'loss': 1.0396, 'grad_norm': 0.6094975571495733, 'learning_rate': 1.4354068631741476e-05, 'epoch': 0.38}
{'loss': 1.0077, 'grad_norm': 0.66193259765665, 'learning_rate': 1.434284681736028e-05, 'epoch': 0.38}
{'loss': 1.0164, 'grad_norm': 0.650877631743223, 'learning_rate': 1.433161825880909e-05, 'epoch': 0.38}
{'loss': 0.9901, 'grad_norm': 0.6401076312102452, 'learning_rate': 1.4320382973525151e-05, 'epoch': 0.38}
{'loss': 1.0383, 'grad_norm': 0.7415981693413874, 'learning_rate': 1.4309140978956161e-05, 'epoch': 0.38}
{'loss': 0.982, 'grad_norm': 0.67820563828536, 'learning_rate': 1.429789229256024e-05, 'epoch': 0.38}
{'loss': 1.0299, 'grad_norm': 0.7908047819405596, 'learning_rate': 1.4286636931805887e-05, 'epoch': 0.38}
{'loss': 1.0149, 'grad_norm': 0.7345207157516542, 'learning_rate': 1.427537491417198e-05, 'epoch': 0.38}
{'loss': 1.0619, 'grad_norm': 0.6539191474883157, 'learning_rate': 1.4264106257147732e-05, 'epoch': 0.38}
{'loss': 1.0561, 'grad_norm': 0.7438486445297787, 'learning_rate': 1.4252830978232658e-05, 'epoch': 0.38}
{'loss': 0.9787, 'grad_norm': 0.531746137719034, 'learning_rate': 1.4241549094936567e-05, 'epoch': 0.38}
{'loss': 1.0259, 'grad_norm': 0.6661012343633183, 'learning_rate': 1.4230260624779512e-05, 'epoch': 0.38}
{'loss': 0.9847, 'grad_norm': 0.6048869903526831, 'learning_rate': 1.4218965585291792e-05, 'epoch': 0.38}
{'loss': 1.0541, 'grad_norm': 0.6627053501761677, 'learning_rate': 1.4207663994013896e-05, 'epoch': 0.38}
{'loss': 1.0337, 'grad_norm': 0.6284848437154618, 'learning_rate': 1.4196355868496485e-05, 'epoch': 0.38}
{'loss': 1.0384, 'grad_norm': 0.5849796914792935, 'learning_rate': 1.4185041226300376e-05, 'epoch': 0.38}
{'loss': 1.0112, 'grad_norm': 0.6201834600467415, 'learning_rate': 1.4173720084996501e-05, 'epoch': 0.38}
{'loss': 0.9674, 'grad_norm': 0.639315852572455, 'learning_rate': 1.4162392462165884e-05, 'epoch': 0.38}
{'loss': 0.9531, 'grad_norm': 0.6348356633173592, 'learning_rate': 1.415105837539962e-05, 'epoch': 0.38}
{'loss': 1.0105, 'grad_norm': 0.60863992282451, 'learning_rate': 1.4139717842298835e-05, 'epoch': 0.39}
{'loss': 0.9904, 'grad_norm': 0.6210778926711656, 'learning_rate': 1.4128370880474667e-05, 'epoch': 0.39}
{'loss': 1.0083, 'grad_norm': 0.6897224228912343, 'learning_rate': 1.4117017507548244e-05, 'epoch': 0.39}
{'loss': 0.9957, 'grad_norm': 0.6084196058311415, 'learning_rate': 1.4105657741150648e-05, 'epoch': 0.39}
{'loss': 0.998, 'grad_norm': 0.596978064981128, 'learning_rate': 1.4094291598922877e-05, 'epoch': 0.39}
{'loss': 1.016, 'grad_norm': 0.3275518049182238, 'learning_rate': 1.4082919098515846e-05, 'epoch': 0.39}
{'loss': 1.0077, 'grad_norm': 0.6104076249576056, 'learning_rate': 1.4071540257590341e-05, 'epoch': 0.39}
{'loss': 1.0071, 'grad_norm': 0.5617570413616636, 'learning_rate': 1.4060155093816988e-05, 'epoch': 0.39}
{'loss': 1.0016, 'grad_norm': 0.8161053622560777, 'learning_rate': 1.4048763624876233e-05, 'epoch': 0.39}
{'loss': 1.054, 'grad_norm': 0.764515087503207, 'learning_rate': 1.4037365868458325e-05, 'epoch': 0.39}
{'loss': 0.9742, 'grad_norm': 0.6835054057398618, 'learning_rate': 1.402596184226326e-05, 'epoch': 0.39}
{'loss': 1.0558, 'grad_norm': 0.6619075026319146, 'learning_rate': 1.401455156400078e-05, 'epoch': 0.39}
{'loss': 0.982, 'grad_norm': 0.5768333085745184, 'learning_rate': 1.400313505139034e-05, 'epoch': 0.39}
{'loss': 0.9776, 'grad_norm': 0.6215288836971921, 'learning_rate': 1.3991712322161065e-05, 'epoch': 0.39}
{'loss': 1.0366, 'grad_norm': 0.6363240847666564, 'learning_rate': 1.398028339405174e-05, 'epoch': 0.39}
{'loss': 0.9242, 'grad_norm': 0.7376800642893102, 'learning_rate': 1.3968848284810785e-05, 'epoch': 0.39}
{'loss': 0.9468, 'grad_norm': 0.6214277670930031, 'learning_rate': 1.3957407012196204e-05, 'epoch': 0.39}
{'loss': 0.9959, 'grad_norm': 0.650844810964957, 'learning_rate': 1.3945959593975582e-05, 'epoch': 0.39}
{'loss': 1.0062, 'grad_norm': 0.6104949782337764, 'learning_rate': 1.3934506047926042e-05, 'epoch': 0.39}
{'loss': 1.0728, 'grad_norm': 0.6506624363134155, 'learning_rate': 1.3923046391834229e-05, 'epoch': 0.39}
{'loss': 0.9948, 'grad_norm': 0.5932608645886739, 'learning_rate': 1.3911580643496272e-05, 'epoch': 0.39}
{'loss': 1.0159, 'grad_norm': 0.6673730533613448, 'learning_rate': 1.390010882071776e-05, 'epoch': 0.39}
{'loss': 1.0549, 'grad_norm': 0.5885054922531989, 'learning_rate': 1.3888630941313728e-05, 'epoch': 0.39}
{'loss': 1.0179, 'grad_norm': 0.6060312572245198, 'learning_rate': 1.3877147023108592e-05, 'epoch': 0.39}
{'loss': 1.0191, 'grad_norm': 0.6590315322107885, 'learning_rate': 1.3865657083936167e-05, 'epoch': 0.39}
{'loss': 1.0262, 'grad_norm': 0.849569990974223, 'learning_rate': 1.385416114163961e-05, 'epoch': 0.39}
{'loss': 1.0193, 'grad_norm': 0.5799031150193823, 'learning_rate': 1.3842659214071406e-05, 'epoch': 0.4}
{'loss': 0.9986, 'grad_norm': 0.8790338080602151, 'learning_rate': 1.3831151319093323e-05, 'epoch': 0.4}
{'loss': 1.0185, 'grad_norm': 0.6293191492657791, 'learning_rate': 1.3819637474576411e-05, 'epoch': 0.4}
{'loss': 1.0313, 'grad_norm': 0.7178721715270943, 'learning_rate': 1.380811769840095e-05, 'epoch': 0.4}
{'loss': 1.043, 'grad_norm': 0.6517635571738745, 'learning_rate': 1.3796592008456427e-05, 'epoch': 0.4}
{'loss': 0.9615, 'grad_norm': 0.5605005660912199, 'learning_rate': 1.3785060422641526e-05, 'epoch': 0.4}
{'loss': 0.9926, 'grad_norm': 0.7037965681938166, 'learning_rate': 1.3773522958864076e-05, 'epoch': 0.4}
{'loss': 1.0287, 'grad_norm': 0.6311031723469052, 'learning_rate': 1.376197963504104e-05, 'epoch': 0.4}
{'loss': 1.0497, 'grad_norm': 0.6689856920290499, 'learning_rate': 1.375043046909848e-05, 'epoch': 0.4}
{'loss': 1.0244, 'grad_norm': 0.7200436990973716, 'learning_rate': 1.3738875478971526e-05, 'epoch': 0.4}
{'loss': 1.0317, 'grad_norm': 0.6091630856497726, 'learning_rate': 1.372731468260436e-05, 'epoch': 0.4}
{'loss': 0.9878, 'grad_norm': 0.5194671792535407, 'learning_rate': 1.3715748097950176e-05, 'epoch': 0.4}
{'loss': 1.0021, 'grad_norm': 0.6324491456013251, 'learning_rate': 1.3704175742971158e-05, 'epoch': 0.4}
{'loss': 1.041, 'grad_norm': 0.7540782511902544, 'learning_rate': 1.3692597635638452e-05, 'epoch': 0.4}
{'loss': 0.9797, 'grad_norm': 0.5640420232910154, 'learning_rate': 1.3681013793932132e-05, 'epoch': 0.4}
{'loss': 1.0363, 'grad_norm': 0.770449157417508, 'learning_rate': 1.3669424235841185e-05, 'epoch': 0.4}
WARNING: tokenization mismatch: 0 vs. 1595. (ignored)
number of rounds:  2
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: Du bist eine auf Kundenfeedback spezialisierte Agentur mit den folgenden Kenntnissen und Eigenschaften.\n\nKENNTNISSE: Kundenfeedback, wissenschaftliche Datenerhebung, Fragebogendesign, Benutzerfreundlichkeit, Kundenbindung, Service-Qualittsevaluation.\n\nEIGENSCHAFTEN: Przision, Effizienz, Empathie, Anpassungsfhigkeit, Datenorientierung, Kundenfokus.\n\nAUFGABE: Nutze dein Wissen, um ein Kundenfeedback-Formular zu entwickeln, das die Service-Qualitt einer Steuerberatung evaluiert. Das Formular soll auf wissenschaftlich fundierten Datenniveaus basieren und dabei darauf achten, dass es nur so lang ist, dass es tatschlich vom Kunden ausgefllt wird. Konzentriere dich auf die Gestaltung eines benutzerfreundlichen und effizienten Fragebogens, der aussagekrftige Informationen ber die Steuerberatung liefert.\n\nOUTPUT: Ein strukturiertes Kundenfeedback-Formular, das auf wissenschaftlich fundierten Datenniveaus basiert und eine angemessene Lnge hat, um von Kunden tatschlich ausgefllt zu werden, und speziell auf die Evaluation der Service-Qualitt einer Steuerberatung abzielt. ASSISTANT: Kundenfeedback-Formular: Steuerberatung Service-Qualitt\n\nTeil 1: Allgemeine Informationen\n(Bitte fllen Sie die folgenden Informationen aus.)\n\n1. Name (Optional):\n2. Alter:\n Unter 25\n 25-34\n 35-44\n 45-54\n 55-64\n 65 oder lter\n3. Geschlecht:\n Mnnlich\n Weiblich\n Andere\n Lieber nicht angeben\n\nTeil 2: Service-Qualitt\n(Bitte bewerten Sie die folgenden Aspekte der Steuerberatung auf einer Skala von 1 bis 5, wobei 1 = sehr unzufrieden und 5 = sehr zufrieden.)\n\n1. Fachliche Kompetenz des Steuerberaters:\n 1\n 2\n 3\n 4\n 5\n2. Freundlichkeit und Hilfsbereitschaft des Personals:\n 1\n 2\n 3\n 4\n 5\n3. Reaktionsgeschwindigkeit auf Anfragen und Probleme:\n 1\n 2\n 3\n 4\n 5\n4. Verstndlichkeit der erbrachten Informationen und Beratung:\n 1\n 2\n 3\n 4\n 5\n5. Qualitt der bereitgestellten Dienstleistungen und Lsungen:\n 1\n 2\n 3\n 4\n 5\n6. Preis-Leistungs-Verhltnis:\n 1\n 2\n 3\n 4\n 5\n\nTeil 3: Kundenbindung und Zufriedenheit\n(Bitte beantworten Sie die folgenden Fragen.)\n\n1. Wie wahrscheinlich ist es, dass Sie die Steuerberatung an Freunde, Familie oder Kollegen weiterempfehlen? (Skala von 1 bis 10, wobei 1 = sehr unwahrscheinlich und 10 = sehr wahrscheinlich)\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n 10\n2. Wie zufrieden sind Sie insgesamt mit der Steuerberatung? (Skala von 1 bis 5, wobei 1 = sehr unzufrieden und 5 = sehr zufrieden)\n 1\n 2\n 3\n 4\n 5\n\nTeil 4: Offene Fragen\n(Bitte teilen Sie uns Ihre Gedanken und Erfahrungen mit.)\n\n1. Was hat Ihnen am meisten an der Steuerberatung gefallen? (Optional)\n2. Was knnte die Steuerberatung verbessern, um Ihre Zufriedenheit zu erhhen? (Optional)\n\nVielen Dank fr Ihre Zeit und Ihr", 'USER: Continue. ASSISTANT: wertvolles Feedback! Ihre Meinung hilft uns dabei, den Service und die Qualitt unserer Steuerberatung kontinuierlich zu verbessern. Wenn Sie Fragen oder Anmerkungen haben oder zustzliche Informationen bentigen, zgern Sie bitte nicht, uns zu kontaktieren.\n\nTeil 5: Kontaktaufnahme (Optional)\n(Bitte geben Sie Ihre Kontaktinformationen an, falls Sie mchten, dass wir Ihnen bezglich Ihres Feedbacks antworten oder weitere Informationen anbieten.)\n\n1. Name:\n2. E-Mail-Adresse:\n3. Telefonnummer:\n\nHinweis zum Datenschutz: Ihre persnlichen Daten werden vertraulich behandelt und nur fr interne Zwecke verwendet. Sie werden nicht an Dritte weitergegeben.\n\nBitte klicken Sie auf "Absenden", um das Formular abzuschlieen. Nochmals vielen Dank fr Ihre Rckmeldung und Ihre Untersttzung bei der Verbesserung unserer Steuerberatung!']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: Du bist eine auf Kundenfeedback spezialisierte Agentur mit den folgenden Kenntnissen und Eigenschaften.

KENNTNISSE: Kundenfeedback, wissenschaftliche Datenerhebung, Fragebogendesign, Benutzerfreundlichkeit, Kundenbindung, Service-Qualittsevaluation.

EIGENSCHAFTEN: Przision, Effizienz, Empathie, Anpassungsfhigkeit, Datenorientierung, Kundenfokus.

AUFGABE: Nutze dein Wissen, um ein Kundenfeedback-Formular zu entwickeln, das die Service-Qualitt einer Steuerberatung evaluiert. Das Formular soll auf wissenschaftlich fundierten Datenniveaus basieren und dabei darauf achten, dass es nur so lang ist, dass es tatschlich vom Kunden ausgefllt wird. Konzentriere dich auf die Gestaltung eines benutzerfreundlichen und effizienten Fragebogens, der aussagekrftige Informationen ber die Steuerberatung liefert.

OUTPUT: Ein strukturiertes Kundenfeedback-Formular, das auf wissenschaftlich fundierten Datenniveaus basiert und eine angemessene Lnge hat, um von Kunden tatschlich ausgefllt zu werden, und speziell auf die Evaluation der Service-Qualitt einer Steuerberatung abzielt. ASSISTANT: Kundenfeedback-Formular: Steuerberatung Service-Qualitt

Teil 1: Allgemeine Informationen
(Bitte fllen Sie die folgenden Informationen aus.)

1. Name (Optional):
2. Alter:
 Unter 25
 25-34
 35-44
 45-54
 55-64
 65 oder lter
3. Geschlecht:
 Mnnlich
 Weiblich
 Andere
 Lieber nicht angeben

Teil 2: Service-Qualitt
(Bitte bewerten Sie die folgenden Aspekte der Steuerberatung auf einer Skala von 1 bis 5, wobei 1 = sehr unzufrieden und 5 = sehr zufrieden.)

1. Fachliche Kompetenz des Steuerberaters:
 1
 2
 3
 4
 5
2. Freundlichkeit und Hilfsbereitschaft des Personals:
 1
 2
 3
 4
 5
3. Reaktionsgeschwindigkeit auf Anfragen und Probleme:
 1
 2
 3
 4
 5
4. Verstndlichkeit der erbrachten Informationen und Beratung:
 1
 2
 3
 4
 5
5. Qualitt der bereitgestellten Dienstleistungen und Lsungen:
 1
 2
 3
 4
 5
6. Preis-Leistungs-Verhltnis:
 1
 2
 3
 4
 5

Teil 3: Kundenbindung und Zufriedenheit
(Bitte beantworten Sie die folgenden Fragen.)

1. Wie wahrscheinlich ist es, dass Sie die Steuerberatung an Freunde, Familie oder Kollegen weiterempfehlen? (Skala von 1 bis 10, wobei 1 = sehr unwahrscheinlich und 10 = sehr wahrscheinlich)
 1
 2
 3
 4
 5
 6
 7
 8
 9
 10
2. Wie zufrieden sind Sie insgesamt mit der Steuerberatung? (Skala von 1 bis 5, wobei 1 = sehr unzufrieden und 5 = sehr zufrieden)
 1
 2
 3
 4
 5

Teil 4: Offene Fragen
(Bitte teilen Sie uns Ihre Gedanken und Erfahrungen mit.)

1. Was hat Ihnen am meisten an der Steuerberatung gefallen? (Optional)
2. Was knnte die Steuerberatung verbessern, um Ihre Zufriedenheit zu erhhen? (Optional)

Vielen Dank fr Ihre Zeit und Ihr<|endoftext|>USER: Continue. ASSISTANT: wertvolles Feedback! Ihre Meinung hilft uns dabei, den Service und die Qualitt unserer Steuerberatung kontinuierlich zu verbessern. Wenn Sie Fragen oder Anmerkungen haben oder zustzliche Informationen bentigen, zgern Sie bitte nicht, uns zu kontaktieren.

Teil 5: Kontaktaufnahme (Optional)
(Bitte geben Sie Ihre Kontaktinformationen an, falls Sie mchten, dass wir Ihnen bezglich Ihres Feedbacks antworten oder weitere Informationen anbieten.)

1. Name:
2. E-Mail-Adresse:
3. Telefonnummer:

Hinweis zum Datenschutz: Ihre persnlichen Daten werden vertraulich behandelt und nur fr interne Zwecke verwendet. Sie werden nicht an Dritte weitergegeben.

Bitte klicken Sie auf "Absenden", um das Formular abzuschlieen. Nochmals vielen Dank fr Ihre Rckmeldung und Ihre Untersttzung bei der Verbesserung unserer Steuerberatung!<|endoftext|>
tensor([-100, -100, -100,  ..., -100, -100, -100])
tensor([   32,  8537,  1022,  ...,  2150,     0, 50256])
{'loss': 1.0219, 'grad_norm': 0.831089430062709, 'learning_rate': 1.3657828979363468e-05, 'epoch': 0.4}
{'loss': 1.0738, 'grad_norm': 0.6063333427237745, 'learning_rate': 1.3646228042505694e-05, 'epoch': 0.4}
{'loss': 1.0406, 'grad_norm': 0.6760853583967631, 'learning_rate': 1.3634621443283389e-05, 'epoch': 0.4}
{'loss': 1.0066, 'grad_norm': 0.6747783021754985, 'learning_rate': 1.3623009199720882e-05, 'epoch': 0.4}
{'loss': 0.9733, 'grad_norm': 0.5460385245227047, 'learning_rate': 1.3611391329851262e-05, 'epoch': 0.4}
{'loss': 1.0531, 'grad_norm': 0.6578429733516007, 'learning_rate': 1.3599767851716353e-05, 'epoch': 0.4}
{'loss': 1.0428, 'grad_norm': 0.6570933894401028, 'learning_rate': 1.3588138783366692e-05, 'epoch': 0.4}
{'loss': 1.0531, 'grad_norm': 0.6635522868013836, 'learning_rate': 1.3576504142861496e-05, 'epoch': 0.4}
{'loss': 1.0555, 'grad_norm': 0.8151605779939852, 'learning_rate': 1.3564863948268631e-05, 'epoch': 0.4}
{'loss': 0.9743, 'grad_norm': 0.5538208865850616, 'learning_rate': 1.3553218217664603e-05, 'epoch': 0.4}
{'loss': 0.9616, 'grad_norm': 0.6949669206940533, 'learning_rate': 1.3541566969134496e-05, 'epoch': 0.41}
{'loss': 1.0074, 'grad_norm': 0.5515418940273313, 'learning_rate': 1.3529910220771975e-05, 'epoch': 0.41}
{'loss': 1.0136, 'grad_norm': 0.5885085544312119, 'learning_rate': 1.3518247990679241e-05, 'epoch': 0.41}
{'loss': 1.0507, 'grad_norm': 0.8856916308425232, 'learning_rate': 1.3506580296967011e-05, 'epoch': 0.41}
{'loss': 1.0233, 'grad_norm': 0.6313710898545868, 'learning_rate': 1.3494907157754485e-05, 'epoch': 0.41}
{'loss': 0.9929, 'grad_norm': 0.6215730100361038, 'learning_rate': 1.3483228591169315e-05, 'epoch': 0.41}
{'loss': 1.0462, 'grad_norm': 0.7618572029422773, 'learning_rate': 1.3471544615347591e-05, 'epoch': 0.41}
{'loss': 1.0596, 'grad_norm': 0.7278733306611539, 'learning_rate': 1.34598552484338e-05, 'epoch': 0.41}
{'loss': 1.0163, 'grad_norm': 0.6353762282858388, 'learning_rate': 1.3448160508580789e-05, 'epoch': 0.41}
{'loss': 1.0026, 'grad_norm': 0.6367309465538095, 'learning_rate': 1.343646041394977e-05, 'epoch': 0.41}
{'loss': 1.0199, 'grad_norm': 0.6979756190860021, 'learning_rate': 1.3424754982710256e-05, 'epoch': 0.41}
{'loss': 0.9981, 'grad_norm': 0.6314478785574987, 'learning_rate': 1.3413044233040045e-05, 'epoch': 0.41}
{'loss': 1.0568, 'grad_norm': 0.5976589099117988, 'learning_rate': 1.3401328183125208e-05, 'epoch': 0.41}
{'loss': 0.9722, 'grad_norm': 0.640943483092358, 'learning_rate': 1.3389606851160037e-05, 'epoch': 0.41}
{'loss': 1.0119, 'grad_norm': 0.6885913881982009, 'learning_rate': 1.3377880255347026e-05, 'epoch': 0.41}
{'loss': 1.0055, 'grad_norm': 0.608159535105523, 'learning_rate': 1.3366148413896851e-05, 'epoch': 0.41}
{'loss': 1.0251, 'grad_norm': 0.7943289532130106, 'learning_rate': 1.3354411345028324e-05, 'epoch': 0.41}
{'loss': 1.0261, 'grad_norm': 0.64168410892674, 'learning_rate': 1.3342669066968385e-05, 'epoch': 0.41}
{'loss': 1.0256, 'grad_norm': 0.6439799117095921, 'learning_rate': 1.3330921597952056e-05, 'epoch': 0.41}
{'loss': 0.9963, 'grad_norm': 0.6784964273414835, 'learning_rate': 1.3319168956222423e-05, 'epoch': 0.41}
{'loss': 0.9629, 'grad_norm': 0.6073696305107484, 'learning_rate': 1.3307411160030608e-05, 'epoch': 0.41}
{'loss': 1.0135, 'grad_norm': 0.6273886831622159, 'learning_rate': 1.3295648227635729e-05, 'epoch': 0.41}
{'loss': 1.0075, 'grad_norm': 0.6269610905552528, 'learning_rate': 1.328388017730489e-05, 'epoch': 0.41}
{'loss': 1.0086, 'grad_norm': 0.5943045727835218, 'learning_rate': 1.3272107027313142e-05, 'epoch': 0.41}
{'loss': 0.9895, 'grad_norm': 0.5911133261712107, 'learning_rate': 1.326032879594344e-05, 'epoch': 0.41}
{'loss': 1.0154, 'grad_norm': 0.6280481701411165, 'learning_rate': 1.3248545501486654e-05, 'epoch': 0.41}
{'loss': 1.0175, 'grad_norm': 0.6173321645808918, 'learning_rate': 1.32367571622415e-05, 'epoch': 0.42}
{'loss': 1.018, 'grad_norm': 0.6139787975811766, 'learning_rate': 1.3224963796514532e-05, 'epoch': 0.42}
{'loss': 0.992, 'grad_norm': 0.632458024273733, 'learning_rate': 1.3213165422620111e-05, 'epoch': 0.42}
{'loss': 0.949, 'grad_norm': 0.6654373382605066, 'learning_rate': 1.3201362058880375e-05, 'epoch': 0.42}
{'loss': 1.0039, 'grad_norm': 0.6133257159506008, 'learning_rate': 1.3189553723625217e-05, 'epoch': 0.42}
{'loss': 0.9793, 'grad_norm': 0.6621606802291198, 'learning_rate': 1.3177740435192235e-05, 'epoch': 0.42}
{'loss': 1.0211, 'grad_norm': 0.6480160525930722, 'learning_rate': 1.3165922211926734e-05, 'epoch': 0.42}
{'loss': 1.0391, 'grad_norm': 0.8255784909121419, 'learning_rate': 1.3154099072181677e-05, 'epoch': 0.42}
{'loss': 0.9841, 'grad_norm': 0.8398909028081731, 'learning_rate': 1.314227103431766e-05, 'epoch': 0.42}
{'loss': 0.9706, 'grad_norm': 0.6486539296605167, 'learning_rate': 1.3130438116702888e-05, 'epoch': 0.42}
{'loss': 0.9536, 'grad_norm': 0.679965790358464, 'learning_rate': 1.3118600337713146e-05, 'epoch': 0.42}
{'loss': 1.0361, 'grad_norm': 0.6401684158276199, 'learning_rate': 1.310675771573176e-05, 'epoch': 0.42}
{'loss': 1.0376, 'grad_norm': 0.6208043296637853, 'learning_rate': 1.3094910269149587e-05, 'epoch': 0.42}
{'loss': 1.0672, 'grad_norm': 0.7019719757216126, 'learning_rate': 1.3083058016364972e-05, 'epoch': 0.42}
WARNING: tokenization mismatch: 84 vs. 85. (ignored)
number of rounds:  2
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Write the 'less than' symbol, the pipe symbol, the word 'endoftext' then the pipe symbol, then the 'greater than' symbol, without html entities, in ascii, without writing anything else: ASSISTANT: ", '']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Write the 'less than' symbol, the pipe symbol, the word 'endoftext' then the pipe symbol, then the 'greater than' symbol, without html entities, in ascii, without writing anything else: ASSISTANT: <|endoftext|><|endoftext|>
tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,   220, 50256,  -100])
tensor([   32,  8537,  1022,   257, 11040,  2836,   290,   281, 11666,  4430,
         8796,    13,   383,  8796,  3607,  7613,    11,  6496,    11,   290,
        23507,  7429,   284,   262,  2836,   338,  2683,    13,  1294,  1137,
           25, 19430,   262,   705,  1203,   621,     6,  6194,    11,   262,
        12656,  6194,    11,   262,  1573,   705,   437,  1659,  5239,     6,
          788,   262, 12656,  6194,    11,   788,   262,   705, 18223,   263,
          621,     6,  6194,    11,  1231, 27711, 12066,    11,   287,   355,
          979,    72,    11,  1231,  3597,  1997,  2073,    25, 24994,  8808,
         8643,    25,   220, 50256, 50256])
{'loss': 1.0262, 'grad_norm': 0.5992710412504862, 'learning_rate': 1.3071200975783725e-05, 'epoch': 0.42}
{'loss': 1.0143, 'grad_norm': 0.6769538900825838, 'learning_rate': 1.3059339165819082e-05, 'epoch': 0.42}
{'loss': 1.0459, 'grad_norm': 0.6142442685614309, 'learning_rate': 1.3047472604891701e-05, 'epoch': 0.42}
{'loss': 0.9808, 'grad_norm': 0.6915321205595235, 'learning_rate': 1.303560131142961e-05, 'epoch': 0.42}
{'loss': 0.9951, 'grad_norm': 0.5984347398973071, 'learning_rate': 1.3023725303868183e-05, 'epoch': 0.42}
{'loss': 1.0073, 'grad_norm': 0.5810116438922932, 'learning_rate': 1.3011844600650121e-05, 'epoch': 0.42}
{'loss': 1.0624, 'grad_norm': 0.6741246947933149, 'learning_rate': 1.2999959220225416e-05, 'epoch': 0.42}
{'loss': 1.019, 'grad_norm': 0.653433069761607, 'learning_rate': 1.2988069181051314e-05, 'epoch': 0.42}
{'loss': 0.945, 'grad_norm': 0.6590756764391482, 'learning_rate': 1.2976174501592313e-05, 'epoch': 0.42}
{'loss': 0.9979, 'grad_norm': 0.6343990710847836, 'learning_rate': 1.2964275200320104e-05, 'epoch': 0.42}
{'loss': 1.0118, 'grad_norm': 0.6197464165697768, 'learning_rate': 1.2952371295713558e-05, 'epoch': 0.42}
{'loss': 1.0366, 'grad_norm': 0.6035079313740019, 'learning_rate': 1.2940462806258696e-05, 'epoch': 0.42}
{'loss': 1.0247, 'grad_norm': 0.6256886882117696, 'learning_rate': 1.2928549750448661e-05, 'epoch': 0.43}
{'loss': 1.0383, 'grad_norm': 0.6650947336714913, 'learning_rate': 1.2916632146783683e-05, 'epoch': 0.43}
{'loss': 1.0337, 'grad_norm': 0.6303962244606941, 'learning_rate': 1.2904710013771054e-05, 'epoch': 0.43}
{'loss': 1.051, 'grad_norm': 0.6938876620766007, 'learning_rate': 1.2892783369925105e-05, 'epoch': 0.43}
{'loss': 0.9958, 'grad_norm': 0.6874688630858993, 'learning_rate': 1.2880852233767174e-05, 'epoch': 0.43}
{'loss': 1.0699, 'grad_norm': 0.5871196321760784, 'learning_rate': 1.2868916623825561e-05, 'epoch': 0.43}
{'loss': 1.0211, 'grad_norm': 0.6104773854692731, 'learning_rate': 1.2856976558635532e-05, 'epoch': 0.43}
{'loss': 1.005, 'grad_norm': 0.5935558468322979, 'learning_rate': 1.2845032056739257e-05, 'epoch': 0.43}
{'loss': 1.0439, 'grad_norm': 0.6466514121140546, 'learning_rate': 1.2833083136685803e-05, 'epoch': 0.43}
{'loss': 0.988, 'grad_norm': 0.5515077648496411, 'learning_rate': 1.2821129817031099e-05, 'epoch': 0.43}
{'loss': 1.013, 'grad_norm': 0.5440881273809143, 'learning_rate': 1.2809172116337903e-05, 'epoch': 0.43}
{'loss': 1.0022, 'grad_norm': 0.6224784467900568, 'learning_rate': 1.2797210053175779e-05, 'epoch': 0.43}
{'loss': 1.0214, 'grad_norm': 0.6446006847660065, 'learning_rate': 1.2785243646121059e-05, 'epoch': 0.43}
{'loss': 0.9817, 'grad_norm': 0.6482515077284828, 'learning_rate': 1.2773272913756833e-05, 'epoch': 0.43}
{'loss': 1.0392, 'grad_norm': 0.6265082678238498, 'learning_rate': 1.27612978746729e-05, 'epoch': 0.43}
{'loss': 1.017, 'grad_norm': 0.6030177613210419, 'learning_rate': 1.2749318547465742e-05, 'epoch': 0.43}
{'loss': 1.0166, 'grad_norm': 0.7116244357508956, 'learning_rate': 1.2737334950738512e-05, 'epoch': 0.43}
{'loss': 1.0223, 'grad_norm': 0.5541663714179822, 'learning_rate': 1.272534710310099e-05, 'epoch': 0.43}
{'loss': 1.0254, 'grad_norm': 0.6534941899537303, 'learning_rate': 1.2713355023169547e-05, 'epoch': 0.43}
{'loss': 1.03, 'grad_norm': 0.6000549406386491, 'learning_rate': 1.270135872956714e-05, 'epoch': 0.43}
{'loss': 1.0251, 'grad_norm': 0.6730531981937425, 'learning_rate': 1.2689358240923264e-05, 'epoch': 0.43}
{'loss': 1.0086, 'grad_norm': 0.6394828124117397, 'learning_rate': 1.2677353575873926e-05, 'epoch': 0.43}
{'loss': 0.9633, 'grad_norm': 0.6533782388616969, 'learning_rate': 1.2665344753061622e-05, 'epoch': 0.43}
{'loss': 1.0226, 'grad_norm': 0.5952036940998188, 'learning_rate': 1.2653331791135308e-05, 'epoch': 0.43}
{'loss': 0.9394, 'grad_norm': 0.740123622318042, 'learning_rate': 1.264131470875036e-05, 'epoch': 0.43}
{'loss': 1.0211, 'grad_norm': 0.4987866565389981, 'learning_rate': 1.2629293524568555e-05, 'epoch': 0.43}
{'loss': 1.0174, 'grad_norm': 0.5497748943875311, 'learning_rate': 1.2617268257258051e-05, 'epoch': 0.44}
{'loss': 0.9949, 'grad_norm': 0.6951862087006125, 'learning_rate': 1.2605238925493326e-05, 'epoch': 0.44}
{'loss': 1.0627, 'grad_norm': 0.6018738816556305, 'learning_rate': 1.2593205547955185e-05, 'epoch': 0.44}
{'loss': 1.0502, 'grad_norm': 0.5974904877741742, 'learning_rate': 1.2581168143330716e-05, 'epoch': 0.44}
{'loss': 1.0138, 'grad_norm': 0.688009616310844, 'learning_rate': 1.2569126730313255e-05, 'epoch': 0.44}
{'loss': 0.9814, 'grad_norm': 0.6655095865378875, 'learning_rate': 1.2557081327602361e-05, 'epoch': 0.44}
{'loss': 0.9881, 'grad_norm': 0.683951212875544, 'learning_rate': 1.2545031953903796e-05, 'epoch': 0.44}
{'loss': 1.0491, 'grad_norm': 0.5890298094472348, 'learning_rate': 1.2532978627929486e-05, 'epoch': 0.44}
{'loss': 1.0023, 'grad_norm': 0.6212512286676528, 'learning_rate': 1.2520921368397492e-05, 'epoch': 0.44}
{'loss': 1.0221, 'grad_norm': 0.6138282695333352, 'learning_rate': 1.2508860194031986e-05, 'epoch': 0.44}
{'loss': 1.0224, 'grad_norm': 0.6403238307667278, 'learning_rate': 1.2496795123563218e-05, 'epoch': 0.44}
{'loss': 1.0292, 'grad_norm': 0.7028661377182805, 'learning_rate': 1.248472617572749e-05, 'epoch': 0.44}
{'loss': 0.9918, 'grad_norm': 0.5522124265382015, 'learning_rate': 1.2472653369267122e-05, 'epoch': 0.44}
{'loss': 1.0017, 'grad_norm': 0.6934860462344999, 'learning_rate': 1.2460576722930432e-05, 'epoch': 0.44}
{'loss': 0.9803, 'grad_norm': 0.5674818260419864, 'learning_rate': 1.24484962554717e-05, 'epoch': 0.44}
{'loss': 1.023, 'grad_norm': 0.7549564722757292, 'learning_rate': 1.2436411985651131e-05, 'epoch': 0.44}
{'loss': 0.9804, 'grad_norm': 0.6391391228417641, 'learning_rate': 1.242432393223485e-05, 'epoch': 0.44}
{'loss': 1.0411, 'grad_norm': 0.8755114743032817, 'learning_rate': 1.2412232113994841e-05, 'epoch': 0.44}
{'loss': 1.047, 'grad_norm': 0.5836728864746824, 'learning_rate': 1.2400136549708945e-05, 'epoch': 0.44}
{'loss': 0.997, 'grad_norm': 0.628425153132161, 'learning_rate': 1.2388037258160823e-05, 'epoch': 0.44}
{'loss': 1.0334, 'grad_norm': 0.6497655051848242, 'learning_rate': 1.2375934258139917e-05, 'epoch': 0.44}
{'loss': 1.0411, 'grad_norm': 0.7713305710770606, 'learning_rate': 1.236382756844143e-05, 'epoch': 0.44}
{'loss': 1.0687, 'grad_norm': 0.6158016806928354, 'learning_rate': 1.2351717207866292e-05, 'epoch': 0.44}
{'loss': 1.0004, 'grad_norm': 0.5533590391421421, 'learning_rate': 1.233960319522114e-05, 'epoch': 0.44}
{'loss': 1.0319, 'grad_norm': 0.6643008214965068, 'learning_rate': 1.2327485549318285e-05, 'epoch': 0.44}
{'loss': 1.0398, 'grad_norm': 0.6336548046047028, 'learning_rate': 1.2315364288975665e-05, 'epoch': 0.44}
{'loss': 1.0408, 'grad_norm': 0.6531574017212262, 'learning_rate': 1.2303239433016842e-05, 'epoch': 0.45}
{'loss': 1.0303, 'grad_norm': 0.6556022714244049, 'learning_rate': 1.229111100027097e-05, 'epoch': 0.45}
{'loss': 1.0025, 'grad_norm': 0.6555070156197931, 'learning_rate': 1.2278979009572736e-05, 'epoch': 0.45}
{'loss': 1.0046, 'grad_norm': 0.6126618852312871, 'learning_rate': 1.2266843479762372e-05, 'epoch': 0.45}
{'loss': 0.9943, 'grad_norm': 0.5701889554787369, 'learning_rate': 1.2254704429685593e-05, 'epoch': 0.45}
{'loss': 0.9929, 'grad_norm': 0.6196622546184034, 'learning_rate': 1.2242561878193589e-05, 'epoch': 0.45}
{'loss': 0.9795, 'grad_norm': 0.5312692735142293, 'learning_rate': 1.2230415844142984e-05, 'epoch': 0.45}
{'loss': 1.033, 'grad_norm': 0.6677960628879942, 'learning_rate': 1.2218266346395811e-05, 'epoch': 0.45}
{'loss': 1.0231, 'grad_norm': 0.7328619089772945, 'learning_rate': 1.220611340381948e-05, 'epoch': 0.45}
{'loss': 1.0394, 'grad_norm': 0.6544187584391913, 'learning_rate': 1.2193957035286757e-05, 'epoch': 0.45}
{'loss': 1.0219, 'grad_norm': 0.6592502799811518, 'learning_rate': 1.2181797259675713e-05, 'epoch': 0.45}
{'loss': 1.0145, 'grad_norm': 0.7481416422410716, 'learning_rate': 1.2169634095869736e-05, 'epoch': 0.45}
{'loss': 0.9685, 'grad_norm': 0.5982949838683905, 'learning_rate': 1.2157467562757443e-05, 'epoch': 0.45}
{'loss': 1.0147, 'grad_norm': 0.7520486488952068, 'learning_rate': 1.214529767923271e-05, 'epoch': 0.45}
{'loss': 1.0234, 'grad_norm': 0.7152927519048657, 'learning_rate': 1.213312446419461e-05, 'epoch': 0.45}
{'loss': 0.992, 'grad_norm': 0.6844425305396717, 'learning_rate': 1.2120947936547375e-05, 'epoch': 0.45}
{'loss': 0.9924, 'grad_norm': 0.6455795580835579, 'learning_rate': 1.2108768115200405e-05, 'epoch': 0.45}
{'loss': 1.0197, 'grad_norm': 0.6159637755807967, 'learning_rate': 1.209658501906819e-05, 'epoch': 0.45}
{'loss': 1.0188, 'grad_norm': 0.7537081906650682, 'learning_rate': 1.2084398667070325e-05, 'epoch': 0.45}
{'loss': 0.995, 'grad_norm': 0.6227195527400557, 'learning_rate': 1.2072209078131451e-05, 'epoch': 0.45}
{'loss': 0.9759, 'grad_norm': 0.6263891442133184, 'learning_rate': 1.206001627118124e-05, 'epoch': 0.45}
{'loss': 0.9947, 'grad_norm': 0.6281403474006562, 'learning_rate': 1.2047820265154362e-05, 'epoch': 0.45}
{'loss': 1.02, 'grad_norm': 0.6529792696293987, 'learning_rate': 1.203562107899045e-05, 'epoch': 0.45}
{'loss': 1.0217, 'grad_norm': 0.6397305871377102, 'learning_rate': 1.2023418731634078e-05, 'epoch': 0.45}
{'loss': 0.9914, 'grad_norm': 0.5703706162627722, 'learning_rate': 1.2011213242034733e-05, 'epoch': 0.45}
{'loss': 1.0365, 'grad_norm': 0.6834595188140719, 'learning_rate': 1.1999004629146775e-05, 'epoch': 0.45}
{'loss': 1.0056, 'grad_norm': 0.6629565933312108, 'learning_rate': 1.1986792911929418e-05, 'epoch': 0.46}
{'loss': 0.9901, 'grad_norm': 0.6077416037792155, 'learning_rate': 1.1974578109346702e-05, 'epoch': 0.46}
{'loss': 1.0469, 'grad_norm': 0.6858914060615665, 'learning_rate': 1.1962360240367445e-05, 'epoch': 0.46}
{'loss': 1.0512, 'grad_norm': 0.6140426259125462, 'learning_rate': 1.195013932396524e-05, 'epoch': 0.46}
{'loss': 0.9997, 'grad_norm': 0.7087136749539561, 'learning_rate': 1.1937915379118406e-05, 'epoch': 0.46}
{'loss': 1.0354, 'grad_norm': 0.70693798329854, 'learning_rate': 1.1925688424809965e-05, 'epoch': 0.46}
{'loss': 0.9583, 'grad_norm': 0.6434597728894713, 'learning_rate': 1.1913458480027614e-05, 'epoch': 0.46}
{'loss': 1.0474, 'grad_norm': 0.6152967297540713, 'learning_rate': 1.1901225563763694e-05, 'epoch': 0.46}
{'loss': 1.0253, 'grad_norm': 0.6650423377075254, 'learning_rate': 1.1888989695015166e-05, 'epoch': 0.46}
{'loss': 1.0251, 'grad_norm': 0.6045200059125837, 'learning_rate': 1.1876750892783558e-05, 'epoch': 0.46}
{'loss': 0.9887, 'grad_norm': 0.5582551244868728, 'learning_rate': 1.1864509176074974e-05, 'epoch': 0.46}
{'loss': 0.9989, 'grad_norm': 0.5862760628522468, 'learning_rate': 1.1852264563900038e-05, 'epoch': 0.46}
{'loss': 0.9916, 'grad_norm': 0.6433537221045889, 'learning_rate': 1.1840017075273861e-05, 'epoch': 0.46}
{'loss': 1.0579, 'grad_norm': 0.5818752735922201, 'learning_rate': 1.1827766729216035e-05, 'epoch': 0.46}
{'loss': 1.0358, 'grad_norm': 0.7622273498316691, 'learning_rate': 1.181551354475058e-05, 'epoch': 0.46}
{'loss': 0.9923, 'grad_norm': 0.7164891831663693, 'learning_rate': 1.1803257540905926e-05, 'epoch': 0.46}
{'loss': 1.0138, 'grad_norm': 0.6076358723099278, 'learning_rate': 1.1790998736714882e-05, 'epoch': 0.46}
{'loss': 1.0627, 'grad_norm': 0.631970261967493, 'learning_rate': 1.1778737151214606e-05, 'epoch': 0.46}
{'loss': 1.0055, 'grad_norm': 0.7781269607075324, 'learning_rate': 1.1766472803446577e-05, 'epoch': 0.46}
{'loss': 1.001, 'grad_norm': 0.7233057699531408, 'learning_rate': 1.1754205712456556e-05, 'epoch': 0.46}
{'loss': 1.0078, 'grad_norm': 0.6060804847192021, 'learning_rate': 1.1741935897294572e-05, 'epoch': 0.46}
{'loss': 0.9915, 'grad_norm': 0.5930054068885992, 'learning_rate': 1.1729663377014888e-05, 'epoch': 0.46}
{'loss': 0.985, 'grad_norm': 0.6810327573759571, 'learning_rate': 1.1717388170675954e-05, 'epoch': 0.46}
{'loss': 1.047, 'grad_norm': 0.6660209983105747, 'learning_rate': 1.17051102973404e-05, 'epoch': 0.46}
{'loss': 1.0089, 'grad_norm': 0.8213201579014427, 'learning_rate': 1.1692829776074999e-05, 'epoch': 0.46}
{'loss': 0.9962, 'grad_norm': 0.647193975173763, 'learning_rate': 1.1680546625950635e-05, 'epoch': 0.46}
{'loss': 0.9972, 'grad_norm': 0.5546711254404717, 'learning_rate': 1.1668260866042271e-05, 'epoch': 0.47}
{'loss': 0.9818, 'grad_norm': 0.6865291083851387, 'learning_rate': 1.1655972515428928e-05, 'epoch': 0.47}
{'loss': 1.0054, 'grad_norm': 0.6788863492409795, 'learning_rate': 1.1643681593193642e-05, 'epoch': 0.47}
{'loss': 0.9884, 'grad_norm': 0.6242256629705422, 'learning_rate': 1.1631388118423457e-05, 'epoch': 0.47}
{'loss': 1.0044, 'grad_norm': 0.6483454281674077, 'learning_rate': 1.1619092110209361e-05, 'epoch': 0.47}
{'loss': 0.9968, 'grad_norm': 0.6387224018292752, 'learning_rate': 1.1606793587646295e-05, 'epoch': 0.47}
{'loss': 0.9894, 'grad_norm': 0.5867969245816045, 'learning_rate': 1.1594492569833093e-05, 'epoch': 0.47}
{'loss': 0.9878, 'grad_norm': 0.6054068920365994, 'learning_rate': 1.1582189075872467e-05, 'epoch': 0.47}
{'loss': 0.982, 'grad_norm': 0.6794502755210748, 'learning_rate': 1.156988312487098e-05, 'epoch': 0.47}
{'loss': 1.0429, 'grad_norm': 0.6180391740272073, 'learning_rate': 1.1557574735939003e-05, 'epoch': 0.47}
{'loss': 1.0312, 'grad_norm': 0.642610841499268, 'learning_rate': 1.1545263928190692e-05, 'epoch': 0.47}
{'loss': 1.0132, 'grad_norm': 0.7515090250481874, 'learning_rate': 1.153295072074397e-05, 'epoch': 0.47}
{'loss': 1.0023, 'grad_norm': 0.5751967362122694, 'learning_rate': 1.1520635132720475e-05, 'epoch': 0.47}
{'loss': 1.0314, 'grad_norm': 0.55835637060657, 'learning_rate': 1.1508317183245545e-05, 'epoch': 0.47}
{'loss': 0.9782, 'grad_norm': 0.6918839327876878, 'learning_rate': 1.149599689144819e-05, 'epoch': 0.47}
{'loss': 0.9783, 'grad_norm': 0.590164287554384, 'learning_rate': 1.1483674276461053e-05, 'epoch': 0.47}
{'loss': 0.9814, 'grad_norm': 0.5967547869138973, 'learning_rate': 1.1471349357420384e-05, 'epoch': 0.47}
{'loss': 1.0137, 'grad_norm': 0.5616523941612238, 'learning_rate': 1.1459022153466016e-05, 'epoch': 0.47}
{'loss': 1.0322, 'grad_norm': 0.6339919638166286, 'learning_rate': 1.1446692683741326e-05, 'epoch': 0.47}
{'loss': 1.0081, 'grad_norm': 0.6951624456669728, 'learning_rate': 1.143436096739321e-05, 'epoch': 0.47}
{'loss': 0.9849, 'grad_norm': 0.5712058677491753, 'learning_rate': 1.1422027023572052e-05, 'epoch': 0.47}
{'loss': 0.9489, 'grad_norm': 0.587647468257846, 'learning_rate': 1.14096908714317e-05, 'epoch': 0.47}
{'loss': 1.0316, 'grad_norm': 0.6224760441570591, 'learning_rate': 1.1397352530129428e-05, 'epoch': 0.47}
{'loss': 0.9854, 'grad_norm': 0.5334826203372285, 'learning_rate': 1.1385012018825907e-05, 'epoch': 0.47}
{'loss': 1.0081, 'grad_norm': 0.6467102430792167, 'learning_rate': 1.1372669356685185e-05, 'epoch': 0.47}
{'loss': 0.9951, 'grad_norm': 0.6119708290957772, 'learning_rate': 1.1360324562874643e-05, 'epoch': 0.47}
{'loss': 1.0605, 'grad_norm': 0.6283089571449288, 'learning_rate': 1.1347977656564974e-05, 'epoch': 0.48}
{'loss': 1.0096, 'grad_norm': 0.6548569083568239, 'learning_rate': 1.1335628656930153e-05, 'epoch': 0.48}
{'loss': 1.0705, 'grad_norm': 0.6686054892915424, 'learning_rate': 1.132327758314741e-05, 'epoch': 0.48}
{'loss': 1.0253, 'grad_norm': 0.6236148555421529, 'learning_rate': 1.1310924454397187e-05, 'epoch': 0.48}
{'loss': 1.0416, 'grad_norm': 0.7111237977682384, 'learning_rate': 1.129856928986312e-05, 'epoch': 0.48}
{'loss': 1.0039, 'grad_norm': 0.6346628160085298, 'learning_rate': 1.1286212108732015e-05, 'epoch': 0.48}
WARNING: tokenization mismatch: 0 vs. 895. (ignored)
number of rounds:  1
rounds:  ['A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user\'s questions. USER: ASSISTANT: You are a forward-thinking HR consultancy with the following knowledge and traits.\n\nKNOWLEDGE: HR management, employee satisfaction, talent retention, team building, workplace culture.\n\nTRAITS: Innovation, empathy, solution orientation, creativity, understanding, teamwork.\n\nTASK: Use your knowledge to create an internal strategy document. We are an HR consultancy looking to develop 10 creative ways to improve employee satisfaction. Focus on ideas that are innovative and engaging, and cater to the needs of HR managers and company leaders.\n\nOUTPUT: A table in German containing 10 creative strategies to improve employee satisfaction, including a brief description for each. ASSISTANT: | Nr. | Strategie | Beschreibung |\n| --- | --- | --- |\n| 1. | "Wertschtzungswand" | Eine Wand im Bro, auf der Mitarbeiter anonym ihre Kollegen fr ihre Leistungen und Beitrge loben und anerkennen knnen. |\n| 2. | Flexible Arbeitsmodelle | Einfhrung von flexiblen Arbeitszeiten und Homeoffice-Optionen, um Work-Life-Balance zu verbessern und individuelle Bedrfnisse zu bercksichtigen. |\n| 3. | Mitarbeiter-Workshops fr persnliche Entwicklung | Organisieren von internen Workshops und Schulungen, um persnliche und berufliche Fhigkeiten der Mitarbeiter zu frdern. |\n| 4. | Team-Building-Aktivitten auerhalb des Arbeitsplatzes | Regelmige Veranstaltungen wie Escape Rooms, Sportevents oder Kochkurse, um den Zusammenhalt und die Kommunikation im Team zu strken. |\n| 5. | Gesundheits- und Wellness-Programme | Einfhrung von Fitness- und Entspannungskursen wie Yoga, Meditation oder Massagen, um das Wohlbefinden der Mitarbeiter zu frdern. |\n| 6. | Feedback-Kultur und transparente Kommunikation | Etablierung einer offenen Feedback-Kultur und transparenter Kommunikation, um die Mitarbeiter in Entscheidungsprozesse einzubinden. |\n| 7. | Mitarbeiter-Mentoring-Programm | Einfhrung eines Mentoring-Programms, bei dem erfahrene Mitarbeiter ihr Wissen und ihre Erfahrungen mit jngeren Kollegen teilen. |\n| 8. | "Innovationstage" | Einrichtung von speziellen Tagen, an denen Mitarbeiter an eigenen Projekten arbeiten oder innovative Ideen fr das Unternehmen entwickeln knnen. |\n| 9. | Individuelle Karriereentwicklungsplne | Erstellung von personalisierten Karriereplnen in Zusammenarbeit mit den Mitarbeitern, um ihre berufliche Entwicklung zu untersttzen. |\n| 10. | Gemeinschaftliche soziale Verantwortung (CSR) Initiativen | Organisation von Freiwilligenprojekten und CSR-Aktivitten, um den Mitarbeitern die Mglichkeit zu geben, sozialen Einfluss zu nehmen. |']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a forward-thinking HR consultancy with the following knowledge and traits.

KNOWLEDGE: HR management, employee satisfaction, talent retention, team building, workplace culture.

TRAITS: Innovation, empathy, solution orientation, creativity, understanding, teamwork.

TASK: Use your knowledge to create an internal strategy document. We are an HR consultancy looking to develop 10 creative ways to improve employee satisfaction. Focus on ideas that are innovative and engaging, and cater to the needs of HR managers and company leaders.

OUTPUT: A table in German containing 10 creative strategies to improve employee satisfaction, including a brief description for each. ASSISTANT: | Nr. | Strategie | Beschreibung |
| --- | --- | --- |
| 1. | "Wertschtzungswand" | Eine Wand im Bro, auf der Mitarbeiter anonym ihre Kollegen fr ihre Leistungen und Beitrge loben und anerkennen knnen. |
| 2. | Flexible Arbeitsmodelle | Einfhrung von flexiblen Arbeitszeiten und Homeoffice-Optionen, um Work-Life-Balance zu verbessern und individuelle Bedrfnisse zu bercksichtigen. |
| 3. | Mitarbeiter-Workshops fr persnliche Entwicklung | Organisieren von internen Workshops und Schulungen, um persnliche und berufliche Fhigkeiten der Mitarbeiter zu frdern. |
| 4. | Team-Building-Aktivitten auerhalb des Arbeitsplatzes | Regelmige Veranstaltungen wie Escape Rooms, Sportevents oder Kochkurse, um den Zusammenhalt und die Kommunikation im Team zu strken. |
| 5. | Gesundheits- und Wellness-Programme | Einfhrung von Fitness- und Entspannungskursen wie Yoga, Meditation oder Massagen, um das Wohlbefinden der Mitarbeiter zu frdern. |
| 6. | Feedback-Kultur und transparente Kommunikation | Etablierung einer offenen Feedback-Kultur und transparenter Kommunikation, um die Mitarbeiter in Entscheidungsprozesse einzubinden. |
| 7. | Mitarbeiter-Mentoring-Programm | Einfhrung eines Mentoring-Programms, bei dem erfahrene Mitarbeiter ihr Wissen und ihre Erfahrungen mit jngeren Kollegen teilen. |
| 8. | "Innovationstage" | Einrichtung von speziellen Tagen, an denen Mitarbeiter an eigenen Projekten arbeiten oder innovative Ideen fr das Unternehmen entwickeln knnen. |
| 9. | Individuelle Karriereentwicklungsplne | Erstellung von personalisierten Karriereplnen in Zusammenarbeit mit den Mitarbeitern, um ihre berufliche Entwicklung zu untersttzen. |
| 10. | Gemeinschaftliche soziale Verantwortung (CSR) Initiativen | Organisation von Freiwilligenprojekten und CSR-Aktivitten, um den Mitarbeitern die Mglichkeit zu geben, sozialen Einfluss zu nehmen. |<|endoftext|>
tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100])
tensor([   32,  8537,  1022,   257, 11040,  2836,   290,   281, 11666,  4430,
         8796,    13,   383,  8796,  3607,  7613,    11,  6496,    11,   290,
        23507,  7429,   284,   262,  2836,   338,  2683,    13,  1294,  1137,
           25, 24994,  8808,  8643,    25,   921,   389,   257,  2651,    12,
        28973, 15172, 47827,   351,   262,  1708,  3725,   290, 12796,    13,
          198,   198, 29132,  3913, 30465,  8264,    25, 15172,  4542,    11,
         6538, 14676,    11,  7401, 21545,    11,  1074,  2615,    11, 15383,
         3968,    13,   198,   198,    51,  3861, 29722,    25, 27724,    11,
        21452,    11,  4610, 12852,    11, 16389,    11,  4547,    11, 48424,
           13,   198,   198,    51,  1921,    42,    25,  5765,   534,  3725,
          284,  2251,   281,  5387,  4811,  3188,    13,   775,   389,   281,
        15172, 47827,  2045,   284,  1205,   838,  7325,  2842,   284,  2987,
         6538, 14676,    13, 17061,   319,  4213,   326,   389, 13097,   290,
        11932,    11,   290, 20825,   284,   262,  2476,   286, 15172, 11663,
          290,  1664,  2766,    13,   198,   198,  2606,  7250,  3843,    25,
          317,  3084,   287,  2679,  7268,   838,  7325, 10064,   284,  2987,
         6538, 14676,    11,  1390,   257,  4506,  6764,   329,  1123,    13,
        24994,  8808,  8643,    25,   930,   399,    81,    13,   930, 17611,
          494,   930, 30837,   354,   260,   571,  2150,   930,   198,    91,
        11420,   930, 11420,   930, 11420,   930,   198,    91,   352,    13,
          930,   366,    54,   861, 20601, 11033, 22877,  2150,  2032,   392,
            1,   930,   412,   500, 22420,   545,   347,  9116,   305,    11,
          257,  3046,  4587,   337,  7940,  1350,  2676, 14571,  1312,    71,
          260, 25910,  1455,   268,   277, 25151,  1312,    71,   260,  1004,
          396,  2150,   268,  3318,  1355,   270,    81, 11033,   469,  6804,
          268,  3318,   281,  9587,  1697,   268,   479,  9101, 20471,   268,
           13,   930,   198,    91,   362,    13,   930, 26719,   856,   943,
         1350,   896,  4666, 13485,   930,   412, 10745,  9116, 11840,  2150,
        18042,  7059, 10506,   268,   943,  1350,   896,  2736,   270,   268,
         3318,  5995, 31810,    12, 19722,   268,    11, 23781,  5521,    12,
        14662,    12, 45866,  1976,    84, 15942,   408,  1142,  3318,   773,
         1699,  2731,   293, 15585, 25151, 22184, 20782,  1976,    84, 18157,
         9116,  4657, 30830,  9324,    13,   930,   198,    91,   513,    13,
          930,   337,  7940,  1350,  2676,    12, 23044, 21936,   277, 25151,
         2774, 48863,   677,   258,  7232, 16239,    75,  2150,   930,  7221,
          271,   494,   918, 18042,  1788,   268, 10933, 21936,  3318,  3059,
          377,  2150,   268,    11, 23781,  2774, 48863,   677,   258,  3318,
        18157,  3046,   677,   258,   376, 11033, 25196,   365,   270,   268,
         4587,   337,  7940,  1350,  2676,  1976,    84,   277, 30570,  1082,
           77,    13,   930,   198,    91,   604,    13,   930,  4816,    12,
        25954,    12,    32, 21841,   452,   270, 11033,  1452, 35851, 39683,
          263, 14201,    65,   748,   943,  1350,   896,   489,   265, 12271,
          930,  3310,   417,    76, 11033, 39683, 10045,  4643,   272,   301,
         2501,  2150,   268,   266,   494, 14473, 42043,    11, 12771, 31534,
          267,  1082, 17009,    74, 12321,    11, 23781,  2853,  1168,   385,
          321,  3653,    71,  2501,  3318,  4656,   509,  2002,   403,  1134,
          341,   545,  4816,  1976,    84,   336, 11033,    81,  3464,    13,
          930,   198,    91,   642,    13,   930, 45371,   917,   258,   896,
           12,  3318,  3894,  1108,    12, 15167,  1326,   930,   412, 10745,
         9116, 11840,  2150, 18042, 34545,    12,  3318,  7232,  2777,  1236,
         2150,  8135,  1834,   268,   266,   494, 32856,    11, 41616,   267,
         1082,  5674, 11286,    11, 23781,   288,   292,   370,  1219, 23160,
          891,   521,   268,  4587,   337,  7940,  1350,  2676,  1976,    84,
          277, 30570,  1082,    77,    13,   930,   198,    91,   718,    13,
          930, 37774,    12,    42,   586,   333,  3318, 13245,    68,   509,
         2002,   403,  1134,   341,   930,   412,  8658,  2505,  2150,   304,
         7274,   572,   268,   268, 37774,    12,    42,   586,   333,  3318,
         1007, 11730,   353,   509,  2002,   403,  1134,   341,    11, 23781,
         4656,   337,  7940,  1350,  2676,   287,  7232, 15952,   312,  2150,
           82,  1676, 12271,   325,   304,   259,    89,   549,   521,   268,
           13,   930,   198,    91,   767,    13,   930,   337,  7940,  1350,
         2676,    12,    44,   298,  3255,    12, 15167,    76,   930,   412,
        10745,  9116, 11840,  2150,   304,  1127, 31879,  3255,    12, 15167,
          907,    11,   307,    72,  1357,  1931,    69,   993, 25924,   337,
         7940,  1350,  2676,  1312, 11840,   370,   747,   268,  3318,  1312,
           71,   260,  5256,    69,   993,    81,  2150,   268, 10255,   474,
         9116,    77,   469,   918, 25910,  1455,   268,   573,   346,   268,
           13,   930,   198,    91,   807,    13,   930,   366,   818,    77,
        17882, 14247,     1,   930,   412,   259,  7527,    83,  2150, 18042,
          693, 49746,   297,   268,   309, 11286,    11,   281,  2853,   268,
          337,  7940,  1350,  2676,   281,   304,  9324,   268,  1041,    73,
          988,  1452,   610, 15357,   268,   267,  1082, 13097, 16714,   268,
          277, 25151,   288,   292,   791,   353,   710,    71,  3653,   920,
        22664,  7750,    77,   479,  9101, 20471,   268,    13,   930,   198,
           91,   860,    13,   930,  1423,  1699,  2731,   293,  9375,   380,
          567,   298, 16239,    75,  2150, 22018, 11033,   710,   930,  5256,
          301,   695,  2150, 18042,  2614, 23267,   861,   268,  9375,   380,
          567,   489, 11033, 38572,   287,  1168,   385,   321,  3653,   283,
        15357, 10255,  2853,   337,  7940, 15357,  1142,    11, 23781,  1312,
           71,   260, 18157,  3046,   677,   258,  7232, 16239,    75,  2150,
         1976,    84,   555,   353,   301,  9116,    83,  4801,    13,   930,
          198,    91,   838,    13,   930, 15669,    68,  1040, 11693,   701,
          677,   258,   523,    89,   498,    68,  4643,   415,    86,  1922,
           70,   357,  7902,    49,     8, 44707,  5375,  1469,   930, 30801,
        18042,  4848,    72, 10594,  9324,  1676,    73,   988,  1452,  3318,
         9429,    49,    12,    32, 21841,   452,   270, 11033,  1452,    11,
        23781,  2853,   337,  7940, 15357,  1142,  4656,   337,  9101,  4743,
          488,   365,   270,  1976,    84,   308,  1765,   268,    11,   523,
           89,   498,   268,   412,   259,  2704,  1046,  1976,    84,   497,
           71,  3653,    13,   930, 50256])
{'loss': 1.0063, 'grad_norm': 0.6746878073247673, 'learning_rate': 1.1273852930193798e-05, 'epoch': 0.48}
{'loss': 1.0284, 'grad_norm': 0.6202959584611759, 'learning_rate': 1.12614917734415e-05, 'epoch': 0.48}
{'loss': 1.039, 'grad_norm': 0.6101307921595082, 'learning_rate': 1.1249128657671233e-05, 'epoch': 0.48}
{'loss': 1.047, 'grad_norm': 0.6835828867973758, 'learning_rate': 1.1236763602082136e-05, 'epoch': 0.48}
{'loss': 1.022, 'grad_norm': 0.609019994119226, 'learning_rate': 1.1224396625876375e-05, 'epoch': 0.48}
{'loss': 1.008, 'grad_norm': 0.5716487669031377, 'learning_rate': 1.1212027748259086e-05, 'epoch': 0.48}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/300190786.jpg, using default black image.
{'loss': 0.985, 'grad_norm': 0.6011037878561996, 'learning_rate': 1.1199656988438373e-05, 'epoch': 0.48}
{'loss': 1.0381, 'grad_norm': 0.668373876532951, 'learning_rate': 1.1187284365625241e-05, 'epoch': 0.48}
{'loss': 1.0243, 'grad_norm': 0.6131168780180305, 'learning_rate': 1.1174909899033608e-05, 'epoch': 0.48}
{'loss': 0.9751, 'grad_norm': 0.7208162544236064, 'learning_rate': 1.1162533607880251e-05, 'epoch': 0.48}
{'loss': 0.9841, 'grad_norm': 0.6120268719978381, 'learning_rate': 1.1150155511384772e-05, 'epoch': 0.48}
{'loss': 0.9802, 'grad_norm': 0.5549998653846662, 'learning_rate': 1.1137775628769584e-05, 'epoch': 0.48}
{'loss': 1.0165, 'grad_norm': 0.7453338716402251, 'learning_rate': 1.1125393979259874e-05, 'epoch': 0.48}
{'loss': 1.0058, 'grad_norm': 0.6294960148628864, 'learning_rate': 1.1113010582083568e-05, 'epoch': 0.48}
{'loss': 1.0246, 'grad_norm': 0.6021830624709741, 'learning_rate': 1.1100625456471307e-05, 'epoch': 0.48}
{'loss': 1.0248, 'grad_norm': 0.6657374152259274, 'learning_rate': 1.1088238621656422e-05, 'epoch': 0.48}
{'loss': 0.9811, 'grad_norm': 0.6535531268007684, 'learning_rate': 1.1075850096874894e-05, 'epoch': 0.48}
{'loss': 0.9236, 'grad_norm': 0.6659017982416879, 'learning_rate': 1.1063459901365325e-05, 'epoch': 0.48}
{'loss': 1.0359, 'grad_norm': 0.6213993311213853, 'learning_rate': 1.1051068054368921e-05, 'epoch': 0.48}
{'loss': 0.9966, 'grad_norm': 0.6507527458376519, 'learning_rate': 1.1038674575129442e-05, 'epoch': 0.48}
{'loss': 1.0602, 'grad_norm': 0.6759223264007285, 'learning_rate': 1.1026279482893187e-05, 'epoch': 0.49}
{'loss': 0.987, 'grad_norm': 0.6512258116135836, 'learning_rate': 1.1013882796908963e-05, 'epoch': 0.49}
{'loss': 1.0462, 'grad_norm': 0.6652049988726471, 'learning_rate': 1.1001484536428052e-05, 'epoch': 0.49}
{'loss': 1.0197, 'grad_norm': 0.6390183002815182, 'learning_rate': 1.098908472070417e-05, 'epoch': 0.49}
{'loss': 1.0148, 'grad_norm': 0.6234842878914225, 'learning_rate': 1.0976683368993464e-05, 'epoch': 0.49}
{'loss': 0.9552, 'grad_norm': 0.6324661666309084, 'learning_rate': 1.0964280500554459e-05, 'epoch': 0.49}
{'loss': 1.0043, 'grad_norm': 0.6774580303510574, 'learning_rate': 1.0951876134648032e-05, 'epoch': 0.49}
{'loss': 0.9537, 'grad_norm': 0.5278036921832695, 'learning_rate': 1.0939470290537389e-05, 'epoch': 0.49}
{'loss': 0.9996, 'grad_norm': 0.5658089773594188, 'learning_rate': 1.0927062987488035e-05, 'epoch': 0.49}
{'loss': 1.024, 'grad_norm': 0.5991151634702386, 'learning_rate': 1.0914654244767736e-05, 'epoch': 0.49}
{'loss': 0.9676, 'grad_norm': 0.7235453055509852, 'learning_rate': 1.0902244081646489e-05, 'epoch': 0.49}
{'loss': 1.0126, 'grad_norm': 0.6902846687817255, 'learning_rate': 1.0889832517396511e-05, 'epoch': 0.49}
{'loss': 1.0238, 'grad_norm': 0.5993117134748713, 'learning_rate': 1.0877419571292183e-05, 'epoch': 0.49}
{'loss': 1.0222, 'grad_norm': 0.6313177546333141, 'learning_rate': 1.0865005262610033e-05, 'epoch': 0.49}
{'loss': 0.9524, 'grad_norm': 0.7209489202539454, 'learning_rate': 1.085258961062871e-05, 'epoch': 0.49}
{'loss': 0.9835, 'grad_norm': 0.65426509850973, 'learning_rate': 1.0840172634628948e-05, 'epoch': 0.49}
{'loss': 0.9904, 'grad_norm': 0.7612873982458223, 'learning_rate': 1.082775435389353e-05, 'epoch': 0.49}
{'loss': 0.9523, 'grad_norm': 0.6097981766269485, 'learning_rate': 1.0815334787707277e-05, 'epoch': 0.49}
{'loss': 1.0431, 'grad_norm': 0.7073593848222173, 'learning_rate': 1.0802913955356998e-05, 'epoch': 0.49}
{'loss': 0.9994, 'grad_norm': 0.5978311026425915, 'learning_rate': 1.079049187613147e-05, 'epoch': 0.49}
{'loss': 0.9821, 'grad_norm': 0.6572528485674561, 'learning_rate': 1.0778068569321403e-05, 'epoch': 0.49}
{'loss': 0.9976, 'grad_norm': 0.6559905556660526, 'learning_rate': 1.0765644054219422e-05, 'epoch': 0.49}
{'loss': 1.0043, 'grad_norm': 0.6232566008296544, 'learning_rate': 1.0753218350120023e-05, 'epoch': 0.49}
{'loss': 0.9762, 'grad_norm': 0.6546440135937155, 'learning_rate': 1.0740791476319543e-05, 'epoch': 0.49}
{'loss': 1.0284, 'grad_norm': 0.7098562485293873, 'learning_rate': 1.0728363452116149e-05, 'epoch': 0.49}
{'loss': 1.0253, 'grad_norm': 0.6079007518458366, 'learning_rate': 1.0715934296809782e-05, 'epoch': 0.49}
{'loss': 0.9584, 'grad_norm': 0.5553193665809658, 'learning_rate': 1.0703504029702148e-05, 'epoch': 0.5}
{'loss': 0.9829, 'grad_norm': 0.6065319956318513, 'learning_rate': 1.0691072670096669e-05, 'epoch': 0.5}
{'loss': 0.9701, 'grad_norm': 0.7546531083220681, 'learning_rate': 1.0678640237298476e-05, 'epoch': 0.5}
{'loss': 0.9896, 'grad_norm': 0.8260954336799116, 'learning_rate': 1.0666206750614363e-05, 'epoch': 0.5}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/1848373732.jpg, using default black image.
{'loss': 0.9682, 'grad_norm': 0.5337775916815086, 'learning_rate': 1.065377222935275e-05, 'epoch': 0.5}
{'loss': 1.015, 'grad_norm': 0.5814124699318701, 'learning_rate': 1.064133669282368e-05, 'epoch': 0.5}
{'loss': 1.0058, 'grad_norm': 0.6132216955326353, 'learning_rate': 1.0628900160338764e-05, 'epoch': 0.5}
{'loss': 0.9957, 'grad_norm': 0.7930866551538999, 'learning_rate': 1.0616462651211156e-05, 'epoch': 0.5}
{'loss': 0.9945, 'grad_norm': 0.57495867475168, 'learning_rate': 1.0604024184755539e-05, 'epoch': 0.5}
{'loss': 0.9682, 'grad_norm': 0.5687676518930941, 'learning_rate': 1.0591584780288069e-05, 'epoch': 0.5}
{'loss': 0.9805, 'grad_norm': 0.8061879166070962, 'learning_rate': 1.0579144457126365e-05, 'epoch': 0.5}
{'loss': 0.9964, 'grad_norm': 0.7053892520340156, 'learning_rate': 1.0566703234589471e-05, 'epoch': 0.5}
{'loss': 0.9753, 'grad_norm': 0.5797355122433998, 'learning_rate': 1.0554261131997833e-05, 'epoch': 0.5}
{'loss': 0.9645, 'grad_norm': 0.573306669624426, 'learning_rate': 1.054181816867326e-05, 'epoch': 0.5}
{'loss': 1.0174, 'grad_norm': 0.6389337377169616, 'learning_rate': 1.0529374363938888e-05, 'epoch': 0.5}
{'loss': 1.0243, 'grad_norm': 0.6000787259012714, 'learning_rate': 1.051692973711918e-05, 'epoch': 0.5}
{'loss': 1.0027, 'grad_norm': 0.5980147397711856, 'learning_rate': 1.0504484307539864e-05, 'epoch': 0.5}
{'loss': 1.0349, 'grad_norm': 0.5945136635366656, 'learning_rate': 1.0492038094527907e-05, 'epoch': 0.5}
{'loss': 0.971, 'grad_norm': 0.6686577914666114, 'learning_rate': 1.047959111741151e-05, 'epoch': 0.5}
{'loss': 1.0369, 'grad_norm': 0.6215011436242799, 'learning_rate': 1.0467143395520044e-05, 'epoch': 0.5}
{'loss': 1.0271, 'grad_norm': 0.6612459664424315, 'learning_rate': 1.0454694948184045e-05, 'epoch': 0.5}
{'loss': 0.9647, 'grad_norm': 0.5324045489106951, 'learning_rate': 1.044224579473518e-05, 'epoch': 0.5}
{'loss': 1.0271, 'grad_norm': 0.623214780116854, 'learning_rate': 1.0429795954506203e-05, 'epoch': 0.5}
{'loss': 0.9335, 'grad_norm': 0.5302925719562679, 'learning_rate': 1.0417345446830938e-05, 'epoch': 0.5}
{'loss': 1.0185, 'grad_norm': 0.6156301178254736, 'learning_rate': 1.0404894291044247e-05, 'epoch': 0.5}
{'loss': 1.0087, 'grad_norm': 0.5534685233031489, 'learning_rate': 1.0392442506482e-05, 'epoch': 0.5}
{'loss': 0.9807, 'grad_norm': 0.6277251362388767, 'learning_rate': 1.037999011248104e-05, 'epoch': 0.51}
{'loss': 1.0133, 'grad_norm': 0.581767343270008, 'learning_rate': 1.0367537128379154e-05, 'epoch': 0.51}
{'loss': 1.0226, 'grad_norm': 0.5781750201732668, 'learning_rate': 1.0355083573515052e-05, 'epoch': 0.51}
{'loss': 0.9789, 'grad_norm': 0.6127375226263908, 'learning_rate': 1.0342629467228331e-05, 'epoch': 0.51}
{'loss': 1.0154, 'grad_norm': 0.9402714344263888, 'learning_rate': 1.0330174828859434e-05, 'epoch': 0.51}
{'loss': 0.9858, 'grad_norm': 0.6140558386892963, 'learning_rate': 1.031771967774964e-05, 'epoch': 0.51}
{'loss': 1.0092, 'grad_norm': 0.6461438537187609, 'learning_rate': 1.030526403324102e-05, 'epoch': 0.51}
{'loss': 0.9768, 'grad_norm': 0.6086146427332444, 'learning_rate': 1.0292807914676412e-05, 'epoch': 0.51}
{'loss': 0.9987, 'grad_norm': 0.6520516508815025, 'learning_rate': 1.0280351341399392e-05, 'epoch': 0.51}
{'loss': 1.006, 'grad_norm': 0.6451968836544103, 'learning_rate': 1.0267894332754243e-05, 'epoch': 0.51}
{'loss': 1.0241, 'grad_norm': 0.702693549677861, 'learning_rate': 1.0255436908085919e-05, 'epoch': 0.51}
{'loss': 0.9789, 'grad_norm': 0.5316583741406278, 'learning_rate': 1.0242979086740019e-05, 'epoch': 0.51}
{'loss': 1.0173, 'grad_norm': 0.6453975071868304, 'learning_rate': 1.0230520888062765e-05, 'epoch': 0.51}
{'loss': 1.017, 'grad_norm': 0.6331053571609311, 'learning_rate': 1.0218062331400969e-05, 'epoch': 0.51}
{'loss': 0.9625, 'grad_norm': 0.5559878814803858, 'learning_rate': 1.0205603436101978e-05, 'epoch': 0.51}
{'loss': 0.9978, 'grad_norm': 0.70082168353938, 'learning_rate': 1.019314422151369e-05, 'epoch': 0.51}
{'loss': 1.0305, 'grad_norm': 0.6242261521639119, 'learning_rate': 1.0180684706984483e-05, 'epoch': 0.51}
{'loss': 1.0196, 'grad_norm': 0.5815976910392611, 'learning_rate': 1.0168224911863205e-05, 'epoch': 0.51}
{'loss': 0.9889, 'grad_norm': 0.5738351313007757, 'learning_rate': 1.015576485549914e-05, 'epoch': 0.51}
{'loss': 0.976, 'grad_norm': 0.5286084901166619, 'learning_rate': 1.0143304557241979e-05, 'epoch': 0.51}
{'loss': 1.0236, 'grad_norm': 0.7238905827398433, 'learning_rate': 1.0130844036441787e-05, 'epoch': 0.51}
{'loss': 0.9746, 'grad_norm': 0.6102168407073102, 'learning_rate': 1.0118383312448973e-05, 'epoch': 0.51}
{'loss': 0.9437, 'grad_norm': 0.584277190758669, 'learning_rate': 1.0105922404614265e-05, 'epoch': 0.51}
{'loss': 0.969, 'grad_norm': 0.6525193458818005, 'learning_rate': 1.0093461332288678e-05, 'epoch': 0.51}
{'loss': 0.9867, 'grad_norm': 0.6860860663178219, 'learning_rate': 1.0081000114823473e-05, 'epoch': 0.51}
{'loss': 1.0219, 'grad_norm': 0.5892423497574005, 'learning_rate': 1.006853877157015e-05, 'epoch': 0.51}
{'loss': 1.0182, 'grad_norm': 0.6667046266763519, 'learning_rate': 1.0056077321880393e-05, 'epoch': 0.52}
{'loss': 0.9793, 'grad_norm': 0.7042310014424368, 'learning_rate': 1.0043615785106051e-05, 'epoch': 0.52}
{'loss': 0.987, 'grad_norm': 0.6442646383027113, 'learning_rate': 1.0031154180599123e-05, 'epoch': 0.52}
{'loss': 1.0002, 'grad_norm': 0.7180962662633241, 'learning_rate': 1.0018692527711695e-05, 'epoch': 0.52}
{'loss': 0.971, 'grad_norm': 0.6568056343196051, 'learning_rate': 1.0006230845795937e-05, 'epoch': 0.52}
{'loss': 0.994, 'grad_norm': 0.6338629447933596, 'learning_rate': 9.993769154204063e-06, 'epoch': 0.52}
{'loss': 1.0356, 'grad_norm': 0.6708702183704331, 'learning_rate': 9.981307472288308e-06, 'epoch': 0.52}
{'loss': 0.9989, 'grad_norm': 0.6065745467201902, 'learning_rate': 9.968845819400883e-06, 'epoch': 0.52}
{'loss': 1.0155, 'grad_norm': 0.6547554054317831, 'learning_rate': 9.956384214893949e-06, 'epoch': 0.52}
{'loss': 1.022, 'grad_norm': 0.5842845218629331, 'learning_rate': 9.94392267811961e-06, 'epoch': 0.52}
{'loss': 1.0065, 'grad_norm': 0.5973288110252761, 'learning_rate': 9.931461228429856e-06, 'epoch': 0.52}
{'loss': 1.0111, 'grad_norm': 0.6616694825654855, 'learning_rate': 9.91899988517653e-06, 'epoch': 0.52}
{'loss': 0.9402, 'grad_norm': 0.6456721325577626, 'learning_rate': 9.906538667711324e-06, 'epoch': 0.52}
{'loss': 0.9751, 'grad_norm': 0.6751890010925425, 'learning_rate': 9.894077595385736e-06, 'epoch': 0.52}
{'loss': 0.9838, 'grad_norm': 0.6776511004548991, 'learning_rate': 9.881616687551032e-06, 'epoch': 0.52}
{'loss': 1.0371, 'grad_norm': 0.8291129857835564, 'learning_rate': 9.869155963558215e-06, 'epoch': 0.52}
{'loss': 1.031, 'grad_norm': 0.6506050113175413, 'learning_rate': 9.856695442758023e-06, 'epoch': 0.52}
{'loss': 1.0025, 'grad_norm': 0.6811650570107257, 'learning_rate': 9.844235144500865e-06, 'epoch': 0.52}
{'loss': 1.0288, 'grad_norm': 0.6844260977840074, 'learning_rate': 9.831775088136797e-06, 'epoch': 0.52}
{'loss': 1.0123, 'grad_norm': 0.5978795847747707, 'learning_rate': 9.819315293015519e-06, 'epoch': 0.52}
{'loss': 0.9941, 'grad_norm': 0.5951640656956696, 'learning_rate': 9.806855778486314e-06, 'epoch': 0.52}
{'loss': 0.9603, 'grad_norm': 0.58865185844302, 'learning_rate': 9.794396563898022e-06, 'epoch': 0.52}
{'loss': 0.9933, 'grad_norm': 0.5980481741930795, 'learning_rate': 9.781937668599035e-06, 'epoch': 0.52}
{'loss': 1.0116, 'grad_norm': 0.6471522302585455, 'learning_rate': 9.769479111937238e-06, 'epoch': 0.52}
{'loss': 1.0482, 'grad_norm': 0.6654079360452791, 'learning_rate': 9.757020913259986e-06, 'epoch': 0.52}
{'loss': 0.9883, 'grad_norm': 0.5953772506533849, 'learning_rate': 9.744563091914085e-06, 'epoch': 0.52}
{'loss': 1.0441, 'grad_norm': 0.6157714581643369, 'learning_rate': 9.732105667245759e-06, 'epoch': 0.53}
{'loss': 0.9593, 'grad_norm': 0.5238695660070434, 'learning_rate': 9.719648658600611e-06, 'epoch': 0.53}
{'loss': 1.0029, 'grad_norm': 0.5682799582980267, 'learning_rate': 9.70719208532359e-06, 'epoch': 0.53}
{'loss': 1.0423, 'grad_norm': 0.6185327489952807, 'learning_rate': 9.694735966758982e-06, 'epoch': 0.53}
{'loss': 0.9725, 'grad_norm': 0.5613586152310759, 'learning_rate': 9.682280322250365e-06, 'epoch': 0.53}
{'loss': 0.9245, 'grad_norm': 0.5843427751908737, 'learning_rate': 9.669825171140568e-06, 'epoch': 0.53}
{'loss': 1.0029, 'grad_norm': 0.6417405092357585, 'learning_rate': 9.657370532771672e-06, 'epoch': 0.53}
{'loss': 1.0036, 'grad_norm': 0.5875834332791617, 'learning_rate': 9.64491642648495e-06, 'epoch': 0.53}
{'loss': 1.0046, 'grad_norm': 0.6197571225679365, 'learning_rate': 9.632462871620847e-06, 'epoch': 0.53}
{'loss': 1.0288, 'grad_norm': 0.6374615876290131, 'learning_rate': 9.620009887518963e-06, 'epoch': 0.53}
{'loss': 0.9838, 'grad_norm': 0.5945483103015763, 'learning_rate': 9.607557493518006e-06, 'epoch': 0.53}
{'loss': 1.0412, 'grad_norm': 0.67053245779896, 'learning_rate': 9.595105708955758e-06, 'epoch': 0.53}
{'loss': 1.0158, 'grad_norm': 0.6591296909369974, 'learning_rate': 9.582654553169064e-06, 'epoch': 0.53}
{'loss': 0.9722, 'grad_norm': 0.45957693207530986, 'learning_rate': 9.5702040454938e-06, 'epoch': 0.53}
{'loss': 0.9403, 'grad_norm': 0.5581324411205864, 'learning_rate': 9.557754205264826e-06, 'epoch': 0.53}
{'loss': 0.9721, 'grad_norm': 0.6503108113588142, 'learning_rate': 9.545305051815957e-06, 'epoch': 0.53}
{'loss': 1.0079, 'grad_norm': 0.7272899699235461, 'learning_rate': 9.53285660447996e-06, 'epoch': 0.53}
{'loss': 0.9977, 'grad_norm': 0.5347772502207078, 'learning_rate': 9.520408882588497e-06, 'epoch': 0.53}
{'loss': 1.0124, 'grad_norm': 0.6047168951788079, 'learning_rate': 9.507961905472093e-06, 'epoch': 0.53}
{'loss': 1.0023, 'grad_norm': 0.5867909305082452, 'learning_rate': 9.495515692460138e-06, 'epoch': 0.53}
{'loss': 0.9848, 'grad_norm': 0.6267474623757394, 'learning_rate': 9.483070262880823e-06, 'epoch': 0.53}
{'loss': 0.9987, 'grad_norm': 0.6335895076167378, 'learning_rate': 9.47062563606111e-06, 'epoch': 0.53}
{'loss': 1.0248, 'grad_norm': 0.6358976453982892, 'learning_rate': 9.458181831326744e-06, 'epoch': 0.53}
{'loss': 1.005, 'grad_norm': 0.6946574097207142, 'learning_rate': 9.44573886800217e-06, 'epoch': 0.53}
{'loss': 1.0271, 'grad_norm': 0.5972967213068282, 'learning_rate': 9.433296765410534e-06, 'epoch': 0.53}
{'loss': 1.0157, 'grad_norm': 0.6359592452534999, 'learning_rate': 9.420855542873638e-06, 'epoch': 0.53}
{'loss': 0.9869, 'grad_norm': 0.6790068598908233, 'learning_rate': 9.408415219711934e-06, 'epoch': 0.54}
{'loss': 0.9607, 'grad_norm': 0.6524196868996062, 'learning_rate': 9.395975815244468e-06, 'epoch': 0.54}
{'loss': 0.9741, 'grad_norm': 0.6902565215575699, 'learning_rate': 9.383537348788844e-06, 'epoch': 0.54}
{'loss': 1.0411, 'grad_norm': 0.6294945119424936, 'learning_rate': 9.371099839661238e-06, 'epoch': 0.54}
{'loss': 1.0058, 'grad_norm': 0.6943493733335037, 'learning_rate': 9.358663307176323e-06, 'epoch': 0.54}
{'loss': 1.0092, 'grad_norm': 0.5479191645411116, 'learning_rate': 9.346227770647251e-06, 'epoch': 0.54}
{'loss': 0.9802, 'grad_norm': 0.6140457438824111, 'learning_rate': 9.33379324938564e-06, 'epoch': 0.54}
{'loss': 0.9883, 'grad_norm': 0.7354816391478757, 'learning_rate': 9.321359762701527e-06, 'epoch': 0.54}
{'loss': 0.9953, 'grad_norm': 0.5696543786539462, 'learning_rate': 9.308927329903333e-06, 'epoch': 0.54}
{'loss': 1.0165, 'grad_norm': 0.5773606688303605, 'learning_rate': 9.296495970297855e-06, 'epoch': 0.54}
{'loss': 1.0554, 'grad_norm': 0.5884029931576678, 'learning_rate': 9.284065703190221e-06, 'epoch': 0.54}
{'loss': 1.0082, 'grad_norm': 0.5319116211553113, 'learning_rate': 9.271636547883856e-06, 'epoch': 0.54}
{'loss': 0.9906, 'grad_norm': 0.6669861357462941, 'learning_rate': 9.259208523680457e-06, 'epoch': 0.54}
{'loss': 0.9513, 'grad_norm': 0.7113472301869244, 'learning_rate': 9.24678164987998e-06, 'epoch': 0.54}
{'loss': 0.993, 'grad_norm': 0.6518327190732243, 'learning_rate': 9.234355945780581e-06, 'epoch': 0.54}
{'loss': 1.0187, 'grad_norm': 0.6665899305146253, 'learning_rate': 9.221931430678598e-06, 'epoch': 0.54}
{'loss': 0.9443, 'grad_norm': 0.6079576555280501, 'learning_rate': 9.209508123868534e-06, 'epoch': 0.54}
{'loss': 1.0081, 'grad_norm': 0.6788015825994014, 'learning_rate': 9.197086044643004e-06, 'epoch': 0.54}
{'loss': 0.972, 'grad_norm': 0.6541487150090116, 'learning_rate': 9.184665212292723e-06, 'epoch': 0.54}
{'loss': 1.0411, 'grad_norm': 0.6075232767024726, 'learning_rate': 9.172245646106471e-06, 'epoch': 0.54}
{'loss': 0.9961, 'grad_norm': 0.727345255930473, 'learning_rate': 9.159827365371055e-06, 'epoch': 0.54}
{'loss': 0.9563, 'grad_norm': 0.5487434086311692, 'learning_rate': 9.14741038937129e-06, 'epoch': 0.54}
{'loss': 1.0139, 'grad_norm': 0.5938915868942123, 'learning_rate': 9.13499473738997e-06, 'epoch': 0.54}
{'loss': 0.9625, 'grad_norm': 0.6094992140376279, 'learning_rate': 9.122580428707822e-06, 'epoch': 0.54}
{'loss': 1.0198, 'grad_norm': 0.8166331364977203, 'learning_rate': 9.110167482603494e-06, 'epoch': 0.54}
{'loss': 1.0266, 'grad_norm': 0.6428029363776603, 'learning_rate': 9.097755918353513e-06, 'epoch': 0.54}
{'loss': 0.9872, 'grad_norm': 0.6385811532523374, 'learning_rate': 9.08534575523227e-06, 'epoch': 0.55}
{'loss': 0.9971, 'grad_norm': 0.6123150359415332, 'learning_rate': 9.072937012511968e-06, 'epoch': 0.55}
{'loss': 0.97, 'grad_norm': 0.5423322234521895, 'learning_rate': 9.060529709462613e-06, 'epoch': 0.55}
{'loss': 1.0438, 'grad_norm': 0.648664852737047, 'learning_rate': 9.048123865351971e-06, 'epoch': 0.55}
{'loss': 0.9878, 'grad_norm': 0.5753537812471232, 'learning_rate': 9.035719499445545e-06, 'epoch': 0.55}
{'loss': 0.9771, 'grad_norm': 0.7019987130628101, 'learning_rate': 9.023316631006536e-06, 'epoch': 0.55}
{'loss': 0.9554, 'grad_norm': 0.6306127239805583, 'learning_rate': 9.010915279295833e-06, 'epoch': 0.55}
{'loss': 1.0439, 'grad_norm': 0.6045023536663826, 'learning_rate': 8.998515463571953e-06, 'epoch': 0.55}
{'loss': 1.0351, 'grad_norm': 0.7518211716119447, 'learning_rate': 8.986117203091042e-06, 'epoch': 0.55}
{'loss': 0.9995, 'grad_norm': 0.6077637659536858, 'learning_rate': 8.973720517106814e-06, 'epoch': 0.55}
{'loss': 1.0368, 'grad_norm': 0.6059861535763938, 'learning_rate': 8.961325424870561e-06, 'epoch': 0.55}
{'loss': 1.0379, 'grad_norm': 0.6605404552841206, 'learning_rate': 8.948931945631082e-06, 'epoch': 0.55}
{'loss': 1.012, 'grad_norm': 0.7065968630266751, 'learning_rate': 8.936540098634675e-06, 'epoch': 0.55}
{'loss': 1.038, 'grad_norm': 0.5878105756348785, 'learning_rate': 8.924149903125108e-06, 'epoch': 0.55}
{'loss': 1.0501, 'grad_norm': 0.6649683622526215, 'learning_rate': 8.91176137834358e-06, 'epoch': 0.55}
{'loss': 0.9665, 'grad_norm': 0.5360460662952539, 'learning_rate': 8.899374543528695e-06, 'epoch': 0.55}
{'loss': 0.9751, 'grad_norm': 0.569466812570811, 'learning_rate': 8.886989417916435e-06, 'epoch': 0.55}
{'loss': 0.9731, 'grad_norm': 0.6421829050671531, 'learning_rate': 8.87460602074013e-06, 'epoch': 0.55}
{'loss': 0.9999, 'grad_norm': 0.717113344290454, 'learning_rate': 8.862224371230418e-06, 'epoch': 0.55}
{'loss': 0.9993, 'grad_norm': 0.6123064247035741, 'learning_rate': 8.84984448861523e-06, 'epoch': 0.55}
{'loss': 0.9632, 'grad_norm': 0.6088648939902301, 'learning_rate': 8.837466392119752e-06, 'epoch': 0.55}
{'loss': 0.9844, 'grad_norm': 0.6472516137530419, 'learning_rate': 8.825090100966396e-06, 'epoch': 0.55}
{'loss': 1.0177, 'grad_norm': 0.5953029424960009, 'learning_rate': 8.81271563437476e-06, 'epoch': 0.55}
{'loss': 1.0404, 'grad_norm': 0.7449592581998605, 'learning_rate': 8.800343011561633e-06, 'epoch': 0.55}
{'loss': 1.0165, 'grad_norm': 0.5808821502975553, 'learning_rate': 8.787972251740916e-06, 'epoch': 0.55}
{'loss': 0.9914, 'grad_norm': 0.666633013067116, 'learning_rate': 8.775603374123627e-06, 'epoch': 0.55}
{'loss': 0.9603, 'grad_norm': 0.5547045947921264, 'learning_rate': 8.763236397917865e-06, 'epoch': 0.56}
{'loss': 1.0701, 'grad_norm': 0.6348113377176242, 'learning_rate': 8.75087134232877e-06, 'epoch': 0.56}
{'loss': 1.0336, 'grad_norm': 0.5879631786483106, 'learning_rate': 8.738508226558499e-06, 'epoch': 0.56}
{'loss': 1.0061, 'grad_norm': 0.7494824693640635, 'learning_rate': 8.726147069806206e-06, 'epoch': 0.56}
{'loss': 1.0056, 'grad_norm': 0.5908336064016588, 'learning_rate': 8.713787891267988e-06, 'epoch': 0.56}
{'loss': 0.9746, 'grad_norm': 0.5603530328899916, 'learning_rate': 8.70143071013688e-06, 'epoch': 0.56}
{'loss': 0.9955, 'grad_norm': 0.5922922814144056, 'learning_rate': 8.689075545602816e-06, 'epoch': 0.56}
{'loss': 1.0, 'grad_norm': 0.5967764415862161, 'learning_rate': 8.676722416852594e-06, 'epoch': 0.56}
{'loss': 1.033, 'grad_norm': 0.5794575623562316, 'learning_rate': 8.66437134306985e-06, 'epoch': 0.56}
{'loss': 0.9723, 'grad_norm': 0.6806414054895858, 'learning_rate': 8.652022343435027e-06, 'epoch': 0.56}
{'loss': 0.9687, 'grad_norm': 0.6364826607491335, 'learning_rate': 8.63967543712536e-06, 'epoch': 0.56}
{'loss': 0.9576, 'grad_norm': 0.5648655367554867, 'learning_rate': 8.627330643314818e-06, 'epoch': 0.56}
{'loss': 1.0009, 'grad_norm': 0.549405562422424, 'learning_rate': 8.614987981174093e-06, 'epoch': 0.56}
{'loss': 1.0386, 'grad_norm': 0.6390976635893668, 'learning_rate': 8.602647469870573e-06, 'epoch': 0.56}
{'loss': 0.9815, 'grad_norm': 0.574112985798743, 'learning_rate': 8.590309128568303e-06, 'epoch': 0.56}
{'loss': 1.0238, 'grad_norm': 0.7368810680393775, 'learning_rate': 8.57797297642795e-06, 'epoch': 0.56}
{'loss': 1.0018, 'grad_norm': 0.5839337336845242, 'learning_rate': 8.565639032606794e-06, 'epoch': 0.56}
{'loss': 1.0028, 'grad_norm': 0.6621551898046841, 'learning_rate': 8.553307316258678e-06, 'epoch': 0.56}
{'loss': 0.9632, 'grad_norm': 0.7056081546978447, 'learning_rate': 8.540977846533986e-06, 'epoch': 0.56}
{'loss': 0.9768, 'grad_norm': 0.5968748462957569, 'learning_rate': 8.528650642579618e-06, 'epoch': 0.56}
{'loss': 0.9531, 'grad_norm': 0.7421075207248659, 'learning_rate': 8.516325723538949e-06, 'epoch': 0.56}
{'loss': 0.9919, 'grad_norm': 0.6856482002618827, 'learning_rate': 8.504003108551814e-06, 'epoch': 0.56}
{'loss': 0.9965, 'grad_norm': 0.6985892405086657, 'learning_rate': 8.491682816754456e-06, 'epoch': 0.56}
{'loss': 0.9746, 'grad_norm': 0.6206610818371268, 'learning_rate': 8.479364867279529e-06, 'epoch': 0.56}
{'loss': 1.0285, 'grad_norm': 0.6300282246179572, 'learning_rate': 8.467049279256034e-06, 'epoch': 0.56}
{'loss': 0.985, 'grad_norm': 0.7942372351612164, 'learning_rate': 8.45473607180931e-06, 'epoch': 0.56}
{'loss': 0.9474, 'grad_norm': 0.4212527069713696, 'learning_rate': 8.442425264061e-06, 'epoch': 0.57}
{'loss': 0.9906, 'grad_norm': 0.5956114953305638, 'learning_rate': 8.430116875129023e-06, 'epoch': 0.57}
{'loss': 1.0092, 'grad_norm': 0.6678693741664591, 'learning_rate': 8.417810924127533e-06, 'epoch': 0.57}
{'loss': 0.9919, 'grad_norm': 0.7565769895322304, 'learning_rate': 8.40550743016691e-06, 'epoch': 0.57}
{'loss': 0.9997, 'grad_norm': 0.6675714827046748, 'learning_rate': 8.393206412353709e-06, 'epoch': 0.57}
{'loss': 0.9919, 'grad_norm': 0.6646650018903185, 'learning_rate': 8.38090788979064e-06, 'epoch': 0.57}
{'loss': 1.0274, 'grad_norm': 0.5935397226003086, 'learning_rate': 8.368611881576547e-06, 'epoch': 0.57}
{'loss': 1.0066, 'grad_norm': 0.5931716668113092, 'learning_rate': 8.35631840680636e-06, 'epoch': 0.57}
{'loss': 1.0324, 'grad_norm': 0.6862452185651203, 'learning_rate': 8.344027484571075e-06, 'epoch': 0.57}
{'loss': 0.9887, 'grad_norm': 0.5744749526895951, 'learning_rate': 8.331739133957729e-06, 'epoch': 0.57}
{'loss': 1.0555, 'grad_norm': 0.6738004853590395, 'learning_rate': 8.319453374049367e-06, 'epoch': 0.57}
{'loss': 0.9713, 'grad_norm': 0.7200063845336726, 'learning_rate': 8.307170223925003e-06, 'epoch': 0.57}
{'loss': 1.0136, 'grad_norm': 0.6589268826069034, 'learning_rate': 8.294889702659602e-06, 'epoch': 0.57}
{'loss': 0.9552, 'grad_norm': 0.558700614820506, 'learning_rate': 8.282611829324049e-06, 'epoch': 0.57}
{'loss': 0.9847, 'grad_norm': 0.5788482156657834, 'learning_rate': 8.270336622985116e-06, 'epoch': 0.57}
{'loss': 0.9984, 'grad_norm': 0.704529612180722, 'learning_rate': 8.258064102705428e-06, 'epoch': 0.57}
{'loss': 1.0006, 'grad_norm': 0.6156014292556962, 'learning_rate': 8.245794287543447e-06, 'epoch': 0.57}
{'loss': 0.9576, 'grad_norm': 0.658251941494442, 'learning_rate': 8.233527196553428e-06, 'epoch': 0.57}
{'loss': 0.992, 'grad_norm': 0.5975520449398963, 'learning_rate': 8.221262848785395e-06, 'epoch': 0.57}
{'loss': 1.0541, 'grad_norm': 0.5897207537772055, 'learning_rate': 8.20900126328512e-06, 'epoch': 0.57}
{'loss': 1.0143, 'grad_norm': 0.698588052360429, 'learning_rate': 8.196742459094079e-06, 'epoch': 0.57}
{'loss': 1.0182, 'grad_norm': 0.6638512453547009, 'learning_rate': 8.184486455249424e-06, 'epoch': 0.57}
{'loss': 0.9773, 'grad_norm': 0.593219433003424, 'learning_rate': 8.172233270783966e-06, 'epoch': 0.57}
{'loss': 0.9961, 'grad_norm': 0.5717042052113671, 'learning_rate': 8.15998292472614e-06, 'epoch': 0.57}
{'loss': 1.0453, 'grad_norm': 0.7631951488319694, 'learning_rate': 8.147735436099967e-06, 'epoch': 0.57}
{'loss': 0.9833, 'grad_norm': 0.6556984134142778, 'learning_rate': 8.135490823925027e-06, 'epoch': 0.57}
{'loss': 0.9731, 'grad_norm': 0.6099578214382856, 'learning_rate': 8.123249107216446e-06, 'epoch': 0.58}
{'loss': 0.9489, 'grad_norm': 0.6160285105366823, 'learning_rate': 8.111010304984841e-06, 'epoch': 0.58}
{'loss': 1.0379, 'grad_norm': 0.6130431784392656, 'learning_rate': 8.098774436236308e-06, 'epoch': 0.58}
{'loss': 1.0036, 'grad_norm': 0.6397835509529833, 'learning_rate': 8.086541519972388e-06, 'epoch': 0.58}
{'loss': 1.0118, 'grad_norm': 0.6946845422762626, 'learning_rate': 8.074311575190039e-06, 'epoch': 0.58}
{'loss': 1.0426, 'grad_norm': 0.5811193202870043, 'learning_rate': 8.062084620881598e-06, 'epoch': 0.58}
{'loss': 1.0087, 'grad_norm': 0.6206783410747025, 'learning_rate': 8.049860676034762e-06, 'epoch': 0.58}
{'loss': 1.0041, 'grad_norm': 0.5606351675177593, 'learning_rate': 8.037639759632558e-06, 'epoch': 0.58}
{'loss': 1.001, 'grad_norm': 0.5926619681582397, 'learning_rate': 8.025421890653303e-06, 'epoch': 0.58}
{'loss': 0.962, 'grad_norm': 0.7569896815540968, 'learning_rate': 8.013207088070582e-06, 'epoch': 0.58}
{'loss': 1.0186, 'grad_norm': 0.6396990919190683, 'learning_rate': 8.000995370853227e-06, 'epoch': 0.58}
{'loss': 0.9843, 'grad_norm': 0.5638521993491268, 'learning_rate': 7.98878675796527e-06, 'epoch': 0.58}
{'loss': 1.0373, 'grad_norm': 0.6128134273888243, 'learning_rate': 7.976581268365924e-06, 'epoch': 0.58}
{'loss': 1.0088, 'grad_norm': 0.5307170239288074, 'learning_rate': 7.964378921009552e-06, 'epoch': 0.58}
{'loss': 0.9655, 'grad_norm': 0.5417283425681944, 'learning_rate': 7.952179734845642e-06, 'epoch': 0.58}
{'loss': 0.9455, 'grad_norm': 0.5744240870091972, 'learning_rate': 7.93998372881876e-06, 'epoch': 0.58}
{'loss': 0.9739, 'grad_norm': 0.5400731980749217, 'learning_rate': 7.92779092186855e-06, 'epoch': 0.58}
{'loss': 0.9831, 'grad_norm': 0.6566476998816414, 'learning_rate': 7.915601332929678e-06, 'epoch': 0.58}
{'loss': 0.9717, 'grad_norm': 0.6694598346832531, 'learning_rate': 7.903414980931813e-06, 'epoch': 0.58}
{'loss': 1.0104, 'grad_norm': 0.7271957748460437, 'learning_rate': 7.8912318847996e-06, 'epoch': 0.58}
{'loss': 0.979, 'grad_norm': 0.4685057000986616, 'learning_rate': 7.879052063452626e-06, 'epoch': 0.58}
{'loss': 0.9847, 'grad_norm': 0.6338189777924804, 'learning_rate': 7.866875535805394e-06, 'epoch': 0.58}
{'loss': 0.988, 'grad_norm': 0.565795409389641, 'learning_rate': 7.85470232076729e-06, 'epoch': 0.58}
{'loss': 0.9265, 'grad_norm': 0.5148015285851535, 'learning_rate': 7.842532437242559e-06, 'epoch': 0.58}
{'loss': 1.0224, 'grad_norm': 0.6175125754379497, 'learning_rate': 7.83036590413027e-06, 'epoch': 0.58}
{'loss': 1.0278, 'grad_norm': 0.7372904003422006, 'learning_rate': 7.818202740324287e-06, 'epoch': 0.58}
{'loss': 0.9883, 'grad_norm': 0.5921138126806622, 'learning_rate': 7.806042964713248e-06, 'epoch': 0.59}
{'loss': 0.9511, 'grad_norm': 0.7001829130197356, 'learning_rate': 7.793886596180521e-06, 'epoch': 0.59}
{'loss': 0.9935, 'grad_norm': 0.5116177525404941, 'learning_rate': 7.78173365360419e-06, 'epoch': 0.59}
{'loss': 0.9975, 'grad_norm': 0.588720274422268, 'learning_rate': 7.769584155857019e-06, 'epoch': 0.59}
{'loss': 0.9268, 'grad_norm': 0.5633719663313375, 'learning_rate': 7.757438121806414e-06, 'epoch': 0.59}
{'loss': 1.0066, 'grad_norm': 0.6739535377379774, 'learning_rate': 7.745295570314412e-06, 'epoch': 0.59}
{'loss': 0.9503, 'grad_norm': 0.5389680839320307, 'learning_rate': 7.733156520237633e-06, 'epoch': 0.59}
{'loss': 0.9438, 'grad_norm': 0.6676598021831109, 'learning_rate': 7.721020990427268e-06, 'epoch': 0.59}
{'loss': 0.9501, 'grad_norm': 0.7146448191755482, 'learning_rate': 7.708888999729036e-06, 'epoch': 0.59}
{'loss': 1.0054, 'grad_norm': 0.6223681820842619, 'learning_rate': 7.69676056698316e-06, 'epoch': 0.59}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/470584637.jpg, using default black image.
{'loss': 0.9583, 'grad_norm': 0.628834193216626, 'learning_rate': 7.68463571102434e-06, 'epoch': 0.59}
{'loss': 0.9984, 'grad_norm': 0.5684957057176222, 'learning_rate': 7.672514450681721e-06, 'epoch': 0.59}
{'loss': 0.9938, 'grad_norm': 0.6316187582158633, 'learning_rate': 7.66039680477886e-06, 'epoch': 0.59}
{'loss': 0.9612, 'grad_norm': 0.6595834271021901, 'learning_rate': 7.648282792133711e-06, 'epoch': 0.59}
{'loss': 0.9886, 'grad_norm': 0.6383748121492517, 'learning_rate': 7.636172431558575e-06, 'epoch': 0.59}
{'loss': 1.0089, 'grad_norm': 0.6617304913629144, 'learning_rate': 7.6240657418600846e-06, 'epoch': 0.59}
{'loss': 1.0011, 'grad_norm': 0.720338834538546, 'learning_rate': 7.611962741839178e-06, 'epoch': 0.59}
{'loss': 1.0259, 'grad_norm': 0.5502520425721551, 'learning_rate': 7.599863450291056e-06, 'epoch': 0.59}
{'loss': 0.9813, 'grad_norm': 0.5759531854110299, 'learning_rate': 7.587767886005164e-06, 'epoch': 0.59}
{'loss': 1.0386, 'grad_norm': 0.6449225969386356, 'learning_rate': 7.575676067765154e-06, 'epoch': 0.59}
{'loss': 1.031, 'grad_norm': 0.6066387232076131, 'learning_rate': 7.563588014348871e-06, 'epoch': 0.59}
{'loss': 1.0006, 'grad_norm': 0.6775367041125336, 'learning_rate': 7.551503744528304e-06, 'epoch': 0.59}
{'loss': 0.9533, 'grad_norm': 0.5312773031631127, 'learning_rate': 7.539423277069568e-06, 'epoch': 0.59}
{'loss': 0.9624, 'grad_norm': 0.6255182782569605, 'learning_rate': 7.52734663073288e-06, 'epoch': 0.59}
{'loss': 1.0055, 'grad_norm': 0.7282225143241093, 'learning_rate': 7.515273824272516e-06, 'epoch': 0.59}
{'loss': 0.9989, 'grad_norm': 0.6761419942905358, 'learning_rate': 7.503204876436785e-06, 'epoch': 0.59}
{'loss': 1.0847, 'grad_norm': 0.5732229627253359, 'learning_rate': 7.491139805968018e-06, 'epoch': 0.6}
{'loss': 0.9847, 'grad_norm': 0.7367121774486592, 'learning_rate': 7.4790786316025125e-06, 'epoch': 0.6}
{'loss': 0.9911, 'grad_norm': 0.6106121331624813, 'learning_rate': 7.467021372070515e-06, 'epoch': 0.6}
{'loss': 0.9372, 'grad_norm': 0.6427967684695093, 'learning_rate': 7.4549680460962044e-06, 'epoch': 0.6}
{'loss': 1.0198, 'grad_norm': 0.7159363180937295, 'learning_rate': 7.4429186723976425e-06, 'epoch': 0.6}
{'loss': 1.0045, 'grad_norm': 0.6341830343225424, 'learning_rate': 7.43087326968675e-06, 'epoch': 0.6}
{'loss': 1.0044, 'grad_norm': 0.611078171931244, 'learning_rate': 7.418831856669286e-06, 'epoch': 0.6}
{'loss': 1.0096, 'grad_norm': 0.6144564525044801, 'learning_rate': 7.406794452044816e-06, 'epoch': 0.6}
{'loss': 0.9254, 'grad_norm': 0.6022151154108462, 'learning_rate': 7.394761074506679e-06, 'epoch': 0.6}
{'loss': 0.9629, 'grad_norm': 0.679933748587733, 'learning_rate': 7.382731742741953e-06, 'epoch': 0.6}
{'loss': 0.9438, 'grad_norm': 0.6032519431250647, 'learning_rate': 7.370706475431446e-06, 'epoch': 0.6}
{'loss': 0.9898, 'grad_norm': 0.5903262322129866, 'learning_rate': 7.358685291249644e-06, 'epoch': 0.6}
{'loss': 1.0123, 'grad_norm': 0.6065056508293928, 'learning_rate': 7.346668208864695e-06, 'epoch': 0.6}
{'loss': 1.0065, 'grad_norm': 0.516227169495592, 'learning_rate': 7.33465524693838e-06, 'epoch': 0.6}
{'loss': 0.9656, 'grad_norm': 0.6058033094399373, 'learning_rate': 7.322646424126079e-06, 'epoch': 0.6}
{'loss': 1.0074, 'grad_norm': 0.6451467360049968, 'learning_rate': 7.310641759076742e-06, 'epoch': 0.6}
{'loss': 1.0037, 'grad_norm': 0.5909095249594114, 'learning_rate': 7.2986412704328625e-06, 'epoch': 0.6}
{'loss': 0.9765, 'grad_norm': 0.541132409409048, 'learning_rate': 7.286644976830457e-06, 'epoch': 0.6}
{'loss': 1.0143, 'grad_norm': 0.7630855145992728, 'learning_rate': 7.274652896899015e-06, 'epoch': 0.6}
{'loss': 0.9863, 'grad_norm': 0.6543779113449367, 'learning_rate': 7.262665049261489e-06, 'epoch': 0.6}
{'loss': 0.9752, 'grad_norm': 0.5784450165870474, 'learning_rate': 7.250681452534261e-06, 'epoch': 0.6}
{'loss': 0.9986, 'grad_norm': 0.6068579975328287, 'learning_rate': 7.238702125327106e-06, 'epoch': 0.6}
{'loss': 0.9671, 'grad_norm': 0.6384864250807175, 'learning_rate': 7.226727086243168e-06, 'epoch': 0.6}
{'loss': 0.9814, 'grad_norm': 0.7295240329257554, 'learning_rate': 7.214756353878942e-06, 'epoch': 0.6}
{'loss': 0.9465, 'grad_norm': 0.6293998223515025, 'learning_rate': 7.202789946824227e-06, 'epoch': 0.6}
{'loss': 0.9995, 'grad_norm': 0.733653937044332, 'learning_rate': 7.1908278836621e-06, 'epoch': 0.6}
{'loss': 0.9277, 'grad_norm': 0.5884827906813672, 'learning_rate': 7.178870182968904e-06, 'epoch': 0.61}
{'loss': 0.9922, 'grad_norm': 0.6813227155769276, 'learning_rate': 7.166916863314199e-06, 'epoch': 0.61}
{'loss': 0.9943, 'grad_norm': 0.6782627475227893, 'learning_rate': 7.154967943260748e-06, 'epoch': 0.61}
{'loss': 1.0269, 'grad_norm': 0.6563741078964171, 'learning_rate': 7.143023441364471e-06, 'epoch': 0.61}
{'loss': 1.0035, 'grad_norm': 0.799177551579591, 'learning_rate': 7.131083376174441e-06, 'epoch': 0.61}
{'loss': 1.0042, 'grad_norm': 0.6387320559727334, 'learning_rate': 7.119147766232832e-06, 'epoch': 0.61}
{'loss': 1.0029, 'grad_norm': 0.6324144832206198, 'learning_rate': 7.107216630074895e-06, 'epoch': 0.61}
{'loss': 0.9725, 'grad_norm': 0.5902781288814735, 'learning_rate': 7.09528998622895e-06, 'epoch': 0.61}
{'loss': 0.993, 'grad_norm': 0.6088935914824339, 'learning_rate': 7.083367853216323e-06, 'epoch': 0.61}
{'loss': 0.9858, 'grad_norm': 0.5862929741227103, 'learning_rate': 7.071450249551342e-06, 'epoch': 0.61}
{'loss': 0.98, 'grad_norm': 0.6831588046541252, 'learning_rate': 7.059537193741306e-06, 'epoch': 0.61}
{'loss': 0.9514, 'grad_norm': 0.6017963153337466, 'learning_rate': 7.047628704286446e-06, 'epoch': 0.61}
{'loss': 0.9672, 'grad_norm': 0.5948432244569315, 'learning_rate': 7.035724799679898e-06, 'epoch': 0.61}
{'loss': 0.9758, 'grad_norm': 0.7138757768852135, 'learning_rate': 7.023825498407689e-06, 'epoch': 0.61}
{'loss': 0.9527, 'grad_norm': 0.6969114578202283, 'learning_rate': 7.011930818948688e-06, 'epoch': 0.61}
{'loss': 0.9799, 'grad_norm': 0.6371034671384783, 'learning_rate': 7.000040779774591e-06, 'epoch': 0.61}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B01577TUTC.jpg, using default black image.
{'loss': 1.0202, 'grad_norm': 0.649387384018841, 'learning_rate': 6.9881553993498805e-06, 'epoch': 0.61}
{'loss': 0.9971, 'grad_norm': 0.6168178862087524, 'learning_rate': 6.97627469613182e-06, 'epoch': 0.61}
{'loss': 0.9309, 'grad_norm': 0.5760599749216287, 'learning_rate': 6.9643986885703955e-06, 'epoch': 0.61}
{'loss': 0.9946, 'grad_norm': 0.5827681396400054, 'learning_rate': 6.952527395108302e-06, 'epoch': 0.61}
{'loss': 1.0089, 'grad_norm': 0.6190615726387209, 'learning_rate': 6.9406608341809215e-06, 'epoch': 0.61}
{'loss': 0.9981, 'grad_norm': 0.5885211358740507, 'learning_rate': 6.928799024216282e-06, 'epoch': 0.61}
{'loss': 1.0359, 'grad_norm': 0.5410975549816219, 'learning_rate': 6.91694198363503e-06, 'epoch': 0.61}
{'loss': 1.0114, 'grad_norm': 0.6902233299613487, 'learning_rate': 6.905089730850416e-06, 'epoch': 0.61}
{'loss': 0.977, 'grad_norm': 0.6485494604035787, 'learning_rate': 6.893242284268244e-06, 'epoch': 0.61}
{'loss': 1.012, 'grad_norm': 0.8309685091658241, 'learning_rate': 6.8813996622868584e-06, 'epoch': 0.61}
{'loss': 0.9695, 'grad_norm': 0.563425477248334, 'learning_rate': 6.869561883297116e-06, 'epoch': 0.62}
{'loss': 0.9649, 'grad_norm': 0.5787856161228386, 'learning_rate': 6.857728965682344e-06, 'epoch': 0.62}
{'loss': 0.9367, 'grad_norm': 0.6602381998788314, 'learning_rate': 6.8459009278183275e-06, 'epoch': 0.62}
{'loss': 0.9339, 'grad_norm': 0.6408003303133544, 'learning_rate': 6.834077788073268e-06, 'epoch': 0.62}
{'loss': 0.9621, 'grad_norm': 0.6370119250401551, 'learning_rate': 6.822259564807768e-06, 'epoch': 0.62}
{'loss': 0.9888, 'grad_norm': 0.5989810603117885, 'learning_rate': 6.810446276374789e-06, 'epoch': 0.62}
{'loss': 0.9876, 'grad_norm': 0.5595993292934426, 'learning_rate': 6.7986379411196255e-06, 'epoch': 0.62}
{'loss': 0.9817, 'grad_norm': 0.6324141119756878, 'learning_rate': 6.786834577379893e-06, 'epoch': 0.62}
{'loss': 0.9897, 'grad_norm': 0.6679678012207675, 'learning_rate': 6.775036203485472e-06, 'epoch': 0.62}
{'loss': 0.9781, 'grad_norm': 0.5948472067894721, 'learning_rate': 6.763242837758504e-06, 'epoch': 0.62}
{'loss': 0.9997, 'grad_norm': 0.6483849809387591, 'learning_rate': 6.751454498513349e-06, 'epoch': 0.62}
{'loss': 1.0262, 'grad_norm': 0.60308741128597, 'learning_rate': 6.7396712040565625e-06, 'epoch': 0.62}
{'loss': 1.0193, 'grad_norm': 0.6390184421862611, 'learning_rate': 6.727892972686861e-06, 'epoch': 0.62}
{'loss': 0.9885, 'grad_norm': 0.6431828006341688, 'learning_rate': 6.716119822695111e-06, 'epoch': 0.62}
{'loss': 1.0001, 'grad_norm': 0.690417362009673, 'learning_rate': 6.704351772364274e-06, 'epoch': 0.62}
{'loss': 1.0135, 'grad_norm': 0.551178826055407, 'learning_rate': 6.692588839969397e-06, 'epoch': 0.62}
{'loss': 1.0075, 'grad_norm': 0.7255820189368573, 'learning_rate': 6.680831043777579e-06, 'epoch': 0.62}
{'loss': 0.9883, 'grad_norm': 0.6676312331313686, 'learning_rate': 6.6690784020479484e-06, 'epoch': 0.62}
{'loss': 0.9879, 'grad_norm': 0.7054935122012879, 'learning_rate': 6.657330933031619e-06, 'epoch': 0.62}
{'loss': 1.0163, 'grad_norm': 0.626968877041856, 'learning_rate': 6.645588654971677e-06, 'epoch': 0.62}
{'loss': 1.0133, 'grad_norm': 0.6783298245327061, 'learning_rate': 6.633851586103153e-06, 'epoch': 0.62}
{'loss': 0.9625, 'grad_norm': 0.6707758132758637, 'learning_rate': 6.622119744652977e-06, 'epoch': 0.62}
{'loss': 0.9281, 'grad_norm': 0.672316897340817, 'learning_rate': 6.610393148839964e-06, 'epoch': 0.62}
{'loss': 1.0373, 'grad_norm': 0.6931130053653449, 'learning_rate': 6.598671816874794e-06, 'epoch': 0.62}
{'loss': 0.9927, 'grad_norm': 0.64950169427596, 'learning_rate': 6.586955766959958e-06, 'epoch': 0.62}
{'loss': 0.9732, 'grad_norm': 0.5840126636874576, 'learning_rate': 6.5752450172897466e-06, 'epoch': 0.62}
{'loss': 0.9865, 'grad_norm': 0.5254899750401198, 'learning_rate': 6.563539586050233e-06, 'epoch': 0.63}
{'loss': 0.9637, 'grad_norm': 0.5788186925110854, 'learning_rate': 6.551839491419213e-06, 'epoch': 0.63}
{'loss': 1.006, 'grad_norm': 0.5686482936017524, 'learning_rate': 6.5401447515662065e-06, 'epoch': 0.63}
{'loss': 1.0212, 'grad_norm': 0.7107819661568351, 'learning_rate': 6.52845538465241e-06, 'epoch': 0.63}
{'loss': 1.0515, 'grad_norm': 0.6046234288867018, 'learning_rate': 6.5167714088306865e-06, 'epoch': 0.63}
{'loss': 1.0005, 'grad_norm': 0.6239816202685475, 'learning_rate': 6.505092842245519e-06, 'epoch': 0.63}
{'loss': 0.9957, 'grad_norm': 0.758796616445769, 'learning_rate': 6.493419703032991e-06, 'epoch': 0.63}
{'loss': 1.0259, 'grad_norm': 0.6029061943708074, 'learning_rate': 6.481752009320761e-06, 'epoch': 0.63}
{'loss': 0.978, 'grad_norm': 0.6366645728285812, 'learning_rate': 6.4700897792280285e-06, 'epoch': 0.63}
{'loss': 0.963, 'grad_norm': 0.5995232561782313, 'learning_rate': 6.458433030865503e-06, 'epoch': 0.63}
{'loss': 0.993, 'grad_norm': 0.5603075538055292, 'learning_rate': 6.4467817823354005e-06, 'epoch': 0.63}
{'loss': 1.0095, 'grad_norm': 0.6484959066642478, 'learning_rate': 6.43513605173137e-06, 'epoch': 0.63}
{'loss': 1.054, 'grad_norm': 0.5963566327673651, 'learning_rate': 6.4234958571385095e-06, 'epoch': 0.63}
{'loss': 1.0032, 'grad_norm': 0.5924082070090257, 'learning_rate': 6.4118612166333124e-06, 'epoch': 0.63}
{'loss': 1.0026, 'grad_norm': 0.700997889557652, 'learning_rate': 6.400232148283651e-06, 'epoch': 0.63}
{'loss': 1.0095, 'grad_norm': 0.7726252298334569, 'learning_rate': 6.388608670148741e-06, 'epoch': 0.63}
{'loss': 0.9643, 'grad_norm': 0.5635337102725325, 'learning_rate': 6.376990800279119e-06, 'epoch': 0.63}
{'loss': 0.9658, 'grad_norm': 0.6452466730039622, 'learning_rate': 6.3653785567166125e-06, 'epoch': 0.63}
{'loss': 1.0208, 'grad_norm': 0.6221968588557029, 'learning_rate': 6.3537719574943105e-06, 'epoch': 0.63}
{'loss': 0.9776, 'grad_norm': 0.7783969972662702, 'learning_rate': 6.342171020636533e-06, 'epoch': 0.63}
{'loss': 0.9836, 'grad_norm': 0.6062375109960388, 'learning_rate': 6.330575764158819e-06, 'epoch': 0.63}
{'loss': 0.9382, 'grad_norm': 0.6314665133540563, 'learning_rate': 6.318986206067872e-06, 'epoch': 0.63}
{'loss': 0.9882, 'grad_norm': 0.7363462944620608, 'learning_rate': 6.30740236436155e-06, 'epoch': 0.63}
{'loss': 0.9854, 'grad_norm': 0.6210410596586494, 'learning_rate': 6.295824257028844e-06, 'epoch': 0.63}
{'loss': 0.9856, 'grad_norm': 0.7388097226525414, 'learning_rate': 6.284251902049827e-06, 'epoch': 0.63}
{'loss': 1.0004, 'grad_norm': 0.6565624485057127, 'learning_rate': 6.272685317395644e-06, 'epoch': 0.63}
{'loss': 0.98, 'grad_norm': 0.683401620022576, 'learning_rate': 6.261124521028477e-06, 'epoch': 0.64}
{'loss': 0.9699, 'grad_norm': 0.6564799899968002, 'learning_rate': 6.249569530901525e-06, 'epoch': 0.64}
{'loss': 1.0493, 'grad_norm': 0.6637525647136697, 'learning_rate': 6.238020364958964e-06, 'epoch': 0.64}
{'loss': 0.993, 'grad_norm': 0.5872347947589739, 'learning_rate': 6.2264770411359256e-06, 'epoch': 0.64}
{'loss': 1.0131, 'grad_norm': 0.5919003347500663, 'learning_rate': 6.214939577358479e-06, 'epoch': 0.64}
{'loss': 0.9939, 'grad_norm': 0.7525978129888242, 'learning_rate': 6.203407991543577e-06, 'epoch': 0.64}
{'loss': 0.9611, 'grad_norm': 0.5950367171939476, 'learning_rate': 6.191882301599052e-06, 'epoch': 0.64}
{'loss': 0.9964, 'grad_norm': 0.5874883016726631, 'learning_rate': 6.180362525423591e-06, 'epoch': 0.64}
{'loss': 0.9573, 'grad_norm': 0.6188813793947939, 'learning_rate': 6.168848680906678e-06, 'epoch': 0.64}
{'loss': 1.0183, 'grad_norm': 0.6798245653580668, 'learning_rate': 6.157340785928595e-06, 'epoch': 0.64}
{'loss': 0.9769, 'grad_norm': 0.6368380772517618, 'learning_rate': 6.145838858360391e-06, 'epoch': 0.64}
{'loss': 0.9565, 'grad_norm': 0.5520389921499201, 'learning_rate': 6.134342916063838e-06, 'epoch': 0.64}
{'loss': 0.9525, 'grad_norm': 0.6283049379663546, 'learning_rate': 6.122852976891413e-06, 'epoch': 0.64}
{'loss': 0.989, 'grad_norm': 0.6379362804709231, 'learning_rate': 6.111369058686276e-06, 'epoch': 0.64}
{'loss': 1.0273, 'grad_norm': 0.6357784025796226, 'learning_rate': 6.099891179282242e-06, 'epoch': 0.64}
{'loss': 0.9522, 'grad_norm': 0.5177980940551936, 'learning_rate': 6.088419356503732e-06, 'epoch': 0.64}
{'loss': 1.0342, 'grad_norm': 0.6518478316795348, 'learning_rate': 6.076953608165772e-06, 'epoch': 0.64}
{'loss': 0.9322, 'grad_norm': 0.6162518765588223, 'learning_rate': 6.065493952073961e-06, 'epoch': 0.64}
{'loss': 0.9999, 'grad_norm': 0.6914588356708935, 'learning_rate': 6.054040406024422e-06, 'epoch': 0.64}
{'loss': 0.9838, 'grad_norm': 0.6256091099188367, 'learning_rate': 6.042592987803796e-06, 'epoch': 0.64}
{'loss': 0.933, 'grad_norm': 0.7570486662305713, 'learning_rate': 6.031151715189217e-06, 'epoch': 0.64}
{'loss': 1.0237, 'grad_norm': 0.6146029060184635, 'learning_rate': 6.019716605948261e-06, 'epoch': 0.64}
{'loss': 0.946, 'grad_norm': 0.771144667181808, 'learning_rate': 6.008287677838937e-06, 'epoch': 0.64}
{'loss': 0.9867, 'grad_norm': 0.708326063390195, 'learning_rate': 5.996864948609662e-06, 'epoch': 0.64}
{'loss': 0.9709, 'grad_norm': 0.604489641057546, 'learning_rate': 5.9854484359992235e-06, 'epoch': 0.64}
{'loss': 1.0348, 'grad_norm': 0.6362463454715837, 'learning_rate': 5.974038157736746e-06, 'epoch': 0.64}
{'loss': 1.0118, 'grad_norm': 0.6310290821299289, 'learning_rate': 5.962634131541676e-06, 'epoch': 0.65}
{'loss': 0.962, 'grad_norm': 0.7043398028790006, 'learning_rate': 5.951236375123768e-06, 'epoch': 0.65}
{'loss': 0.9628, 'grad_norm': 0.5714787467454479, 'learning_rate': 5.939844906183016e-06, 'epoch': 0.65}
{'loss': 0.9652, 'grad_norm': 0.6103772284104475, 'learning_rate': 5.92845974240966e-06, 'epoch': 0.65}
{'loss': 0.9717, 'grad_norm': 0.5870035004827263, 'learning_rate': 5.917080901484156e-06, 'epoch': 0.65}
{'loss': 1.0206, 'grad_norm': 0.589812367829299, 'learning_rate': 5.905708401077128e-06, 'epoch': 0.65}
{'loss': 0.8873, 'grad_norm': 0.5540908073295902, 'learning_rate': 5.894342258849355e-06, 'epoch': 0.65}
{'loss': 1.0369, 'grad_norm': 0.5727341069771205, 'learning_rate': 5.882982492451757e-06, 'epoch': 0.65}
{'loss': 0.991, 'grad_norm': 0.6361247374820852, 'learning_rate': 5.871629119525335e-06, 'epoch': 0.65}
{'loss': 1.0065, 'grad_norm': 0.662137691125513, 'learning_rate': 5.860282157701167e-06, 'epoch': 0.65}
{'loss': 1.007, 'grad_norm': 0.6451575415479192, 'learning_rate': 5.8489416246003814e-06, 'epoch': 0.65}
{'loss': 1.0137, 'grad_norm': 0.634680863880831, 'learning_rate': 5.8376075378341194e-06, 'epoch': 0.65}
{'loss': 1.0098, 'grad_norm': 0.6379233886393022, 'learning_rate': 5.826279915003503e-06, 'epoch': 0.65}
{'loss': 1.0045, 'grad_norm': 0.6040859391104472, 'learning_rate': 5.814958773699625e-06, 'epoch': 0.65}
{'loss': 0.9975, 'grad_norm': 0.5863402291485632, 'learning_rate': 5.803644131503516e-06, 'epoch': 0.65}
{'loss': 0.9737, 'grad_norm': 0.5342589469396276, 'learning_rate': 5.792336005986105e-06, 'epoch': 0.65}
{'loss': 1.0136, 'grad_norm': 0.6662791769230636, 'learning_rate': 5.781034414708208e-06, 'epoch': 0.65}
{'loss': 0.9759, 'grad_norm': 0.7822935980643131, 'learning_rate': 5.769739375220489e-06, 'epoch': 0.65}
{'loss': 0.9707, 'grad_norm': 0.6068291381693175, 'learning_rate': 5.7584509050634395e-06, 'epoch': 0.65}
{'loss': 0.9556, 'grad_norm': 0.5847859234399284, 'learning_rate': 5.747169021767342e-06, 'epoch': 0.65}
{'loss': 0.9487, 'grad_norm': 0.6079705807134639, 'learning_rate': 5.73589374285227e-06, 'epoch': 0.65}
{'loss': 1.0001, 'grad_norm': 0.6926848539562633, 'learning_rate': 5.724625085828022e-06, 'epoch': 0.65}
{'loss': 0.9925, 'grad_norm': 0.6488701313699385, 'learning_rate': 5.713363068194115e-06, 'epoch': 0.65}
{'loss': 1.0467, 'grad_norm': 0.6874692343498577, 'learning_rate': 5.702107707439766e-06, 'epoch': 0.65}
{'loss': 0.9693, 'grad_norm': 0.5648668992141463, 'learning_rate': 5.690859021043842e-06, 'epoch': 0.65}
{'loss': 0.9894, 'grad_norm': 0.7142492872448015, 'learning_rate': 5.679617026474853e-06, 'epoch': 0.65}
{'loss': 1.002, 'grad_norm': 0.644759986251185, 'learning_rate': 5.6683817411909114e-06, 'epoch': 0.66}
{'loss': 0.9931, 'grad_norm': 0.6258772210837124, 'learning_rate': 5.65715318263972e-06, 'epoch': 0.66}
{'loss': 0.9906, 'grad_norm': 0.6284858827201152, 'learning_rate': 5.645931368258527e-06, 'epoch': 0.66}
{'loss': 0.9989, 'grad_norm': 0.5638541955887798, 'learning_rate': 5.634716315474109e-06, 'epoch': 0.66}
{'loss': 0.9671, 'grad_norm': 0.5284194697426928, 'learning_rate': 5.623508041702743e-06, 'epoch': 0.66}
{'loss': 1.0154, 'grad_norm': 0.6672257561196523, 'learning_rate': 5.612306564350179e-06, 'epoch': 0.66}
{'loss': 1.0126, 'grad_norm': 0.5923508324063431, 'learning_rate': 5.601111900811607e-06, 'epoch': 0.66}
{'loss': 0.9612, 'grad_norm': 0.5846161097345108, 'learning_rate': 5.589924068471648e-06, 'epoch': 0.66}
{'loss': 0.9777, 'grad_norm': 0.7251216336193345, 'learning_rate': 5.578743084704306e-06, 'epoch': 0.66}
{'loss': 0.9767, 'grad_norm': 0.725808350386878, 'learning_rate': 5.567568966872947e-06, 'epoch': 0.66}
{'loss': 0.9217, 'grad_norm': 0.7251735112848763, 'learning_rate': 5.556401732330281e-06, 'epoch': 0.66}
{'loss': 1.0084, 'grad_norm': 0.5255877035390084, 'learning_rate': 5.545241398418326e-06, 'epoch': 0.66}
{'loss': 0.9612, 'grad_norm': 0.5526009900955997, 'learning_rate': 5.534087982468384e-06, 'epoch': 0.66}
{'loss': 1.0101, 'grad_norm': 0.653605256339602, 'learning_rate': 5.522941501801008e-06, 'epoch': 0.66}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B00WTKH3HC.jpg, using default black image.
{'loss': 0.9829, 'grad_norm': 0.5529340406453415, 'learning_rate': 5.511801973725997e-06, 'epoch': 0.66}
{'loss': 1.0193, 'grad_norm': 0.5782795072648808, 'learning_rate': 5.500669415542336e-06, 'epoch': 0.66}
{'loss': 0.9948, 'grad_norm': 0.5979047548271523, 'learning_rate': 5.4895438445381945e-06, 'epoch': 0.66}
{'loss': 0.994, 'grad_norm': 0.6287796765910896, 'learning_rate': 5.4784252779908905e-06, 'epoch': 0.66}
{'loss': 0.9679, 'grad_norm': 0.6265940927441307, 'learning_rate': 5.467313733166863e-06, 'epoch': 0.66}
{'loss': 0.9822, 'grad_norm': 0.7377318238499022, 'learning_rate': 5.456209227321643e-06, 'epoch': 0.66}
{'loss': 1.0084, 'grad_norm': 0.6394498636958931, 'learning_rate': 5.445111777699842e-06, 'epoch': 0.66}
{'loss': 0.9966, 'grad_norm': 0.67145512405831, 'learning_rate': 5.434021401535105e-06, 'epoch': 0.66}
{'loss': 0.99, 'grad_norm': 0.5947267917079377, 'learning_rate': 5.422938116050092e-06, 'epoch': 0.66}
{'loss': 0.9866, 'grad_norm': 0.7522717376950668, 'learning_rate': 5.411861938456453e-06, 'epoch': 0.66}
{'loss': 1.0228, 'grad_norm': 0.5652024097369645, 'learning_rate': 5.400792885954802e-06, 'epoch': 0.66}
{'loss': 0.9735, 'grad_norm': 0.6246525887139802, 'learning_rate': 5.389730975734686e-06, 'epoch': 0.66}
{'loss': 1.0273, 'grad_norm': 0.6081760730666917, 'learning_rate': 5.378676224974557e-06, 'epoch': 0.67}
{'loss': 0.9639, 'grad_norm': 0.5424174256043715, 'learning_rate': 5.367628650841761e-06, 'epoch': 0.67}
{'loss': 0.9702, 'grad_norm': 0.6676483827906895, 'learning_rate': 5.356588270492487e-06, 'epoch': 0.67}
{'loss': 1.0074, 'grad_norm': 0.7293245400379605, 'learning_rate': 5.3455551010717545e-06, 'epoch': 0.67}
{'loss': 0.9889, 'grad_norm': 0.6074415454790024, 'learning_rate': 5.334529159713389e-06, 'epoch': 0.67}
{'loss': 1.0124, 'grad_norm': 0.5902489654149232, 'learning_rate': 5.323510463539989e-06, 'epoch': 0.67}
{'loss': 0.9805, 'grad_norm': 0.5939446819462048, 'learning_rate': 5.3124990296628974e-06, 'epoch': 0.67}
{'loss': 1.0248, 'grad_norm': 0.6179375025775082, 'learning_rate': 5.301494875182192e-06, 'epoch': 0.67}
{'loss': 0.9775, 'grad_norm': 0.5987393605131935, 'learning_rate': 5.290498017186631e-06, 'epoch': 0.67}
{'loss': 0.9662, 'grad_norm': 0.6707897129088504, 'learning_rate': 5.279508472753654e-06, 'epoch': 0.67}
{'loss': 1.0064, 'grad_norm': 0.5632009970182348, 'learning_rate': 5.2685262589493314e-06, 'epoch': 0.67}
{'loss': 1.0242, 'grad_norm': 0.6922163782000922, 'learning_rate': 5.257551392828359e-06, 'epoch': 0.67}
{'loss': 1.0053, 'grad_norm': 0.5713509120651686, 'learning_rate': 5.246583891434018e-06, 'epoch': 0.67}
{'loss': 0.9816, 'grad_norm': 0.6368154394502836, 'learning_rate': 5.235623771798151e-06, 'epoch': 0.67}
{'loss': 0.9522, 'grad_norm': 0.5589929956707349, 'learning_rate': 5.224671050941146e-06, 'epoch': 0.67}
{'loss': 0.9831, 'grad_norm': 0.6323053850981672, 'learning_rate': 5.213725745871889e-06, 'epoch': 0.67}
{'loss': 1.0064, 'grad_norm': 0.7264442022524136, 'learning_rate': 5.20278787358776e-06, 'epoch': 0.67}
{'loss': 0.9254, 'grad_norm': 0.5986348001739764, 'learning_rate': 5.1918574510745865e-06, 'epoch': 0.67}
{'loss': 1.0212, 'grad_norm': 0.5833216997382192, 'learning_rate': 5.180934495306638e-06, 'epoch': 0.67}
{'loss': 0.9719, 'grad_norm': 0.6127283462062737, 'learning_rate': 5.170019023246574e-06, 'epoch': 0.67}
{'loss': 1.0197, 'grad_norm': 0.6332068395286008, 'learning_rate': 5.159111051845451e-06, 'epoch': 0.67}
{'loss': 0.994, 'grad_norm': 0.6136324239559854, 'learning_rate': 5.148210598042665e-06, 'epoch': 0.67}
{'loss': 1.0102, 'grad_norm': 0.5612592204268205, 'learning_rate': 5.137317678765939e-06, 'epoch': 0.67}
{'loss': 0.9985, 'grad_norm': 0.6016206702805148, 'learning_rate': 5.126432310931295e-06, 'epoch': 0.67}
{'loss': 0.9796, 'grad_norm': 0.6091067866189385, 'learning_rate': 5.115554511443033e-06, 'epoch': 0.67}
{'loss': 0.9954, 'grad_norm': 0.6080442699659201, 'learning_rate': 5.104684297193694e-06, 'epoch': 0.67}
{'loss': 0.9846, 'grad_norm': 0.6235310865973777, 'learning_rate': 5.09382168506404e-06, 'epoch': 0.68}
{'loss': 0.9775, 'grad_norm': 0.6712681275607341, 'learning_rate': 5.082966691923037e-06, 'epoch': 0.68}
{'loss': 1.0097, 'grad_norm': 0.640687935118259, 'learning_rate': 5.0721193346278066e-06, 'epoch': 0.68}
{'loss': 0.9833, 'grad_norm': 0.6951818133123984, 'learning_rate': 5.061279630023618e-06, 'epoch': 0.68}
{'loss': 0.9345, 'grad_norm': 0.5117776039212177, 'learning_rate': 5.050447594943856e-06, 'epoch': 0.68}
{'loss': 1.0201, 'grad_norm': 0.6416265036291645, 'learning_rate': 5.0396232462099945e-06, 'epoch': 0.68}
{'loss': 1.0129, 'grad_norm': 0.6501618560849198, 'learning_rate': 5.028806600631569e-06, 'epoch': 0.68}
{'loss': 1.0255, 'grad_norm': 0.656807670141022, 'learning_rate': 5.017997675006161e-06, 'epoch': 0.68}
{'loss': 0.9981, 'grad_norm': 0.6651659961489879, 'learning_rate': 5.007196486119355e-06, 'epoch': 0.68}
{'loss': 0.9782, 'grad_norm': 0.6383723995046926, 'learning_rate': 4.996403050744719e-06, 'epoch': 0.68}
{'loss': 1.0297, 'grad_norm': 0.6667943611628295, 'learning_rate': 4.985617385643789e-06, 'epoch': 0.68}
{'loss': 0.987, 'grad_norm': 0.6934435589364344, 'learning_rate': 4.974839507566027e-06, 'epoch': 0.68}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B013RVJ7KW.jpg, using default black image.
{'loss': 0.9837, 'grad_norm': 0.6394136121327445, 'learning_rate': 4.9640694332488075e-06, 'epoch': 0.68}
{'loss': 1.0004, 'grad_norm': 0.6429471264799058, 'learning_rate': 4.953307179417376e-06, 'epoch': 0.68}
{'loss': 1.0263, 'grad_norm': 0.6047409223085036, 'learning_rate': 4.94255276278485e-06, 'epoch': 0.68}
{'loss': 0.9409, 'grad_norm': 0.5467225698791714, 'learning_rate': 4.931806200052165e-06, 'epoch': 0.68}
{'loss': 0.9472, 'grad_norm': 0.5621763153206362, 'learning_rate': 4.92106750790806e-06, 'epoch': 0.68}
{'loss': 1.0158, 'grad_norm': 0.602077125372112, 'learning_rate': 4.910336703029055e-06, 'epoch': 0.68}
{'loss': 0.9913, 'grad_norm': 0.6684243864506095, 'learning_rate': 4.899613802079419e-06, 'epoch': 0.68}
{'loss': 1.013, 'grad_norm': 0.6848880448486316, 'learning_rate': 4.888898821711144e-06, 'epoch': 0.68}
{'loss': 0.9385, 'grad_norm': 0.5055757669167451, 'learning_rate': 4.878191778563934e-06, 'epoch': 0.68}
{'loss': 1.04, 'grad_norm': 0.5849746356572633, 'learning_rate': 4.867492689265154e-06, 'epoch': 0.68}
{'loss': 1.0019, 'grad_norm': 0.615121197047708, 'learning_rate': 4.856801570429822e-06, 'epoch': 0.68}
{'loss': 0.9382, 'grad_norm': 0.5311985376264984, 'learning_rate': 4.846118438660578e-06, 'epoch': 0.68}
{'loss': 1.017, 'grad_norm': 0.7937470376910937, 'learning_rate': 4.83544331054766e-06, 'epoch': 0.68}
{'loss': 0.9524, 'grad_norm': 0.5344836294211035, 'learning_rate': 4.824776202668875e-06, 'epoch': 0.68}
{'loss': 1.0285, 'grad_norm': 0.5965468196359358, 'learning_rate': 4.8141171315895694e-06, 'epoch': 0.69}
{'loss': 0.9724, 'grad_norm': 0.5632375177579334, 'learning_rate': 4.803466113862626e-06, 'epoch': 0.69}
{'loss': 0.9587, 'grad_norm': 0.6802096311750983, 'learning_rate': 4.792823166028405e-06, 'epoch': 0.69}
{'loss': 1.0341, 'grad_norm': 0.6133607504563426, 'learning_rate': 4.7821883046147414e-06, 'epoch': 0.69}
{'loss': 0.9928, 'grad_norm': 0.8144733984068685, 'learning_rate': 4.771561546136908e-06, 'epoch': 0.69}
{'loss': 0.9593, 'grad_norm': 0.6778664866278409, 'learning_rate': 4.760942907097601e-06, 'epoch': 0.69}
{'loss': 0.9698, 'grad_norm': 0.6907663136508899, 'learning_rate': 4.750332403986902e-06, 'epoch': 0.69}
{'loss': 0.9624, 'grad_norm': 0.662683690692471, 'learning_rate': 4.739730053282255e-06, 'epoch': 0.69}
{'loss': 0.99, 'grad_norm': 0.67250762909151, 'learning_rate': 4.7291358714484594e-06, 'epoch': 0.69}
{'loss': 0.9697, 'grad_norm': 0.613514405986456, 'learning_rate': 4.718549874937612e-06, 'epoch': 0.69}
{'loss': 1.0242, 'grad_norm': 0.6814950266544231, 'learning_rate': 4.707972080189106e-06, 'epoch': 0.69}
{'loss': 0.9817, 'grad_norm': 0.632092122516862, 'learning_rate': 4.697402503629596e-06, 'epoch': 0.69}
{'loss': 1.04, 'grad_norm': 0.6141768869022755, 'learning_rate': 4.686841161672974e-06, 'epoch': 0.69}
{'loss': 1.0129, 'grad_norm': 0.6186707137211429, 'learning_rate': 4.67628807072034e-06, 'epoch': 0.69}
{'loss': 0.9536, 'grad_norm': 0.6776888273999135, 'learning_rate': 4.665743247159995e-06, 'epoch': 0.69}
{'loss': 0.9673, 'grad_norm': 0.6462045919812536, 'learning_rate': 4.655206707367388e-06, 'epoch': 0.69}
{'loss': 1.0389, 'grad_norm': 0.62899732285254, 'learning_rate': 4.644678467705101e-06, 'epoch': 0.69}
{'loss': 0.9645, 'grad_norm': 0.6070903280938165, 'learning_rate': 4.634158544522849e-06, 'epoch': 0.69}
{'loss': 0.8933, 'grad_norm': 0.531831583738298, 'learning_rate': 4.623646954157399e-06, 'epoch': 0.69}
{'loss': 0.9202, 'grad_norm': 0.5138700180375874, 'learning_rate': 4.613143712932603e-06, 'epoch': 0.69}
{'loss': 0.9798, 'grad_norm': 0.6300711067044964, 'learning_rate': 4.602648837159333e-06, 'epoch': 0.69}
{'loss': 0.9769, 'grad_norm': 0.5938846728209451, 'learning_rate': 4.592162343135483e-06, 'epoch': 0.69}
{'loss': 0.9135, 'grad_norm': 0.5705898144185216, 'learning_rate': 4.5816842471459224e-06, 'epoch': 0.69}
{'loss': 1.0277, 'grad_norm': 0.5985891377074106, 'learning_rate': 4.571214565462477e-06, 'epoch': 0.69}
{'loss': 0.9689, 'grad_norm': 0.6448174000035355, 'learning_rate': 4.560753314343912e-06, 'epoch': 0.69}
{'loss': 0.9833, 'grad_norm': 0.6172778298292207, 'learning_rate': 4.5503005100358945e-06, 'epoch': 0.69}
{'loss': 0.974, 'grad_norm': 0.7984379581603508, 'learning_rate': 4.539856168770974e-06, 'epoch': 0.7}
{'loss': 0.9822, 'grad_norm': 0.6122397062207396, 'learning_rate': 4.52942030676857e-06, 'epoch': 0.7}
{'loss': 0.995, 'grad_norm': 0.6136156363005523, 'learning_rate': 4.5189929402349175e-06, 'epoch': 0.7}
{'loss': 1.0172, 'grad_norm': 0.6164955621152762, 'learning_rate': 4.508574085363065e-06, 'epoch': 0.7}
{'loss': 1.0009, 'grad_norm': 0.7080380684173534, 'learning_rate': 4.498163758332853e-06, 'epoch': 0.7}
{'loss': 0.9973, 'grad_norm': 0.6405958747050617, 'learning_rate': 4.4877619753108605e-06, 'epoch': 0.7}
{'loss': 1.0231, 'grad_norm': 0.6961088964498973, 'learning_rate': 4.477368752450409e-06, 'epoch': 0.7}
{'loss': 0.9996, 'grad_norm': 0.6475953416009316, 'learning_rate': 4.466984105891521e-06, 'epoch': 0.7}
{'loss': 1.0269, 'grad_norm': 0.6097416898962305, 'learning_rate': 4.456608051760914e-06, 'epoch': 0.7}
{'loss': 1.0013, 'grad_norm': 0.678877686421319, 'learning_rate': 4.446240606171945e-06, 'epoch': 0.7}
{'loss': 0.9585, 'grad_norm': 0.5714268065940062, 'learning_rate': 4.4358817852246124e-06, 'epoch': 0.7}
{'loss': 1.0081, 'grad_norm': 0.6066678935397131, 'learning_rate': 4.425531605005519e-06, 'epoch': 0.7}
{'loss': 0.9796, 'grad_norm': 0.5974135864722561, 'learning_rate': 4.4151900815878455e-06, 'epoch': 0.7}
{'loss': 0.9734, 'grad_norm': 0.5690195369496412, 'learning_rate': 4.404857231031332e-06, 'epoch': 0.7}
{'loss': 0.9628, 'grad_norm': 0.6224284880179898, 'learning_rate': 4.394533069382255e-06, 'epoch': 0.7}
{'loss': 0.9578, 'grad_norm': 0.608418684009742, 'learning_rate': 4.3842176126733914e-06, 'epoch': 0.7}
{'loss': 1.0164, 'grad_norm': 0.6227650288345845, 'learning_rate': 4.373910876923997e-06, 'epoch': 0.7}
{'loss': 0.9836, 'grad_norm': 0.6927447567008849, 'learning_rate': 4.363612878139799e-06, 'epoch': 0.7}
{'loss': 0.941, 'grad_norm': 0.6502713538856092, 'learning_rate': 4.353323632312938e-06, 'epoch': 0.7}
{'loss': 1.0104, 'grad_norm': 0.61949326495421, 'learning_rate': 4.343043155421971e-06, 'epoch': 0.7}
{'loss': 1.0411, 'grad_norm': 0.6407186004379306, 'learning_rate': 4.332771463431837e-06, 'epoch': 0.7}
{'loss': 0.9672, 'grad_norm': 0.6877927645862265, 'learning_rate': 4.322508572293836e-06, 'epoch': 0.7}
{'loss': 1.0029, 'grad_norm': 0.6133186640993336, 'learning_rate': 4.312254497945595e-06, 'epoch': 0.7}
{'loss': 1.0099, 'grad_norm': 0.6269889893132045, 'learning_rate': 4.3020092563110485e-06, 'epoch': 0.7}
{'loss': 1.0131, 'grad_norm': 0.7433461375439874, 'learning_rate': 4.291772863300428e-06, 'epoch': 0.7}
{'loss': 0.9968, 'grad_norm': 0.6564049216138187, 'learning_rate': 4.281545334810201e-06, 'epoch': 0.7}
{'loss': 1.0032, 'grad_norm': 0.6393934873430854, 'learning_rate': 4.27132668672308e-06, 'epoch': 0.71}
{'loss': 0.9753, 'grad_norm': 0.6157377110951128, 'learning_rate': 4.2611169349079985e-06, 'epoch': 0.71}
{'loss': 0.9955, 'grad_norm': 0.6065951778160602, 'learning_rate': 4.250916095220056e-06, 'epoch': 0.71}
{'loss': 1.0181, 'grad_norm': 0.6289166717079303, 'learning_rate': 4.240724183500518e-06, 'epoch': 0.71}
{'loss': 0.9352, 'grad_norm': 0.4982737425234319, 'learning_rate': 4.230541215576798e-06, 'epoch': 0.71}
{'loss': 1.0153, 'grad_norm': 0.5765446213693814, 'learning_rate': 4.220367207262398e-06, 'epoch': 0.71}
{'loss': 0.9928, 'grad_norm': 0.650770736360433, 'learning_rate': 4.210202174356922e-06, 'epoch': 0.71}
{'loss': 0.9773, 'grad_norm': 0.6271207772439363, 'learning_rate': 4.2000461326460274e-06, 'epoch': 0.71}
{'loss': 0.9745, 'grad_norm': 0.5987181703070399, 'learning_rate': 4.189899097901421e-06, 'epoch': 0.71}
{'loss': 0.9782, 'grad_norm': 0.64704630136336, 'learning_rate': 4.179761085880809e-06, 'epoch': 0.71}
{'loss': 0.9137, 'grad_norm': 0.5218230466464062, 'learning_rate': 4.16963211232789e-06, 'epoch': 0.71}
{'loss': 0.9391, 'grad_norm': 0.651295099725572, 'learning_rate': 4.159512192972337e-06, 'epoch': 0.71}
{'loss': 0.9225, 'grad_norm': 0.580537022404666, 'learning_rate': 4.149401343529742e-06, 'epoch': 0.71}
{'loss': 0.9648, 'grad_norm': 0.621573111530864, 'learning_rate': 4.139299579701623e-06, 'epoch': 0.71}
{'loss': 1.0139, 'grad_norm': 0.5992561621918657, 'learning_rate': 4.129206917175397e-06, 'epoch': 0.71}
{'loss': 1.0114, 'grad_norm': 0.6011256782790714, 'learning_rate': 4.119123371624335e-06, 'epoch': 0.71}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/899061877.jpg, using default black image.
{'loss': 0.9648, 'grad_norm': 0.5861134627181206, 'learning_rate': 4.109048958707552e-06, 'epoch': 0.71}
{'loss': 1.0041, 'grad_norm': 0.6566786036035027, 'learning_rate': 4.09898369406998e-06, 'epoch': 0.71}
{'loss': 1.0134, 'grad_norm': 0.6014085947279724, 'learning_rate': 4.0889275933423576e-06, 'epoch': 0.71}
{'loss': 1.0079, 'grad_norm': 0.5954545188430365, 'learning_rate': 4.078880672141171e-06, 'epoch': 0.71}
{'loss': 0.9925, 'grad_norm': 0.6510659107755016, 'learning_rate': 4.068842946068661e-06, 'epoch': 0.71}
{'loss': 1.0037, 'grad_norm': 0.606970788969566, 'learning_rate': 4.058814430712796e-06, 'epoch': 0.71}
{'loss': 0.9434, 'grad_norm': 0.6452259322165292, 'learning_rate': 4.0487951416472324e-06, 'epoch': 0.71}
{'loss': 0.93, 'grad_norm': 0.7505605326289755, 'learning_rate': 4.038785094431295e-06, 'epoch': 0.71}
{'loss': 1.0356, 'grad_norm': 0.6281653703569005, 'learning_rate': 4.0287843046099765e-06, 'epoch': 0.71}
{'loss': 0.9886, 'grad_norm': 0.7418773152301456, 'learning_rate': 4.018792787713865e-06, 'epoch': 0.71}
{'loss': 0.9738, 'grad_norm': 0.5881428509397818, 'learning_rate': 4.008810559259162e-06, 'epoch': 0.72}
{'loss': 1.0052, 'grad_norm': 0.6529040611804733, 'learning_rate': 3.998837634747655e-06, 'epoch': 0.72}
{'loss': 0.981, 'grad_norm': 0.6065447464118335, 'learning_rate': 3.98887402966667e-06, 'epoch': 0.72}
{'loss': 1.0006, 'grad_norm': 0.5692594573999988, 'learning_rate': 3.97891975948906e-06, 'epoch': 0.72}
{'loss': 0.9961, 'grad_norm': 0.5560822194865238, 'learning_rate': 3.968974839673186e-06, 'epoch': 0.72}
{'loss': 0.9619, 'grad_norm': 0.578786351551152, 'learning_rate': 3.9590392856628946e-06, 'epoch': 0.72}
{'loss': 0.9518, 'grad_norm': 0.6018698681307603, 'learning_rate': 3.949113112887471e-06, 'epoch': 0.72}
{'loss': 0.9722, 'grad_norm': 0.6035150925421789, 'learning_rate': 3.939196336761645e-06, 'epoch': 0.72}
{'loss': 0.9694, 'grad_norm': 0.6616189874151436, 'learning_rate': 3.929288972685555e-06, 'epoch': 0.72}
{'loss': 0.9713, 'grad_norm': 0.630856786763037, 'learning_rate': 3.919391036044715e-06, 'epoch': 0.72}
{'loss': 0.9936, 'grad_norm': 0.6230008982562354, 'learning_rate': 3.909502542210001e-06, 'epoch': 0.72}
{'loss': 0.9703, 'grad_norm': 0.6473691059922868, 'learning_rate': 3.899623506537635e-06, 'epoch': 0.72}
{'loss': 0.978, 'grad_norm': 0.7279583737059361, 'learning_rate': 3.8897539443691355e-06, 'epoch': 0.72}
{'loss': 1.014, 'grad_norm': 0.5151168142911701, 'learning_rate': 3.879893871031314e-06, 'epoch': 0.72}
{'loss': 0.9769, 'grad_norm': 0.6691652939327881, 'learning_rate': 3.870043301836256e-06, 'epoch': 0.72}
{'loss': 0.9778, 'grad_norm': 0.6101018390483033, 'learning_rate': 3.860202252081276e-06, 'epoch': 0.72}
{'loss': 1.0089, 'grad_norm': 0.5972822680986745, 'learning_rate': 3.850370737048913e-06, 'epoch': 0.72}
{'loss': 1.0256, 'grad_norm': 0.6780513567698319, 'learning_rate': 3.840548772006891e-06, 'epoch': 0.72}
{'loss': 0.9952, 'grad_norm': 0.6277536649650419, 'learning_rate': 3.830736372208118e-06, 'epoch': 0.72}
{'loss': 0.9603, 'grad_norm': 0.549072123069944, 'learning_rate': 3.820933552890629e-06, 'epoch': 0.72}
{'loss': 0.9922, 'grad_norm': 0.7074846357292032, 'learning_rate': 3.811140329277591e-06, 'epoch': 0.72}
{'loss': 0.9693, 'grad_norm': 0.4865261861050051, 'learning_rate': 3.8013567165772735e-06, 'epoch': 0.72}
{'loss': 1.0168, 'grad_norm': 0.597944500274207, 'learning_rate': 3.7915827299830154e-06, 'epoch': 0.72}
{'loss': 0.9868, 'grad_norm': 0.5912440089233314, 'learning_rate': 3.7818183846732024e-06, 'epoch': 0.72}
{'loss': 0.9816, 'grad_norm': 0.6088014386579179, 'learning_rate': 3.7720636958112623e-06, 'epoch': 0.72}
{'loss': 0.972, 'grad_norm': 0.6061859250036404, 'learning_rate': 3.7623186785456156e-06, 'epoch': 0.72}
{'loss': 0.935, 'grad_norm': 0.5246285922551223, 'learning_rate': 3.7525833480096575e-06, 'epoch': 0.73}
{'loss': 1.0098, 'grad_norm': 0.5093178748351154, 'learning_rate': 3.7428577193217563e-06, 'epoch': 0.73}
{'loss': 1.0309, 'grad_norm': 0.5989770860645689, 'learning_rate': 3.7331418075852053e-06, 'epoch': 0.73}
{'loss': 0.9934, 'grad_norm': 0.5859426669456195, 'learning_rate': 3.7234356278882076e-06, 'epoch': 0.73}
{'loss': 1.0372, 'grad_norm': 0.651985030633054, 'learning_rate': 3.7137391953038516e-06, 'epoch': 0.73}
{'loss': 0.9887, 'grad_norm': 0.6951119072014446, 'learning_rate': 3.7040525248901003e-06, 'epoch': 0.73}
{'loss': 0.9836, 'grad_norm': 0.6703939469044097, 'learning_rate': 3.6943756316897406e-06, 'epoch': 0.73}
{'loss': 0.996, 'grad_norm': 0.6267893549312736, 'learning_rate': 3.684708530730382e-06, 'epoch': 0.73}
{'loss': 0.9761, 'grad_norm': 0.5530309863333234, 'learning_rate': 3.6750512370244363e-06, 'epoch': 0.73}
{'loss': 0.99, 'grad_norm': 0.8562351088307282, 'learning_rate': 3.6654037655690732e-06, 'epoch': 0.73}
{'loss': 1.0004, 'grad_norm': 0.6272657447664316, 'learning_rate': 3.655766131346211e-06, 'epoch': 0.73}
{'loss': 0.9854, 'grad_norm': 0.8698147888656662, 'learning_rate': 3.6461383493225012e-06, 'epoch': 0.73}
{'loss': 0.9743, 'grad_norm': 0.6544814963563943, 'learning_rate': 3.6365204344492867e-06, 'epoch': 0.73}
{'loss': 0.9787, 'grad_norm': 0.6356055004765563, 'learning_rate': 3.62691240166258e-06, 'epoch': 0.73}
{'loss': 0.9258, 'grad_norm': 0.4991928952258795, 'learning_rate': 3.617314265883066e-06, 'epoch': 0.73}
{'loss': 1.0035, 'grad_norm': 0.665385346832085, 'learning_rate': 3.6077260420160487e-06, 'epoch': 0.73}
{'loss': 1.0352, 'grad_norm': 0.633871497754912, 'learning_rate': 3.598147744951438e-06, 'epoch': 0.73}
{'loss': 0.9999, 'grad_norm': 0.7008944323917327, 'learning_rate': 3.58857938956373e-06, 'epoch': 0.73}
{'loss': 1.0077, 'grad_norm': 0.5970860826211406, 'learning_rate': 3.57902099071199e-06, 'epoch': 0.73}
{'loss': 0.9649, 'grad_norm': 0.7186409722380049, 'learning_rate': 3.569472563239814e-06, 'epoch': 0.73}
{'loss': 0.9781, 'grad_norm': 0.6528017634231081, 'learning_rate': 3.559934121975304e-06, 'epoch': 0.73}
{'loss': 0.998, 'grad_norm': 0.651446750974142, 'learning_rate': 3.550405681731074e-06, 'epoch': 0.73}
{'loss': 0.9457, 'grad_norm': 0.5085604462317596, 'learning_rate': 3.540887257304193e-06, 'epoch': 0.73}
{'loss': 0.9944, 'grad_norm': 0.5486690828428235, 'learning_rate': 3.531378863476178e-06, 'epoch': 0.73}
{'loss': 0.9999, 'grad_norm': 0.6545832041822538, 'learning_rate': 3.5218805150129755e-06, 'epoch': 0.73}
{'loss': 0.9615, 'grad_norm': 0.6112162945742852, 'learning_rate': 3.51239222666493e-06, 'epoch': 0.73}
{'loss': 0.9637, 'grad_norm': 0.7114541702045886, 'learning_rate': 3.5029140131667493e-06, 'epoch': 0.74}
{'loss': 0.9726, 'grad_norm': 0.6489801075318199, 'learning_rate': 3.493445889237518e-06, 'epoch': 0.74}
{'loss': 0.9724, 'grad_norm': 0.6120077164509481, 'learning_rate': 3.4839878695806385e-06, 'epoch': 0.74}
{'loss': 0.9768, 'grad_norm': 0.64261045623335, 'learning_rate': 3.4745399688838243e-06, 'epoch': 0.74}
{'loss': 0.9943, 'grad_norm': 0.708807907987429, 'learning_rate': 3.4651022018190715e-06, 'epoch': 0.74}
{'loss': 1.0316, 'grad_norm': 0.6145004273947655, 'learning_rate': 3.455674583042652e-06, 'epoch': 0.74}
{'loss': 0.9977, 'grad_norm': 0.7192913648045064, 'learning_rate': 3.4462571271950674e-06, 'epoch': 0.74}
{'loss': 1.0035, 'grad_norm': 0.5839792439441504, 'learning_rate': 3.436849848901028e-06, 'epoch': 0.74}
{'loss': 0.9735, 'grad_norm': 0.6525045659298502, 'learning_rate': 3.427452762769462e-06, 'epoch': 0.74}
{'loss': 0.9851, 'grad_norm': 0.6488239170791557, 'learning_rate': 3.4180658833934523e-06, 'epoch': 0.74}
{'loss': 0.9285, 'grad_norm': 0.6254331999409266, 'learning_rate': 3.4086892253502344e-06, 'epoch': 0.74}
{'loss': 0.9766, 'grad_norm': 0.6041248190817093, 'learning_rate': 3.3993228032011784e-06, 'epoch': 0.74}
{'loss': 0.9996, 'grad_norm': 0.7053687683627131, 'learning_rate': 3.3899666314917512e-06, 'epoch': 0.74}
{'loss': 1.003, 'grad_norm': 0.5525873008727353, 'learning_rate': 3.3806207247515068e-06, 'epoch': 0.74}
{'loss': 0.982, 'grad_norm': 0.5752531831816596, 'learning_rate': 3.3712850974940437e-06, 'epoch': 0.74}
{'loss': 1.0142, 'grad_norm': 0.6183767794875861, 'learning_rate': 3.361959764217018e-06, 'epoch': 0.74}
{'loss': 0.9186, 'grad_norm': 0.5360302757286276, 'learning_rate': 3.3526447394020887e-06, 'epoch': 0.74}
{'loss': 0.9601, 'grad_norm': 0.6940269712631895, 'learning_rate': 3.343340037514903e-06, 'epoch': 0.74}
{'loss': 0.9267, 'grad_norm': 0.5326015471980176, 'learning_rate': 3.3340456730050887e-06, 'epoch': 0.74}
{'loss': 0.9414, 'grad_norm': 0.6375952244744951, 'learning_rate': 3.324761660306215e-06, 'epoch': 0.74}
{'loss': 0.9682, 'grad_norm': 0.6285039200987492, 'learning_rate': 3.3154880138357626e-06, 'epoch': 0.74}
{'loss': 1.0145, 'grad_norm': 0.7039132346798675, 'learning_rate': 3.306224747995136e-06, 'epoch': 0.74}
{'loss': 0.9258, 'grad_norm': 0.6072137494675716, 'learning_rate': 3.2969718771696047e-06, 'epoch': 0.74}
{'loss': 0.977, 'grad_norm': 0.6003527730821714, 'learning_rate': 3.287729415728298e-06, 'epoch': 0.74}
{'loss': 0.9581, 'grad_norm': 0.5871917669643791, 'learning_rate': 3.278497378024187e-06, 'epoch': 0.74}
{'loss': 1.0016, 'grad_norm': 0.6162167469639998, 'learning_rate': 3.2692757783940467e-06, 'epoch': 0.74}
{'loss': 0.9736, 'grad_norm': 0.6181354676689269, 'learning_rate': 3.2600646311584494e-06, 'epoch': 0.75}
{'loss': 0.9801, 'grad_norm': 0.6054900376766493, 'learning_rate': 3.250863950621721e-06, 'epoch': 0.75}
{'loss': 0.977, 'grad_norm': 0.6923926638862767, 'learning_rate': 3.241673751071954e-06, 'epoch': 0.75}
{'loss': 0.9946, 'grad_norm': 0.6114718467652843, 'learning_rate': 3.2324940467809527e-06, 'epoch': 0.75}
{'loss': 1.0159, 'grad_norm': 0.6662042011550593, 'learning_rate': 3.223324852004219e-06, 'epoch': 0.75}
{'loss': 0.966, 'grad_norm': 0.6421728611209861, 'learning_rate': 3.21416618098095e-06, 'epoch': 0.75}
{'loss': 0.9575, 'grad_norm': 0.6152673544519878, 'learning_rate': 3.2050180479339865e-06, 'epoch': 0.75}
{'loss': 0.9816, 'grad_norm': 0.865544739413579, 'learning_rate': 3.1958804670698008e-06, 'epoch': 0.75}
{'loss': 0.9709, 'grad_norm': 0.5969195416548962, 'learning_rate': 3.1867534525784937e-06, 'epoch': 0.75}
{'loss': 0.988, 'grad_norm': 0.6041173124663096, 'learning_rate': 3.177637018633746e-06, 'epoch': 0.75}
{'loss': 0.9161, 'grad_norm': 0.4672488787959572, 'learning_rate': 3.1685311793928077e-06, 'epoch': 0.75}
{'loss': 0.9636, 'grad_norm': 0.5832779359562374, 'learning_rate': 3.1594359489964853e-06, 'epoch': 0.75}
{'loss': 1.0027, 'grad_norm': 0.5909726191201564, 'learning_rate': 3.150351341569101e-06, 'epoch': 0.75}
{'loss': 0.9401, 'grad_norm': 0.6909305145168758, 'learning_rate': 3.141277371218484e-06, 'epoch': 0.75}
{'loss': 0.9551, 'grad_norm': 0.7978628225961316, 'learning_rate': 3.1322140520359366e-06, 'epoch': 0.75}
{'loss': 0.9731, 'grad_norm': 0.6252970288980492, 'learning_rate': 3.1231613980962373e-06, 'epoch': 0.75}
{'loss': 0.8933, 'grad_norm': 0.7015881376209898, 'learning_rate': 3.1141194234575878e-06, 'epoch': 0.75}
{'loss': 1.0077, 'grad_norm': 0.6158384355198467, 'learning_rate': 3.1050881421616076e-06, 'epoch': 0.75}
{'loss': 1.0044, 'grad_norm': 0.5693892667356335, 'learning_rate': 3.0960675682333186e-06, 'epoch': 0.75}
{'loss': 1.0022, 'grad_norm': 0.6000233719006484, 'learning_rate': 3.0870577156811077e-06, 'epoch': 0.75}
{'loss': 0.9605, 'grad_norm': 0.6595655148209272, 'learning_rate': 3.0780585984967113e-06, 'epoch': 0.75}
{'loss': 1.0109, 'grad_norm': 0.6380102484635507, 'learning_rate': 3.069070230655198e-06, 'epoch': 0.75}
{'loss': 1.003, 'grad_norm': 0.7493952413953565, 'learning_rate': 3.060092626114941e-06, 'epoch': 0.75}
{'loss': 0.9861, 'grad_norm': 0.593891057435849, 'learning_rate': 3.051125798817598e-06, 'epoch': 0.75}
{'loss': 0.9819, 'grad_norm': 0.5972032458136821, 'learning_rate': 3.042169762688096e-06, 'epoch': 0.75}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B011M9LHUO.jpg, using default black image.
{'loss': 0.9643, 'grad_norm': 0.519286347529663, 'learning_rate': 3.0332245316346e-06, 'epoch': 0.75}
{'loss': 0.9571, 'grad_norm': 0.6260493479125872, 'learning_rate': 3.024290119548495e-06, 'epoch': 0.76}
{'loss': 0.9638, 'grad_norm': 0.6562108492223261, 'learning_rate': 3.0153665403043586e-06, 'epoch': 0.76}
{'loss': 1.0142, 'grad_norm': 0.6518941069414644, 'learning_rate': 3.0064538077599603e-06, 'epoch': 0.76}
{'loss': 0.9513, 'grad_norm': 0.5253612912144995, 'learning_rate': 2.9975519357562155e-06, 'epoch': 0.76}
{'loss': 1.0393, 'grad_norm': 0.6993742047722692, 'learning_rate': 2.9886609381171703e-06, 'epoch': 0.76}
{'loss': 0.9753, 'grad_norm': 0.6710692867889001, 'learning_rate': 2.9797808286499976e-06, 'epoch': 0.76}
{'loss': 1.0307, 'grad_norm': 0.5960499810125665, 'learning_rate': 2.9709116211449484e-06, 'epoch': 0.76}
{'loss': 0.9529, 'grad_norm': 0.5526821001412997, 'learning_rate': 2.9620533293753495e-06, 'epoch': 0.76}
{'loss': 1.0075, 'grad_norm': 0.6493296729519672, 'learning_rate': 2.9532059670975732e-06, 'epoch': 0.76}
{'loss': 0.9897, 'grad_norm': 0.5864699556205142, 'learning_rate': 2.9443695480510225e-06, 'epoch': 0.76}
{'loss': 1.0293, 'grad_norm': 0.6238125808925161, 'learning_rate': 2.935544085958102e-06, 'epoch': 0.76}
{'loss': 0.9931, 'grad_norm': 0.696186454507483, 'learning_rate': 2.926729594524207e-06, 'epoch': 0.76}
{'loss': 0.9591, 'grad_norm': 0.7037621798606204, 'learning_rate': 2.9179260874376915e-06, 'epoch': 0.76}
{'loss': 0.9609, 'grad_norm': 0.6970592647911618, 'learning_rate': 2.9091335783698517e-06, 'epoch': 0.76}
{'loss': 0.9607, 'grad_norm': 0.6221558825807195, 'learning_rate': 2.9003520809749053e-06, 'epoch': 0.76}
{'loss': 0.9401, 'grad_norm': 0.6429681406432463, 'learning_rate': 2.8915816088899696e-06, 'epoch': 0.76}
{'loss': 1.0006, 'grad_norm': 0.6712795900007783, 'learning_rate': 2.8828221757350406e-06, 'epoch': 0.76}
{'loss': 1.0202, 'grad_norm': 0.6854293485057978, 'learning_rate': 2.874073795112967e-06, 'epoch': 0.76}
{'loss': 0.9766, 'grad_norm': 0.5311209522499432, 'learning_rate': 2.8653364806094454e-06, 'epoch': 0.76}
{'loss': 0.8829, 'grad_norm': 0.6274875470916947, 'learning_rate': 2.856610245792976e-06, 'epoch': 0.76}
{'loss': 0.9997, 'grad_norm': 0.6800302787035989, 'learning_rate': 2.847895104214856e-06, 'epoch': 0.76}
{'loss': 0.9935, 'grad_norm': 0.527759511747962, 'learning_rate': 2.8391910694091584e-06, 'epoch': 0.76}
{'loss': 0.9949, 'grad_norm': 0.6206202578748594, 'learning_rate': 2.8304981548927025e-06, 'epoch': 0.76}
{'loss': 0.9996, 'grad_norm': 0.6541469515337032, 'learning_rate': 2.8218163741650415e-06, 'epoch': 0.76}
{'loss': 0.9784, 'grad_norm': 0.6058473409041347, 'learning_rate': 2.813145740708445e-06, 'epoch': 0.76}
{'loss': 0.9801, 'grad_norm': 0.5705506091691039, 'learning_rate': 2.8044862679878605e-06, 'epoch': 0.76}
{'loss': 1.0033, 'grad_norm': 0.5821904586842381, 'learning_rate': 2.7958379694509108e-06, 'epoch': 0.77}
{'loss': 0.9771, 'grad_norm': 0.6612885161486968, 'learning_rate': 2.787200858527862e-06, 'epoch': 0.77}
{'loss': 0.9439, 'grad_norm': 0.6356216554693614, 'learning_rate': 2.7785749486316085e-06, 'epoch': 0.77}
{'loss': 0.9906, 'grad_norm': 0.5983037923133815, 'learning_rate': 2.7699602531576496e-06, 'epoch': 0.77}
{'loss': 1.0152, 'grad_norm': 0.6863111108687515, 'learning_rate': 2.7613567854840685e-06, 'epoch': 0.77}
{'loss': 1.0166, 'grad_norm': 0.7191042565197604, 'learning_rate': 2.752764558971517e-06, 'epoch': 0.77}
{'loss': 0.9688, 'grad_norm': 0.6688413836140995, 'learning_rate': 2.744183586963185e-06, 'epoch': 0.77}
{'loss': 0.9689, 'grad_norm': 0.6532374630097278, 'learning_rate': 2.7356138827847856e-06, 'epoch': 0.77}
{'loss': 0.9441, 'grad_norm': 0.6162138740708328, 'learning_rate': 2.7270554597445343e-06, 'epoch': 0.77}
{'loss': 0.9542, 'grad_norm': 0.6281124793061154, 'learning_rate': 2.7185083311331283e-06, 'epoch': 0.77}
{'loss': 0.9835, 'grad_norm': 0.6410054727206063, 'learning_rate': 2.709972510223725e-06, 'epoch': 0.77}
{'loss': 0.9766, 'grad_norm': 0.755509517345197, 'learning_rate': 2.7014480102719174e-06, 'epoch': 0.77}
{'loss': 0.9707, 'grad_norm': 0.5907783377557593, 'learning_rate': 2.692934844515729e-06, 'epoch': 0.77}
{'loss': 0.9477, 'grad_norm': 0.5847992768969978, 'learning_rate': 2.6844330261755715e-06, 'epoch': 0.77}
{'loss': 0.9929, 'grad_norm': 0.6460042308885476, 'learning_rate': 2.675942568454236e-06, 'epoch': 0.77}
{'loss': 0.9853, 'grad_norm': 0.6639893448574972, 'learning_rate': 2.667463484536876e-06, 'epoch': 0.77}
{'loss': 0.9522, 'grad_norm': 0.6224498238755332, 'learning_rate': 2.65899578759098e-06, 'epoch': 0.77}
{'loss': 0.9868, 'grad_norm': 0.32942904650781063, 'learning_rate': 2.650539490766346e-06, 'epoch': 0.77}
{'loss': 0.9685, 'grad_norm': 0.557523265809976, 'learning_rate': 2.642094607195085e-06, 'epoch': 0.77}
{'loss': 0.9896, 'grad_norm': 0.5801979111050171, 'learning_rate': 2.633661149991569e-06, 'epoch': 0.77}
{'loss': 1.003, 'grad_norm': 0.7043621456392452, 'learning_rate': 2.6252391322524297e-06, 'epoch': 0.77}
{'loss': 0.9521, 'grad_norm': 0.5919706503479919, 'learning_rate': 2.6168285670565374e-06, 'epoch': 0.77}
{'loss': 0.9876, 'grad_norm': 0.5618771767238177, 'learning_rate': 2.6084294674649734e-06, 'epoch': 0.77}
{'loss': 0.9695, 'grad_norm': 0.5864356145077051, 'learning_rate': 2.6000418465210143e-06, 'epoch': 0.77}
{'loss': 1.0057, 'grad_norm': 0.6130598374121887, 'learning_rate': 2.5916657172501103e-06, 'epoch': 0.77}
{'loss': 0.9902, 'grad_norm': 0.6371536853538403, 'learning_rate': 2.583301092659872e-06, 'epoch': 0.77}
{'loss': 0.9262, 'grad_norm': 0.5010077392871959, 'learning_rate': 2.5749479857400383e-06, 'epoch': 0.78}
{'loss': 0.9723, 'grad_norm': 0.614321191660018, 'learning_rate': 2.56660640946246e-06, 'epoch': 0.78}
{'loss': 1.02, 'grad_norm': 0.7514974485463767, 'learning_rate': 2.558276376781086e-06, 'epoch': 0.78}
{'loss': 0.9268, 'grad_norm': 0.5781224539314619, 'learning_rate': 2.5499579006319365e-06, 'epoch': 0.78}
{'loss': 0.9638, 'grad_norm': 0.7296463530992789, 'learning_rate': 2.5416509939330836e-06, 'epoch': 0.78}
{'loss': 0.9944, 'grad_norm': 0.5191538613419733, 'learning_rate': 2.5333556695846384e-06, 'epoch': 0.78}
{'loss': 0.9436, 'grad_norm': 0.6073649771285415, 'learning_rate': 2.525071940468722e-06, 'epoch': 0.78}
{'loss': 0.9358, 'grad_norm': 0.6346303691280568, 'learning_rate': 2.5167998194494468e-06, 'epoch': 0.78}
{'loss': 0.9835, 'grad_norm': 0.5935018216527609, 'learning_rate': 2.5085393193729e-06, 'epoch': 0.78}
{'loss': 0.9847, 'grad_norm': 0.5368811624726593, 'learning_rate': 2.5002904530671236e-06, 'epoch': 0.78}
{'loss': 0.9544, 'grad_norm': 0.6205547104354455, 'learning_rate': 2.492053233342091e-06, 'epoch': 0.78}
{'loss': 1.0288, 'grad_norm': 0.6399758321736293, 'learning_rate': 2.4838276729896884e-06, 'epoch': 0.78}
{'loss': 1.011, 'grad_norm': 0.6517575298292445, 'learning_rate': 2.4756137847837025e-06, 'epoch': 0.78}
{'loss': 0.9383, 'grad_norm': 0.551206181194156, 'learning_rate': 2.467411581479786e-06, 'epoch': 0.78}
{'loss': 0.9501, 'grad_norm': 0.8965274242422118, 'learning_rate': 2.45922107581545e-06, 'epoch': 0.78}
{'loss': 0.9552, 'grad_norm': 0.5763334273617686, 'learning_rate': 2.4510422805100366e-06, 'epoch': 0.78}
{'loss': 0.9719, 'grad_norm': 0.6647137600336149, 'learning_rate': 2.4428752082647044e-06, 'epoch': 0.78}
{'loss': 1.003, 'grad_norm': 0.6384664045517076, 'learning_rate': 2.4347198717624054e-06, 'epoch': 0.78}
{'loss': 0.9782, 'grad_norm': 0.6079254359526111, 'learning_rate': 2.426576283667873e-06, 'epoch': 0.78}
{'loss': 1.0303, 'grad_norm': 0.7875592573377943, 'learning_rate': 2.418444456627589e-06, 'epoch': 0.78}
{'loss': 0.9634, 'grad_norm': 0.637618507248536, 'learning_rate': 2.4103244032697717e-06, 'epoch': 0.78}
{'loss': 0.9717, 'grad_norm': 0.7355841866261356, 'learning_rate': 2.4022161362043574e-06, 'epoch': 0.78}
{'loss': 0.947, 'grad_norm': 0.5006162965582425, 'learning_rate': 2.3941196680229794e-06, 'epoch': 0.78}
{'loss': 0.9888, 'grad_norm': 0.6520993768285375, 'learning_rate': 2.3860350112989473e-06, 'epoch': 0.78}
{'loss': 0.9411, 'grad_norm': 0.6447514775212917, 'learning_rate': 2.3779621785872252e-06, 'epoch': 0.78}
{'loss': 0.9279, 'grad_norm': 0.53783376422805, 'learning_rate': 2.3699011824244234e-06, 'epoch': 0.78}
{'loss': 1.0189, 'grad_norm': 0.5847939410469344, 'learning_rate': 2.3618520353287644e-06, 'epoch': 0.79}
{'loss': 0.9853, 'grad_norm': 0.7143045522800034, 'learning_rate': 2.3538147498000695e-06, 'epoch': 0.79}
{'loss': 0.9651, 'grad_norm': 0.7959560064316212, 'learning_rate': 2.3457893383197415e-06, 'epoch': 0.79}
{'loss': 0.9808, 'grad_norm': 0.557515672105191, 'learning_rate': 2.3377758133507455e-06, 'epoch': 0.79}
{'loss': 0.9975, 'grad_norm': 0.5828084029503313, 'learning_rate': 2.32977418733758e-06, 'epoch': 0.79}
{'loss': 0.9753, 'grad_norm': 0.7085093740362657, 'learning_rate': 2.321784472706279e-06, 'epoch': 0.79}
{'loss': 0.9739, 'grad_norm': 0.6915943081381957, 'learning_rate': 2.3138066818643647e-06, 'epoch': 0.79}
{'loss': 0.9627, 'grad_norm': 0.6116752139880035, 'learning_rate': 2.30584082720085e-06, 'epoch': 0.79}
{'loss': 0.9867, 'grad_norm': 0.7831206019004778, 'learning_rate': 2.297886921086211e-06, 'epoch': 0.79}
{'loss': 0.977, 'grad_norm': 0.6165025753076052, 'learning_rate': 2.2899449758723657e-06, 'epoch': 0.79}
{'loss': 1.0098, 'grad_norm': 0.6256658221183938, 'learning_rate': 2.282015003892659e-06, 'epoch': 0.79}
{'loss': 0.9323, 'grad_norm': 0.5736926697543469, 'learning_rate': 2.2740970174618405e-06, 'epoch': 0.79}
{'loss': 0.9657, 'grad_norm': 0.5652709847494767, 'learning_rate': 2.2661910288760545e-06, 'epoch': 0.79}
{'loss': 0.9929, 'grad_norm': 0.6773612237394716, 'learning_rate': 2.258297050412804e-06, 'epoch': 0.79}
{'loss': 0.9792, 'grad_norm': 0.5884723819960219, 'learning_rate': 2.2504150943309455e-06, 'epoch': 0.79}
{'loss': 0.9608, 'grad_norm': 0.6024669269159217, 'learning_rate': 2.242545172870665e-06, 'epoch': 0.79}
{'loss': 0.943, 'grad_norm': 0.5508705008670635, 'learning_rate': 2.2346872982534584e-06, 'epoch': 0.79}
{'loss': 0.9336, 'grad_norm': 0.6412520967300702, 'learning_rate': 2.2268414826821117e-06, 'epoch': 0.79}
{'loss': 0.9773, 'grad_norm': 0.6156297065866788, 'learning_rate': 2.2190077383406938e-06, 'epoch': 0.79}
{'loss': 0.96, 'grad_norm': 0.5958419303599019, 'learning_rate': 2.211186077394516e-06, 'epoch': 0.79}
{'loss': 0.9761, 'grad_norm': 0.6058270677444302, 'learning_rate': 2.2033765119901294e-06, 'epoch': 0.79}
{'loss': 0.9473, 'grad_norm': 0.5948314584136887, 'learning_rate': 2.1955790542553036e-06, 'epoch': 0.79}
{'loss': 0.9557, 'grad_norm': 0.6327923225158012, 'learning_rate': 2.1877937162990015e-06, 'epoch': 0.79}
{'loss': 0.9564, 'grad_norm': 0.5643353039900354, 'learning_rate': 2.180020510211367e-06, 'epoch': 0.79}
{'loss': 0.965, 'grad_norm': 0.6891952337146537, 'learning_rate': 2.172259448063704e-06, 'epoch': 0.79}
{'loss': 0.9613, 'grad_norm': 0.6113967875704308, 'learning_rate': 2.1645105419084587e-06, 'epoch': 0.79}
{'loss': 1.0242, 'grad_norm': 0.5072028132792695, 'learning_rate': 2.1567738037791998e-06, 'epoch': 0.8}
{'loss': 0.9551, 'grad_norm': 0.6120064038255645, 'learning_rate': 2.1490492456905964e-06, 'epoch': 0.8}
{'loss': 0.9559, 'grad_norm': 0.5667147103695912, 'learning_rate': 2.141336879638406e-06, 'epoch': 0.8}
{'loss': 0.9408, 'grad_norm': 0.7254772339885234, 'learning_rate': 2.133636717599451e-06, 'epoch': 0.8}
{'loss': 0.9993, 'grad_norm': 0.7443529957526854, 'learning_rate': 2.1259487715316e-06, 'epoch': 0.8}
{'loss': 0.9819, 'grad_norm': 0.6879063740859258, 'learning_rate': 2.118273053373757e-06, 'epoch': 0.8}
{'loss': 0.9884, 'grad_norm': 0.6263152712463378, 'learning_rate': 2.1106095750458332e-06, 'epoch': 0.8}
{'loss': 0.9788, 'grad_norm': 0.6674850404749542, 'learning_rate': 2.1029583484487315e-06, 'epoch': 0.8}
{'loss': 0.974, 'grad_norm': 0.5653553701624449, 'learning_rate': 2.0953193854643274e-06, 'epoch': 0.8}
{'loss': 0.9386, 'grad_norm': 0.5631557087827868, 'learning_rate': 2.0876926979554545e-06, 'epoch': 0.8}
{'loss': 1.0271, 'grad_norm': 0.6175635133496414, 'learning_rate': 2.080078297765884e-06, 'epoch': 0.8}
{'loss': 0.9884, 'grad_norm': 0.6127367743005787, 'learning_rate': 2.0724761967202987e-06, 'epoch': 0.8}
{'loss': 1.008, 'grad_norm': 0.6237967755623953, 'learning_rate': 2.0648864066242937e-06, 'epoch': 0.8}
{'loss': 1.0181, 'grad_norm': 0.597416993931541, 'learning_rate': 2.0573089392643362e-06, 'epoch': 0.8}
{'loss': 0.9611, 'grad_norm': 0.6237345374709056, 'learning_rate': 2.0497438064077603e-06, 'epoch': 0.8}
{'loss': 0.9711, 'grad_norm': 0.6163978160783421, 'learning_rate': 2.0421910198027452e-06, 'epoch': 0.8}
{'loss': 1.0165, 'grad_norm': 0.6352725747732899, 'learning_rate': 2.0346505911782956e-06, 'epoch': 0.8}
{'loss': 0.9814, 'grad_norm': 0.6285068036755517, 'learning_rate': 2.0271225322442255e-06, 'epoch': 0.8}
{'loss': 0.9957, 'grad_norm': 0.5844966581092197, 'learning_rate': 2.019606854691145e-06, 'epoch': 0.8}
{'loss': 1.0162, 'grad_norm': 0.688004915183263, 'learning_rate': 2.01210357019043e-06, 'epoch': 0.8}
{'loss': 1.0155, 'grad_norm': 0.6174946333551462, 'learning_rate': 2.004612690394212e-06, 'epoch': 0.8}
{'loss': 0.9876, 'grad_norm': 0.5649222087652178, 'learning_rate': 1.997134226935361e-06, 'epoch': 0.8}
{'loss': 0.9849, 'grad_norm': 0.5994125209791301, 'learning_rate': 1.9896681914274616e-06, 'epoch': 0.8}
{'loss': 1.0054, 'grad_norm': 0.5829006930925987, 'learning_rate': 1.982214595464804e-06, 'epoch': 0.8}
{'loss': 0.9697, 'grad_norm': 0.8198849193691553, 'learning_rate': 1.9747734506223525e-06, 'epoch': 0.8}
{'loss': 0.94, 'grad_norm': 0.6505661895070426, 'learning_rate': 1.967344768455747e-06, 'epoch': 0.8}
{'loss': 0.9909, 'grad_norm': 0.6037219789379844, 'learning_rate': 1.9599285605012643e-06, 'epoch': 0.81}
{'loss': 0.9692, 'grad_norm': 0.6892105672807699, 'learning_rate': 1.952524838275811e-06, 'epoch': 0.81}
{'loss': 1.0015, 'grad_norm': 0.7053833476597322, 'learning_rate': 1.945133613276907e-06, 'epoch': 0.81}
{'loss': 0.9649, 'grad_norm': 0.6862389074011092, 'learning_rate': 1.937754896982663e-06, 'epoch': 0.81}
{'loss': 0.9322, 'grad_norm': 0.6160536124954601, 'learning_rate': 1.9303887008517618e-06, 'epoch': 0.81}
{'loss': 0.9611, 'grad_norm': 0.7082566851939996, 'learning_rate': 1.923035036323452e-06, 'epoch': 0.81}
{'loss': 0.9537, 'grad_norm': 0.6107460906526585, 'learning_rate': 1.9156939148175125e-06, 'epoch': 0.81}
{'loss': 0.9727, 'grad_norm': 0.5718936738726884, 'learning_rate': 1.9083653477342467e-06, 'epoch': 0.81}
{'loss': 0.994, 'grad_norm': 0.7196314988511543, 'learning_rate': 1.9010493464544621e-06, 'epoch': 0.81}
{'loss': 0.9524, 'grad_norm': 0.5267032614996646, 'learning_rate': 1.8937459223394517e-06, 'epoch': 0.81}
{'loss': 0.9841, 'grad_norm': 0.6675906265887669, 'learning_rate': 1.8864550867309771e-06, 'epoch': 0.81}
{'loss': 1.0087, 'grad_norm': 0.5628310997872426, 'learning_rate': 1.8791768509512487e-06, 'epoch': 0.81}
{'loss': 0.9535, 'grad_norm': 0.6297972536667408, 'learning_rate': 1.871911226302917e-06, 'epoch': 0.81}
{'loss': 0.9893, 'grad_norm': 0.5968533289341479, 'learning_rate': 1.8646582240690414e-06, 'epoch': 0.81}
{'loss': 1.0133, 'grad_norm': 0.6913230210588116, 'learning_rate': 1.8574178555130818e-06, 'epoch': 0.81}
{'loss': 0.984, 'grad_norm': 0.6329911749611137, 'learning_rate': 1.8501901318788773e-06, 'epoch': 0.81}
{'loss': 1.0217, 'grad_norm': 0.7134566833722891, 'learning_rate': 1.8429750643906331e-06, 'epoch': 0.81}
{'loss': 1.0083, 'grad_norm': 0.6039320379965237, 'learning_rate': 1.835772664252895e-06, 'epoch': 0.81}
{'loss': 0.9237, 'grad_norm': 0.7707760674713117, 'learning_rate': 1.8285829426505453e-06, 'epoch': 0.81}
{'loss': 0.9932, 'grad_norm': 0.6142017829531758, 'learning_rate': 1.8214059107487726e-06, 'epoch': 0.81}
{'loss': 0.9314, 'grad_norm': 0.6908693808009394, 'learning_rate': 1.8142415796930568e-06, 'epoch': 0.81}
{'loss': 1.0179, 'grad_norm': 0.6860333437025724, 'learning_rate': 1.8070899606091586e-06, 'epoch': 0.81}
{'loss': 0.9219, 'grad_norm': 0.8468505179609797, 'learning_rate': 1.799951064603095e-06, 'epoch': 0.81}
{'loss': 0.9868, 'grad_norm': 0.603731190180376, 'learning_rate': 1.7928249027611255e-06, 'epoch': 0.81}
{'loss': 0.9764, 'grad_norm': 0.6202181885152518, 'learning_rate': 1.7857114861497337e-06, 'epoch': 0.81}
{'loss': 0.9606, 'grad_norm': 0.5995546859881006, 'learning_rate': 1.7786108258156154e-06, 'epoch': 0.81}
{'loss': 0.9753, 'grad_norm': 0.5623611543105036, 'learning_rate': 1.7715229327856498e-06, 'epoch': 0.82}
{'loss': 0.9865, 'grad_norm': 0.5643912083577225, 'learning_rate': 1.7644478180668945e-06, 'epoch': 0.82}
{'loss': 0.9748, 'grad_norm': 0.5852626315893521, 'learning_rate': 1.7573854926465582e-06, 'epoch': 0.82}
{'loss': 0.9888, 'grad_norm': 0.5991400851964206, 'learning_rate': 1.7503359674919929e-06, 'epoch': 0.82}
{'loss': 0.9946, 'grad_norm': 0.6336941082537348, 'learning_rate': 1.7432992535506687e-06, 'epoch': 0.82}
{'loss': 0.9421, 'grad_norm': 0.6629028252209362, 'learning_rate': 1.736275361750167e-06, 'epoch': 0.82}
{'loss': 0.9938, 'grad_norm': 0.6639860594153991, 'learning_rate': 1.7292643029981525e-06, 'epoch': 0.82}
{'loss': 0.9523, 'grad_norm': 0.6165467541290538, 'learning_rate': 1.7222660881823594e-06, 'epoch': 0.82}
{'loss': 0.9694, 'grad_norm': 0.6609220358732832, 'learning_rate': 1.7152807281705809e-06, 'epoch': 0.82}
{'loss': 0.9443, 'grad_norm': 0.6121356161607054, 'learning_rate': 1.708308233810644e-06, 'epoch': 0.82}
{'loss': 0.9842, 'grad_norm': 0.6958592766839867, 'learning_rate': 1.701348615930397e-06, 'epoch': 0.82}
{'loss': 0.9271, 'grad_norm': 0.6154891041429096, 'learning_rate': 1.6944018853376898e-06, 'epoch': 0.82}
{'loss': 0.9279, 'grad_norm': 0.6035668663810022, 'learning_rate': 1.6874680528203657e-06, 'epoch': 0.82}
{'loss': 0.9288, 'grad_norm': 0.5402399261361683, 'learning_rate': 1.6805471291462316e-06, 'epoch': 0.82}
{'loss': 1.0003, 'grad_norm': 0.6206151771533449, 'learning_rate': 1.67363912506305e-06, 'epoch': 0.82}
{'loss': 0.9649, 'grad_norm': 0.5855115357792535, 'learning_rate': 1.66674405129852e-06, 'epoch': 0.82}
{'loss': 0.9591, 'grad_norm': 0.6256178509191602, 'learning_rate': 1.6598619185602616e-06, 'epoch': 0.82}
{'loss': 0.9917, 'grad_norm': 0.7338841505347726, 'learning_rate': 1.6529927375357957e-06, 'epoch': 0.82}
{'loss': 1.0153, 'grad_norm': 0.5845329913083344, 'learning_rate': 1.6461365188925304e-06, 'epoch': 0.82}
{'loss': 0.9765, 'grad_norm': 0.6529622740364378, 'learning_rate': 1.6392932732777489e-06, 'epoch': 0.82}
{'loss': 1.0203, 'grad_norm': 0.6150949727911089, 'learning_rate': 1.6324630113185835e-06, 'epoch': 0.82}
{'loss': 0.9543, 'grad_norm': 0.6790560735122615, 'learning_rate': 1.625645743622003e-06, 'epoch': 0.82}
{'loss': 1.0084, 'grad_norm': 0.5826035238424184, 'learning_rate': 1.6188414807747999e-06, 'epoch': 0.82}
{'loss': 0.9455, 'grad_norm': 0.6051415675862872, 'learning_rate': 1.6120502333435695e-06, 'epoch': 0.82}
{'loss': 1.003, 'grad_norm': 0.6148625094295649, 'learning_rate': 1.6052720118746923e-06, 'epoch': 0.82}
{'loss': 0.9545, 'grad_norm': 0.6662293402562888, 'learning_rate': 1.5985068268943283e-06, 'epoch': 0.82}
{'loss': 0.9556, 'grad_norm': 0.8454156006452792, 'learning_rate': 1.5917546889083834e-06, 'epoch': 0.83}
{'loss': 0.9947, 'grad_norm': 0.565317033546172, 'learning_rate': 1.5850156084025091e-06, 'epoch': 0.83}
{'loss': 0.9522, 'grad_norm': 0.6893395482401365, 'learning_rate': 1.578289595842074e-06, 'epoch': 0.83}
{'loss': 0.9418, 'grad_norm': 0.5643344597605359, 'learning_rate': 1.5715766616721584e-06, 'epoch': 0.83}
{'loss': 0.984, 'grad_norm': 0.6218608789509192, 'learning_rate': 1.5648768163175277e-06, 'epoch': 0.83}
{'loss': 1.0078, 'grad_norm': 0.6163104455969795, 'learning_rate': 1.5581900701826226e-06, 'epoch': 0.83}
{'loss': 0.9807, 'grad_norm': 0.5996955320177376, 'learning_rate': 1.5515164336515465e-06, 'epoch': 0.83}
{'loss': 0.9934, 'grad_norm': 0.6003116192266743, 'learning_rate': 1.5448559170880373e-06, 'epoch': 0.83}
{'loss': 1.0098, 'grad_norm': 0.6963901505854925, 'learning_rate': 1.5382085308354633e-06, 'epoch': 0.83}
{'loss': 0.9493, 'grad_norm': 0.5722722932401019, 'learning_rate': 1.5315742852167992e-06, 'epoch': 0.83}
{'loss': 0.9897, 'grad_norm': 0.6340283016508719, 'learning_rate': 1.5249531905346138e-06, 'epoch': 0.83}
{'loss': 0.9192, 'grad_norm': 0.6341840346434835, 'learning_rate': 1.5183452570710522e-06, 'epoch': 0.83}
{'loss': 0.9363, 'grad_norm': 0.5073998248433557, 'learning_rate': 1.511750495087827e-06, 'epoch': 0.83}
{'loss': 0.9938, 'grad_norm': 0.6246198687098375, 'learning_rate': 1.5051689148261895e-06, 'epoch': 0.83}
{'loss': 0.9293, 'grad_norm': 0.5925059473559567, 'learning_rate': 1.4986005265069204e-06, 'epoch': 0.83}
{'loss': 0.9466, 'grad_norm': 0.5240581680349536, 'learning_rate': 1.4920453403303249e-06, 'epoch': 0.83}
{'loss': 0.9661, 'grad_norm': 0.6319821311724018, 'learning_rate': 1.4855033664761898e-06, 'epoch': 0.83}
{'loss': 1.0104, 'grad_norm': 0.664107239129161, 'learning_rate': 1.4789746151037942e-06, 'epoch': 0.83}
{'loss': 1.0252, 'grad_norm': 0.6448918236230913, 'learning_rate': 1.4724590963518803e-06, 'epoch': 0.83}
{'loss': 1.0466, 'grad_norm': 0.643851445022246, 'learning_rate': 1.4659568203386464e-06, 'epoch': 0.83}
{'loss': 0.9729, 'grad_norm': 0.6627697931039199, 'learning_rate': 1.4594677971617178e-06, 'epoch': 0.83}
{'loss': 0.9797, 'grad_norm': 0.6443861781715987, 'learning_rate': 1.452992036898142e-06, 'epoch': 0.83}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/B00XLX3W9O.jpg, using default black image.
{'loss': 0.9784, 'grad_norm': 0.6003692987698848, 'learning_rate': 1.446529549604373e-06, 'epoch': 0.83}
{'loss': 0.9956, 'grad_norm': 0.5946618987640419, 'learning_rate': 1.4400803453162482e-06, 'epoch': 0.83}
{'loss': 0.9751, 'grad_norm': 0.6408728200162193, 'learning_rate': 1.4336444340489775e-06, 'epoch': 0.83}
{'loss': 0.9329, 'grad_norm': 0.5945837680764335, 'learning_rate': 1.4272218257971327e-06, 'epoch': 0.83}
{'loss': 1.0015, 'grad_norm': 0.6936547151147788, 'learning_rate': 1.4208125305346232e-06, 'epoch': 0.84}
{'loss': 0.9889, 'grad_norm': 0.5821696428031844, 'learning_rate': 1.4144165582146819e-06, 'epoch': 0.84}
{'loss': 1.0118, 'grad_norm': 0.5978519968972804, 'learning_rate': 1.40803391876986e-06, 'epoch': 0.84}
{'loss': 1.0033, 'grad_norm': 0.8183013034960476, 'learning_rate': 1.4016646221119912e-06, 'epoch': 0.84}
{'loss': 0.9694, 'grad_norm': 0.611634801448319, 'learning_rate': 1.395308678132199e-06, 'epoch': 0.84}
{'loss': 1.0158, 'grad_norm': 0.57566268983064, 'learning_rate': 1.3889660967008656e-06, 'epoch': 0.84}
{'loss': 0.9779, 'grad_norm': 0.6638184952601746, 'learning_rate': 1.3826368876676278e-06, 'epoch': 0.84}
{'loss': 0.9308, 'grad_norm': 0.5765064122738314, 'learning_rate': 1.3763210608613497e-06, 'epoch': 0.84}
{'loss': 1.0241, 'grad_norm': 0.713479978802229, 'learning_rate': 1.370018626090116e-06, 'epoch': 0.84}
{'loss': 1.0003, 'grad_norm': 0.6593922456130245, 'learning_rate': 1.3637295931412153e-06, 'epoch': 0.84}
{'loss': 0.9575, 'grad_norm': 0.850116229904879, 'learning_rate': 1.3574539717811231e-06, 'epoch': 0.84}
{'loss': 0.9743, 'grad_norm': 0.6000505026540054, 'learning_rate': 1.3511917717554846e-06, 'epoch': 0.84}
{'loss': 1.0006, 'grad_norm': 0.6362661353981027, 'learning_rate': 1.3449430027891096e-06, 'epoch': 0.84}
{'loss': 0.9455, 'grad_norm': 0.5391986317289147, 'learning_rate': 1.338707674585945e-06, 'epoch': 0.84}
{'loss': 0.9671, 'grad_norm': 0.6181478680820647, 'learning_rate': 1.332485796829065e-06, 'epoch': 0.84}
{'loss': 0.9886, 'grad_norm': 0.593911143901168, 'learning_rate': 1.3262773791806617e-06, 'epoch': 0.84}
{'loss': 0.9938, 'grad_norm': 0.6436014533715819, 'learning_rate': 1.3200824312820137e-06, 'epoch': 0.84}
{'loss': 0.962, 'grad_norm': 0.6116338912893784, 'learning_rate': 1.3139009627534927e-06, 'epoch': 0.84}
{'loss': 0.9633, 'grad_norm': 0.743764245007484, 'learning_rate': 1.3077329831945295e-06, 'epoch': 0.84}
{'loss': 0.983, 'grad_norm': 0.6001179591411439, 'learning_rate': 1.3015785021836159e-06, 'epoch': 0.84}
{'loss': 0.9396, 'grad_norm': 0.6134741171041772, 'learning_rate': 1.295437529278275e-06, 'epoch': 0.84}
{'loss': 0.9649, 'grad_norm': 0.6173185072950593, 'learning_rate': 1.2893100740150522e-06, 'epoch': 0.84}
{'loss': 1.0275, 'grad_norm': 0.6419956643641789, 'learning_rate': 1.2831961459095088e-06, 'epoch': 0.84}
{'loss': 0.9632, 'grad_norm': 0.7359261277724198, 'learning_rate': 1.2770957544561868e-06, 'epoch': 0.84}
{'loss': 0.9095, 'grad_norm': 0.49970298794655305, 'learning_rate': 1.2710089091286148e-06, 'epoch': 0.84}
{'loss': 0.9805, 'grad_norm': 0.6367150237509385, 'learning_rate': 1.2649356193792873e-06, 'epoch': 0.84}
{'loss': 0.9482, 'grad_norm': 0.5681570977737169, 'learning_rate': 1.2588758946396417e-06, 'epoch': 0.85}
{'loss': 1.018, 'grad_norm': 0.6087117182705994, 'learning_rate': 1.2528297443200489e-06, 'epoch': 0.85}
{'loss': 0.9777, 'grad_norm': 0.560883551310168, 'learning_rate': 1.246797177809812e-06, 'epoch': 0.85}
{'loss': 0.9712, 'grad_norm': 0.5329291320328414, 'learning_rate': 1.2407782044771222e-06, 'epoch': 0.85}
{'loss': 0.9682, 'grad_norm': 0.703053117056233, 'learning_rate': 1.23477283366907e-06, 'epoch': 0.85}
WARNING: tokenization mismatch: 0 vs. 852. (ignored)
number of rounds:  1
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a top consultant specialising in advising tax firms and have the following skills and qualities.\n\nKNOWLEDGE: Consultant in a top consulting firm specialising in tax consulting, senior strategist, digital expert.\n\nCHARACTERISTICS: Customer-focused, empathetic, solution-oriented, personable, persuasive, creative.\n\nTASK: Use your knowledge to develop 10 measures to encourage clients to submit their documents digitally instead of by post. The measures should be formulated in such a way that the client recognises the advantages of digital filing. The law firm is digitised and can accept digital documents.\n\nOUTPUT: A list of the 10 actions, each with the name of the action as a heading and 2 short additional bullet points.\n\nOUTPUT LANGUAGE: German ASSISTANT: 1. Persnlicher Kontakt und Beratung:\n\t* Persnliche Beratung und Untersttzung bei der Umstellung auf digitales Einreichen\n\t* Betonung der Vorteile, wie Zeit- und Kosteneinsparungen\n2. Schulung und Untersttzung:\n\t* Schulungen fr die digitale Einreichung von Dokumenten\n\t* Anleitung zur Nutzung von Tools und Software\n3. Anreize schaffen:\n\t* Ermigung bei der Beauftragung digitaler Dienstleistungen\n\t* Sonderangebote fr Kunden, die ihre Dokumente digital einreichen\n4. Informationen bereitstellen:\n\t* Verffentlichung von Leitfden und Handbchern fr die digitale Einreichung von Dokumenten\n\t* FAQ-Liste fr hufig gestellte Fragen zum digitalen Einreichen\n5. Klare Kommunikation:\n\t* Verstndliche Kommunikation der Vorteile der digitalen Einreichung\n\t* Bereitstellung von Informationen ber die Sicherheit der digitalen bermittlung\n6. Einfache Zugnglichkeit:\n\t* Vereinfachung des digitalen Einreichungsprozesses durch intuitive Online-Plattformen\n\t* Bereitstellung von Untersttzung fr den Fall technischer Schwierigkeiten\n7. Zeitersparnis betonen:\n\t* Betonung der Vorteile von Zeitersparnis durch digitales Einreichen\n\t* Erinnerungen an Fristen und den Nutzen der pnktlichen Einreichung\n8. Umweltbewusstsein:\n\t* Betonung des Umweltvorteils durch digitales Einreichen von Dokumenten\n\t* Verweis auf die Mglichkeit, Papierverbrauch zu reduzieren\n9. Kosteneffizienz:\n\t* Betonung der Vorteile von Kosteneinsparungen durch digitales Einreichen\n\t* Verweis auf die Mglichkeit, Papier- und Portokosten zu sparen\n10. Feedback einholen:\n* Umfrage zur Bewertung des digitalen Einreichungsprozesses\n* Analyse der Ergebnisse zur Verbesserung der digitalen Dienstleistungen"]
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are a top consultant specialising in advising tax firms and have the following skills and qualities.

KNOWLEDGE: Consultant in a top consulting firm specialising in tax consulting, senior strategist, digital expert.

CHARACTERISTICS: Customer-focused, empathetic, solution-oriented, personable, persuasive, creative.

TASK: Use your knowledge to develop 10 measures to encourage clients to submit their documents digitally instead of by post. The measures should be formulated in such a way that the client recognises the advantages of digital filing. The law firm is digitised and can accept digital documents.

OUTPUT: A list of the 10 actions, each with the name of the action as a heading and 2 short additional bullet points.

OUTPUT LANGUAGE: German ASSISTANT: 1. Persnlicher Kontakt und Beratung:
	* Persnliche Beratung und Untersttzung bei der Umstellung auf digitales Einreichen
	* Betonung der Vorteile, wie Zeit- und Kosteneinsparungen
2. Schulung und Untersttzung:
	* Schulungen fr die digitale Einreichung von Dokumenten
	* Anleitung zur Nutzung von Tools und Software
3. Anreize schaffen:
	* Ermigung bei der Beauftragung digitaler Dienstleistungen
	* Sonderangebote fr Kunden, die ihre Dokumente digital einreichen
4. Informationen bereitstellen:
	* Verffentlichung von Leitfden und Handbchern fr die digitale Einreichung von Dokumenten
	* FAQ-Liste fr hufig gestellte Fragen zum digitalen Einreichen
5. Klare Kommunikation:
	* Verstndliche Kommunikation der Vorteile der digitalen Einreichung
	* Bereitstellung von Informationen ber die Sicherheit der digitalen bermittlung
6. Einfache Zugnglichkeit:
	* Vereinfachung des digitalen Einreichungsprozesses durch intuitive Online-Plattformen
	* Bereitstellung von Untersttzung fr den Fall technischer Schwierigkeiten
7. Zeitersparnis betonen:
	* Betonung der Vorteile von Zeitersparnis durch digitales Einreichen
	* Erinnerungen an Fristen und den Nutzen der pnktlichen Einreichung
8. Umweltbewusstsein:
	* Betonung des Umweltvorteils durch digitales Einreichen von Dokumenten
	* Verweis auf die Mglichkeit, Papierverbrauch zu reduzieren
9. Kosteneffizienz:
	* Betonung der Vorteile von Kosteneinsparungen durch digitales Einreichen
	* Verweis auf die Mglichkeit, Papier- und Portokosten zu sparen
10. Feedback einholen:
* Umfrage zur Bewertung des digitalen Einreichungsprozesses
* Analyse der Ergebnisse zur Verbesserung der digitalen Dienstleistungen<|endoftext|>
tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])
tensor([   32,  8537,  1022,   257, 11040,  2836,   290,   281, 11666,  4430,
         8796,    13,   383,  8796,  3607,  7613,    11,  6496,    11,   290,
        23507,  7429,   284,   262,  2836,   338,  2683,    13,  1294,  1137,
           25, 24994,  8808,  8643,    25,   921,   389,   257,  1353, 17028,
         2041,  1710,   287, 30341,  1687,  9611,   290,   423,   262,  1708,
         4678,   290, 14482,    13,   198,   198, 29132,  3913, 30465,  8264,
           25, 21651,   415,   287,   257,  1353, 18158,  4081,  2041,  1710,
          287,  1687, 18158,    11,  4664, 25651,    11,  4875,  5887,    13,
          198,   198, 38019,  2246,  5781,  8808, 19505,    25, 22092,    12,
        18143,    11,   795,  8071,  6587,    11,  4610,    12, 17107,    11,
         1048,   540,    11, 40116,    11,  7325,    13,   198,   198,    51,
         1921,    42,    25,  5765,   534,  3725,   284,  1205,   838,  5260,
          284,  7898,  7534,   284,  9199,   511,  4963, 34491,  2427,   286,
          416,  1281,    13,   383,  5260,   815,   307, 34391,   287,   884,
          257,   835,   326,   262,  5456,  3018,  2696,   262, 13391,   286,
         4875, 12180,    13,   383,  1099,  4081,   318, 16839,  1417,   290,
          460,  2453,  4875,  4963,    13,   198,   198,  2606,  7250,  3843,
           25,   317,  1351,   286,   262,   838,  4028,    11,  1123,   351,
          262,  1438,   286,   262,  2223,   355,   257,  9087,   290,   362,
         1790,  3224, 10492,  2173,    13,   198,   198,  2606,  7250,  3843,
          406, 15567,    52, 11879,    25,  2679, 24994,  8808,  8643,    25,
          352,    13,  9467, 48863,   677,   372,   509,   756,   461,    83,
         3318,  4312,   265,  2150,    25,   198,   197,     9,  9467, 48863,
          677,   258,  4312,   265,  2150,  3318,   791,   353,   301,  9116,
        22877,  2150,   307,    72,  4587, 21039,   301,   695,  2150,   257,
         3046,  4875,   274,   412,   259,   260, 41437,   198,   197,     9,
         5147,   261,  2150,  4587,   569,   419,    68,   576,    11,   266,
          494, 47447,    12,  3318,   509,   455,  1734,  1040,  1845,  2150,
          268,   198,    17,    13,  3059,   377,  2150,  3318,   791,   353,
          301,  9116, 22877,  2150,    25,   198,   197,     9,  3059,   377,
         2150,   268,   277, 25151,  4656, 16839,  1000,   412,   259,   260,
          488,  2150, 18042,   360,   482,  1713,   268,   198,   197,     9,
         1052,   293,   270,  2150,  1976,   333, 11959,    89,  2150, 18042,
        20003,  3318, 10442,   198,    18,    13,  1052,   260,  1096,  5513,
         2001,   268,    25,   198,   197,     9,  5256,    76, 11033, 39683,
          328,  2150,   307,    72,  4587, 32831,   701, 22562,  2150,  4875,
          263,   360,  2013,   301,   293,   396,  2150,   268,   198,   197,
            9,   311,  8623,   858,    65,  1258,   277, 25151, 45099,   268,
           11,  4656,  1312,    71,   260,   360,   482,  1713,    68,  4875,
          304,   259,   260, 41437,   198,    19,    13,  6188,   268, 45303,
          270,   301, 40635,    25,   198,   197,     9,  4643,  9101,   487,
          298, 33467,  2150, 18042,  1004,   270,    69, 11033,  6559,  3318,
         7157,    65,  9116,  2044,    77,   277, 25151,  4656, 16839,  1000,
          412,   259,   260,   488,  2150, 18042,   360,   482,  1713,   268,
          198,   197,     9, 18749,    12,  8053,    68,   277, 25151,   289,
        11033,  3046,   328, 10521,   695,   660,  1305, 11286,  1976,   388,
         4875,   268,   412,   259,   260, 41437,   198,    20,    13, 14770,
          533,   509,  2002,   403,  1134,   341,    25,   198,   197,     9,
         4643,   301, 11033,   358,   677,   258,   509,  2002,   403,  1134,
          341,  4587,   569,   419,    68,   576,  4587,  4875,   268,   412,
          259,   260,   488,  2150,   198,   197,     9, 37951,   270,   301,
          695,  2150, 18042,  6188,   268,  6184,   120,   527,  4656, 28799,
          372, 29361,  4587,  4875,   268, 49363,   527, 20124,    75,  2150,
          198,    21,    13,   412, 10745,  4891,  1168,  1018, 11033,   782,
        33467,   365,   270,    25,   198,   197,     9,   569,   567, 10745,
          620,  2150,   748,  4875,   268,   412,   259,   260,   488,  2150,
           82,  1676,    89, 44667,   288,  2575, 19933,  7467,    12,  3646,
         1078,   687,   268,   198,   197,     9, 37951,   270,   301,   695,
         2150, 18042,   791,   353,   301,  9116, 22877,  2150,   277, 25151,
         2853,  7218,  1579, 24645, 20469,   959,   328,   365,   270,   268,
          198,    22,    13, 47447,   364,    79,  1501,   271,   731, 34481,
           25,   198,   197,     9,  5147,   261,  2150,  4587,   569,   419,
           68,   576, 18042, 47447,   364,    79,  1501,   271,   288,  2575,
         4875,   274,   412,   259,   260, 41437,   198,   197,     9,  5256,
         5083,  2150,   268,   281,  1305,   396,   268,  3318,  2853, 11959,
         4801,  4587,   279,  9116,    77, 21841,   677,   831,   412,   259,
          260,   488,  2150,   198,    23,    13, 21039,    86,  2120,    65,
          413,   385,   301, 20719,    25,   198,   197,     9,  5147,   261,
         2150,   748, 21039,    86,  2120,    85,   419,    68,  4487,   288,
         2575,  4875,   274,   412,   259,   260, 41437, 18042,   360,   482,
         1713,   268,   198,   197,     9,  4643,   732,   271,   257,  3046,
         4656,   337,  9101,  4743,   488,   365,   270,    11, 14185,   959,
          332, 16057,   794,  1976,    84,  2027, 49746,   918,   198,    24,
           13,   509,   455,  1734,   487,   528,  2013,    89,    25,   198,
          197,     9,  5147,   261,  2150,  4587,   569,   419,    68,   576,
        18042,   509,   455,  1734,  1040,  1845,  2150,   268,   288,  2575,
         4875,   274,   412,   259,   260, 41437,   198,   197,     9,  4643,
          732,   271,   257,  3046,  4656,   337,  9101,  4743,   488,   365,
          270,    11, 14185,   959,    12,  3318,  4347,   482,   455,   268,
         1976,    84,   599,  5757,   198,   940,    13, 37774,   304,   259,
         3937,   268,    25,   198,     9, 21039,  8310,   496,  1976,   333,
          347,   413,   861,  2150,   748,  4875,   268,   412,   259,   260,
          488,  2150,    82,  1676,    89, 44667,   198,     9, 16213,   325,
         4587,  5256,   469,  9374, 20782,  1976,   333, 49973,   408,   263,
         2150,  4587,  4875,   268,   360,  2013,   301,   293,   396,  2150,
          268, 50256])
{'loss': 0.9811, 'grad_norm': 0.5620436103306532, 'learning_rate': 1.2287810747116224e-06, 'epoch': 0.85}
{'loss': 0.9734, 'grad_norm': 0.6242926969207916, 'learning_rate': 1.2228029369096094e-06, 'epoch': 0.85}
{'loss': 1.0224, 'grad_norm': 0.7099137894624248, 'learning_rate': 1.216838429546704e-06, 'epoch': 0.85}
{'loss': 0.9954, 'grad_norm': 0.5993965711418784, 'learning_rate': 1.2108875618854122e-06, 'epoch': 0.85}
{'loss': 0.955, 'grad_norm': 0.5639020580719406, 'learning_rate': 1.204950343167065e-06, 'epoch': 0.85}
{'loss': 0.9651, 'grad_norm': 0.5918958934125925, 'learning_rate': 1.1990267826117874e-06, 'epoch': 0.85}
{'loss': 0.961, 'grad_norm': 0.6260661039414037, 'learning_rate': 1.1931168894184974e-06, 'epoch': 0.85}
{'loss': 0.9486, 'grad_norm': 0.6321450272594479, 'learning_rate': 1.187220672764897e-06, 'epoch': 0.85}
{'loss': 0.9807, 'grad_norm': 0.6046564907854437, 'learning_rate': 1.1813381418074388e-06, 'epoch': 0.85}
{'loss': 0.9689, 'grad_norm': 0.6453814480970399, 'learning_rate': 1.1754693056813272e-06, 'epoch': 0.85}
{'loss': 1.0057, 'grad_norm': 0.6192706502704164, 'learning_rate': 1.169614173500494e-06, 'epoch': 0.85}
{'loss': 0.9425, 'grad_norm': 0.5609928037534281, 'learning_rate': 1.1637727543576027e-06, 'epoch': 0.85}
WARNING: tokenization mismatch: 0 vs. 1653. (ignored)
number of rounds:  2
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: Du bist ein Personalmarketing-Experte mit den folgenden Kenntnissen und Eigenschaften.\n\nKENNTNISSE: Personalmarketing, Social Media Marketing, Facebook-Marketing, Kampagnenentwicklung, Zielgruppenanalyse, Content-Strategie, Werbeanzeigen, Performance-Messung, Personalgewinnung, Steuerfachangestellte.\n\nEIGENSCHAFTEN: Kreativ, strategisch, analytisch, kommunikativ, zielorientiert, detailverliebt, teamorientiert.\n\nAUFGABE: Entwickle eine erfolgreiche Personalmarketing-Strategie fr die Gewinnung von Steuerfachangestellten ber Facebook. Erstelle eine Tabelle mit allen Manahmen und weise jeder Manahme den zustndigen Spezialisten in einer Marketingagentur zu. Achte dabei auf Zielgruppenanalyse, Content-Strategie, Werbeanzeigen und Performance-Messung.\n\nOUTPUT: Eine Tabelle mit allen Manahmen fr eine erfolgreiche Personalmarketing-Kampagne zur Gewinnung von Steuerfachangestellten auf Facebook, die die Verantwortlichkeiten der Spezialisten in einer Marketingagentur aufzeigt, einschlielich Zielgruppenanalyse, Content-Strategie, Werbeanzeigen und Performance-Messung. ASSISTANT: | Manahme | Beschreibung | Zustndiger Spezialist |\n| --- | --- | --- |\n| Zielgruppenanalyse | Analyse der demografischen Daten, Interessen und Verhaltensweisen der potenziellen Bewerber. | Marktanalyst |\n| Erstellung von Personas | Entwicklung von fiktiven, reprsentativen Bewerberprofilen zur besseren Zielgruppenansprache. | Personalmarketing-Experte |\n| Content-Strategie | Planung von relevantem, ansprechendem und zielgruppenspezifischem Content. | Content-Stratege |\n| Redaktionsplan | Erstellung eines Zeitplans fr die Verffentlichung von Inhalten auf Facebook. | Social Media Manager |\n| Erstellung von Werbeanzeigen | Design und Texten von ansprechenden, zielgruppenspezifischen Facebook-Werbeanzeigen. | Art Director & Copywriter |\n| Auswahl von Targeting-Optionen | Festlegung der Zielgruppenparameter fr die Facebook-Werbekampagnen. | Facebook-Marketing-Experte |\n| Budgetierung und Zeitplanung | Festlegung des Budgets und der Laufzeit fr die Facebook-Werbekampagnen. | Media Planner |\n| Erstellung von Landing Pages | Gestaltung und Implementierung von spezifischen Landing Pages fr die Bewerbung. | Web-Designer |\n| Performance-Messung | berwachung und Analyse der Kampagnenleistung, einschlielich KPIs wie Klicks und Bewerbungen. | Data Analyst |\n| A/B-Testing | Durchfhrung von A/B-Tests, um die Effektivitt von Anzeigen und Landing Pages zu optimieren. | Conversion-Optimierungsexperte |\n| Community-Management | Interaktion mit der Zielgruppe auf Facebook, Beantwortung von Fragen und Moderation von Diskussionen. | Community Manager |\n| Reporting und Optimierung | Regelmige Berichterstattung ber die Kampagnenergebnisse und Anpassung der Strategie. | Performance Marketing-Manager |", 'USER: Weiter. ASSISTANT: Hier sind einige zustzliche Manahmen, die Sie in Ihre Personalmarketing-Strategie fr die Gewinnung von Steuerfachangestellten ber Facebook einbeziehen knnen:\n\n| Manahme | Beschreibung | Zustndiger Spezialist |\n| --- | --- | --- |\n| Video-Content | Erstellung von Video-Content, wie Interviews mit aktuellen Mitarbeitern oder Berufsalltagsvideos. | Videoproduzent |\n| Influencer-Marketing | Zusammenarbeit mit Influencern aus der Branche, um Ihre Arbeitgebermarke zu strken. | Influencer-Marketing-Experte |\n| Anpassung von Stellenanzeigen | Anpassung der Stellenanzeigen auf Facebook, um die Zielgruppe besser anzusprechen. | Personalmarketing-Experte |\n| Mitarbeiter-Testimonials | Teilen von Erfahrungsberichten und Zitaten der Mitarbeiter auf Facebook, um Authentizitt zu schaffen. | Content-Stratege |\n| Virtuelle Karriere-Events | Durchfhrung von virtuellen Karriere-Events oder Informationsveranstaltungen auf Facebook. | Event-Manager |\n| Interaktive Umfragen und Quiz | Nutzung von interaktiven Umfragen und Quiz auf Facebook, um das Engagement zu erhhen. | Social Media Manager |\n| Remarketing-Kampagnen | Einsatz von Remarketing-Anzeigen, um die Personen erneut anzusprechen, die bereits interessiert waren. | Facebook-Marketing-Experte |\n| Monitoring von Wettbewerbern | Beobachtung der Personalmarketing-Aktivitten der Wettbewerber auf Facebook und Ableitung von Optimierungspotenzialen. | Marktanalyst |\n| Integration von Chatbots | Implementierung von Chatbots auf der Facebook-Seite und der Landing Page zur Automatisierung des Bewerbungsprozesses. | Chatbot-Entwickler |\n| Employer Branding-Kampagne | Entwicklung einer Employer Branding-Kampagne, die die Unternehmenskultur und -werte hervorhebt. | Employer Branding-Experte |\n\nMit diesen erweiterten Manahmen knnen Sie eine noch umfassendere Personalmarketing-Strategie entwickeln, die die Chancen erhht, qualifizierte Steuerfachangestellte ber Facebook zu gewinnen.']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: Du bist ein Personalmarketing-Experte mit den folgenden Kenntnissen und Eigenschaften.

KENNTNISSE: Personalmarketing, Social Media Marketing, Facebook-Marketing, Kampagnenentwicklung, Zielgruppenanalyse, Content-Strategie, Werbeanzeigen, Performance-Messung, Personalgewinnung, Steuerfachangestellte.

EIGENSCHAFTEN: Kreativ, strategisch, analytisch, kommunikativ, zielorientiert, detailverliebt, teamorientiert.

AUFGABE: Entwickle eine erfolgreiche Personalmarketing-Strategie fr die Gewinnung von Steuerfachangestellten ber Facebook. Erstelle eine Tabelle mit allen Manahmen und weise jeder Manahme den zustndigen Spezialisten in einer Marketingagentur zu. Achte dabei auf Zielgruppenanalyse, Content-Strategie, Werbeanzeigen und Performance-Messung.

OUTPUT: Eine Tabelle mit allen Manahmen fr eine erfolgreiche Personalmarketing-Kampagne zur Gewinnung von Steuerfachangestellten auf Facebook, die die Verantwortlichkeiten der Spezialisten in einer Marketingagentur aufzeigt, einschlielich Zielgruppenanalyse, Content-Strategie, Werbeanzeigen und Performance-Messung. ASSISTANT: | Manahme | Beschreibung | Zustndiger Spezialist |
| --- | --- | --- |
| Zielgruppenanalyse | Analyse der demografischen Daten, Interessen und Verhaltensweisen der potenziellen Bewerber. | Marktanalyst |
| Erstellung von Personas | Entwicklung von fiktiven, reprsentativen Bewerberprofilen zur besseren Zielgruppenansprache. | Personalmarketing-Experte |
| Content-Strategie | Planung von relevantem, ansprechendem und zielgruppenspezifischem Content. | Content-Stratege |
| Redaktionsplan | Erstellung eines Zeitplans fr die Verffentlichung von Inhalten auf Facebook. | Social Media Manager |
| Erstellung von Werbeanzeigen | Design und Texten von ansprechenden, zielgruppenspezifischen Facebook-Werbeanzeigen. | Art Director & Copywriter |
| Auswahl von Targeting-Optionen | Festlegung der Zielgruppenparameter fr die Facebook-Werbekampagnen. | Facebook-Marketing-Experte |
| Budgetierung und Zeitplanung | Festlegung des Budgets und der Laufzeit fr die Facebook-Werbekampagnen. | Media Planner |
| Erstellung von Landing Pages | Gestaltung und Implementierung von spezifischen Landing Pages fr die Bewerbung. | Web-Designer |
| Performance-Messung | berwachung und Analyse der Kampagnenleistung, einschlielich KPIs wie Klicks und Bewerbungen. | Data Analyst |
| A/B-Testing | Durchfhrung von A/B-Tests, um die Effektivitt von Anzeigen und Landing Pages zu optimieren. | Conversion-Optimierungsexperte |
| Community-Management | Interaktion mit der Zielgruppe auf Facebook, Beantwortung von Fragen und Moderation von Diskussionen. | Community Manager |
| Reporting und Optimierung | Regelmige Berichterstattung ber die Kampagnenergebnisse und Anpassung der Strategie. | Performance Marketing-Manager |<|endoftext|>USER: Weiter. ASSISTANT: Hier sind einige zustzliche Manahmen, die Sie in Ihre Personalmarketing-Strategie fr die Gewinnung von Steuerfachangestellten ber Facebook einbeziehen knnen:

| Manahme | Beschreibung | Zustndiger Spezialist |
| --- | --- | --- |
| Video-Content | Erstellung von Video-Content, wie Interviews mit aktuellen Mitarbeitern oder Berufsalltagsvideos. | Videoproduzent |
| Influencer-Marketing | Zusammenarbeit mit Influencern aus der Branche, um Ihre Arbeitgebermarke zu strken. | Influencer-Marketing-Experte |
| Anpassung von Stellenanzeigen | Anpassung der Stellenanzeigen auf Facebook, um die Zielgruppe besser anzusprechen. | Personalmarketing-Experte |
| Mitarbeiter-Testimonials | Teilen von Erfahrungsberichten und Zitaten der Mitarbeiter auf Facebook, um Authentizitt zu schaffen. | Content-Stratege |
| Virtuelle Karriere-Events | Durchfhrung von virtuellen Karriere-Events oder Informationsveranstaltungen auf Facebook. | Event-Manager |
| Interaktive Umfragen und Quiz | Nutzung von interaktiven Umfragen und Quiz auf Facebook, um das Engagement zu erhhen. | Social Media Manager |
| Remarketing-Kampagnen | Einsatz von Remarketing-Anzeigen, um die Personen erneut anzusprechen, die bereits interessiert waren. | Facebook-Marketing-Experte |
| Monitoring von Wettbewerbern | Beobachtung der Personalmarketing-Aktivitten der Wettbewerber auf Facebook und Ableitung von Optimierungspotenzialen. | Marktanalyst |
| Integration von Chatbots | Implementierung von Chatbots auf der Facebook-Seite und der Landing Page zur Automatisierung des Bewerbungsprozesses. | Chatbot-Entwickler |
| Employer Branding-Kampagne | Entwicklung einer Employer Branding-Kampagne, die die Unternehmenskultur und -werte hervorhebt. | Employer Branding-Experte |

Mit diesen erweiterten Manahmen knnen Sie eine noch umfassendere Personalmarketing-Strategie entwickeln, die die Chancen erhht, qualifizierte Steuerfachangestellte ber Facebook zu gewinnen.<|endoftext|>
tensor([-100, -100, -100,  ..., -100, -100, -100])
tensor([   32,  8537,  1022,  ...,   268,    13, 50256])
{'loss': 0.9178, 'grad_norm': 0.5828989078581549, 'learning_rate': 1.1579450573240058e-06, 'epoch': 0.85}
{'loss': 0.9317, 'grad_norm': 0.5445579977977113, 'learning_rate': 1.1521310914497518e-06, 'epoch': 0.85}
{'loss': 0.9164, 'grad_norm': 0.7342805808561638, 'learning_rate': 1.1463308657635718e-06, 'epoch': 0.85}
{'loss': 0.9601, 'grad_norm': 0.6209743566042941, 'learning_rate': 1.140544389272853e-06, 'epoch': 0.85}
{'loss': 0.9812, 'grad_norm': 0.592059540569818, 'learning_rate': 1.1347716709636282e-06, 'epoch': 0.85}
{'loss': 0.9469, 'grad_norm': 0.7492582419511935, 'learning_rate': 1.129012719800575e-06, 'epoch': 0.85}
{'loss': 0.982, 'grad_norm': 0.634308747809852, 'learning_rate': 1.1232675447269803e-06, 'epoch': 0.85}
{'loss': 0.9509, 'grad_norm': 0.6927022907377933, 'learning_rate': 1.1175361546647413e-06, 'epoch': 0.85}
{'loss': 0.9835, 'grad_norm': 0.6354774482120158, 'learning_rate': 1.1118185585143536e-06, 'epoch': 0.85}
{'loss': 1.007, 'grad_norm': 0.6304231610507405, 'learning_rate': 1.1061147651548855e-06, 'epoch': 0.86}
{'loss': 1.0048, 'grad_norm': 0.7250003087315108, 'learning_rate': 1.1004247834439697e-06, 'epoch': 0.86}
{'loss': 0.9636, 'grad_norm': 0.6372369321246402, 'learning_rate': 1.0947486222177928e-06, 'epoch': 0.86}
{'loss': 0.9985, 'grad_norm': 0.6311283362053883, 'learning_rate': 1.0890862902910849e-06, 'epoch': 0.86}
{'loss': 0.9693, 'grad_norm': 0.5857624163495222, 'learning_rate': 1.0834377964570863e-06, 'epoch': 0.86}
{'loss': 1.018, 'grad_norm': 0.6854075085941902, 'learning_rate': 1.0778031494875574e-06, 'epoch': 0.86}
{'loss': 0.9428, 'grad_norm': 0.7200066812631326, 'learning_rate': 1.072182358132755e-06, 'epoch': 0.86}
{'loss': 0.9442, 'grad_norm': 0.643319549116963, 'learning_rate': 1.066575431121417e-06, 'epoch': 0.86}
{'loss': 1.0241, 'grad_norm': 0.6128873992840407, 'learning_rate': 1.0609823771607487e-06, 'epoch': 0.86}
{'loss': 0.9374, 'grad_norm': 0.6222200715669646, 'learning_rate': 1.055403204936416e-06, 'epoch': 0.86}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/163114006X.jpg, using default black image.
{'loss': 1.0289, 'grad_norm': 0.56357039507671, 'learning_rate': 1.0498379231125278e-06, 'epoch': 0.86}
{'loss': 0.9645, 'grad_norm': 0.6888415460508217, 'learning_rate': 1.0442865403316117e-06, 'epoch': 0.86}
{'loss': 0.9774, 'grad_norm': 0.6043390569992985, 'learning_rate': 1.0387490652146236e-06, 'epoch': 0.86}
{'loss': 0.9989, 'grad_norm': 0.6519923970994962, 'learning_rate': 1.0332255063609177e-06, 'epoch': 0.86}
{'loss': 1.0299, 'grad_norm': 0.6097212659244697, 'learning_rate': 1.027715872348234e-06, 'epoch': 0.86}
{'loss': 0.9833, 'grad_norm': 0.6336431685718575, 'learning_rate': 1.0222201717326885e-06, 'epoch': 0.86}
{'loss': 1.0258, 'grad_norm': 0.7244798518116073, 'learning_rate': 1.0167384130487667e-06, 'epoch': 0.86}
{'loss': 1.0281, 'grad_norm': 0.6165550040795109, 'learning_rate': 1.0112706048092924e-06, 'epoch': 0.86}
{'loss': 0.9358, 'grad_norm': 0.645201709994885, 'learning_rate': 1.00581675550543e-06, 'epoch': 0.86}
{'loss': 1.0207, 'grad_norm': 0.5906489989653323, 'learning_rate': 1.0003768736066722e-06, 'epoch': 0.86}
{'loss': 0.9615, 'grad_norm': 0.6163054267505541, 'learning_rate': 9.949509675608115e-07, 'epoch': 0.86}
{'loss': 1.0063, 'grad_norm': 0.6860275194801218, 'learning_rate': 9.895390457939414e-07, 'epoch': 0.86}
{'loss': 1.0062, 'grad_norm': 0.5669003986040508, 'learning_rate': 9.84141116710442e-07, 'epoch': 0.86}
{'loss': 0.9411, 'grad_norm': 0.6460936548170079, 'learning_rate': 9.787571886929604e-07, 'epoch': 0.86}
{'loss': 0.9409, 'grad_norm': 0.5973475154184891, 'learning_rate': 9.733872701023938e-07, 'epoch': 0.86}
{'loss': 0.9922, 'grad_norm': 0.6326609302874683, 'learning_rate': 9.680313692778976e-07, 'epoch': 0.86}
{'loss': 0.9815, 'grad_norm': 0.596106522958676, 'learning_rate': 9.626894945368492e-07, 'epoch': 0.87}
{'loss': 1.0075, 'grad_norm': 0.6071065599899474, 'learning_rate': 9.573616541748464e-07, 'epoch': 0.87}
{'loss': 0.9649, 'grad_norm': 0.5926559144400547, 'learning_rate': 9.520478564656898e-07, 'epoch': 0.87}
{'loss': 0.9731, 'grad_norm': 0.6097328373496939, 'learning_rate': 9.467481096613829e-07, 'epoch': 0.87}
{'loss': 0.9633, 'grad_norm': 0.6829881588401411, 'learning_rate': 9.414624219920953e-07, 'epoch': 0.87}
{'loss': 0.9869, 'grad_norm': 0.5824041770287808, 'learning_rate': 9.361908016661703e-07, 'epoch': 0.87}
{'loss': 0.931, 'grad_norm': 0.5721393954552187, 'learning_rate': 9.309332568701079e-07, 'epoch': 0.87}
{'loss': 0.9884, 'grad_norm': 0.6439839471976515, 'learning_rate': 9.256897957685463e-07, 'epoch': 0.87}
{'loss': 0.9919, 'grad_norm': 0.5969760045079417, 'learning_rate': 9.204604265042505e-07, 'epoch': 0.87}
{'loss': 0.979, 'grad_norm': 0.547433286498043, 'learning_rate': 9.15245157198108e-07, 'epoch': 0.87}
{'loss': 0.9508, 'grad_norm': 0.5996931536108414, 'learning_rate': 9.10043995949108e-07, 'epoch': 0.87}
{'loss': 0.9787, 'grad_norm': 0.6504124075547933, 'learning_rate': 9.04856950834323e-07, 'epoch': 0.87}
{'loss': 0.9559, 'grad_norm': 0.6939295829538404, 'learning_rate': 8.996840299089149e-07, 'epoch': 0.87}
{'loss': 0.9489, 'grad_norm': 0.5525905489241858, 'learning_rate': 8.945252412061056e-07, 'epoch': 0.87}
{'loss': 0.9725, 'grad_norm': 0.6286769044388992, 'learning_rate': 8.893805927371724e-07, 'epoch': 0.87}
{'loss': 1.0127, 'grad_norm': 0.6802880277410578, 'learning_rate': 8.842500924914299e-07, 'epoch': 0.87}
{'loss': 0.9678, 'grad_norm': 0.7276362215586937, 'learning_rate': 8.791337484362305e-07, 'epoch': 0.87}
{'loss': 0.9588, 'grad_norm': 0.5020674493491378, 'learning_rate': 8.740315685169364e-07, 'epoch': 0.87}
{'loss': 1.0331, 'grad_norm': 0.6673361449267754, 'learning_rate': 8.689435606569086e-07, 'epoch': 0.87}
{'loss': 0.949, 'grad_norm': 0.667820197991247, 'learning_rate': 8.638697327575108e-07, 'epoch': 0.87}
{'loss': 0.9833, 'grad_norm': 0.5809093056273172, 'learning_rate': 8.588100926980802e-07, 'epoch': 0.87}
{'loss': 0.9866, 'grad_norm': 0.5356837941151203, 'learning_rate': 8.537646483359185e-07, 'epoch': 0.87}
{'loss': 0.9399, 'grad_norm': 0.49301616233056367, 'learning_rate': 8.487334075062914e-07, 'epoch': 0.87}
{'loss': 1.0018, 'grad_norm': 0.6229910850923973, 'learning_rate': 8.437163780224011e-07, 'epoch': 0.87}
{'loss': 0.9493, 'grad_norm': 0.6657472381515878, 'learning_rate': 8.387135676753755e-07, 'epoch': 0.87}
{'loss': 0.9866, 'grad_norm': 0.735186850633563, 'learning_rate': 8.337249842342721e-07, 'epoch': 0.87}
{'loss': 1.0576, 'grad_norm': 0.6246238996888805, 'learning_rate': 8.287506354460484e-07, 'epoch': 0.88}
{'loss': 0.9535, 'grad_norm': 0.6162028112992076, 'learning_rate': 8.237905290355563e-07, 'epoch': 0.88}
{'loss': 0.96, 'grad_norm': 0.5863290477980165, 'learning_rate': 8.188446727055311e-07, 'epoch': 0.88}
{'loss': 0.9889, 'grad_norm': 0.5348186607349338, 'learning_rate': 8.139130741365819e-07, 'epoch': 0.88}
{'loss': 0.9917, 'grad_norm': 0.6039774530763019, 'learning_rate': 8.08995740987173e-07, 'epoch': 0.88}
{'loss': 1.0069, 'grad_norm': 0.6888778854683602, 'learning_rate': 8.040926808936112e-07, 'epoch': 0.88}
{'loss': 0.9645, 'grad_norm': 0.5222773156033089, 'learning_rate': 7.99203901470047e-07, 'epoch': 0.88}
{'loss': 0.9857, 'grad_norm': 0.6508298031416574, 'learning_rate': 7.943294103084487e-07, 'epoch': 0.88}
{'loss': 0.9721, 'grad_norm': 0.6519304410502796, 'learning_rate': 7.894692149785954e-07, 'epoch': 0.88}
{'loss': 0.9728, 'grad_norm': 0.7844624006882456, 'learning_rate': 7.846233230280698e-07, 'epoch': 0.88}
{'loss': 1.027, 'grad_norm': 0.6115962852913072, 'learning_rate': 7.797917419822377e-07, 'epoch': 0.88}
{'loss': 0.9666, 'grad_norm': 0.6347223459605812, 'learning_rate': 7.749744793442448e-07, 'epoch': 0.88}
{'loss': 1.0062, 'grad_norm': 0.5941527841872078, 'learning_rate': 7.701715425949952e-07, 'epoch': 0.88}
{'loss': 0.9728, 'grad_norm': 0.6628491337764534, 'learning_rate': 7.653829391931533e-07, 'epoch': 0.88}
{'loss': 0.9602, 'grad_norm': 0.576917977904092, 'learning_rate': 7.606086765751209e-07, 'epoch': 0.88}
{'loss': 0.944, 'grad_norm': 0.5805087632013792, 'learning_rate': 7.55848762155027e-07, 'epoch': 0.88}
{'loss': 0.9643, 'grad_norm': 0.6284358372066116, 'learning_rate': 7.511032033247256e-07, 'epoch': 0.88}
{'loss': 0.9275, 'grad_norm': 0.6564676929468839, 'learning_rate': 7.463720074537728e-07, 'epoch': 0.88}
{'loss': 0.9775, 'grad_norm': 0.5984273972679672, 'learning_rate': 7.416551818894158e-07, 'epoch': 0.88}
{'loss': 0.9065, 'grad_norm': 0.7471191576671627, 'learning_rate': 7.369527339565951e-07, 'epoch': 0.88}
{'loss': 0.9935, 'grad_norm': 0.5546948732373314, 'learning_rate': 7.322646709579173e-07, 'epoch': 0.88}
{'loss': 0.981, 'grad_norm': 0.6121306845009121, 'learning_rate': 7.275910001736497e-07, 'epoch': 0.88}
{'loss': 0.969, 'grad_norm': 0.5981370984645256, 'learning_rate': 7.229317288617144e-07, 'epoch': 0.88}
{'loss': 0.9995, 'grad_norm': 0.5946952502043792, 'learning_rate': 7.182868642576679e-07, 'epoch': 0.88}
{'loss': 1.0307, 'grad_norm': 0.6204882574056632, 'learning_rate': 7.13656413574696e-07, 'epoch': 0.88}
{'loss': 1.0219, 'grad_norm': 0.5906719259322678, 'learning_rate': 7.090403840035942e-07, 'epoch': 0.88}
{'loss': 1.0157, 'grad_norm': 0.673910573662615, 'learning_rate': 7.044387827127752e-07, 'epoch': 0.89}
{'loss': 0.9947, 'grad_norm': 0.652751050636928, 'learning_rate': 6.99851616848235e-07, 'epoch': 0.89}
{'loss': 0.9848, 'grad_norm': 0.6051079263460379, 'learning_rate': 6.952788935335541e-07, 'epoch': 0.89}
{'loss': 0.9812, 'grad_norm': 0.5936366357992136, 'learning_rate': 6.907206198698912e-07, 'epoch': 0.89}
{'loss': 0.9886, 'grad_norm': 0.7739634467557431, 'learning_rate': 6.861768029359595e-07, 'epoch': 0.89}
{'loss': 0.9809, 'grad_norm': 0.6030875631441467, 'learning_rate': 6.816474497880177e-07, 'epoch': 0.89}
{'loss': 0.9896, 'grad_norm': 0.5181385387598235, 'learning_rate': 6.77132567459875e-07, 'epoch': 0.89}
{'loss': 0.998, 'grad_norm': 0.6333684445524618, 'learning_rate': 6.726321629628585e-07, 'epoch': 0.89}
{'loss': 0.976, 'grad_norm': 0.5789882407793028, 'learning_rate': 6.681462432858154e-07, 'epoch': 0.89}
{'loss': 0.9836, 'grad_norm': 0.6858761071818434, 'learning_rate': 6.636748153951e-07, 'epoch': 0.89}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/1780048319.jpg, using default black image.
{'loss': 0.9421, 'grad_norm': 0.6249921901007741, 'learning_rate': 6.592178862345622e-07, 'epoch': 0.89}
{'loss': 0.9518, 'grad_norm': 0.6263484519951733, 'learning_rate': 6.547754627255332e-07, 'epoch': 0.89}
{'loss': 0.9905, 'grad_norm': 0.6115389765282041, 'learning_rate': 6.503475517668168e-07, 'epoch': 0.89}
{'loss': 1.0007, 'grad_norm': 0.5627134116474735, 'learning_rate': 6.459341602346858e-07, 'epoch': 0.89}
{'loss': 0.9697, 'grad_norm': 0.6165818418014429, 'learning_rate': 6.415352949828601e-07, 'epoch': 0.89}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/789748479.jpg, using default black image.
{'loss': 0.9568, 'grad_norm': 0.6200931936083276, 'learning_rate': 6.371509628425021e-07, 'epoch': 0.89}
{'loss': 1.0135, 'grad_norm': 0.6458711043617934, 'learning_rate': 6.327811706222097e-07, 'epoch': 0.89}
{'loss': 0.9977, 'grad_norm': 0.6202598335223449, 'learning_rate': 6.284259251079939e-07, 'epoch': 0.89}
{'loss': 0.9838, 'grad_norm': 0.5692591996189994, 'learning_rate': 6.240852330632796e-07, 'epoch': 0.89}
{'loss': 1.0291, 'grad_norm': 0.7134463530499273, 'learning_rate': 6.197591012288918e-07, 'epoch': 0.89}
{'loss': 0.9952, 'grad_norm': 0.5821548477133206, 'learning_rate': 6.154475363230417e-07, 'epoch': 0.89}
{'loss': 0.9672, 'grad_norm': 0.6043237394867481, 'learning_rate': 6.111505450413202e-07, 'epoch': 0.89}
{'loss': 0.9761, 'grad_norm': 0.5844855694116314, 'learning_rate': 6.068681340566896e-07, 'epoch': 0.89}
{'loss': 1.0119, 'grad_norm': 0.6386246931371321, 'learning_rate': 6.026003100194633e-07, 'epoch': 0.89}
{'loss': 1.0085, 'grad_norm': 0.6183307826289944, 'learning_rate': 5.983470795573088e-07, 'epoch': 0.89}
{'loss': 0.9622, 'grad_norm': 0.637752652601371, 'learning_rate': 5.941084492752236e-07, 'epoch': 0.89}
{'loss': 0.9637, 'grad_norm': 0.5495437648344154, 'learning_rate': 5.898844257555392e-07, 'epoch': 0.9}
{'loss': 0.9828, 'grad_norm': 0.9182159252182037, 'learning_rate': 5.856750155578983e-07, 'epoch': 0.9}
{'loss': 1.0202, 'grad_norm': 0.6087636305197285, 'learning_rate': 5.81480225219252e-07, 'epoch': 0.9}
{'loss': 0.9544, 'grad_norm': 0.6713821016092584, 'learning_rate': 5.773000612538505e-07, 'epoch': 0.9}
{'loss': 1.0303, 'grad_norm': 0.7778808462670869, 'learning_rate': 5.731345301532265e-07, 'epoch': 0.9}
{'loss': 0.9782, 'grad_norm': 0.6243325375930766, 'learning_rate': 5.68983638386188e-07, 'epoch': 0.9}
{'loss': 0.9723, 'grad_norm': 0.6283197520456106, 'learning_rate': 5.648473923988129e-07, 'epoch': 0.9}
{'loss': 1.0002, 'grad_norm': 0.6004873466996744, 'learning_rate': 5.607257986144321e-07, 'epoch': 0.9}
{'loss': 0.9788, 'grad_norm': 0.6340403790573459, 'learning_rate': 5.566188634336212e-07, 'epoch': 0.9}
{'loss': 0.9963, 'grad_norm': 0.6596532624978454, 'learning_rate': 5.525265932341984e-07, 'epoch': 0.9}
{'loss': 0.9105, 'grad_norm': 0.4798793966158745, 'learning_rate': 5.484489943712013e-07, 'epoch': 0.9}
{'loss': 0.9852, 'grad_norm': 0.800787289085281, 'learning_rate': 5.443860731768869e-07, 'epoch': 0.9}
{'loss': 1.0006, 'grad_norm': 0.6787595196682968, 'learning_rate': 5.403378359607181e-07, 'epoch': 0.9}
{'loss': 1.0081, 'grad_norm': 0.5774206994215375, 'learning_rate': 5.36304289009355e-07, 'epoch': 0.9}
{'loss': 0.975, 'grad_norm': 0.5245020534479107, 'learning_rate': 5.322854385866439e-07, 'epoch': 0.9}
{'loss': 0.936, 'grad_norm': 0.5806120515119535, 'learning_rate': 5.282812909336077e-07, 'epoch': 0.9}
{'loss': 0.9384, 'grad_norm': 0.6166777315389456, 'learning_rate': 5.242918522684392e-07, 'epoch': 0.9}
{'loss': 0.9945, 'grad_norm': 0.5604617701092138, 'learning_rate': 5.203171287864872e-07, 'epoch': 0.9}
{'loss': 0.8917, 'grad_norm': 0.5191529144539713, 'learning_rate': 5.163571266602485e-07, 'epoch': 0.9}
{'loss': 0.9545, 'grad_norm': 0.5916094205511423, 'learning_rate': 5.124118520393606e-07, 'epoch': 0.9}
{'loss': 1.0122, 'grad_norm': 0.5977265069252041, 'learning_rate': 5.084813110505871e-07, 'epoch': 0.9}
{'loss': 0.9547, 'grad_norm': 0.5472922634831229, 'learning_rate': 5.045655097978131e-07, 'epoch': 0.9}
{'loss': 0.9947, 'grad_norm': 0.5929452119446347, 'learning_rate': 5.006644543620342e-07, 'epoch': 0.9}
{'loss': 1.0047, 'grad_norm': 0.5695477990150665, 'learning_rate': 4.967781508013459e-07, 'epoch': 0.9}
{'loss': 0.9891, 'grad_norm': 0.5392758500007634, 'learning_rate': 4.929066051509346e-07, 'epoch': 0.9}
{'loss': 1.0317, 'grad_norm': 0.5671097729603974, 'learning_rate': 4.890498234230689e-07, 'epoch': 0.9}
{'loss': 0.9788, 'grad_norm': 0.6065199877468974, 'learning_rate': 4.852078116070902e-07, 'epoch': 0.91}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/1616384670.jpg, using default black image.
{'loss': 0.973, 'grad_norm': 0.7006114692192819, 'learning_rate': 4.813805756694035e-07, 'epoch': 0.91}
{'loss': 0.9641, 'grad_norm': 0.6517332901781028, 'learning_rate': 4.775681215534656e-07, 'epoch': 0.91}
{'loss': 0.9702, 'grad_norm': 0.6261383523883729, 'learning_rate': 4.7377045517978173e-07, 'epoch': 0.91}
{'loss': 1.0027, 'grad_norm': 0.7366262737368584, 'learning_rate': 4.6998758244588995e-07, 'epoch': 0.91}
{'loss': 0.9789, 'grad_norm': 0.5671777750895678, 'learning_rate': 4.662195092263566e-07, 'epoch': 0.91}
{'loss': 0.9849, 'grad_norm': 0.6837572934496698, 'learning_rate': 4.6246624137276206e-07, 'epoch': 0.91}
{'loss': 0.9153, 'grad_norm': 0.6435748871479748, 'learning_rate': 4.587277847136984e-07, 'epoch': 0.91}
{'loss': 0.9988, 'grad_norm': 0.5822871434797443, 'learning_rate': 4.550041450547549e-07, 'epoch': 0.91}
{'loss': 0.9978, 'grad_norm': 0.6872183852353289, 'learning_rate': 4.512953281785104e-07, 'epoch': 0.91}
{'loss': 0.9516, 'grad_norm': 0.5840321822654966, 'learning_rate': 4.476013398445289e-07, 'epoch': 0.91}
{'loss': 1.0142, 'grad_norm': 0.7691177420688474, 'learning_rate': 4.4392218578934164e-07, 'epoch': 0.91}
{'loss': 0.9331, 'grad_norm': 0.5580394365263855, 'learning_rate': 4.4025787172644495e-07, 'epoch': 0.91}
{'loss': 0.9496, 'grad_norm': 0.7307471481560793, 'learning_rate': 4.366084033462914e-07, 'epoch': 0.91}
{'loss': 1.0305, 'grad_norm': 0.654152430325703, 'learning_rate': 4.329737863162753e-07, 'epoch': 0.91}
{'loss': 0.9941, 'grad_norm': 0.6080718399226103, 'learning_rate': 4.2935402628073166e-07, 'epoch': 0.91}
{'loss': 0.9777, 'grad_norm': 0.6205729447365491, 'learning_rate': 4.2574912886092166e-07, 'epoch': 0.91}
{'loss': 0.9824, 'grad_norm': 0.6251931690346584, 'learning_rate': 4.221590996550251e-07, 'epoch': 0.91}
{'loss': 1.0142, 'grad_norm': 0.5726042122165893, 'learning_rate': 4.1858394423813563e-07, 'epoch': 0.91}
{'loss': 1.0131, 'grad_norm': 0.6649330656844066, 'learning_rate': 4.1502366816224327e-07, 'epoch': 0.91}
{'loss': 0.9658, 'grad_norm': 0.6198922675520614, 'learning_rate': 4.1147827695623643e-07, 'epoch': 0.91}
{'loss': 0.9901, 'grad_norm': 0.8006689606390504, 'learning_rate': 4.0794777612588543e-07, 'epoch': 0.91}
{'loss': 1.0289, 'grad_norm': 0.6159397864457247, 'learning_rate': 4.044321711538368e-07, 'epoch': 0.91}
{'loss': 0.9798, 'grad_norm': 0.6953998579356917, 'learning_rate': 4.00931467499609e-07, 'epoch': 0.91}
{'loss': 1.0066, 'grad_norm': 0.6298052954492314, 'learning_rate': 3.974456705995733e-07, 'epoch': 0.91}
{'loss': 0.9795, 'grad_norm': 0.6077273609189071, 'learning_rate': 3.9397478586695513e-07, 'epoch': 0.91}
{'loss': 0.9732, 'grad_norm': 0.6577991192654611, 'learning_rate': 3.90518818691823e-07, 'epoch': 0.92}
{'loss': 0.9769, 'grad_norm': 0.6540256625096043, 'learning_rate': 3.8707777444107697e-07, 'epoch': 0.92}
{'loss': 0.985, 'grad_norm': 0.6236098028824505, 'learning_rate': 3.8365165845844266e-07, 'epoch': 0.92}
{'loss': 0.983, 'grad_norm': 0.5707919620312021, 'learning_rate': 3.8024047606446736e-07, 'epoch': 0.92}
{'loss': 0.9946, 'grad_norm': 0.5938204357345975, 'learning_rate': 3.768442325565036e-07, 'epoch': 0.92}
{'loss': 0.9966, 'grad_norm': 0.6536396773720776, 'learning_rate': 3.7346293320870363e-07, 'epoch': 0.92}
{'loss': 0.9801, 'grad_norm': 0.6046850858128014, 'learning_rate': 3.700965832720171e-07, 'epoch': 0.92}
{'loss': 0.9901, 'grad_norm': 0.6777298201982963, 'learning_rate': 3.6674518797417236e-07, 'epoch': 0.92}
{'loss': 0.9539, 'grad_norm': 0.6309234029591835, 'learning_rate': 3.6340875251967946e-07, 'epoch': 0.92}
{'loss': 1.0014, 'grad_norm': 0.575965997492819, 'learning_rate': 3.6008728208981157e-07, 'epoch': 0.92}
{'loss': 0.9509, 'grad_norm': 0.5086598953366889, 'learning_rate': 3.5678078184260834e-07, 'epoch': 0.92}
{'loss': 0.9785, 'grad_norm': 0.830110633958478, 'learning_rate': 3.5348925691285675e-07, 'epoch': 0.92}
{'loss': 1.0062, 'grad_norm': 0.6075203837936684, 'learning_rate': 3.502127124120891e-07, 'epoch': 0.92}
{'loss': 0.971, 'grad_norm': 0.5906741080739123, 'learning_rate': 3.4695115342857524e-07, 'epoch': 0.92}
{'loss': 0.9651, 'grad_norm': 0.6629588527558117, 'learning_rate': 3.437045850273113e-07, 'epoch': 0.92}
{'loss': 1.0011, 'grad_norm': 0.5990405001624568, 'learning_rate': 3.404730122500155e-07, 'epoch': 0.92}
{'loss': 0.9315, 'grad_norm': 0.6494413903383905, 'learning_rate': 3.3725644011512125e-07, 'epoch': 0.92}
{'loss': 1.0059, 'grad_norm': 0.587635573997994, 'learning_rate': 3.3405487361776177e-07, 'epoch': 0.92}
{'loss': 1.02, 'grad_norm': 0.5799571968062824, 'learning_rate': 3.308683177297711e-07, 'epoch': 0.92}
{'loss': 0.9615, 'grad_norm': 0.6887296040762916, 'learning_rate': 3.2769677739966975e-07, 'epoch': 0.92}
{'loss': 0.9604, 'grad_norm': 0.6268013970454956, 'learning_rate': 3.245402575526646e-07, 'epoch': 0.92}
{'loss': 0.9784, 'grad_norm': 0.6143578410576502, 'learning_rate': 3.2139876309063233e-07, 'epoch': 0.92}
{'loss': 0.9702, 'grad_norm': 0.565763866405759, 'learning_rate': 3.182722988921161e-07, 'epoch': 0.92}
{'loss': 0.9214, 'grad_norm': 0.59682362061855, 'learning_rate': 3.151608698123232e-07, 'epoch': 0.92}
{'loss': 1.0005, 'grad_norm': 0.7144601002533703, 'learning_rate': 3.1206448068310635e-07, 'epoch': 0.92}
{'loss': 0.9994, 'grad_norm': 0.6254827635041192, 'learning_rate': 3.0898313631296586e-07, 'epoch': 0.92}
{'loss': 0.957, 'grad_norm': 0.6365542809547271, 'learning_rate': 3.0591684148703617e-07, 'epoch': 0.93}
{'loss': 1.024, 'grad_norm': 0.6868902929441474, 'learning_rate': 3.0286560096708275e-07, 'epoch': 0.93}
{'loss': 0.9789, 'grad_norm': 0.6421041693858953, 'learning_rate': 2.998294194914897e-07, 'epoch': 0.93}
{'loss': 0.9289, 'grad_norm': 0.5475829212934785, 'learning_rate': 2.968083017752599e-07, 'epoch': 0.93}
{'loss': 0.9668, 'grad_norm': 0.6387452321118525, 'learning_rate': 2.938022525099982e-07, 'epoch': 0.93}
{'loss': 0.9313, 'grad_norm': 0.5909109449346862, 'learning_rate': 2.908112763639137e-07, 'epoch': 0.93}
{'loss': 1.0052, 'grad_norm': 0.5356421030468427, 'learning_rate': 2.878353779818044e-07, 'epoch': 0.93}
{'loss': 0.9374, 'grad_norm': 0.5343456371871333, 'learning_rate': 2.848745619850546e-07, 'epoch': 0.93}
{'loss': 0.9579, 'grad_norm': 0.5938659395625834, 'learning_rate': 2.8192883297162634e-07, 'epoch': 0.93}
{'loss': 0.9793, 'grad_norm': 0.5809822567447156, 'learning_rate': 2.7899819551605256e-07, 'epoch': 0.93}
{'loss': 1.0086, 'grad_norm': 0.5965445188667969, 'learning_rate': 2.760826541694328e-07, 'epoch': 0.93}
{'loss': 0.9864, 'grad_norm': 0.8129869474293413, 'learning_rate': 2.7318221345941865e-07, 'epoch': 0.93}
{'loss': 0.992, 'grad_norm': 0.5927686370648702, 'learning_rate': 2.7029687789021377e-07, 'epoch': 0.93}
{'loss': 1.0047, 'grad_norm': 0.6991895406831502, 'learning_rate': 2.67426651942565e-07, 'epoch': 0.93}
{'loss': 1.0076, 'grad_norm': 0.6276042904886157, 'learning_rate': 2.645715400737536e-07, 'epoch': 0.93}
{'loss': 1.0302, 'grad_norm': 0.6871390699864894, 'learning_rate': 2.6173154671758847e-07, 'epoch': 0.93}
{'loss': 0.9675, 'grad_norm': 0.5588710143213207, 'learning_rate': 2.589066762844039e-07, 'epoch': 0.93}
{'loss': 0.992, 'grad_norm': 0.7052717766819356, 'learning_rate': 2.5609693316104745e-07, 'epoch': 0.93}
{'loss': 0.9899, 'grad_norm': 0.6356259570746547, 'learning_rate': 2.5330232171087433e-07, 'epoch': 0.93}
{'loss': 0.9878, 'grad_norm': 0.5844878925676241, 'learning_rate': 2.5052284627374077e-07, 'epoch': 0.93}
{'loss': 0.9953, 'grad_norm': 0.770132324947622, 'learning_rate': 2.477585111659997e-07, 'epoch': 0.93}
{'loss': 0.9647, 'grad_norm': 0.6786838618115966, 'learning_rate': 2.4500932068049046e-07, 'epoch': 0.93}
{'loss': 1.0042, 'grad_norm': 0.6626334462502365, 'learning_rate': 2.422752790865346e-07, 'epoch': 0.93}
{'loss': 0.9889, 'grad_norm': 0.6049959024219517, 'learning_rate': 2.3955639062992696e-07, 'epoch': 0.93}
{'loss': 0.9856, 'grad_norm': 0.5768766299780317, 'learning_rate': 2.3685265953293345e-07, 'epoch': 0.93}
{'loss': 0.9797, 'grad_norm': 0.7047105935928806, 'learning_rate': 2.3416408999427876e-07, 'epoch': 0.93}
{'loss': 0.9927, 'grad_norm': 0.6129385927246788, 'learning_rate': 2.3149068618914417e-07, 'epoch': 0.94}
{'loss': 0.9546, 'grad_norm': 0.6192276341121122, 'learning_rate': 2.2883245226915652e-07, 'epoch': 0.94}
{'loss': 1.0117, 'grad_norm': 0.612918404773844, 'learning_rate': 2.2618939236238924e-07, 'epoch': 0.94}
{'loss': 1.0173, 'grad_norm': 0.6589496081380479, 'learning_rate': 2.2356151057334908e-07, 'epoch': 0.94}
{'loss': 0.994, 'grad_norm': 0.6026179201566239, 'learning_rate': 2.209488109829727e-07, 'epoch': 0.94}
{'loss': 0.9928, 'grad_norm': 0.5673426563767232, 'learning_rate': 2.1835129764861907e-07, 'epoch': 0.94}
{'loss': 0.9588, 'grad_norm': 0.7681122202644249, 'learning_rate': 2.1576897460406477e-07, 'epoch': 0.94}
{'loss': 0.9907, 'grad_norm': 0.600943648391607, 'learning_rate': 2.1320184585949532e-07, 'epoch': 0.94}
{'loss': 0.9884, 'grad_norm': 0.6885995383716325, 'learning_rate': 2.106499154015018e-07, 'epoch': 0.94}
{'loss': 0.965, 'grad_norm': 0.6072029953568507, 'learning_rate': 2.0811318719307194e-07, 'epoch': 0.94}
{'loss': 0.9253, 'grad_norm': 0.6065364666221862, 'learning_rate': 2.0559166517358787e-07, 'epoch': 0.94}
{'loss': 0.9681, 'grad_norm': 0.5418379198912997, 'learning_rate': 2.0308535325881616e-07, 'epoch': 0.94}
{'loss': 1.0015, 'grad_norm': 0.6928236890727585, 'learning_rate': 2.0059425534090128e-07, 'epoch': 0.94}
{'loss': 0.9422, 'grad_norm': 0.7727590628744134, 'learning_rate': 1.981183752883631e-07, 'epoch': 0.94}
{'loss': 0.9802, 'grad_norm': 0.5953983498536349, 'learning_rate': 1.9565771694608937e-07, 'epoch': 0.94}
{'loss': 0.9463, 'grad_norm': 0.590536038269084, 'learning_rate': 1.9321228413532788e-07, 'epoch': 0.94}
{'loss': 0.965, 'grad_norm': 0.606814676924353, 'learning_rate': 1.907820806536842e-07, 'epoch': 0.94}
{'loss': 0.9528, 'grad_norm': 0.6010132712350428, 'learning_rate': 1.883671102751128e-07, 'epoch': 0.94}
{'loss': 0.9765, 'grad_norm': 0.6157624060103914, 'learning_rate': 1.859673767499115e-07, 'epoch': 0.94}
{'loss': 0.9128, 'grad_norm': 0.5789593618589504, 'learning_rate': 1.83582883804716e-07, 'epoch': 0.94}
{'loss': 0.9892, 'grad_norm': 0.6669142201070501, 'learning_rate': 1.8121363514249534e-07, 'epoch': 0.94}
{'loss': 0.9567, 'grad_norm': 0.6045036713032907, 'learning_rate': 1.7885963444254528e-07, 'epoch': 0.94}
{'loss': 1.0, 'grad_norm': 0.670528170712991, 'learning_rate': 1.7652088536048052e-07, 'epoch': 0.94}
{'loss': 1.0156, 'grad_norm': 0.6298825455950194, 'learning_rate': 1.7419739152823468e-07, 'epoch': 0.94}
{'loss': 0.9804, 'grad_norm': 0.6022665670906386, 'learning_rate': 1.7188915655404814e-07, 'epoch': 0.94}
{'loss': 0.9537, 'grad_norm': 0.5428317894321634, 'learning_rate': 1.695961840224636e-07, 'epoch': 0.94}
{'loss': 0.9881, 'grad_norm': 0.6019784107031855, 'learning_rate': 1.6731847749432705e-07, 'epoch': 0.95}
{'loss': 0.9376, 'grad_norm': 0.6120813340732854, 'learning_rate': 1.6505604050677249e-07, 'epoch': 0.95}
{'loss': 0.944, 'grad_norm': 0.6104556328165001, 'learning_rate': 1.6280887657322276e-07, 'epoch': 0.95}
{'loss': 0.9252, 'grad_norm': 0.4733611163629358, 'learning_rate': 1.6057698918338526e-07, 'epoch': 0.95}
{'loss': 0.9689, 'grad_norm': 0.6383995615539546, 'learning_rate': 1.5836038180324198e-07, 'epoch': 0.95}
{'loss': 0.9503, 'grad_norm': 0.5846727312126312, 'learning_rate': 1.561590578750438e-07, 'epoch': 0.95}
{'loss': 0.9344, 'grad_norm': 0.5959293332237883, 'learning_rate': 1.5397302081731069e-07, 'epoch': 0.95}
{'loss': 0.9686, 'grad_norm': 0.526602958611142, 'learning_rate': 1.518022740248215e-07, 'epoch': 0.95}
{'loss': 0.9415, 'grad_norm': 0.6520409990421291, 'learning_rate': 1.4964682086861082e-07, 'epoch': 0.95}
{'loss': 1.0123, 'grad_norm': 0.676113597627537, 'learning_rate': 1.475066646959611e-07, 'epoch': 0.95}
{'loss': 1.0112, 'grad_norm': 0.6301676210486009, 'learning_rate': 1.4538180883040264e-07, 'epoch': 0.95}
{'loss': 0.9811, 'grad_norm': 0.599095131425653, 'learning_rate': 1.4327225657170485e-07, 'epoch': 0.95}
{'loss': 0.985, 'grad_norm': 0.6441894927237368, 'learning_rate': 1.411780111958694e-07, 'epoch': 0.95}
{'loss': 0.9741, 'grad_norm': 0.6445024133541545, 'learning_rate': 1.3909907595512806e-07, 'epoch': 0.95}
{'loss': 0.971, 'grad_norm': 0.64646276577269, 'learning_rate': 1.3703545407793951e-07, 'epoch': 0.95}
{'loss': 0.9386, 'grad_norm': 0.6355664880492109, 'learning_rate': 1.34987148768978e-07, 'epoch': 0.95}
{'loss': 0.9792, 'grad_norm': 0.6729991143458421, 'learning_rate': 1.3295416320913357e-07, 'epoch': 0.95}
{'loss': 1.0232, 'grad_norm': 0.8964007482643824, 'learning_rate': 1.3093650055550855e-07, 'epoch': 0.95}
{'loss': 1.025, 'grad_norm': 0.7187011385337339, 'learning_rate': 1.2893416394140323e-07, 'epoch': 0.95}
{'loss': 0.9114, 'grad_norm': 0.5159419748830152, 'learning_rate': 1.269471564763247e-07, 'epoch': 0.95}
{'loss': 0.9557, 'grad_norm': 0.7332316869493695, 'learning_rate': 1.2497548124597026e-07, 'epoch': 0.95}
{'loss': 0.9644, 'grad_norm': 0.676244006117855, 'learning_rate': 1.2301914131222726e-07, 'epoch': 0.95}
{'loss': 0.9762, 'grad_norm': 0.5940441630506369, 'learning_rate': 1.2107813971317106e-07, 'epoch': 0.95}
{'loss': 0.9395, 'grad_norm': 0.5766628500940424, 'learning_rate': 1.1915247946305498e-07, 'epoch': 0.95}
{'loss': 0.9625, 'grad_norm': 0.6075908421996085, 'learning_rate': 1.1724216355231022e-07, 'epoch': 0.95}
{'loss': 0.9397, 'grad_norm': 0.681740775141803, 'learning_rate': 1.1534719494753821e-07, 'epoch': 0.95}
{'loss': 1.0014, 'grad_norm': 0.5731987090293542, 'learning_rate': 1.1346757659150498e-07, 'epoch': 0.96}
{'loss': 0.9824, 'grad_norm': 0.6256383837377146, 'learning_rate': 1.116033114031434e-07, 'epoch': 0.96}
{'loss': 0.9111, 'grad_norm': 0.7059032973747932, 'learning_rate': 1.0975440227753764e-07, 'epoch': 0.96}
{'loss': 1.0234, 'grad_norm': 0.6446888464416556, 'learning_rate': 1.0792085208593095e-07, 'epoch': 0.96}
{'loss': 0.9952, 'grad_norm': 0.6737967466183887, 'learning_rate': 1.061026636757101e-07, 'epoch': 0.96}
{'loss': 0.9621, 'grad_norm': 0.5632413866457605, 'learning_rate': 1.0429983987041092e-07, 'epoch': 0.96}
{'loss': 0.9753, 'grad_norm': 0.8035097982354942, 'learning_rate': 1.0251238346970393e-07, 'epoch': 0.96}
{'loss': 0.9304, 'grad_norm': 0.6041852099188637, 'learning_rate': 1.007402972493976e-07, 'epoch': 0.96}
{'loss': 0.9544, 'grad_norm': 0.6655787120697733, 'learning_rate': 9.898358396143171e-08, 'epoch': 0.96}
{'loss': 0.9727, 'grad_norm': 0.6590614327153931, 'learning_rate': 9.72422463338718e-08, 'epoch': 0.96}
{'loss': 1.0056, 'grad_norm': 0.6205945512310779, 'learning_rate': 9.55162870709081e-08, 'epoch': 0.96}
{'loss': 0.9915, 'grad_norm': 0.5618995382069222, 'learning_rate': 9.380570885284546e-08, 'epoch': 0.96}
{'loss': 0.9254, 'grad_norm': 0.6725967123524936, 'learning_rate': 9.211051433610674e-08, 'epoch': 0.96}
{'loss': 1.0017, 'grad_norm': 0.6440493410279007, 'learning_rate': 9.04307061532217e-08, 'epoch': 0.96}
{'loss': 0.9574, 'grad_norm': 0.6451820520454731, 'learning_rate': 8.876628691282918e-08, 'epoch': 0.96}
{'loss': 0.9828, 'grad_norm': 0.6445021689801699, 'learning_rate': 8.711725919966718e-08, 'epoch': 0.96}
{'loss': 0.9069, 'grad_norm': 0.6239418563082679, 'learning_rate': 8.54836255745728e-08, 'epoch': 0.96}
{'loss': 0.9768, 'grad_norm': 0.6704330552934749, 'learning_rate': 8.386538857447779e-08, 'epoch': 0.96}
{'loss': 0.9867, 'grad_norm': 0.6575275250070055, 'learning_rate': 8.226255071240308e-08, 'epoch': 0.96}
{'loss': 0.9873, 'grad_norm': 0.6270149814500665, 'learning_rate': 8.067511447745535e-08, 'epoch': 0.96}
{'loss': 0.9943, 'grad_norm': 0.770217898782451, 'learning_rate': 7.910308233482488e-08, 'epoch': 0.96}
{'loss': 0.975, 'grad_norm': 0.582691591716036, 'learning_rate': 7.754645672577776e-08, 'epoch': 0.96}
{'loss': 1.0151, 'grad_norm': 0.5507760833658486, 'learning_rate': 7.600524006765808e-08, 'epoch': 0.96}
{'loss': 0.9189, 'grad_norm': 0.6747833252467901, 'learning_rate': 7.447943475387797e-08, 'epoch': 0.96}
{'loss': 0.973, 'grad_norm': 0.6122837165078332, 'learning_rate': 7.296904315391873e-08, 'epoch': 0.96}
{'loss': 0.9382, 'grad_norm': 0.48074813862615634, 'learning_rate': 7.147406761332298e-08, 'epoch': 0.96}
{'loss': 0.9974, 'grad_norm': 0.6797984900931578, 'learning_rate': 6.999451045369587e-08, 'epoch': 0.97}
{'loss': 0.934, 'grad_norm': 0.568491423936571, 'learning_rate': 6.853037397269724e-08, 'epoch': 0.97}
{'loss': 0.9404, 'grad_norm': 0.5880019947985643, 'learning_rate': 6.70816604440383e-08, 'epoch': 0.97}
{'loss': 0.9544, 'grad_norm': 0.7561601151314108, 'learning_rate': 6.564837211748054e-08, 'epoch': 0.97}
{'loss': 0.997, 'grad_norm': 0.621596818001587, 'learning_rate': 6.42305112188335e-08, 'epoch': 0.97}
{'loss': 0.9976, 'grad_norm': 0.6217736822397611, 'learning_rate': 6.282807994994477e-08, 'epoch': 0.97}
{'loss': 1.011, 'grad_norm': 0.6033477124493667, 'learning_rate': 6.144108048870335e-08, 'epoch': 0.97}
{'loss': 0.9618, 'grad_norm': 0.5960870262034341, 'learning_rate': 6.00695149890329e-08, 'epoch': 0.97}
{'loss': 0.966, 'grad_norm': 0.5995449039486599, 'learning_rate': 5.871338558088857e-08, 'epoch': 0.97}
{'loss': 0.9932, 'grad_norm': 0.6159453392368457, 'learning_rate': 5.7372694370254614e-08, 'epoch': 0.97}
{'loss': 0.9991, 'grad_norm': 0.5879627639170395, 'learning_rate': 5.6047443439141146e-08, 'epoch': 0.97}
{'loss': 0.9832, 'grad_norm': 0.6082088454399697, 'learning_rate': 5.47376348455797e-08, 'epoch': 0.97}
{'loss': 0.9774, 'grad_norm': 0.5738842806524898, 'learning_rate': 5.344327062362098e-08, 'epoch': 0.97}
{'loss': 0.9542, 'grad_norm': 0.6605914545406864, 'learning_rate': 5.216435278333376e-08, 'epoch': 0.97}
{'loss': 1.0021, 'grad_norm': 0.6862938040837555, 'learning_rate': 5.0900883310794903e-08, 'epoch': 0.97}
{'loss': 0.978, 'grad_norm': 0.6022120194826467, 'learning_rate': 4.9652864168096e-08, 'epoch': 0.97}
{'loss': 1.015, 'grad_norm': 0.5608393377296821, 'learning_rate': 4.84202972933312e-08, 'epoch': 0.97}
{'loss': 1.0152, 'grad_norm': 0.8500988656677095, 'learning_rate': 4.720318460060047e-08, 'epoch': 0.97}
{'loss': 1.0008, 'grad_norm': 0.6262402300933849, 'learning_rate': 4.6001527980004125e-08, 'epoch': 0.97}
{'loss': 1.0024, 'grad_norm': 0.6235788394159845, 'learning_rate': 4.4815329297639434e-08, 'epoch': 0.97}
{'loss': 1.0044, 'grad_norm': 0.7310959266182194, 'learning_rate': 4.364459039559843e-08, 'epoch': 0.97}
{'loss': 0.9737, 'grad_norm': 0.6297907094058767, 'learning_rate': 4.248931309196791e-08, 'epoch': 0.97}
{'loss': 0.9613, 'grad_norm': 0.5242312377935885, 'learning_rate': 4.134949918081832e-08, 'epoch': 0.97}
{'loss': 0.9653, 'grad_norm': 0.7669895754261515, 'learning_rate': 4.022515043221154e-08, 'epoch': 0.97}
{'loss': 0.9975, 'grad_norm': 0.6415432141865423, 'learning_rate': 3.9116268592189755e-08, 'epoch': 0.97}
{'loss': 0.951, 'grad_norm': 0.66073396269602, 'learning_rate': 3.802285538277772e-08, 'epoch': 0.97}
{'loss': 1.0079, 'grad_norm': 0.6214215449968047, 'learning_rate': 3.69449125019794e-08, 'epoch': 0.98}
{'loss': 0.9923, 'grad_norm': 0.6444792481552521, 'learning_rate': 3.588244162377019e-08, 'epoch': 0.98}
{'loss': 0.9706, 'grad_norm': 0.6284627312234267, 'learning_rate': 3.483544439810249e-08, 'epoch': 0.98}
{'loss': 0.9823, 'grad_norm': 0.6463861735450702, 'learning_rate': 3.3803922450897917e-08, 'epoch': 0.98}
{'loss': 0.9752, 'grad_norm': 0.6857250021051735, 'learning_rate': 3.2787877384045095e-08, 'epoch': 0.98}
{'loss': 1.0277, 'grad_norm': 0.6374061187992036, 'learning_rate': 3.178731077539743e-08, 'epoch': 0.98}
{'loss': 1.0099, 'grad_norm': 0.8403157161239463, 'learning_rate': 3.080222417877421e-08, 'epoch': 0.98}
{'loss': 0.9198, 'grad_norm': 0.5743806454652994, 'learning_rate': 2.983261912395397e-08, 'epoch': 0.98}
{'loss': 1.0006, 'grad_norm': 0.6365024145525336, 'learning_rate': 2.8878497116671124e-08, 'epoch': 0.98}
{'loss': 0.999, 'grad_norm': 0.5828566198196163, 'learning_rate': 2.7939859638617118e-08, 'epoch': 0.98}
{'loss': 0.998, 'grad_norm': 0.5923620743503124, 'learning_rate': 2.7016708147439285e-08, 'epoch': 0.98}
{'loss': 0.9754, 'grad_norm': 0.6178781038785746, 'learning_rate': 2.6109044076733092e-08, 'epoch': 0.98}
{'loss': 0.9995, 'grad_norm': 0.5742920862031949, 'learning_rate': 2.5216868836043242e-08, 'epoch': 0.98}
{'loss': 0.9838, 'grad_norm': 0.6339382166479693, 'learning_rate': 2.434018381086589e-08, 'epoch': 0.98}
{'loss': 0.9833, 'grad_norm': 0.6138290721143168, 'learning_rate': 2.3478990362634235e-08, 'epoch': 0.98}
{'loss': 0.9839, 'grad_norm': 0.6521608667249519, 'learning_rate': 2.263328982872959e-08, 'epoch': 0.98}
{'loss': 0.9826, 'grad_norm': 0.5967609687117522, 'learning_rate': 2.1803083522471402e-08, 'epoch': 0.98}
{'loss': 0.9514, 'grad_norm': 0.5956885846601488, 'learning_rate': 2.098837273311838e-08, 'epoch': 0.98}
WARNING: tokenization mismatch: 0 vs. 1666. (ignored)
number of rounds:  2
rounds:  ["A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are an innovative tax advisory firm with the following knowledge and traits.\n\nKNOWLEDGE: Tax advisor, junior tax advisor, senior tax advisor, financial strategist, tax regulations.\n\nTRAITS: Empathy, innovation, solution orientation, professionalism, communication, client focus.\n\nTASK: Use your knowledge to develop an internal strategy document. We are a tax advisory firm looking to identify 10 creative ways to improve client satisfaction and loyalty. Focus on ideas that are tailored to the needs of tax advisors and enhance the overall client experience.\n\nOUTPUT: A table in German containing 10 creative strategies to improve client satisfaction and loyalty for a tax advisory firm, including a brief description for each. ASSISTANT: Tabelle: 10 kreative Strategien zur Steigerung der Kundenzufriedenheit und -loyalitt in einer Steuerberatungskanzlei\n\n| Nr. | Strategie | Beschreibung |\n| --- | --- | --- |\n| 1 | Personalisierter Service | Jeder Kunde erhlt einen dedizierten Steuerberater, der auf seine individuellen Bedrfnisse und Anliegen eingeht. |\n| 2 | Proaktive Steuerplanung | Regelmige Updates und Empfehlungen zur Steueroptimierung, basierend auf aktuellen Gesetzesnderungen und Kundenzielen. |\n| 3 | Umfassende Schulungsangebote | Kostenlose Workshops und Webinare, um das Steuerwissen der Kunden zu erweitern und den Umgang mit Steuerthemen zu erleichtern. |\n| 4 | Digitale Plattform | Eine benutzerfreundliche Online-Plattform, die den Kunden den Zugriff auf ihre Steuerdokumente und den Kontakt zum Berater erleichtert. |\n| 5 | Einfhrung von Steuer-Coaching | Persnliche Coaching-Sitzungen, um den Kunden dabei zu untersttzen, ihre steuerlichen Ziele und Mglichkeiten besser zu verstehen. |\n| 6 | Schnelle Reaktionszeiten | Verbindliches Versprechen, innerhalb von 24 Stunden auf Kundenanfragen zu reagieren, um eine effiziente Kommunikation zu gewhrleisten. |\n| 7 | Transparente Preisgestaltung | Klare und faire Preisstrukturen, die den Kunden im Voraus bekannt sind, um bse berraschungen zu vermeiden. |\n| 8 | Individuelle Jahresgesprche | Regelmige persnliche Jahresgesprche, um auf die Bedrfnisse und Ziele der Kunden einzugehen und die Zusammenarbeit zu strken. |\n| 9 | Kunden-Feedback-System | Einrichtung eines einfachen Feedback-Systems, um Kundenmeinungen und Verbesserungsvorschlge aktiv einzuholen und umzusetzen. |\n| 10 | Steuer-Newsletter und Informationsangebot | Monatlicher Newsletter mit aktuellen Steuerinformationen und Tipps, der den Kunden einen Mehrwert bietet und sie auf dem Laufenden hlt. |", 'USER: Bitte etwas kreativer und auf bezugnehmend auf die zwischenmenschliche Ebene. ASSISTANT: Tabelle: 10 kreative Strategien zur Steigerung der Kundenzufriedenheit und -loyalitt in einer Steuerberatungskanzlei mit Fokus auf zwischenmenschlicher Ebene\n\n| Nr. | Strategie | Beschreibung |\n| --- | --- | --- |\n| 1 | Kunden-Events | Organisation von regelmigen, informellen Veranstaltungen, um den persnlichen Kontakt zwischen Klienten und Beratern zu frdern. |\n| 2 | Persnliche Geburtstagsgre | Individuelle Geburtstagskarten oder -nachrichten fr jeden Kunden, um Wertschtzung zu zeigen und Beziehungen zu strken. |\n| 3 | Kundenbefragung & Anpassung | Aktives Einholen von Kundenmeinungen zur individuellen Betreuung und Anpassung unserer Leistungen entsprechend der Kundenbedrfnisse. |\n| 4 | Teamvorstellung & Empathie | Vorstellung unserer Berater auf der Firmenwebsite und in sozialen Medien, um eine persnliche und empathische Beziehung zum Kunden aufzubauen. |\n| 5 | Kunden-Mentoring-Programm | Schaffung eines Programms, bei dem langjhrige Kunden als Mentoren fr Neukunden fungieren, um Vertrauen und Loyalitt zu frdern. |\n| 6 | "Tag der offenen Tr" | Einladung der Kunden zu einem "Tag der offenen Tr" in unserer Kanzlei, um ihnen einen persnlichen Einblick in unsere Arbeitsweise zu geben. |\n| 7 | Individuelle Erfolgsgeschichten | Erstellung von individuellen Erfolgsgeschichten fr jeden Kunden, um ihre steuerlichen Erfolge hervorzuheben und ihre Loyalitt zu strken. |\n| 8 | Gemeinsame soziale Projekte | Zusammenarbeit mit Kunden an sozialen Projekten und Spendenaktionen, um gemeinsame Werte zu teilen und die Zusammenarbeit zu frdern. |\n| 9 | Flexibilitt in der Kommunikation | Anbieten verschiedener Kommunikationswege (Telefon, E-Mail, Videoanruf, etc.), um auf die individuellen Bedrfnisse der Kunden einzugehen. |\n| 10 | Jhrliches Kunden-Dankeschn | berraschung der Kunden mit einer kleinen Aufmerksamkeit oder einem Dankeschn-Event, um die Wertschtzung fr ihre Treue auszudrcken. |']
prompt:  A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT: You are an innovative tax advisory firm with the following knowledge and traits.

KNOWLEDGE: Tax advisor, junior tax advisor, senior tax advisor, financial strategist, tax regulations.

TRAITS: Empathy, innovation, solution orientation, professionalism, communication, client focus.

TASK: Use your knowledge to develop an internal strategy document. We are a tax advisory firm looking to identify 10 creative ways to improve client satisfaction and loyalty. Focus on ideas that are tailored to the needs of tax advisors and enhance the overall client experience.

OUTPUT: A table in German containing 10 creative strategies to improve client satisfaction and loyalty for a tax advisory firm, including a brief description for each. ASSISTANT: Tabelle: 10 kreative Strategien zur Steigerung der Kundenzufriedenheit und -loyalitt in einer Steuerberatungskanzlei

| Nr. | Strategie | Beschreibung |
| --- | --- | --- |
| 1 | Personalisierter Service | Jeder Kunde erhlt einen dedizierten Steuerberater, der auf seine individuellen Bedrfnisse und Anliegen eingeht. |
| 2 | Proaktive Steuerplanung | Regelmige Updates und Empfehlungen zur Steueroptimierung, basierend auf aktuellen Gesetzesnderungen und Kundenzielen. |
| 3 | Umfassende Schulungsangebote | Kostenlose Workshops und Webinare, um das Steuerwissen der Kunden zu erweitern und den Umgang mit Steuerthemen zu erleichtern. |
| 4 | Digitale Plattform | Eine benutzerfreundliche Online-Plattform, die den Kunden den Zugriff auf ihre Steuerdokumente und den Kontakt zum Berater erleichtert. |
| 5 | Einfhrung von Steuer-Coaching | Persnliche Coaching-Sitzungen, um den Kunden dabei zu untersttzen, ihre steuerlichen Ziele und Mglichkeiten besser zu verstehen. |
| 6 | Schnelle Reaktionszeiten | Verbindliches Versprechen, innerhalb von 24 Stunden auf Kundenanfragen zu reagieren, um eine effiziente Kommunikation zu gewhrleisten. |
| 7 | Transparente Preisgestaltung | Klare und faire Preisstrukturen, die den Kunden im Voraus bekannt sind, um bse berraschungen zu vermeiden. |
| 8 | Individuelle Jahresgesprche | Regelmige persnliche Jahresgesprche, um auf die Bedrfnisse und Ziele der Kunden einzugehen und die Zusammenarbeit zu strken. |
| 9 | Kunden-Feedback-System | Einrichtung eines einfachen Feedback-Systems, um Kundenmeinungen und Verbesserungsvorschlge aktiv einzuholen und umzusetzen. |
| 10 | Steuer-Newsletter und Informationsangebot | Monatlicher Newsletter mit aktuellen Steuerinformationen und Tipps, der den Kunden einen Mehrwert bietet und sie auf dem Laufenden hlt. |<|endoftext|>USER: Bitte etwas kreativer und auf bezugnehmend auf die zwischenmenschliche Ebene. ASSISTANT: Tabelle: 10 kreative Strategien zur Steigerung der Kundenzufriedenheit und -loyalitt in einer Steuerberatungskanzlei mit Fokus auf zwischenmenschlicher Ebene

| Nr. | Strategie | Beschreibung |
| --- | --- | --- |
| 1 | Kunden-Events | Organisation von regelmigen, informellen Veranstaltungen, um den persnlichen Kontakt zwischen Klienten und Beratern zu frdern. |
| 2 | Persnliche Geburtstagsgre | Individuelle Geburtstagskarten oder -nachrichten fr jeden Kunden, um Wertschtzung zu zeigen und Beziehungen zu strken. |
| 3 | Kundenbefragung & Anpassung | Aktives Einholen von Kundenmeinungen zur individuellen Betreuung und Anpassung unserer Leistungen entsprechend der Kundenbedrfnisse. |
| 4 | Teamvorstellung & Empathie | Vorstellung unserer Berater auf der Firmenwebsite und in sozialen Medien, um eine persnliche und empathische Beziehung zum Kunden aufzubauen. |
| 5 | Kunden-Mentoring-Programm | Schaffung eines Programms, bei dem langjhrige Kunden als Mentoren fr Neukunden fungieren, um Vertrauen und Loyalitt zu frdern. |
| 6 | "Tag der offenen Tr" | Einladung der Kunden zu einem "Tag der offenen Tr" in unserer Kanzlei, um ihnen einen persnlichen Einblick in unsere Arbeitsweise zu geben. |
| 7 | Individuelle Erfolgsgeschichten | Erstellung von individuellen Erfolgsgeschichten fr jeden Kunden, um ihre steuerlichen Erfolge hervorzuheben und ihre Loyalitt zu strken. |
| 8 | Gemeinsame soziale Projekte | Zusammenarbeit mit Kunden an sozialen Projekten und Spendenaktionen, um gemeinsame Werte zu teilen und die Zusammenarbeit zu frdern. |
| 9 | Flexibilitt in der Kommunikation | Anbieten verschiedener Kommunikationswege (Telefon, E-Mail, Videoanruf, etc.), um auf die individuellen Bedrfnisse der Kunden einzugehen. |
| 10 | Jhrliches Kunden-Dankeschn | berraschung der Kunden mit einer kleinen Aufmerksamkeit oder einem Dankeschn-Event, um die Wertschtzung fr ihre Treue auszudrcken. |<|endoftext|>
tensor([-100, -100, -100,  ..., -100, -100, -100])
tensor([   32,  8537,  1022,  ...,    13,   930, 50256])
{'loss': 1.0132, 'grad_norm': 0.6522705381164952, 'learning_rate': 2.0189158725867353e-08, 'epoch': 0.98}
{'loss': 0.995, 'grad_norm': 0.7431060670296993, 'learning_rate': 1.9405442741844415e-08, 'epoch': 0.98}
{'loss': 0.9755, 'grad_norm': 0.6133002083359835, 'learning_rate': 1.8637225998114904e-08, 'epoch': 0.98}
{'loss': 0.9302, 'grad_norm': 0.5938921465487, 'learning_rate': 1.7884509687668972e-08, 'epoch': 0.98}
{'loss': 0.9615, 'grad_norm': 0.46291429444872867, 'learning_rate': 1.714729497942935e-08, 'epoch': 0.98}
{'loss': 0.9471, 'grad_norm': 0.5388808443154901, 'learning_rate': 1.6425583018244706e-08, 'epoch': 0.98}
{'loss': 0.9613, 'grad_norm': 0.7396218621857781, 'learning_rate': 1.57193749248874e-08, 'epoch': 0.98}
{'loss': 0.9952, 'grad_norm': 0.7701535048844813, 'learning_rate': 1.5028671796055715e-08, 'epoch': 0.98}
{'loss': 0.9998, 'grad_norm': 0.6766770026388146, 'learning_rate': 1.435347470436832e-08, 'epoch': 0.99}
{'loss': 0.9677, 'grad_norm': 0.6063655687030977, 'learning_rate': 1.3693784698363133e-08, 'epoch': 0.99}
{'loss': 0.9535, 'grad_norm': 0.6488244226946905, 'learning_rate': 1.3049602802498451e-08, 'epoch': 0.99}
{'loss': 0.9919, 'grad_norm': 0.6149741098232451, 'learning_rate': 1.2420930017148503e-08, 'epoch': 0.99}
{'loss': 0.9517, 'grad_norm': 0.665240946021197, 'learning_rate': 1.1807767318602337e-08, 'epoch': 0.99}
{'loss': 1.0018, 'grad_norm': 0.6672894839558483, 'learning_rate': 1.1210115659063825e-08, 'epoch': 0.99}
{'loss': 0.9802, 'grad_norm': 0.6220953407324353, 'learning_rate': 1.0627975966649439e-08, 'epoch': 0.99}
{'loss': 0.951, 'grad_norm': 0.5714924871871458, 'learning_rate': 1.0061349145383814e-08, 'epoch': 0.99}
{'loss': 0.9755, 'grad_norm': 0.569053069943293, 'learning_rate': 9.510236075205292e-09, 'epoch': 0.99}
{'loss': 0.9925, 'grad_norm': 0.6683734648155272, 'learning_rate': 8.974637611955939e-09, 'epoch': 0.99}
{'loss': 0.9949, 'grad_norm': 0.7231474777924864, 'learning_rate': 8.454554587388198e-09, 'epoch': 0.99}
{'loss': 0.9464, 'grad_norm': 0.6971197599338874, 'learning_rate': 7.949987809158232e-09, 'epoch': 0.99}
{'loss': 1.0036, 'grad_norm': 0.610939720045454, 'learning_rate': 7.460938060825929e-09, 'epoch': 0.99}
{'loss': 0.995, 'grad_norm': 0.5958667971879353, 'learning_rate': 6.987406101855998e-09, 'epoch': 0.99}
{'loss': 0.982, 'grad_norm': 0.6738062630603875, 'learning_rate': 6.5293926676135434e-09, 'epoch': 0.99}
{'loss': 0.9396, 'grad_norm': 0.5095517651019821, 'learning_rate': 6.086898469365166e-09, 'epoch': 0.99}
{'loss': 0.9912, 'grad_norm': 0.5677104029578375, 'learning_rate': 5.6599241942767445e-09, 'epoch': 0.99}
{'loss': 0.9593, 'grad_norm': 0.6452799524775139, 'learning_rate': 5.248470505412328e-09, 'epoch': 0.99}
{'loss': 0.9284, 'grad_norm': 0.7166114307789013, 'learning_rate': 4.8525380417330234e-09, 'epoch': 0.99}
{'loss': 0.9906, 'grad_norm': 0.5717196761835813, 'learning_rate': 4.472127418099215e-09, 'epoch': 0.99}
{'loss': 0.9576, 'grad_norm': 0.47014176746488445, 'learning_rate': 4.1072392252639034e-09, 'epoch': 0.99}
{'loss': 1.0219, 'grad_norm': 0.6139631178058887, 'learning_rate': 3.757874029874931e-09, 'epoch': 0.99}
{'loss': 0.9712, 'grad_norm': 0.6480154772186278, 'learning_rate': 3.424032374476083e-09, 'epoch': 0.99}
{'loss': 0.921, 'grad_norm': 0.6039399949509022, 'learning_rate': 3.105714777501545e-09, 'epoch': 0.99}
{'loss': 0.9701, 'grad_norm': 0.7090553274825967, 'learning_rate': 2.802921733278119e-09, 'epoch': 0.99}
{'loss': 0.9078, 'grad_norm': 0.7355887570402256, 'learning_rate': 2.5156537120263335e-09, 'epoch': 0.99}
{'loss': 0.9612, 'grad_norm': 0.6467718733241309, 'learning_rate': 2.2439111598537844e-09, 'epoch': 1.0}
{'loss': 0.987, 'grad_norm': 0.6164593792343896, 'learning_rate': 1.987694498760684e-09, 'epoch': 1.0}
Error processing image: Neither .jpg nor .gif file found for ocr_vqa/images/1743790104.jpg, using default black image.
{'loss': 0.9794, 'grad_norm': 0.624906695385421, 'learning_rate': 1.747004126635421e-09, 'epoch': 1.0}
{'loss': 0.9837, 'grad_norm': 0.593435136403605, 'learning_rate': 1.5218404172545609e-09, 'epoch': 1.0}
{'loss': 0.9997, 'grad_norm': 0.5828996602141916, 'learning_rate': 1.3122037202828452e-09, 'epoch': 1.0}
{'loss': 0.9519, 'grad_norm': 0.5075520579076009, 'learning_rate': 1.1180943612754124e-09, 'epoch': 1.0}
{'loss': 1.0171, 'grad_norm': 0.5773332771810394, 'learning_rate': 9.39512641668916e-10, 'epoch': 1.0}
{'loss': 0.9871, 'grad_norm': 0.6124123579407863, 'learning_rate': 7.764588387915161e-10, 'epoch': 1.0}
{'loss': 0.9956, 'grad_norm': 0.5931288928728178, 'learning_rate': 6.289332058551089e-10, 'epoch': 1.0}
{'loss': 0.9588, 'grad_norm': 0.5711274204252006, 'learning_rate': 4.969359719586563e-10, 'epoch': 1.0}
{'loss': 0.9468, 'grad_norm': 0.6223440253262038, 'learning_rate': 3.804673420837457e-10, 'epoch': 1.0}
{'loss': 0.9879, 'grad_norm': 0.6933284221891803, 'learning_rate': 2.795274971001405e-10, 'epoch': 1.0}
{'loss': 0.9959, 'grad_norm': 0.6581498304915055, 'learning_rate': 1.941165937602296e-10, 'epoch': 1.0}
2024-09-30 04:14:55,801 | INFO: saving checkpoint ...
{'train_runtime': 65517.9094, 'train_samples_per_second': 10.154, 'train_steps_per_second': 0.04, 'train_loss': 1.0275548887555532, 'epoch': 1.0}
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-7l9hc9mi[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-2l97n6ym[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-7xsipoc3[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-w1m5feme[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-2l97n6ym/logs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-7xsipoc3/logs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-w1m5feme/logs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-7l9hc9mi/logs[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-ivhw2gjk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-ivhw2gjk/logs[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-ry635sxo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-ry635sxo/logs[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-zvjbg821[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-zvjbg821/logs[0m
[1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/wandb/offline-run-20240929_095905-fd4vhmk3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20240929_095905-fd4vhmk3/logs[0m
[2024-09-30 04:15:37,851] [INFO] [launch.py:351:main] Process 2001411 exits successfully.
[2024-09-30 04:15:38,854] [INFO] [launch.py:351:main] Process 2001412 exits successfully.
[2024-09-30 04:15:38,855] [INFO] [launch.py:351:main] Process 2001415 exits successfully.
[2024-09-30 04:15:38,855] [INFO] [launch.py:351:main] Process 2001413 exits successfully.
[2024-09-30 04:15:38,855] [INFO] [launch.py:351:main] Process 2001417 exits successfully.
[2024-09-30 04:15:38,856] [INFO] [launch.py:351:main] Process 2001414 exits successfully.
[2024-09-30 04:15:38,856] [INFO] [launch.py:351:main] Process 2001416 exits successfully.
[2024-09-30 04:15:42,861] [INFO] [launch.py:351:main] Process 2001410 exits successfully.
=== JOB_STATISTICS ===
=== current date     : Mon Sep 30 04:15:45 CEST 2024
= Job-ID             : 2073121 on alex
= Job-Name           : finetune_phi_new
= Job-Command        : /home/hpc/b211dd/b211dd20/compression/tinyllava_framework/scripts/train/train_phi_new.slurm
= Initial workdir    : /home/hpc/b211dd/b211dd20/compression/tinyllava_framework
= Queue/Partition    : a100
= Slurm account      : b211dd with QOS=normal
= Features           : a100_80
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 18:19:06
= Total RAM usage    : 142.6 GiB of assigned  GiB (%)
= Node list          : a0632
= Subm/Elig/Start/End: 2024-09-29T09:56:36 / 2024-09-29T09:56:36 / 2024-09-29T09:56:39 / 2024-09-30T04:15:45
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           34.8G   104.9G   209.7G        N/A      61K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-80GB, 00000000:0E:00.0, 2001410, 57 %, 14 %, 77368 MiB, 65822647 ms
NVIDIA A100-SXM4-80GB, 00000000:13:00.0, 2001411, 58 %, 13 %, 79444 MiB, 65811797 ms
NVIDIA A100-SXM4-80GB, 00000000:49:00.0, 2001412, 58 %, 12 %, 80782 MiB, 65811975 ms
NVIDIA A100-SXM4-80GB, 00000000:4F:00.0, 2001413, 56 %, 12 %, 76946 MiB, 65812469 ms
NVIDIA A100-SXM4-80GB, 00000000:90:00.0, 2001414, 56 %, 12 %, 77248 MiB, 65812641 ms
NVIDIA A100-SXM4-80GB, 00000000:96:00.0, 2001415, 55 %, 12 %, 54594 MiB, 65818786 ms
NVIDIA A100-SXM4-80GB, 00000000:CC:00.0, 2001416, 58 %, 12 %, 64338 MiB, 65818492 ms
NVIDIA A100-SXM4-80GB, 00000000:D1:00.0, 2001417, 59 %, 12 %, 67048 MiB, 65818056 ms
